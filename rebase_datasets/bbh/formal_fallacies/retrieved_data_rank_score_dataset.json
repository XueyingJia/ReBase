[
    [
        0.424939289689064,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '935'}",
        "It is impossible that Brian is a lion. It is probable that Bill went to the kitchen. It is unlikely that Lily is a swan. It is probably the case that if 'Bill went to the kitchen and Lily is a swan' then Sandra got the milk. Chances are slight that if 'Bill went to the kitchen' or 'Brian is a lion' or both then Daniel took the apple. There is a better than even chance that if either 'Bill went to the kitchen' or 'Lily is a swan' but not both then Greg is a frog.",
        "valid"
    ],
    [
        0.4241205304861069,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '878'}",
        "It is impossible that either 'Brian is a frog' or 'Greg is a lion' but not both.",
        "valid"
    ],
    [
        0.4231732835372289,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '316'}",
        "We believe that Lily is a frog. It is certain that Greg is a swan. It is unlikely that Daniel grabbed the milk. We doubt that if 'Lily is a frog' or 'Daniel grabbed the milk' or both then Bernhard is green. It is impossible that if either 'Lily is a frog' or 'Greg is a swan' but not both then John went to the kitchen. It is impossible that if either 'Daniel grabbed the milk' or 'Lily is a frog' but not both then Mary left the apple.",
        "valid"
    ],
    [
        0.4227750053008397,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '693'}",
        "It is impossible that Lily is a rhino. It is probably the case that Bernhard is a frog. It is impossible that Daniel took the milk. There is little chance that if 'Daniel took the milk and Lily is a rhino' then Mary left the apple. It is highly unlikely that if either 'Lily is a rhino' or 'Bernhard is a frog' but not both then Greg is yellow. There is a better than even chance that if 'Daniel took the milk' or 'Bernhard is a frog' or both then John moved to the office.",
        "valid"
    ],
    [
        0.4226397822300593,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '649'}",
        "There is little chance that Lily is a lion. It is probably not the case that Brian is white. It is probable that Julius is a frog. It is improbable that if either 'Brian is white' or 'Lily is a lion' but not both then Mary went to the hallway. It is certain that if 'Brian is white' or 'Lily is a lion' or both then Sandra grabbed the milk. It is highly likely that if either 'Julius is a frog' or 'Brian is white' but not both then John left the football.",
        "valid"
    ],
    [
        0.42223499715328217,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '90'}",
        "It is probable that Brian is a frog. It is impossible that Mary picked up the milk. There is a very good chance that Greg is a rhino. We doubt that if either 'Mary picked up the milk' or 'Greg is a rhino' but not both then Julius is yellow. It is probably the case that if 'Greg is a rhino' or 'Brian is a frog' or both then Jason is tired. Chances are slight that if 'Mary picked up the milk' or 'Brian is a frog' or both then Lily is a swan.",
        "valid"
    ],
    [
        0.42212363580862683,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '854'}",
        "There is almost no chance that 'Lily is a frog' or 'Brian is a lion' or both.",
        "valid"
    ],
    [
        0.42054931819438934,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '27'}",
        "It is improbable that Brian is a rhino. It is impossible that Lily is a swan. Chances are slight that John left the football. There is almost no chance that if 'John left the football and Brian is a rhino' then Jessica is a cat. It is improbable that if 'Lily is a swan' or 'John left the football' or both then Julius is a frog. There is little chance that if either 'John left the football' or 'Lily is a swan' but not both then Emily is a wolf.",
        "valid"
    ],
    [
        0.4182121306657791,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '251'}",
        "There is a better than even chance that Brian is a lion. There is a very good chance that Greg is gray. It is likely that Julius is a frog. We doubt that if 'Julius is a frog' or 'Brian is a lion' or both then Bill went to the kitchen. Chances are slight that if 'Brian is a lion' or 'Julius is a frog' or both then Lily is white. It is highly likely that if either 'Julius is a frog' or 'Brian is a lion' but not both then John discarded the apple.",
        "valid"
    ],
    [
        0.41813836991786957,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '124'}",
        "There is a very good chance that Greg is gray. We doubt that Julius is a swan. It is impossible that Winona is a sheep. It is almost certain that if 'Greg is gray and Julius is a swan' then Lily is a frog. We doubt that if 'Winona is a sheep' or 'Julius is a swan' or both then Brian is a rhino. Chances are about even that if 'Winona is a sheep and Greg is gray' then John picked up the apple.",
        "valid"
    ],
    [
        0.4178820699453354,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '461'}",
        "It is improbable that Greg is a lion. We believe that Brian is a swan. There is a better than even chance that Mary went to the garden. Chances are slight that if either 'Greg is a lion' or 'Brian is a swan' but not both then Bernhard is a frog. It is probable that if 'Mary went to the garden and Greg is a lion' then Lily is a rhino. Chances are about even that if either 'Greg is a lion' or 'Brian is a swan' but not both then John left the apple.",
        "valid"
    ],
    [
        0.4178305466969808,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '354'}",
        "\"В Самарской губернии редкий двор не имеет своего мыла, но вот беда: без канифоли, которая идет в мыло, обойтись можно, без соды же сварить мыла нельзя.\"",
        "correct"
    ],
    [
        0.41769610345363617,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '949'}",
        "It is probably not the case that John picked up the apple. It is unlikely that Brian is a rhino. It is likely that Greg is a lion. There is a very good chance that if either 'Greg is a lion' or 'Brian is a rhino' but not both then Sandra got the football. We doubt that if 'John picked up the apple and Greg is a lion' then Lily is a swan. It is impossible that if 'John picked up the apple and Greg is a lion' then Julius is gray.",
        "valid"
    ],
    [
        0.41759492456912994,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '852'}",
        "It is improbable that Brian is a lion. There is almost no chance that Julius is white. It is probably not the case that Mary got the milk. Chances are slight that if 'Brian is a lion' or 'Mary got the milk' or both then Antoine is hungry. Chances are slight that if 'Brian is a lion and Mary got the milk' then Lily is a frog. It is certain that if 'Julius is white and Mary got the milk' then John moved to the office.",
        "valid"
    ],
    [
        0.41718730827172595,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '866'}",
        "It is impossible that Bernhard is a lion. It is probably not the case that John took the apple. We believe that Julius is a rhino. There is a very good chance that if 'Julius is a rhino and Bernhard is a lion' then Emily is a mouse. There is a better than even chance that if 'Bernhard is a lion' or 'Julius is a rhino' or both then Lily is white. It is likely that if 'John took the apple' or 'Bernhard is a lion' or both then Mary left the football.",
        "valid"
    ],
    [
        0.41702669362227124,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '637'}",
        "It is unlikely that Lily is a lion. It is almost certain that Daniel put down the milk. Chances are slight that Mary picked up the apple. It is unlikely that if either 'Mary picked up the apple' or 'Daniel put down the milk' but not both then Fred is in the office. It is probable that if 'Daniel put down the milk' or 'Lily is a lion' or both then Bernhard is gray. It is impossible that if either 'Mary picked up the apple' or 'Lily is a lion' but not both then Emily is a wolf.",
        "valid"
    ],
    [
        0.4160888542731603,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '988'}",
        "There is almost no chance that Greg is a rhino. There is a better than even chance that Winona is a wolf. It is unlikely that Bernhard is a lion. There is almost no chance that if either 'Greg is a rhino' or 'Winona is a wolf' but not both then Mary left the football. It is probably not the case that if 'Bernhard is a lion' or 'Greg is a rhino' or both then John put down the apple. We doubt that if 'Bernhard is a lion' or 'Greg is a rhino' or both then Lily is yellow.",
        "valid"
    ],
    [
        0.41584328313668567,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '858'}",
        "Chances are about even that Lily is a swan. It is probable that Yann is hungry. It is likely that Brian is white. It is probably not the case that if 'Yann is hungry' or 'Brian is white' or both then Winona is a sheep. It is impossible that if 'Yann is hungry and Lily is a swan' then Mary moved to the office. We believe that if 'Lily is a swan' or 'Brian is white' or both then Greg is a frog.",
        "valid"
    ],
    [
        0.41583257416884106,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '237'}",
        "Chances are slight that Julius is a rhino. There is a very good chance that Mary dropped the milk. It is probably not the case that Lily is a lion. There is little chance that if 'Mary dropped the milk and Lily is a lion' then Brian is gray. It is impossible that if either 'Lily is a lion' or 'Julius is a rhino' but not both then Daniel took the apple. It is probably not the case that if either 'Julius is a rhino' or 'Mary dropped the milk' but not both then John went to the kitchen.",
        "valid"
    ],
    [
        0.4157269249359767,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '814'}",
        "There is a very good chance that either 'Brian is a frog' or 'Lily is a swan' but not both.",
        "valid"
    ],
    [
        0.4156610320011775,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '325'}",
        "It is probably not the case that Brian is a frog. It is probably not the case that Jeff put down the milk. It is certain that Bernhard is a rhino. It is probably not the case that if 'Brian is a frog' or 'Jeff put down the milk' or both then Jessica is a cat. It is impossible that if either 'Bernhard is a rhino' or 'Brian is a frog' but not both then Julius is yellow. We doubt that if 'Brian is a frog' or 'Jeff put down the milk' or both then Mary went to the kitchen.",
        "valid"
    ],
    [
        0.4156361172596614,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '169'}",
        "It is almost certain that Jessica is a sheep. It is certain that Brian is a lion. We believe that John got the apple. There is almost no chance that if either 'John got the apple' or 'Brian is a lion' but not both then Mary picked up the milk. Chances are about even that if 'John got the apple and Jessica is a sheep' then Lily is yellow. It is probably not the case that if either 'John got the apple' or 'Jessica is a sheep' but not both then Yann is tired.",
        "valid"
    ],
    [
        0.41517787675062817,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '256'}",
        "We believe that Emily is a mouse. Chances are slight that Lily is a rhino. It is highly unlikely that Julius is a frog. We believe that if 'Emily is a mouse' or 'Lily is a rhino' or both then Daniel left the milk. There is little chance that if either 'Emily is a mouse' or 'Lily is a rhino' but not both then Bernhard is a swan. There is almost no chance that if 'Lily is a rhino' or 'Julius is a frog' or both then Brian is green.",
        "valid"
    ],
    [
        0.41505790253480274,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '824'}",
        "It is impossible that Julius is a rhino. It is probably not the case that Winona is a mouse. It is probable that Mary left the football. Chances are about even that if 'Mary left the football' or 'Winona is a mouse' or both then Bernhard is white. It is almost certain that if either 'Mary left the football' or 'Winona is a mouse' but not both then Greg is a frog. Chances are about even that if either 'Julius is a rhino' or 'Winona is a mouse' but not both then Sandra grabbed the milk.",
        "valid"
    ],
    [
        0.41492704053719837,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '164'}",
        "It is probably the case that John discarded the apple. It is probably the case that Mary dropped the milk. We doubt that Brian is a lion. It is unlikely that if 'John discarded the apple' or 'Mary dropped the milk' or both then Daniel put down the milk. It is certain that if either 'Brian is a lion' or 'John discarded the apple' but not both then Lily is white. There is almost no chance that if either 'Brian is a lion' or 'John discarded the apple' but not both then Bill left the football.",
        "valid"
    ],
    [
        0.4148001621166865,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '435'}",
        "There is a better than even chance that Winona is a mouse. It is impossible that Bernhard is a frog. There is almost no chance that Jason is thirsty. It is unlikely that if either 'Bernhard is a frog' or 'Winona is a mouse' but not both then Julius is a lion. There is little chance that if either 'Winona is a mouse' or 'Bernhard is a frog' but not both then Greg is yellow. It is unlikely that if 'Jason is thirsty' or 'Winona is a mouse' or both then Mary went to the garden.",
        "valid"
    ],
    [
        0.4144577334324519,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '314'}",
        "It is almost certain that Brian is a frog. It is almost certain that Bernhard is a lion. Chances are slight that Greg is a frog. It is likely that if either 'Bernhard is a lion' or 'Greg is a frog' but not both then John dropped the apple. There is almost no chance that if 'Bernhard is a lion' or 'Brian is a frog' or both then Fred went to the office. There is a very good chance that if 'Bernhard is a lion' or 'Brian is a frog' or both then Sandra took the milk.",
        "valid"
    ],
    [
        0.4144342889388402,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '103'}",
        "It is impossible that 'Brian is a lion' or 'John got the apple' or both.",
        "valid"
    ],
    [
        0.4143854131301244,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '905'}",
        "It is probably not the case that either 'Brian is gray' or 'Lily is a swan' but not both.",
        "valid"
    ],
    [
        0.41428469121456146,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '756'}",
        "There is a better than even chance that Lily is gray. Chances are about even that Bernhard is a frog. There is little chance that Greg is a frog. It is unlikely that if either 'Lily is gray' or 'Greg is a frog' but not both then Brian is a swan. We doubt that if either 'Lily is gray' or 'Greg is a frog' but not both then Julius is yellow. There is a better than even chance that if either 'Greg is a frog' or 'Lily is gray' but not both then Mary went to the garden.",
        "valid"
    ],
    [
        0.41413042445977527,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '285'}",
        "It is highly unlikely that Lily is white. It is impossible that Greg is gray. It is improbable that Julius is a rhino. There is almost no chance that if 'Julius is a rhino and Greg is gray' then Brian is green. Chances are about even that if either 'Lily is white' or 'Greg is gray' but not both then Yann is hungry. It is unlikely that if either 'Greg is gray' or 'Lily is white' but not both then Mary left the milk.",
        "valid"
    ],
    [
        0.4140398253997167,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '835'}",
        "It is impossible that Mary left the milk. It is probable that Brian is gray. It is likely that Greg is a frog. Chances are slight that if either 'Brian is gray' or 'Greg is a frog' but not both then Julius is white. Chances are about even that if 'Brian is gray' or 'Mary left the milk' or both then John put down the apple. It is probably the case that if 'Brian is gray' or 'Mary left the milk' or both then Lily is yellow.",
        "valid"
    ],
    [
        0.4139648626248042,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '28'}",
        "It is unlikely that 'Brian is a swan' or 'Greg is a lion' or both.",
        "valid"
    ],
    [
        0.4139387756586075,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '659'}",
        "It is likely that Brian is white. It is highly likely that John dropped the apple. It is probably not the case that Julius is a lion. It is probably not the case that if either 'Brian is white' or 'Julius is a lion' but not both then Gertrude is a sheep. There is little chance that if 'Julius is a lion' or 'Brian is white' or both then Mary left the football. There is a better than even chance that if 'Brian is white' or 'Julius is a lion' or both then Emily is a wolf.",
        "valid"
    ],
    [
        0.41387873391310376,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '33'}",
        "We believe that Lily is white. It is impossible that Emily is a mouse. There is little chance that Brian is a swan. It is probably the case that if 'Emily is a mouse and Lily is white' then John put down the milk. It is unlikely that if 'Lily is white' or 'Brian is a swan' or both then Winona is a wolf. It is likely that if 'Emily is a mouse' or 'Lily is white' or both then Sandra left the apple.",
        "valid"
    ],
    [
        0.41386033594608307,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '7'}",
        "It is highly likely that Brian is a swan. There is a very good chance that Lily is white. It is highly likely that Winona is a sheep. It is probably the case that if 'Winona is a sheep and Brian is a swan' then Sumit is thirsty. It is probably not the case that if 'Brian is a swan and Lily is white' then John put down the apple. It is highly likely that if 'Brian is a swan and Lily is white' then Greg is a frog.",
        "valid"
    ],
    [
        0.4136674255132675,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '459'}",
        "We doubt that Brian is white. It is almost certain that John discarded the apple. Chances are slight that Lily is a swan. We doubt that if 'Lily is a swan and John discarded the apple' then Mary took the football. It is improbable that if 'Brian is white' or 'Lily is a swan' or both then Bernhard is yellow. It is probably not the case that if 'Brian is white' or 'John discarded the apple' or both then Winona is a mouse.",
        "valid"
    ],
    [
        0.41357435286045074,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '250'}",
        "It is unlikely that either 'Lily is a rhino' or 'Greg is a frog' but not both.",
        "valid"
    ],
    [
        0.4135487824678421,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '173'}",
        "There is a better than even chance that Bernhard is a swan. It is almost certain that Brian is white. We believe that Julius is a lion. Chances are slight that if either 'Bernhard is a swan' or 'Julius is a lion' but not both then Lily is yellow. It is probably the case that if either 'Brian is white' or 'Julius is a lion' but not both then Sandra dropped the apple. It is highly unlikely that if either 'Julius is a lion' or 'Bernhard is a swan' but not both then John moved to the garden.",
        "valid"
    ],
    [
        0.4134456366300583,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '764'}",
        "It is impossible that either 'Lily is white' or 'Greg is a swan' but not both.",
        "valid"
    ],
    [
        0.41336208085219067,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '269'}",
        "There is little chance that Brian is yellow. It is almost certain that Lily is a lion. We doubt that Julius is a swan. We believe that if either 'Lily is a lion' or 'Julius is a swan' but not both then Bernhard is gray. It is improbable that if 'Lily is a lion and Brian is yellow' then Bill left the milk. There is a very good chance that if either 'Julius is a swan' or 'Lily is a lion' but not both then John dropped the apple.",
        "valid"
    ],
    [
        0.41327344874540967,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '758'}",
        "It is highly unlikely that Lily is a frog. It is impossible that Brian is a rhino. It is probably not the case that Yann is hungry.",
        "valid"
    ],
    [
        0.41322501997152966,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '429'}",
        "It is impossible that Julius is a lion. It is highly likely that Mary got the football. It is impossible that Gertrude is a mouse. We believe that if either 'Gertrude is a mouse' or 'Julius is a lion' but not both then John picked up the apple. It is almost certain that if either 'Mary got the football' or 'Julius is a lion' but not both then Lily is a rhino. It is unlikely that if 'Mary got the football and Gertrude is a mouse' then Brian is yellow.",
        "valid"
    ],
    [
        0.4131905883550644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '423'}",
        "There is a better than even chance that Lily is a swan. It is impossible that Julius is a frog. We believe that Mary put down the apple. Chances are slight that if 'Julius is a frog and Mary put down the apple' then Sandra got the football. There is a better than even chance that if either 'Mary put down the apple' or 'Lily is a swan' but not both then Greg is a rhino. It is probably not the case that if 'Mary put down the apple and Julius is a frog' then Bernhard is white.",
        "valid"
    ],
    [
        0.413040096561114,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '618'}",
        "It is improbable that Winona is a wolf. It is highly likely that Greg is a lion. There is a better than even chance that Gertrude is a mouse. It is probably the case that if either 'Greg is a lion' or 'Gertrude is a mouse' but not both then Lily is white. It is probably not the case that if 'Greg is a lion and Gertrude is a mouse' then Brian is a frog. It is probably not the case that if 'Greg is a lion and Winona is a wolf' then John moved to the office.",
        "valid"
    ],
    [
        0.4127705047527949,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '655'}",
        "It is unlikely that Julius is a frog. Chances are slight that Brian is gray. Chances are slight that John got the milk. There is little chance that if either 'Brian is gray' or 'Julius is a frog' but not both then Lily is a lion. It is likely that if 'Brian is gray and Julius is a frog' then Jeff moved to the office. It is probable that if 'Brian is gray' or 'Julius is a frog' or both then Greg is a swan.",
        "valid"
    ],
    [
        0.4127156486113866,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '713'}",
        "It is probably not the case that Brian is yellow. Chances are slight that Julius is a swan. Chances are slight that Winona is a sheep. It is probably not the case that if either 'Winona is a sheep' or 'Julius is a swan' but not both then Lily is a rhino. It is almost certain that if either 'Julius is a swan' or 'Brian is yellow' but not both then Sandra dropped the milk. We believe that if either 'Julius is a swan' or 'Winona is a sheep' but not both then Mary went to the kitchen.",
        "valid"
    ],
    [
        0.41259677708148956,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '242'}",
        "There is a very good chance that Bernhard is yellow. There is little chance that Lily is a rhino. There is almost no chance that Brian is a lion. There is little chance that if 'Brian is a lion' or 'Lily is a rhino' or both then Julius is a frog. It is probable that if either 'Bernhard is yellow' or 'Lily is a rhino' but not both then Greg is a swan. It is almost certain that if 'Lily is a rhino and Bernhard is yellow' then John took the football.",
        "valid"
    ],
    [
        0.412523811062177,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '460'}",
        "It is certain that Bernhard is a rhino. There is almost no chance that Brian is a lion. We believe that John got the milk. It is likely that if 'Bernhard is a rhino and John got the milk' then Gertrude is a sheep. It is probable that if either 'John got the milk' or 'Bernhard is a rhino' but not both then Julius is a swan. It is impossible that if 'Brian is a lion and Bernhard is a rhino' then Greg is a frog.",
        "valid"
    ],
    [
        0.41244710981845856,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '523'}",
        "It is improbable that Greg is white. It is almost certain that John put down the apple. There is almost no chance that Winona is a sheep. We believe that if 'Winona is a sheep and Greg is white' then Lily is yellow. There is a very good chance that if 'Greg is white and Winona is a sheep' then Brian is a lion. It is improbable that if 'John put down the apple' or 'Winona is a sheep' or both then Mary got the milk.",
        "valid"
    ],
    [
        0.4123461991548538,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '368'}",
        "We doubt that Lily is white. It is impossible that John took the football. It is likely that Mary discarded the apple. There is a very good chance that if either 'Mary discarded the apple' or 'Lily is white' but not both then Bernhard is gray. It is probably not the case that if 'Lily is white' or 'John took the football' or both then Julius is a frog. It is highly likely that if either 'John took the football' or 'Mary discarded the apple' but not both then Brian is a rhino.",
        "valid"
    ],
    [
        0.4121922602256139,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '75'}",
        "Chances are about even that John put down the apple. It is probably not the case that Greg is a frog. It is probable that Brian is a swan. Chances are about even that if 'Greg is a frog' or 'Brian is a swan' or both then Jessica is a cat. We believe that if 'Greg is a frog' or 'Brian is a swan' or both then Fred is in the school. Chances are slight that if 'Greg is a frog' or 'Brian is a swan' or both then Mary dropped the milk.",
        "valid"
    ],
    [
        0.412155086795489,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '415'}",
        "Chances are slight that Mary went to the hallway. It is almost certain that Greg is a swan. We doubt that Daniel got the milk. It is impossible that if either 'Daniel got the milk' or 'Greg is a swan' but not both then Lily is a swan. It is likely that if 'Greg is a swan' or 'Daniel got the milk' or both then Julius is a rhino. It is improbable that if 'Daniel got the milk and Mary went to the hallway' then John grabbed the apple.",
        "valid"
    ],
    [
        0.412106787165006,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '845'}",
        "It is probably not the case that Julius is a swan. There is a better than even chance that Sandra left the milk. It is probably the case that Lily is a frog. It is probably not the case that if either 'Sandra left the milk' or 'Lily is a frog' but not both then Brian is a rhino. It is highly likely that if 'Sandra left the milk and Lily is a frog' then John went to the garden. We doubt that if 'Sandra left the milk' or 'Julius is a swan' or both then Bernhard is yellow.",
        "valid"
    ],
    [
        0.4120713820060094,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '182'}",
        "There is almost no chance that Lily is a swan. Chances are slight that Jessica is a sheep. There is a very good chance that Brian is white. It is highly unlikely that if 'Lily is a swan and Brian is white' then Julius is green. It is impossible that if 'Jessica is a sheep' or 'Lily is a swan' or both then Fred dropped the milk. It is almost certain that if 'Jessica is a sheep' or 'Brian is white' or both then Mary moved to the office.",
        "valid"
    ],
    [
        0.4120471427838008,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '145'}",
        "Chances are about even that Brian is white. It is highly unlikely that John took the football. It is probably the case that Julius is a frog. There is almost no chance that if 'Brian is white and John took the football' then Bernhard is gray. It is impossible that if either 'Julius is a frog' or 'Brian is white' but not both then Greg is a lion. It is impossible that if 'Julius is a frog and Brian is white' then Mary grabbed the milk.",
        "valid"
    ],
    [
        0.4118722528219223,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '640'}",
        "There is little chance that Brian is a frog. Chances are about even that Bernhard is a swan. It is impossible that Julius is white. It is improbable that if 'Julius is white' or 'Bernhard is a swan' or both then Greg is green. It is likely that if either 'Brian is a frog' or 'Julius is white' but not both then John dropped the apple. We doubt that if either 'Brian is a frog' or 'Bernhard is a swan' but not both then Sandra got the football.",
        "valid"
    ],
    [
        0.4117245425780614,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '432'}",
        "It is unlikely that Mary dropped the milk. It is impossible that Lily is a lion. We doubt that Winona is a mouse. It is probably not the case that if either 'Winona is a mouse' or 'Mary dropped the milk' but not both then John discarded the apple. It is likely that if 'Mary dropped the milk and Lily is a lion' then Greg is white. It is certain that if 'Lily is a lion' or 'Mary dropped the milk' or both then Julius is gray.",
        "valid"
    ],
    [
        0.4116638054450353,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '303'}",
        "It is improbable that either 'Brian is a lion' or 'Greg is gray' but not both.",
        "valid"
    ],
    [
        0.41163988411426544,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '922'}",
        "There is almost no chance that Greg is white. There is little chance that Sandra got the football. It is highly likely that Julius is a lion. It is probably the case that if either 'Julius is a lion' or 'Greg is white' but not both then John put down the apple. It is almost certain that if either 'Greg is white' or 'Julius is a lion' but not both then Brian is yellow. It is improbable that if either 'Julius is a lion' or 'Sandra got the football' but not both then Lily is a rhino.",
        "valid"
    ],
    [
        0.4116109261910121,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '520'}",
        "It is improbable that 'Brian is a lion' or 'Winona is a wolf' or both.",
        "valid"
    ],
    [
        0.41147468984127045,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '519'}",
        "There is little chance that Greg is gray. It is almost certain that Lily is a rhino. It is highly unlikely that Brian is white. It is highly unlikely that if 'Greg is gray' or 'Lily is a rhino' or both then Emily is a sheep. It is improbable that if either 'Lily is a rhino' or 'Brian is white' but not both then Antoine is hungry. It is probable that if 'Greg is gray' or 'Lily is a rhino' or both then Fred moved to the office.",
        "valid"
    ],
    [
        0.4114631364742915,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '928'}",
        "It is probably the case that Mary went to the bedroom. Chances are about even that Brian is a rhino. It is probably the case that Lily is a lion. We doubt that if 'Mary went to the bedroom' or 'Lily is a lion' or both then Greg is a swan. It is certain that if either 'Lily is a lion' or 'Brian is a rhino' but not both then Gertrude is a sheep. It is likely that if 'Lily is a lion and Brian is a rhino' then Sandra dropped the milk.",
        "valid"
    ],
    [
        0.41143395006656647,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '907'}",
        "It is improbable that either 'Greg is a swan' or 'Brian is a frog' but not both.",
        "valid"
    ],
    [
        0.4114324400822322,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '868'}",
        "It is impossible that 'Brian is a lion' or 'Jason is tired' or both.",
        "valid"
    ],
    [
        0.4112887730201085,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '277'}",
        "We believe that Brian is white. There is little chance that Daniel dropped the milk. It is improbable that John went to the hallway. It is impossible that if 'John went to the hallway' or 'Brian is white' or both then Jessica is a mouse. It is highly unlikely that if either 'Brian is white' or 'Daniel dropped the milk' but not both then Greg is a lion. It is probably not the case that if 'John went to the hallway' or 'Daniel dropped the milk' or both then Bernhard is a swan.",
        "valid"
    ],
    [
        0.4112621893485387,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '136'}",
        "It is unlikely that Gertrude is a sheep. There is almost no chance that Julius is a lion. It is almost certain that Bernhard is a frog. Chances are slight that if 'Julius is a lion' or 'Gertrude is a sheep' or both then Greg is a rhino. It is highly likely that if 'Julius is a lion and Gertrude is a sheep' then Brian is white. We believe that if 'Julius is a lion' or 'Bernhard is a frog' or both then John went to the garden.",
        "valid"
    ],
    [
        0.41124752660592395,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '585'}",
        "It is certain that Julius is gray. There is a very good chance that Greg is a frog. It is probable that Lily is a lion. It is highly unlikely that if either 'Lily is a lion' or 'Greg is a frog' but not both then John dropped the apple. There is little chance that if either 'Julius is gray' or 'Lily is a lion' but not both then Bill went to the office. There is little chance that if either 'Greg is a frog' or 'Julius is gray' but not both then Bernhard is yellow.",
        "valid"
    ],
    [
        0.4111279894908269,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '86'}",
        "Chances are about even that Brian is a frog. Chances are about even that John picked up the milk. We doubt that Julius is white. It is likely that if 'Brian is a frog' or 'John picked up the milk' or both then Lily is a lion. There is little chance that if 'Brian is a frog and Julius is white' then Jeff went to the garden. Chances are slight that if 'John picked up the milk' or 'Julius is white' or both then Sandra dropped the apple.",
        "valid"
    ],
    [
        0.4110366255044937,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '240'}",
        "It is highly unlikely that Daniel got the milk. It is highly likely that Lily is a swan. It is highly unlikely that Greg is a rhino. There is little chance that if either 'Daniel got the milk' or 'Greg is a rhino' but not both then Jessica is a cat. It is improbable that if 'Daniel got the milk' or 'Lily is a swan' or both then Bernhard is green. There is almost no chance that if 'Greg is a rhino' or 'Daniel got the milk' or both then Mary went to the hallway.",
        "valid"
    ],
    [
        0.41092739005883533,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '159'}",
        "There is little chance that Brian is a frog. It is probably not the case that Lily is green. Chances are about even that Daniel grabbed the milk. There is a better than even chance that if 'Lily is green and Daniel grabbed the milk' then Greg is gray. It is impossible that if 'Brian is a frog' or 'Lily is green' or both then Mary went to the kitchen. It is almost certain that if either 'Brian is a frog' or 'Daniel grabbed the milk' but not both then John moved to the office.",
        "valid"
    ],
    [
        0.4108939121166865,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '17'}",
        "It is certain that Daniel took the apple. There is little chance that Julius is a lion. It is likely that Mary left the milk. It is highly unlikely that if 'Daniel took the apple and Mary left the milk' then Gertrude is a cat. It is unlikely that if either 'Daniel took the apple' or 'Julius is a lion' but not both then Brian is yellow. We believe that if either 'Julius is a lion' or 'Mary left the milk' but not both then Greg is white.",
        "valid"
    ],
    [
        0.41081978380680084,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '334'}",
        "It is impossible that 'Bernhard is a frog' or 'Lily is a swan' or both.",
        "valid"
    ],
    [
        0.41081901888052624,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '665'}",
        "There is almost no chance that Bernhard is a swan. It is unlikely that Lily is a lion. It is probably not the case that Julius is yellow. There is little chance that if either 'Lily is a lion' or 'Julius is yellow' but not both then Brian is gray. It is highly likely that if 'Bernhard is a swan' or 'Lily is a lion' or both then John dropped the apple. There is a better than even chance that if 'Julius is yellow' or 'Bernhard is a swan' or both then Jeff put down the milk.",
        "valid"
    ],
    [
        0.4107803950707118,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '153'}",
        "It is impossible that either 'John put down the apple' or 'Brian is a lion' but not both.",
        "valid"
    ],
    [
        0.41076456010341644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '674'}",
        "It is highly unlikely that either 'Brian is a swan' or 'Lily is gray' but not both.",
        "valid"
    ],
    [
        0.41057103375593823,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '247'}",
        "There is a very good chance that Julius is yellow. There is a better than even chance that Lily is a rhino. It is impossible that Daniel put down the milk. It is likely that if either 'Daniel put down the milk' or 'Julius is yellow' but not both then Greg is a rhino. There is a very good chance that if either 'Lily is a rhino' or 'Daniel put down the milk' but not both then Brian is a frog. There is a very good chance that if either 'Daniel put down the milk' or 'Julius is yellow' but not both then Mary went to the hallway.",
        "valid"
    ],
    [
        0.410504216949145,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '416'}",
        "There is a very good chance that Lily is a rhino. It is probably the case that Julius is gray. It is impossible that Daniel left the apple. It is likely that if 'Lily is a rhino and Daniel left the apple' then Sandra put down the milk. It is impossible that if 'Daniel left the apple and Lily is a rhino' then Brian is a lion. It is probably the case that if 'Lily is a rhino' or 'Daniel left the apple' or both then Fred moved to the office.",
        "valid"
    ],
    [
        0.41047952075799304,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '16'}",
        "It is likely that Lily is a swan. It is likely that Winona is a cat. It is certain that Brian is white. We believe that if either 'Winona is a cat' or 'Brian is white' but not both then Yann is tired. There is a better than even chance that if 'Brian is white and Lily is a swan' then Bernhard is a rhino. It is almost certain that if either 'Lily is a swan' or 'Brian is white' but not both then Mary moved to the garden.",
        "valid"
    ],
    [
        0.4104735602935155,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '37'}",
        "There is almost no chance that Emily is a sheep. It is likely that Antoine is hungry. There is little chance that Greg is a rhino. We believe that if either 'Greg is a rhino' or 'Emily is a sheep' but not both then Julius is a swan. There is a better than even chance that if either 'Emily is a sheep' or 'Greg is a rhino' but not both then Winona is a cat. We believe that if 'Greg is a rhino and Emily is a sheep' then Brian is white.",
        "valid"
    ],
    [
        0.41005787750085193,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '125'}",
        "There is almost no chance that Brian is a frog. There is little chance that Bernhard is gray. It is probably not the case that Julius is a swan. Chances are slight that if 'Bernhard is gray' or 'Julius is a swan' or both then Greg is a rhino. It is likely that if either 'Bernhard is gray' or 'Brian is a frog' but not both then John took the apple. It is highly unlikely that if 'Bernhard is gray' or 'Julius is a swan' or both then Sandra grabbed the milk.",
        "valid"
    ],
    [
        0.409801517923673,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '255'}",
        "It is highly unlikely that Lily is white. It is improbable that Bernhard is a swan. It is highly unlikely that Julius is gray. We believe that if 'Lily is white and Julius is gray' then Sandra left the apple. We believe that if either 'Julius is gray' or 'Bernhard is a swan' but not both then Emily is a sheep. It is impossible that if either 'Julius is gray' or 'Bernhard is a swan' but not both then Brian is green.",
        "valid"
    ],
    [
        0.40972310801347095,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '902'}",
        "We believe that Winona is a cat. It is certain that Brian is white. It is improbable that Mary went to the garden. It is unlikely that if 'Winona is a cat and Mary went to the garden' then Greg is white. It is probably the case that if 'Winona is a cat and Brian is white' then Lily is a rhino. Chances are about even that if 'Brian is white' or 'Winona is a cat' or both then Julius is yellow.",
        "valid"
    ],
    [
        0.40963127712408703,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '853'}",
        "There is a very good chance that Brian is white. It is certain that Bernhard is white. We doubt that Daniel dropped the apple. Chances are about even that if 'Brian is white' or 'Bernhard is white' or both then Winona is a wolf. There is a very good chance that if either 'Brian is white' or 'Bernhard is white' but not both then Julius is a lion. It is highly unlikely that if either 'Brian is white' or 'Daniel dropped the apple' but not both then Mary went to the hallway.",
        "valid"
    ],
    [
        0.40960389872392017,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '64'}",
        "It is improbable that Winona is a wolf. It is highly unlikely that Greg is white. It is highly likely that Julius is yellow. Chances are about even that if either 'Julius is yellow' or 'Greg is white' but not both then Bernhard is a frog. It is probable that if 'Julius is yellow and Greg is white' then Lily is a lion. We believe that if 'Greg is white' or 'Julius is yellow' or both then John went to the bedroom.",
        "valid"
    ],
    [
        0.40959856410821277,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '766'}",
        "It is impossible that Greg is a swan. It is likely that Mary grabbed the milk. There is a better than even chance that Brian is yellow. It is probable that if 'Mary grabbed the milk and Brian is yellow' then Bernhard is a swan. It is improbable that if either 'Brian is yellow' or 'Greg is a swan' but not both then Lily is white. It is almost certain that if 'Greg is a swan and Mary grabbed the milk' then Julius is green.",
        "valid"
    ],
    [
        0.4095965772867203,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '553'}",
        "It is probably not the case that either 'Brian is a swan' or 'John got the milk' but not both.",
        "valid"
    ],
    [
        0.4095757156610489,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '703'}",
        "There is a better than even chance that Brian is gray. It is probably not the case that John got the milk. Chances are slight that Jessica is a mouse. There is almost no chance that if either 'John got the milk' or 'Jessica is a mouse' but not both then Lily is a rhino. There is little chance that if either 'Jessica is a mouse' or 'John got the milk' but not both then Julius is green. It is probably not the case that if 'Brian is gray' or 'Jessica is a mouse' or both then Bernhard is a frog.",
        "valid"
    ],
    [
        0.40951644877592724,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '276'}",
        "There is a better than even chance that Brian is a lion. We believe that Mary left the football. There is a very good chance that Greg is a rhino. There is a better than even chance that if 'Brian is a lion' or 'Greg is a rhino' or both then Sandra got the milk. There is little chance that if 'Brian is a lion and Mary left the football' then Julius is yellow. It is probably the case that if either 'Mary left the football' or 'Greg is a rhino' but not both then Bill went to the kitchen.",
        "valid"
    ],
    [
        0.40947313606739044,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '105'}",
        "It is impossible that Bernhard is yellow. It is unlikely that Lily is white. There is little chance that Brian is a swan. It is impossible that if either 'Bernhard is yellow' or 'Lily is white' but not both then Julius is green. It is certain that if either 'Bernhard is yellow' or 'Brian is a swan' but not both then Jessica is a mouse. It is likely that if either 'Brian is a swan' or 'Bernhard is yellow' but not both then John left the milk.",
        "valid"
    ],
    [
        0.40934103230635327,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '580'}",
        "We believe that John got the apple. It is unlikely that Greg is a swan. It is likely that Brian is a frog. We believe that if either 'John got the apple' or 'Greg is a swan' but not both then Bernhard is yellow. It is impossible that if 'Greg is a swan and John got the apple' then Julius is a lion. It is probably not the case that if 'Brian is a frog and John got the apple' then Mary left the milk.",
        "valid"
    ],
    [
        0.4093344459931056,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '15'}",
        "It is probably not the case that either 'Lily is a swan' or 'Brian is yellow' but not both.",
        "valid"
    ],
    [
        0.40930189192295074,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '822'}",
        "We doubt that Brian is white. It is probably not the case that Daniel left the milk. It is probably the case that Lily is a swan.",
        "valid"
    ],
    [
        0.40928830206394196,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '578'}",
        "It is probably not the case that John went to the hallway. It is unlikely that Lily is a swan. There is little chance that Bernhard is a lion. We believe that if either 'John went to the hallway' or 'Lily is a swan' but not both then Julius is gray. There is little chance that if 'Bernhard is a lion' or 'John went to the hallway' or both then Brian is a rhino. There is a better than even chance that if 'Bernhard is a lion and Lily is a swan' then Greg is a swan.",
        "valid"
    ],
    [
        0.40928661326567334,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '995'}",
        "There is almost no chance that Brian is yellow. It is impossible that Greg is a swan. It is almost certain that Julius is a frog. It is probably not the case that if 'Greg is a swan and Brian is yellow' then Fred is in the cinema. It is probably the case that if either 'Julius is a frog' or 'Greg is a swan' but not both then John got the apple. We doubt that if 'Greg is a swan and Julius is a frog' then Jessica is a mouse.",
        "valid"
    ],
    [
        0.4092361281315486,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '469'}",
        "It is certain that Greg is a frog. We believe that Brian is white. It is impossible that Jessica is a mouse. It is certain that if 'Jessica is a mouse and Brian is white' then Fred is in the school. There is little chance that if 'Greg is a frog and Jessica is a mouse' then Bernhard is a swan. It is probable that if 'Greg is a frog' or 'Jessica is a mouse' or both then Lily is green.",
        "valid"
    ],
    [
        0.40917135775089264,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '466'}",
        "We doubt that Lily is a rhino. It is improbable that Greg is gray. It is impossible that John went to the office. It is unlikely that if either 'Greg is gray' or 'Lily is a rhino' but not both then Mary left the football. There is little chance that if 'Lily is a rhino' or 'John went to the office' or both then Winona is a sheep. It is highly likely that if 'John went to the office and Greg is gray' then Brian is a frog.",
        "valid"
    ],
    [
        0.4091350585222244,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '738'}",
        "It is almost certain that Brian is a frog. Chances are about even that Bill left the milk. It is impossible that Greg is yellow. It is likely that if 'Greg is yellow' or 'Brian is a frog' or both then Gertrude is a mouse. There is little chance that if 'Bill left the milk' or 'Greg is yellow' or both then Mary got the football. It is probably the case that if either 'Greg is yellow' or 'Bill left the milk' but not both then Bernhard is a swan.",
        "valid"
    ],
    [
        0.40912268062432605,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '765'}",
        "It is highly unlikely that 'Lily is a lion' or 'Bernhard is a frog' or both.",
        "valid"
    ],
    [
        0.4091062893470128,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '352'}",
        "It is highly unlikely that either 'Brian is white' or 'Greg is a swan' but not both.",
        "valid"
    ],
    [
        0.40899157027403515,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '729'}",
        "There is a better than even chance that Greg is a frog. Chances are about even that Brian is a swan. It is probably not the case that Sandra left the football. It is probable that if 'Brian is a swan' or 'Greg is a frog' or both then Julius is white. There is a very good chance that if 'Greg is a frog' or 'Brian is a swan' or both then Mary went to the bedroom. It is highly unlikely that if either 'Greg is a frog' or 'Sandra left the football' but not both then John picked up the apple.",
        "valid"
    ],
    [
        0.40898217260837555,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '261'}",
        "It is probably not the case that John took the apple. It is almost certain that Daniel left the football. It is unlikely that Lily is green. Chances are slight that if 'John took the apple' or 'Daniel left the football' or both then Bernhard is gray. It is probably the case that if either 'John took the apple' or 'Daniel left the football' but not both then Brian is white. It is impossible that if either 'Lily is green' or 'Daniel left the football' but not both then Julius is a frog.",
        "valid"
    ],
    [
        0.408973957101504,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '996'}",
        "It is probably not the case that Julius is a rhino. We doubt that Bill went to the bedroom. It is impossible that Bernhard is a frog. There is a very good chance that if 'Julius is a rhino' or 'Bernhard is a frog' or both then Antoine is hungry. It is probably not the case that if 'Bill went to the bedroom and Bernhard is a frog' then Lily is a lion. We doubt that if 'Julius is a rhino' or 'Bernhard is a frog' or both then John left the football.",
        "valid"
    ],
    [
        0.40895932416121167,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '196'}",
        "Chances are about even that Brian is yellow. We doubt that Sandra dropped the milk. It is impossible that Lily is a lion. It is almost certain that if 'Brian is yellow' or 'Sandra dropped the milk' or both then Mary went to the office. It is certain that if either 'Brian is yellow' or 'Sandra dropped the milk' but not both then John put down the milk. It is impossible that if either 'Brian is yellow' or 'Lily is a lion' but not both then Fred left the apple.",
        "valid"
    ],
    [
        0.40885839362939197,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '69'}",
        "It is probably not the case that Lily is a lion. There is almost no chance that Mary grabbed the apple. It is impossible that Brian is white.",
        "valid"
    ],
    [
        0.4087521980206172,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '956'}",
        "There is little chance that Winona is a cat. Chances are slight that Julius is a frog. It is certain that Brian is white. It is improbable that if either 'Winona is a cat' or 'Brian is white' but not both then Sandra dropped the milk. It is probably the case that if 'Brian is white' or 'Julius is a frog' or both then Bernhard is yellow. It is probably the case that if 'Brian is white and Winona is a cat' then Mary moved to the office.",
        "valid"
    ],
    [
        0.40872788925965625,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '401'}",
        "It is unlikely that Mary got the football. It is likely that Lily is a frog. It is almost certain that Greg is a rhino. It is almost certain that if 'Lily is a frog' or 'Mary got the football' or both then John left the football. It is unlikely that if either 'Lily is a frog' or 'Mary got the football' but not both then Brian is white. We believe that if either 'Lily is a frog' or 'Mary got the football' but not both then Bernhard is green.",
        "valid"
    ],
    [
        0.4087228129307429,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '383'}",
        "It is probably the case that Brian is white. It is highly likely that Greg is a swan. There is almost no chance that Bill went to the kitchen. It is improbable that if 'Bill went to the kitchen and Greg is a swan' then Mary got the football. It is probable that if either 'Brian is white' or 'Greg is a swan' but not both then Gertrude is a sheep. There is little chance that if either 'Greg is a swan' or 'Brian is white' but not both then Lily is green.",
        "valid"
    ],
    [
        0.4086650460958481,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '62'}",
        "It is impossible that Bernhard is a swan. It is highly unlikely that Brian is a frog. There is a better than even chance that Lily is green. It is improbable that if 'Brian is a frog and Bernhard is a swan' then Greg is white. It is highly unlikely that if 'Lily is green and Brian is a frog' then Mary went to the hallway. There is a better than even chance that if either 'Bernhard is a swan' or 'Lily is green' but not both then Jessica is a cat.",
        "valid"
    ],
    [
        0.40855107208093006,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '19'}",
        "There is a better than even chance that Winona is a sheep. It is likely that Mary dropped the apple. There is almost no chance that Brian is white. There is a very good chance that if 'Mary dropped the apple' or 'Brian is white' or both then Lily is a rhino. It is likely that if 'Winona is a sheep' or 'Mary dropped the apple' or both then Bill went to the kitchen. There is little chance that if 'Winona is a sheep' or 'Brian is white' or both then Greg is a lion.",
        "valid"
    ],
    [
        0.40848516921202344,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '461'}",
        "It is highly unlikely that either 'Julius is white' or 'Lily is a frog' but not both.",
        "valid"
    ],
    [
        0.4083859672149022,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '958'}",
        "It is probably the case that Winona is a sheep. It is certain that Julius is white. We believe that John discarded the apple. There is a very good chance that if either 'Winona is a sheep' or 'John discarded the apple' but not both then Mary moved to the office. There is a better than even chance that if either 'John discarded the apple' or 'Winona is a sheep' but not both then Brian is yellow. It is almost certain that if 'John discarded the apple and Winona is a sheep' then Lily is a frog.",
        "valid"
    ],
    [
        0.4083520124355952,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '998'}",
        "There is almost no chance that either 'Daniel got the apple' or 'Lily is a swan' but not both.",
        "valid"
    ],
    [
        0.40819862981637317,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '239'}",
        "It is likely that Brian is a lion. It is probably the case that John put down the apple. There is almost no chance that Jeff discarded the milk. There is little chance that if 'Jeff discarded the milk and John put down the apple' then Mary got the milk. It is highly likely that if either 'Jeff discarded the milk' or 'John put down the apple' but not both then Bernhard is a swan. It is highly unlikely that if either 'Brian is a lion' or 'John put down the apple' but not both then Jessica is a sheep.",
        "valid"
    ],
    [
        0.4081781456867854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '274'}",
        "It is impossible that 'Julius is a lion and Brian is a rhino'.",
        "valid"
    ],
    [
        0.40810738503932953,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '970'}",
        "There is little chance that Mary grabbed the milk. We doubt that Brian is a frog. It is probably not the case that Lily is a swan. It is probably the case that if 'Brian is a frog' or 'Mary grabbed the milk' or both then Jason is tired. Chances are about even that if 'Brian is a frog and Mary grabbed the milk' then Julius is yellow. There is a very good chance that if 'Lily is a swan' or 'Mary grabbed the milk' or both then Bernhard is green.",
        "valid"
    ],
    [
        0.40809907019138336,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '284'}",
        "It is highly unlikely that 'Lily is a rhino' or 'Julius is a swan' or both.",
        "valid"
    ],
    [
        0.4080790927012761,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '108'}",
        "It is probably not the case that Brian is gray. Chances are about even that Lily is yellow. There is almost no chance that John went to the office. It is almost certain that if 'Lily is yellow and Brian is gray' then Mary left the milk. It is certain that if 'Brian is gray' or 'John went to the office' or both then Antoine is thirsty. It is impossible that if 'John went to the office' or 'Lily is yellow' or both then Julius is a swan.",
        "valid"
    ],
    [
        0.4080757349729538,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '271'}",
        "It is probable that Lily is white. There is a very good chance that Brian is a frog. Chances are slight that Julius is gray. There is a very good chance that if 'Brian is a frog and Lily is white' then Mary dropped the milk. There is almost no chance that if 'Brian is a frog and Julius is gray' then John got the apple. It is probably not the case that if 'Brian is a frog and Julius is gray' then Bernhard is green.",
        "valid"
    ],
    [
        0.40804333984851837,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '204'}",
        "Chances are about even that Brian is yellow. We doubt that Jessica is a mouse. There is a better than even chance that Winona is a sheep. It is almost certain that if 'Jessica is a mouse' or 'Winona is a sheep' or both then Bernhard is a rhino. We doubt that if 'Brian is yellow' or 'Winona is a sheep' or both then Julius is white. It is impossible that if 'Winona is a sheep' or 'Brian is yellow' or both then John went to the hallway.",
        "valid"
    ],
    [
        0.4079408993323644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '811'}",
        "Chances are slight that Brian is a swan. It is highly likely that Julius is a rhino. There is a very good chance that Bernhard is a lion. There is a very good chance that if 'Bernhard is a lion and Julius is a rhino' then Antoine is hungry. There is almost no chance that if 'Brian is a swan and Julius is a rhino' then Mary grabbed the milk. We doubt that if either 'Brian is a swan' or 'Julius is a rhino' but not both then Greg is green.",
        "valid"
    ],
    [
        0.4078945070505142,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '375'}",
        "There is almost no chance that Greg is gray. It is highly likely that John took the apple. It is probably not the case that Lily is a swan. There is a very good chance that if either 'John took the apple' or 'Greg is gray' but not both then Winona is a wolf. Chances are about even that if 'Greg is gray and John took the apple' then Bernhard is a frog. It is probable that if 'Lily is a swan and Greg is gray' then Mary got the milk.",
        "valid"
    ],
    [
        0.4078029046456019,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '483'}",
        "It is impossible that Lily is yellow. It is likely that Julius is white. It is highly likely that Greg is yellow. It is almost certain that if either 'Julius is white' or 'Lily is yellow' but not both then Brian is a frog. There is little chance that if 'Lily is yellow and Julius is white' then John took the apple. It is highly likely that if 'Julius is white and Greg is yellow' then Mary put down the apple.",
        "valid"
    ],
    [
        0.4078019807736079,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '335'}",
        "It is highly likely that Winona is a sheep. It is almost certain that Bernhard is white. There is little chance that Brian is gray. It is probably not the case that if either 'Brian is gray' or 'Winona is a sheep' but not both then Sandra left the football. Chances are about even that if 'Bernhard is white' or 'Winona is a sheep' or both then Antoine is hungry. It is unlikely that if 'Bernhard is white and Winona is a sheep' then Julius is a rhino.",
        "valid"
    ],
    [
        0.40777648985385895,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '49'}",
        "It is certain that Lily is a swan. There is a very good chance that Gertrude is a mouse. There is almost no chance that Greg is a frog. It is probably the case that if either 'Greg is a frog' or 'Gertrude is a mouse' but not both then Sandra put down the milk. It is likely that if 'Gertrude is a mouse and Greg is a frog' then Brian is white. It is certain that if either 'Gertrude is a mouse' or 'Lily is a swan' but not both then John went to the kitchen.",
        "valid"
    ],
    [
        0.40764643251895905,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '478'}",
        "We doubt that Lily is a rhino. It is certain that Julius is yellow. There is a better than even chance that Bernhard is a frog. It is unlikely that if 'Julius is yellow and Lily is a rhino' then Greg is a lion. It is impossible that if 'Julius is yellow and Bernhard is a frog' then John grabbed the apple. There is little chance that if 'Julius is yellow and Bernhard is a frog' then Winona is a sheep.",
        "valid"
    ],
    [
        0.4076448529958725,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '693'}",
        "It is probably the case that either 'Brian is a swan' or 'Julius is a rhino' but not both.",
        "valid"
    ],
    [
        0.40760353704293567,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '757'}",
        "We doubt that Julius is a frog. There is a better than even chance that Gertrude is a sheep. It is almost certain that Mary took the milk. There is a better than even chance that if either 'Julius is a frog' or 'Gertrude is a sheep' but not both then Brian is gray. It is improbable that if 'Julius is a frog and Gertrude is a sheep' then John picked up the apple. It is probable that if 'Mary took the milk' or 'Julius is a frog' or both then Lily is a swan.",
        "valid"
    ],
    [
        0.4075550784667333,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '121'}",
        "It is probably the case that either 'Lily is white' or 'Greg is a frog' but not both.",
        "valid"
    ],
    [
        0.40751104056835175,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '679'}",
        "It is impossible that 'John went to the hallway' or 'Brian is a lion' or both.",
        "valid"
    ],
    [
        0.40739181141058606,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '931'}",
        "There is a very good chance that Brian is a swan. There is a very good chance that Julius is a lion. It is certain that Greg is green. It is probably the case that if either 'Julius is a lion' or 'Brian is a swan' but not both then Jason is thirsty. It is almost certain that if 'Brian is a swan' or 'Julius is a lion' or both then John moved to the garden. There is almost no chance that if 'Julius is a lion and Greg is green' then Mary dropped the apple.",
        "valid"
    ],
    [
        0.4073779731988907,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '347'}",
        "It is improbable that Greg is a frog. It is highly likely that John went to the garden. It is highly unlikely that Julius is a swan. It is probably the case that if 'Julius is a swan and John went to the garden' then Bernhard is a lion. There is almost no chance that if either 'John went to the garden' or 'Julius is a swan' but not both then Yann is bored. It is improbable that if either 'Julius is a swan' or 'Greg is a frog' but not both then Sandra grabbed the milk.",
        "valid"
    ],
    [
        0.4072063018878301,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '106'}",
        "It is probable that Greg is white. It is improbable that Sumit is thirsty. It is unlikely that Julius is a frog. We believe that if 'Julius is a frog' or 'Greg is white' or both then Lily is yellow. It is probable that if 'Greg is white and Julius is a frog' then Mary moved to the garden. There is a better than even chance that if 'Julius is a frog' or 'Greg is white' or both then Brian is a lion.",
        "valid"
    ],
    [
        0.4071475913127263,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '858'}",
        "It is impossible that 'Lily is a frog and Brian is white'.",
        "valid"
    ],
    [
        0.40707240998744965,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '843'}",
        "There is almost no chance that 'Brian is a frog and Lily is a rhino'.",
        "valid"
    ],
    [
        0.4069404552380244,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '510'}",
        "It is highly unlikely that 'Brian is yellow' or 'Lily is a swan' or both.",
        "valid"
    ],
    [
        0.4069333424170812,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '480'}",
        "It is probable that Jessica is a mouse. We believe that Greg is a frog. It is highly unlikely that Lily is a swan. It is probably the case that if 'Jessica is a mouse' or 'Lily is a swan' or both then Fred moved to the office. There is a better than even chance that if 'Lily is a swan' or 'Jessica is a mouse' or both then Bernhard is yellow. It is almost certain that if either 'Lily is a swan' or 'Jessica is a mouse' but not both then John put down the apple.",
        "valid"
    ],
    [
        0.4068441142638524,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '24'}",
        "Chances are slight that Julius is white. There is little chance that Greg is a lion. It is certain that John put down the apple. It is probably the case that if 'Julius is white and Greg is a lion' then Sandra got the milk. Chances are slight that if 'Julius is white' or 'John put down the apple' or both then Lily is gray. It is probably the case that if 'John put down the apple' or 'Greg is a lion' or both then Bernhard is a rhino.",
        "valid"
    ],
    [
        0.40673839549223584,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '938'}",
        "It is probably not the case that either 'Brian is a frog' or 'Lily is green' but not both.",
        "valid"
    ],
    [
        0.406732643644015,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '622'}",
        "There is a very good chance that Jessica is a wolf. There is almost no chance that Brian is a lion. It is certain that Bernhard is a swan. Chances are slight that if 'Bernhard is a swan' or 'Brian is a lion' or both then Julius is a rhino. It is highly likely that if either 'Brian is a lion' or 'Bernhard is a swan' but not both then Mary dropped the milk. It is certain that if 'Brian is a lion and Jessica is a wolf' then Fred is in the office.",
        "valid"
    ],
    [
        0.40672142803668976,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '174'}",
        "There is little chance that 'Lily is a swan' or 'Greg is a frog' or both.",
        "valid"
    ],
    [
        0.40669091045856476,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '207'}",
        "We doubt that Lily is white. It is impossible that Emily is a sheep. It is certain that Bernhard is gray. There is a very good chance that if 'Bernhard is gray and Emily is a sheep' then John moved to the office. We believe that if 'Emily is a sheep and Bernhard is gray' then Bill went to the garden. It is probably the case that if 'Bernhard is gray' or 'Lily is white' or both then Julius is a rhino.",
        "valid"
    ],
    [
        0.4066018611192703,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '412'}",
        "It is unlikely that Emily is a sheep. It is highly likely that Bernhard is a swan. It is probable that Daniel got the football. There is a better than even chance that if 'Daniel got the football' or 'Bernhard is a swan' or both then Lily is a lion. We doubt that if 'Emily is a sheep' or 'Bernhard is a swan' or both then Jessica is a cat. There is almost no chance that if either 'Daniel got the football' or 'Bernhard is a swan' but not both then Brian is white.",
        "valid"
    ],
    [
        0.4064454485972722,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '987'}",
        "It is unlikely that 'Brian is a lion' or 'Bernhard is a rhino' or both.",
        "valid"
    ],
    [
        0.40643759071826935,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '690'}",
        "We believe that Brian is yellow. It is highly unlikely that Julius is a frog. There is little chance that Daniel took the milk. Chances are slight that if 'Daniel took the milk' or 'Brian is yellow' or both then Bernhard is green. There is little chance that if 'Daniel took the milk' or 'Brian is yellow' or both then Fred is in the school. It is likely that if 'Brian is yellow' or 'Julius is a frog' or both then John went to the kitchen.",
        "valid"
    ],
    [
        0.40610895057519275,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '597'}",
        "There is almost no chance that 'Greg is a lion' or 'Bernhard is a frog' or both.",
        "valid"
    ],
    [
        0.40605810781319934,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '66'}",
        "It is likely that Bernhard is a swan. It is highly unlikely that Lily is a rhino. It is highly likely that Julius is a swan. It is improbable that if 'Bernhard is a swan' or 'Julius is a swan' or both then Antoine is hungry. There is a very good chance that if 'Bernhard is a swan' or 'Lily is a rhino' or both then Mary dropped the milk. Chances are about even that if either 'Bernhard is a swan' or 'Julius is a swan' but not both then Bill left the football.",
        "valid"
    ],
    [
        0.4060349017381668,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '339'}",
        "There is almost no chance that Daniel left the milk. It is probable that Sandra got the milk. We doubt that Greg is a swan. There is a better than even chance that if 'Greg is a swan and Daniel left the milk' then Julius is a rhino. It is probably not the case that if either 'Sandra got the milk' or 'Greg is a swan' but not both then Brian is a swan. We doubt that if either 'Greg is a swan' or 'Sandra got the milk' but not both then John went to the hallway.",
        "valid"
    ],
    [
        0.4060167719920476,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '422'}",
        "It is almost certain that Brian is a lion. Chances are about even that Emily is a cat. It is probably the case that Mary went to the garden. There is little chance that if 'Brian is a lion and Mary went to the garden' then Lily is green. Chances are slight that if 'Brian is a lion' or 'Mary went to the garden' or both then John dropped the milk. It is improbable that if 'Mary went to the garden' or 'Emily is a cat' or both then Bernhard is a frog.",
        "valid"
    ],
    [
        0.405935600399971,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '214'}",
        "It is certain that Julius is a lion. It is certain that Brian is green. It is improbable that Bernhard is a rhino. It is highly unlikely that if either 'Julius is a lion' or 'Brian is green' but not both then Mary took the milk. It is unlikely that if either 'Julius is a lion' or 'Bernhard is a rhino' but not both then John went to the office. It is probable that if 'Brian is green and Julius is a lion' then Daniel got the apple.",
        "valid"
    ],
    [
        0.4059324810902278,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '526'}",
        "Chances are slight that Lily is a frog. There is little chance that Sumit is thirsty. It is probable that Greg is yellow. It is certain that if either 'Lily is a frog' or 'Sumit is thirsty' but not both then John moved to the garden. It is highly likely that if 'Lily is a frog' or 'Greg is yellow' or both then Julius is a rhino. There is almost no chance that if either 'Greg is yellow' or 'Lily is a frog' but not both then Bernhard is yellow.",
        "valid"
    ],
    [
        0.40589047968387604,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '518'}",
        "It is certain that either 'Daniel left the milk' or 'Brian is a frog' but not both.",
        "valid"
    ],
    [
        0.4058473159869512,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '929'}",
        "It is probable that Mary went to the hallway. Chances are slight that Brian is a lion. Chances are slight that Fred dropped the milk. It is impossible that if either 'Brian is a lion' or 'Mary went to the hallway' but not both then Julius is a swan. It is highly likely that if either 'Mary went to the hallway' or 'Brian is a lion' but not both then Greg is white. Chances are slight that if 'Fred dropped the milk' or 'Mary went to the hallway' or both then John moved to the office.",
        "valid"
    ],
    [
        0.40579546988010406,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '661'}",
        "It is probably not the case that 'Brian is green' or 'Julius is a lion' or both.",
        "valid"
    ],
    [
        0.40576306482156116,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '19'}",
        "It is probably not the case that 'Lily is a swan' or 'Brian is green' or both.",
        "valid"
    ],
    [
        0.4057407925526301,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '151'}",
        "There is almost no chance that either 'Lily is green' or 'Brian is a frog' but not both.",
        "valid"
    ],
    [
        0.405712828040123,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '869'}",
        "It is highly unlikely that Brian is white. It is improbable that Julius is a frog. It is probably not the case that John went to the office. It is highly likely that if 'John went to the office' or 'Brian is white' or both then Winona is a wolf. There is little chance that if 'Julius is a frog and Brian is white' then Mary dropped the apple. Chances are about even that if 'Brian is white and Julius is a frog' then Greg is a rhino.",
        "valid"
    ],
    [
        0.40570391714572906,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '407'}",
        "It is highly unlikely that Sandra got the milk. We believe that Brian is white. It is probable that Lily is a swan. Chances are about even that if 'Brian is white' or 'Sandra got the milk' or both then Jason is tired. There is a better than even chance that if 'Sandra got the milk and Brian is white' then Mary went to the bedroom. It is certain that if either 'Lily is a swan' or 'Sandra got the milk' but not both then Bernhard is a rhino.",
        "valid"
    ],
    [
        0.40569570163885754,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '41'}",
        "There is almost no chance that 'Brian is a frog' or 'Emily is a wolf' or both.",
        "valid"
    ],
    [
        0.4056604852279027,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '976'}",
        "We doubt that Julius is white. It is almost certain that Mary got the football. It is improbable that Lily is a lion. It is likely that if 'Mary got the football and Julius is white' then John discarded the apple. It is almost certain that if 'Julius is white and Mary got the football' then Bernhard is gray. There is little chance that if 'Mary got the football' or 'Lily is a lion' or both then Brian is yellow.",
        "valid"
    ],
    [
        0.40561772882938385,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '357'}",
        "It is probably the case that either 'Bill left the football' or 'Lily is a lion' but not both.",
        "valid"
    ],
    [
        0.405579353372256,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '750'}",
        "It is improbable that 'Greg is a frog' or 'Lily is a frog' or both.",
        "valid"
    ],
    [
        0.40548963844776154,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '763'}",
        "There is almost no chance that either 'Bernhard is white' or 'Lily is a frog' but not both.",
        "valid"
    ],
    [
        0.4054779162009557,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '435'}",
        "It is probably not the case that Lily is a rhino. It is highly unlikely that Mary discarded the milk. It is certain that Greg is a frog.",
        "valid"
    ],
    [
        0.4054318120082219,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '241'}",
        "It is probably the case that Mary discarded the milk. It is impossible that Greg is a frog. It is likely that Lily is a lion.",
        "valid"
    ],
    [
        0.4053436766068141,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '144'}",
        "There is little chance that John discarded the apple. It is highly likely that Brian is yellow. Chances are about even that Julius is a frog. It is probably not the case that if 'Julius is a frog' or 'John discarded the apple' or both then Lily is white. It is probably not the case that if either 'John discarded the apple' or 'Brian is yellow' but not both then Greg is a rhino. It is unlikely that if either 'Julius is a frog' or 'Brian is yellow' but not both then Emily is a wolf.",
        "valid"
    ],
    [
        0.4053429216146469,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '654'}",
        "It is probably not the case that Mary discarded the milk. Chances are about even that Gertrude is a cat. It is certain that Julius is a lion. It is impossible that if either 'Mary discarded the milk' or 'Julius is a lion' but not both then Lily is a rhino. It is improbable that if 'Gertrude is a cat' or 'Mary discarded the milk' or both then Bernhard is white. Chances are slight that if 'Julius is a lion' or 'Mary discarded the milk' or both then John moved to the office.",
        "valid"
    ],
    [
        0.4053203612565994,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '348'}",
        "It is improbable that John went to the kitchen. It is highly likely that Fred is in the cinema. There is a better than even chance that Greg is a frog. It is impossible that if 'John went to the kitchen and Greg is a frog' then Mary discarded the milk. It is probably not the case that if either 'Greg is a frog' or 'Fred is in the cinema' but not both then Lily is a lion. It is probable that if either 'Fred is in the cinema' or 'Greg is a frog' but not both then Bernhard is white.",
        "valid"
    ],
    [
        0.40523573259512585,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '381'}",
        "There is a very good chance that either 'Daniel put down the milk' or 'Brian is a swan' but not both.",
        "valid"
    ],
    [
        0.40508832037448883,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '802'}",
        "It is highly unlikely that Julius is white. There is a better than even chance that Lily is a lion. There is a very good chance that Mary went to the office. It is almost certain that if 'Mary went to the office' or 'Lily is a lion' or both then Bernhard is white. It is highly unlikely that if 'Mary went to the office' or 'Lily is a lion' or both then Jeff left the football. It is unlikely that if 'Julius is white' or 'Mary went to the office' or both then John got the milk.",
        "valid"
    ],
    [
        0.4050506502389908,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '921'}",
        "It is highly unlikely that Julius is a lion. There is a better than even chance that Mary put down the apple. We doubt that Fred is in the cinema. It is probably the case that if either 'Fred is in the cinema' or 'Julius is a lion' but not both then Bernhard is white. It is improbable that if 'Fred is in the cinema' or 'Mary put down the apple' or both then Jeff dropped the apple. There is almost no chance that if either 'Mary put down the apple' or 'Julius is a lion' but not both then Brian is a swan.",
        "valid"
    ],
    [
        0.40498094260692596,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '447'}",
        "There is almost no chance that either 'Daniel dropped the apple' or 'Greg is a lion' but not both.",
        "valid"
    ],
    [
        0.4049308846394221,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '742'}",
        "It is almost certain that Yann is bored. It is improbable that Greg is a rhino. It is highly unlikely that Brian is white. It is probably not the case that if 'Yann is bored' or 'Brian is white' or both then Daniel put down the milk. Chances are slight that if 'Yann is bored and Brian is white' then Julius is a frog. There is little chance that if 'Yann is bored and Greg is a rhino' then John went to the bedroom.",
        "valid"
    ],
    [
        0.40491971870263416,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '552'}",
        "It is probable that Bernhard is a swan. It is probably the case that Lily is a frog. It is highly likely that John went to the garden. It is almost certain that if 'John went to the garden and Lily is a frog' then Jeff discarded the milk. It is certain that if 'Bernhard is a swan' or 'Lily is a frog' or both then Brian is white. It is unlikely that if 'John went to the garden' or 'Lily is a frog' or both then Julius is gray.",
        "valid"
    ],
    [
        0.40473006665706635,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '419'}",
        "It is probably the case that Brian is gray. It is highly unlikely that Fred moved to the office. It is likely that Lily is a lion. We doubt that if 'Lily is a lion' or 'Brian is gray' or both then Greg is a swan. It is probably not the case that if 'Brian is gray and Fred moved to the office' then Daniel dropped the apple. It is certain that if 'Brian is gray and Lily is a lion' then Bernhard is green.",
        "valid"
    ],
    [
        0.4047042081753413,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '60'}",
        "It is highly unlikely that Brian is yellow. There is little chance that Daniel dropped the apple. It is improbable that Mary went to the kitchen. We doubt that if either 'Mary went to the kitchen' or 'Brian is yellow' but not both then Winona is a wolf. It is probably not the case that if either 'Daniel dropped the apple' or 'Brian is yellow' but not both then Lily is a frog. There is almost no chance that if 'Daniel dropped the apple' or 'Brian is yellow' or both then Greg is a swan.",
        "valid"
    ],
    [
        0.4046893169482549,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '607'}",
        "It is highly unlikely that either 'Lily is green' or 'Brian is a frog' but not both.",
        "valid"
    ],
    [
        0.404686763882637,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '781'}",
        "It is probably not the case that either 'Emily is a sheep' or 'Brian is a rhino' but not both.",
        "valid"
    ],
    [
        0.40466353793938953,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '736'}",
        "Chances are slight that Emily is a sheep. We believe that Bernhard is a rhino. It is impossible that Greg is a frog. It is probable that if 'Greg is a frog and Emily is a sheep' then John moved to the garden. Chances are slight that if 'Greg is a frog and Emily is a sheep' then Brian is white. There is almost no chance that if 'Bernhard is a rhino' or 'Greg is a frog' or both then Mary went to the bedroom.",
        "valid"
    ],
    [
        0.40466223657131195,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '76'}",
        "We doubt that John is in the garden. Chances are about even that Julius is a lion. We believe that Mary picked up the milk. It is impossible that if 'Mary picked up the milk and John is in the garden' then Jessica is a mouse. There is a better than even chance that if either 'John is in the garden' or 'Julius is a lion' but not both then Bernhard is a frog. It is highly unlikely that if 'John is in the garden and Julius is a lion' then Greg is a rhino.",
        "valid"
    ],
    [
        0.40461940069993335,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '731'}",
        "'Greg is a swan' or 'Lily is a frog' or both.",
        "valid"
    ],
    [
        0.4045899659395218,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '6'}",
        "It is impossible that John dropped the apple. There is a better than even chance that Daniel got the milk. There is almost no chance that Lily is a lion. It is probably the case that if 'John dropped the apple and Daniel got the milk' then Jeff discarded the milk. We doubt that if 'John dropped the apple and Daniel got the milk' then Mary went to the garden. There is a very good chance that if 'Daniel got the milk and Lily is a lion' then Greg is gray.",
        "valid"
    ],
    [
        0.4045777867237727,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '712'}",
        "It is highly unlikely that 'Julius is a lion' or 'Brian is yellow' or both.",
        "valid"
    ],
    [
        0.4044838299353917,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '83'}",
        "We doubt that John discarded the milk. It is probably the case that Brian is gray. It is unlikely that Emily is a sheep. It is certain that if either 'Emily is a sheep' or 'John discarded the milk' but not both then Mary moved to the garden. It is highly unlikely that if 'John discarded the milk' or 'Brian is gray' or both then Bernhard is a frog. It is almost certain that if either 'John discarded the milk' or 'Brian is gray' but not both then Lily is white.",
        "valid"
    ],
    [
        0.4044276823600133,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '250'}",
        "There is a very good chance that Sandra took the football. It is unlikely that Greg is a frog. It is certain that Brian is a rhino. It is unlikely that if 'Brian is a rhino and Greg is a frog' then Julius is white. It is probably the case that if 'Sandra took the football' or 'Greg is a frog' or both then Jason is thirsty. It is impossible that if 'Greg is a frog' or 'Sandra took the football' or both then John went to the bedroom.",
        "valid"
    ],
    [
        0.4044195959965388,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '847'}",
        "There is little chance that Brian is green. It is almost certain that Julius is a swan. We believe that Greg is a swan. It is almost certain that if 'Brian is green' or 'Greg is a swan' or both then Lily is yellow. It is probable that if 'Brian is green and Greg is a swan' then Winona is a mouse. It is impossible that if 'Julius is a swan and Brian is green' then Mary took the milk.",
        "valid"
    ],
    [
        0.40437277654806775,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '131'}",
        "There is little chance that Winona is a mouse. We doubt that Brian is gray. It is unlikely that Julius is a swan. It is unlikely that if 'Winona is a mouse' or 'Julius is a swan' or both then Jason is tired. We believe that if 'Brian is gray and Julius is a swan' then John went to the office. It is highly likely that if 'Julius is a swan and Brian is gray' then Bernhard is a rhino.",
        "valid"
    ],
    [
        0.40429632862408954,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '590'}",
        "There is little chance that Jeff discarded the milk. It is likely that Mary went to the garden. It is impossible that Lily is a frog. It is probable that if 'Mary went to the garden' or 'Jeff discarded the milk' or both then Winona is a mouse. There is almost no chance that if 'Lily is a frog' or 'Mary went to the garden' or both then Daniel took the football. There is a better than even chance that if 'Mary went to the garden' or 'Lily is a frog' or both then Antoine is hungry.",
        "valid"
    ],
    [
        0.4041370203097661,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '584'}",
        "Chances are about even that Mary grabbed the milk. It is probably not the case that Julius is white. It is improbable that Brian is green. There is a very good chance that if 'Brian is green' or 'Julius is white' or both then Greg is a swan. There is almost no chance that if 'Mary grabbed the milk and Brian is green' then Lily is a lion. It is improbable that if 'Julius is white' or 'Mary grabbed the milk' or both then John left the apple.",
        "valid"
    ],
    [
        0.4040784537792206,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '141'}",
        "There is a better than even chance that Daniel left the milk. There is little chance that Greg is a rhino. Chances are slight that Julius is a frog. It is almost certain that if 'Julius is a frog' or 'Daniel left the milk' or both then Bill went to the garden. It is probable that if either 'Julius is a frog' or 'Daniel left the milk' but not both then Gertrude is a wolf. There is a very good chance that if 'Greg is a rhino and Daniel left the milk' then John moved to the office.",
        "valid"
    ],
    [
        0.4040695130825043,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '390'}",
        "There is a better than even chance that Mary went to the office. There is a better than even chance that Julius is a lion. There is little chance that John took the apple. It is impossible that if 'John took the apple' or 'Julius is a lion' or both then Bill left the milk. It is probable that if either 'John took the apple' or 'Julius is a lion' but not both then Lily is a swan. It is highly unlikely that if either 'Mary went to the office' or 'John took the apple' but not both then Greg is a rhino.",
        "valid"
    ],
    [
        0.40405772626399994,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '378'}",
        "Chances are slight that Bill moved to the office. It is highly likely that Daniel took the milk. It is probably the case that Julius is a swan. Chances are slight that if 'Bill moved to the office' or 'Julius is a swan' or both then Lily is a frog. It is probable that if 'Bill moved to the office' or 'Daniel took the milk' or both then Brian is white. It is unlikely that if 'Daniel took the milk' or 'Julius is a swan' or both then Sandra left the football.",
        "valid"
    ],
    [
        0.4038121650616328,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '292'}",
        "It is likely that Winona is a mouse. Chances are about even that Lily is a swan. It is impossible that Bernhard is yellow. There is a better than even chance that if 'Winona is a mouse' or 'Bernhard is yellow' or both then Julius is gray. It is certain that if 'Winona is a mouse and Bernhard is yellow' then Mary left the football. It is almost certain that if 'Bernhard is yellow and Lily is a swan' then Brian is green.",
        "valid"
    ],
    [
        0.4037158985932668,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '545'}",
        "There is a better than even chance that John got the apple. It is likely that Lily is a frog. There is a very good chance that Mary discarded the milk. There is almost no chance that if 'John got the apple and Lily is a frog' then Greg is a swan. There is a better than even chance that if 'Lily is a frog' or 'Mary discarded the milk' or both then Jeff moved to the office. We doubt that if either 'Lily is a frog' or 'John got the apple' but not both then Brian is gray.",
        "valid"
    ],
    [
        0.40371077756086987,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '26'}",
        "It is highly likely that Emily is a sheep. It is certain that Julius is white. It is probably not the case that Mary left the milk. It is probably not the case that if 'Mary left the milk and Julius is white' then Bernhard is green. We believe that if either 'Mary left the milk' or 'Julius is white' but not both then John discarded the apple. It is probable that if 'Mary left the milk and Emily is a sheep' then Lily is a lion.",
        "valid"
    ],
    [
        0.40370604892571765,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '864'}",
        "It is impossible that Brian is yellow. We believe that Julius is a frog. It is highly likely that Mary got the apple. There is almost no chance that if 'Brian is yellow and Julius is a frog' then Lily is green. It is likely that if 'Brian is yellow and Mary got the apple' then Daniel took the football. It is unlikely that if 'Julius is a frog and Brian is yellow' then Bernhard is a swan.",
        "valid"
    ],
    [
        0.4036416361729304,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '821'}",
        "It is highly likely that Jessica is a sheep. It is probably the case that Mary left the football. There is a better than even chance that Brian is white. Chances are about even that if 'Mary left the football' or 'Jessica is a sheep' or both then Gertrude is a mouse. It is certain that if 'Jessica is a sheep' or 'Brian is white' or both then Fred dropped the apple. It is improbable that if either 'Jessica is a sheep' or 'Brian is white' but not both then Julius is a swan.",
        "valid"
    ],
    [
        0.40352971355120343,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '910'}",
        "It is highly unlikely that Julius is a swan. It is probably the case that Sandra left the milk. It is highly unlikely that Gertrude is a cat. It is highly unlikely that if 'Julius is a swan and Gertrude is a cat' then Greg is yellow. It is probably not the case that if 'Gertrude is a cat' or 'Sandra left the milk' or both then Lily is a lion. It is probably not the case that if either 'Julius is a swan' or 'Gertrude is a cat' but not both then Brian is gray.",
        "valid"
    ],
    [
        0.4034864554802577,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '241'}",
        "Chances are slight that John put down the milk. It is probable that Jeff moved to the garden. Chances are about even that Greg is a lion. We believe that if either 'Jeff moved to the garden' or 'Greg is a lion' but not both then Brian is a frog. It is improbable that if either 'Greg is a lion' or 'John put down the milk' but not both then Jessica is a cat. It is certain that if 'John put down the milk and Greg is a lion' then Julius is a swan.",
        "valid"
    ],
    [
        0.40340620776017505,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '584'}",
        "There is almost no chance that either 'Brian is white' or 'Julius is gray' but not both.",
        "valid"
    ],
    [
        0.403354749083519,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '351'}",
        "It is improbable that Fred went to the garden. It is improbable that Brian is a lion. It is unlikely that Greg is gray. It is improbable that if either 'Fred went to the garden' or 'Greg is gray' but not both then Daniel got the apple. There is almost no chance that if 'Brian is a lion and Fred went to the garden' then Mary left the milk. It is impossible that if 'Fred went to the garden and Brian is a lion' then John moved to the office.",
        "valid"
    ],
    [
        0.40332359572251636,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '270'}",
        "There is almost no chance that either 'Fred is in the school' or 'Lily is a rhino' but not both.",
        "valid"
    ],
    [
        0.4033138304948807,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '846'}",
        "It is improbable that Emily is a sheep. Chances are about even that Greg is a swan. Chances are about even that Brian is yellow. It is probable that if 'Greg is a swan and Emily is a sheep' then Bernhard is white. It is probable that if either 'Greg is a swan' or 'Emily is a sheep' but not both then Mary went to the kitchen. There is almost no chance that if either 'Greg is a swan' or 'Emily is a sheep' but not both then John took the apple.",
        "valid"
    ],
    [
        0.4032471130291621,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '189'}",
        "It is impossible that 'Lily is a rhino' or 'Mary took the football' or both.",
        "valid"
    ],
    [
        0.40323573847611743,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '889'}",
        "It is certain that Julius is a frog. It is probably not the case that Mary is in the bathroom. It is almost certain that Sumit is bored. It is impossible that if 'Julius is a frog and Sumit is bored' then Brian is a swan. There is a very good chance that if 'Mary is in the bathroom' or 'Julius is a frog' or both then Jessica is a sheep. We doubt that if 'Julius is a frog' or 'Mary is in the bathroom' or both then John moved to the garden.",
        "valid"
    ],
    [
        0.403188556432724,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '641'}",
        "It is probably not the case that Julius is a rhino. There is a better than even chance that Mary dropped the milk. Chances are slight that Daniel took the apple. There is little chance that if 'Julius is a rhino and Mary dropped the milk' then Fred went to the garden. There is a better than even chance that if 'Mary dropped the milk' or 'Julius is a rhino' or both then Lily is a lion. It is highly unlikely that if 'Mary dropped the milk' or 'Julius is a rhino' or both then Bernhard is green.",
        "valid"
    ],
    [
        0.4031767596801122,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '751'}",
        "It is likely that Julius is white. Chances are about even that Lily is gray. It is almost certain that Brian is yellow. There is almost no chance that if 'Lily is gray and Brian is yellow' then Bernhard is gray. It is highly likely that if 'Julius is white and Lily is gray' then Daniel got the milk. It is highly likely that if 'Julius is white' or 'Lily is gray' or both then John went to the kitchen.",
        "valid"
    ],
    [
        0.4031423230965932,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '216'}",
        "There is a better than even chance that Jessica is a cat. It is impossible that Brian is a frog. It is probable that Mary moved to the office. We believe that if 'Mary moved to the office and Jessica is a cat' then Bernhard is white. It is probably not the case that if 'Brian is a frog' or 'Mary moved to the office' or both then John picked up the apple. It is highly likely that if either 'Mary moved to the office' or 'Brian is a frog' but not both then Lily is a swan.",
        "valid"
    ],
    [
        0.40309422711531323,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '575'}",
        "It is probably not the case that Julius is a swan. It is unlikely that Winona is a mouse. It is probably not the case that Fred moved to the office. There is a very good chance that if either 'Fred moved to the office' or 'Julius is a swan' but not both then Brian is yellow. Chances are about even that if 'Winona is a mouse and Fred moved to the office' then Mary took the football. It is impossible that if either 'Fred moved to the office' or 'Julius is a swan' but not both then John dropped the milk.",
        "valid"
    ],
    [
        0.40306968490282696,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '518'}",
        "It is likely that Lily is a swan. It is highly likely that Bernhard is a rhino. There is little chance that Yann is hungry. Chances are about even that if 'Bernhard is a rhino and Yann is hungry' then Jessica is a cat. There is a better than even chance that if 'Lily is a swan' or 'Bernhard is a rhino' or both then Brian is a lion. We believe that if either 'Yann is hungry' or 'Lily is a swan' but not both then Mary moved to the garden.",
        "valid"
    ],
    [
        0.40304792920748395,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '509'}",
        "There is a better than even chance that Bernhard is a rhino. Chances are slight that John got the apple. There is a better than even chance that Brian is a frog. There is a very good chance that if 'Bernhard is a rhino' or 'Brian is a frog' or both then Mary took the milk. It is highly unlikely that if 'John got the apple' or 'Bernhard is a rhino' or both then Greg is a swan. It is unlikely that if either 'John got the apple' or 'Bernhard is a rhino' but not both then Emily is a mouse.",
        "valid"
    ],
    [
        0.40296338498592377,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '322'}",
        "There is a better than even chance that Greg is yellow. It is probably the case that Bernhard is white. It is highly likely that Julius is a swan. It is unlikely that if 'Greg is yellow and Bernhard is white' then Mary moved to the garden. We believe that if either 'Bernhard is white' or 'Julius is a swan' but not both then Lily is a lion. It is probably the case that if 'Bernhard is white' or 'Greg is yellow' or both then Sandra left the apple.",
        "valid"
    ],
    [
        0.40295619269212085,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '378'}",
        "It is impossible that Lily is gray. It is probably the case that Julius is a frog. It is almost certain that Mary discarded the milk.",
        "valid"
    ],
    [
        0.4029506395260493,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '337'}",
        "It is almost certain that Bernhard is a frog. It is highly likely that Jason is tired. It is certain that Brian is white. It is probably the case that if either 'Jason is tired' or 'Brian is white' but not both then Julius is a swan. It is highly unlikely that if either 'Brian is white' or 'Bernhard is a frog' but not both then Mary went to the kitchen. There is a very good chance that if 'Brian is white and Jason is tired' then Sandra got the football.",
        "valid"
    ],
    [
        0.4029375414053599,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '410'}",
        "We believe that Julius is gray. It is impossible that Mary went to the kitchen. It is probably not the case that Bill got the milk there. It is probably the case that if 'Bill got the milk there' or 'Mary went to the kitchen' or both then Bernhard is gray. It is certain that if 'Julius is gray' or 'Mary went to the kitchen' or both then Brian is white. There is a better than even chance that if either 'Julius is gray' or 'Bill got the milk there' but not both then Jeff moved to the office.",
        "valid"
    ],
    [
        0.40291036168734234,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '663'}",
        "It is unlikely that Lily is a swan. There is little chance that John discarded the apple. It is highly unlikely that Brian is a lion. There is almost no chance that if 'Brian is a lion and John discarded the apple' then Bernhard is green. It is probably the case that if 'Lily is a swan and Brian is a lion' then Sandra dropped the milk. It is highly likely that if 'Brian is a lion and John discarded the apple' then Mary left the football.",
        "valid"
    ],
    [
        0.40290599564711255,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '948'}",
        "It is almost certain that John moved to the office. It is likely that Lily is a lion. We believe that Mary took the milk. It is probably the case that if 'Lily is a lion and John moved to the office' then Greg is white. It is highly unlikely that if 'John moved to the office and Lily is a lion' then Brian is yellow. There is little chance that if 'Mary took the milk' or 'Lily is a lion' or both then Fred is in the school.",
        "valid"
    ],
    [
        0.4029002437988917,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '925'}",
        "It is impossible that either 'Lily is a rhino' or 'John dropped the apple' but not both.",
        "valid"
    ],
    [
        0.40286608040332794,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '921'}",
        "It is probably not the case that 'John dropped the milk' or 'Lily is a lion' or both.",
        "valid"
    ],
    [
        0.4027975747982661,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '598'}",
        "It is certain that Mary left the football. It is probably not the case that Lily is a frog. There is little chance that Brian is green. It is unlikely that if either 'Lily is a frog' or 'Brian is green' but not both then Julius is gray. There is little chance that if either 'Mary left the football' or 'Brian is green' but not both then Gertrude is a mouse. Chances are slight that if 'Lily is a frog and Brian is green' then Greg is a lion.",
        "valid"
    ],
    [
        0.4027945895989736,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '438'}",
        "We doubt that Sandra left the milk. Chances are slight that Brian is white. It is probably not the case that Greg is yellow. It is highly unlikely that if 'Brian is white' or 'Greg is yellow' or both then Lily is a lion. There is almost no chance that if 'Greg is yellow' or 'Brian is white' or both then Fred went to the garden. It is improbable that if 'Greg is yellow' or 'Sandra left the milk' or both then Mary moved to the office.",
        "valid"
    ],
    [
        0.40273893376191455,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '668'}",
        "It is probably the case that Mary went to the garden. There is little chance that Bernhard is a lion. It is improbable that Lily is a frog. There is little chance that if 'Bernhard is a lion and Mary went to the garden' then Winona is a mouse. It is probably not the case that if 'Mary went to the garden and Lily is a frog' then Daniel grabbed the apple. It is probably the case that if 'Lily is a frog' or 'Mary went to the garden' or both then Julius is yellow.",
        "valid"
    ],
    [
        0.402715598543485,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '267'}",
        "We doubt that Mary went to the office. It is almost certain that Julius is a lion. It is impossible that Winona is a sheep. We doubt that if 'Winona is a sheep' or 'Mary went to the office' or both then John took the apple. It is unlikely that if 'Winona is a sheep and Julius is a lion' then Sandra dropped the milk. It is probably the case that if 'Winona is a sheep and Mary went to the office' then Brian is a swan.",
        "valid"
    ],
    [
        0.4027136266231537,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '224'}",
        "There is little chance that Antoine is thirsty. It is almost certain that Mary discarded the milk. Chances are slight that John took the football. It is improbable that if either 'John took the football' or 'Mary discarded the milk' but not both then Brian is white. There is a better than even chance that if 'John took the football' or 'Mary discarded the milk' or both then Winona is a sheep. It is highly likely that if 'Mary discarded the milk and John took the football' then Greg is a lion.",
        "valid"
    ],
    [
        0.40267487863699597,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '762'}",
        "It is impossible that 'Julius is a rhino' or 'Greg is white' or both.",
        "valid"
    ],
    [
        0.40263808767000836,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '139'}",
        "It is impossible that Mary discarded the milk. Chances are about even that Lily is green. There is little chance that Daniel dropped the apple. There is almost no chance that if 'Lily is green and Daniel dropped the apple' then Brian is white. There is little chance that if either 'Lily is green' or 'Daniel dropped the apple' but not both then John got the football. It is probable that if 'Mary discarded the milk' or 'Daniel dropped the apple' or both then Bernhard is a rhino.",
        "valid"
    ],
    [
        0.4026312579711278,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '896'}",
        "We doubt that Lily is green. It is probably not the case that Julius is a swan. It is probably the case that Mary dropped the milk. It is probable that if 'Mary dropped the milk' or 'Julius is a swan' or both then Greg is white. It is impossible that if 'Lily is green and Mary dropped the milk' then Bernhard is a lion. Chances are about even that if 'Julius is a swan' or 'Mary dropped the milk' or both then Brian is green.",
        "valid"
    ],
    [
        0.40260695417722064,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '158'}",
        "It is impossible that Julius is gray. It is certain that John went to the office. It is probably not the case that Mary got the football. It is improbable that if 'Mary got the football' or 'Julius is gray' or both then Brian is green. We believe that if 'Julius is gray' or 'Mary got the football' or both then Lily is gray. It is almost certain that if either 'John went to the office' or 'Julius is gray' but not both then Daniel dropped the milk.",
        "valid"
    ],
    [
        0.40255499879519147,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '941'}",
        "It is probably the case that Brian is gray. There is a very good chance that Gertrude is a sheep. Chances are about even that Daniel left the apple. It is almost certain that if either 'Daniel left the apple' or 'Gertrude is a sheep' but not both then Jeff went to the bedroom. Chances are about even that if 'Brian is gray' or 'Daniel left the apple' or both then Julius is a rhino. We believe that if either 'Gertrude is a sheep' or 'Brian is gray' but not both then Greg is gray.",
        "valid"
    ],
    [
        0.40254488090674084,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '116'}",
        "Chances are slight that Brian is a lion. It is likely that John went to the bedroom. It is probable that Mary took the football. It is certain that if 'John went to the bedroom' or 'Brian is a lion' or both then Bernhard is green. We believe that if 'Mary took the football and John went to the bedroom' then Winona is a wolf. There is almost no chance that if either 'Mary took the football' or 'Brian is a lion' but not both then Greg is a frog.",
        "valid"
    ],
    [
        0.4025251418352127,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '887'}",
        "It is probably not the case that Julius is a swan. It is improbable that John went to the kitchen. It is highly unlikely that Bill moved to the office. It is impossible that if either 'John went to the kitchen' or 'Julius is a swan' but not both then Gertrude is a cat. There is a very good chance that if 'John went to the kitchen' or 'Bill moved to the office' or both then Mary picked up the milk. It is highly unlikely that if 'Julius is a swan' or 'John went to the kitchen' or both then Lily is yellow.",
        "valid"
    ],
    [
        0.402425875266393,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '393'}",
        "It is impossible that Emily is a sheep. It is probably the case that Bernhard is yellow. It is probably not the case that Greg is yellow. It is certain that if 'Bernhard is yellow and Greg is yellow' then Lily is a rhino. There is a very good chance that if 'Greg is yellow and Emily is a sheep' then Brian is a frog. It is likely that if 'Bernhard is yellow and Greg is yellow' then Sandra dropped the milk.",
        "valid"
    ],
    [
        0.40239909291267395,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '245'}",
        "It is certain that Bill went to the kitchen. There is little chance that Brian is a frog. It is certain that John picked up the milk. There is a better than even chance that if 'Bill went to the kitchen' or 'John picked up the milk' or both then Lily is white. It is highly unlikely that if 'Brian is a frog and Bill went to the kitchen' then Fred is in the school. It is highly unlikely that if either 'Bill went to the kitchen' or 'Brian is a frog' but not both then Jeff dropped the apple.",
        "valid"
    ],
    [
        0.402380312482516,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '582'}",
        "We doubt that either 'Brian is a lion' or 'Jessica is a mouse' but not both.",
        "valid"
    ],
    [
        0.40235309302806854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '172'}",
        "There is a very good chance that Jessica is a mouse. We doubt that Bernhard is a frog. It is likely that Greg is a lion. Chances are slight that if 'Greg is a lion and Jessica is a mouse' then Lily is a rhino. There is almost no chance that if 'Jessica is a mouse and Greg is a lion' then John took the apple. There is a very good chance that if 'Jessica is a mouse and Greg is a lion' then Mary went to the garden.",
        "valid"
    ],
    [
        0.4023510167996089,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '812'}",
        "It is impossible that Brian is a swan. There is almost no chance that Greg is white. It is almost certain that Mary left the apple.",
        "valid"
    ],
    [
        0.4022505184014638,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '670'}",
        "It is improbable that Bernhard is yellow. We doubt that Brian is white. We believe that John picked up the apple. We doubt that if either 'Brian is white' or 'John picked up the apple' but not both then Gertrude is a cat. It is probably not the case that if 'John picked up the apple and Brian is white' then Winona is a sheep. Chances are about even that if 'John picked up the apple and Brian is white' then Greg is a swan.",
        "valid"
    ],
    [
        0.40217360854148865,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '901'}",
        "It is probably not the case that either 'Brian is a lion' or 'Sandra left the apple' but not both.",
        "valid"
    ],
    [
        0.40210116902987164,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '952'}",
        "(1) Двое друзей, Леандр и Криспин, приходят в незнакомый городок. (2) Положение их довольно затруднительно, поскольку они совершенно без денег. (3) Криспин, более изворотливый и неунывающий, нежели Леандр, исполнен решимости раздобыть денег и даже разбогатеть, для чего предлагает дерзкий план. (4) Леандр должен выдать себя за богатого и знатного человека, приехавшего в город по важному государственному делу, а об остальном под видом его слуги позаботится Криспин. (5) Леандру не очень по душе эта затея: его пугают возможные последствия подобного обмана, но он сдаётся перед настойчивостью приятеля, понимая, что положение у них безвыходное. (6) Друзья стучатся в дверь гостиницы и просят лучшие комнаты и обильный ужин. (7) Хозяин сначала относится к ним недоверчиво, но заносчивость Криспина и его напористость убеждают трактирщика, что перед ним важные господа. (8) Вскоре приходят Арлекин, местный поэт, и его Друг Капитан. (9) Не один раз они ели в долг в этой гостинице и надеются поужинать тут и сегодня. (10) Однако терпение трактирщика иссякло, и он отказывается их кормить. (11) Сметливый Криспин решает привлечь Арлекина и Капитана на свою сторону, делая вид, что ему известны блестящие стихи Арлекина и смелые подвиги Капитана. (12) Он тут же приказывает накормить Арлекина и Капитана ужином за счёт Леандра, и трактирщик не смеет отказать: он уже усвоил, что этим знатным господам ни в чём нельзя перечить.",
        "Нерешительный."
    ],
    [
        0.40207970639069873,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '411'}",
        "It is impossible that Brian is a frog. It is almost certain that Daniel dropped the milk. We doubt that Bernhard is white.",
        "valid"
    ],
    [
        0.40204056600729626,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '539'}",
        "There is almost no chance that either 'Lily is gray' or 'Jessica is a sheep' but not both.",
        "valid"
    ],
    [
        0.40202797452608746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '307'}",
        "Chances are slight that John went to the garden. It is likely that Daniel got the apple. It is probable that Winona is a sheep. We believe that if 'Winona is a sheep and John went to the garden' then Bernhard is a swan. Chances are about even that if 'Winona is a sheep' or 'John went to the garden' or both then Lily is a frog. We doubt that if 'Winona is a sheep' or 'Daniel got the apple' or both then Emily is a wolf.",
        "valid"
    ],
    [
        0.40192383031050366,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '574'}",
        "It is unlikely that Brian is a swan. There is a better than even chance that Daniel left the milk. It is probably the case that John put down the apple. There is a very good chance that if 'Daniel left the milk' or 'John put down the apple' or both then Bernhard is green. There is a very good chance that if 'Brian is a swan and Daniel left the milk' then Mary dropped the milk. Chances are slight that if 'Brian is a swan and John put down the apple' then Lily is yellow.",
        "valid"
    ],
    [
        0.4018775125344594,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '2'}",
        "It is almost certain that Brian is a rhino. It is probably not the case that Lily is a lion. It is highly likely that Jeff went to the garden.",
        "valid"
    ],
    [
        0.4018639226754506,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '266'}",
        "There is little chance that Julius is a swan. It is likely that John dropped the apple. It is probably not the case that Bernhard is a lion. We believe that if 'Julius is a swan' or 'John dropped the apple' or both then Daniel left the milk. It is probably the case that if 'Julius is a swan' or 'Bernhard is a lion' or both then Sandra took the milk. It is probably not the case that if either 'Bernhard is a lion' or 'Julius is a swan' but not both then Jeff moved to the garden.",
        "valid"
    ],
    [
        0.40185897052288055,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '445'}",
        "It is unlikely that Lily is green. It is probable that Bernhard is gray. It is highly unlikely that Brian is a lion. There is a very good chance that if either 'Lily is green' or 'Brian is a lion' but not both then Julius is yellow. It is impossible that if 'Lily is green' or 'Bernhard is gray' or both then Mary went to the garden. Chances are about even that if 'Bernhard is gray and Lily is green' then Greg is a swan.",
        "valid"
    ],
    [
        0.40184226135412854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '916'}",
        "Chances are about even that Jessica is a mouse. Chances are about even that Lily is gray. It is certain that Mary went to the garden. It is impossible that if either 'Lily is gray' or 'Mary went to the garden' but not both then Sandra left the football. It is highly unlikely that if 'Lily is gray' or 'Mary went to the garden' or both then Greg is yellow. It is improbable that if 'Lily is gray and Jessica is a mouse' then Julius is a lion.",
        "valid"
    ],
    [
        0.40179936587810516,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '415'}",
        "It is probably not the case that Lily is a rhino. It is probably not the case that Mary dropped the milk. There is almost no chance that Daniel grabbed the milk.",
        "valid"
    ],
    [
        0.40178413192431134,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '507'}",
        "It is unlikely that either 'Bernhard is gray' or 'Lily is a lion' but not both.",
        "valid"
    ],
    [
        0.40176436801751453,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '733'}",
        "It is likely that John went to the hallway. It is probable that Greg is a rhino. We believe that Mary put down the apple. It is probably not the case that if either 'Mary put down the apple' or 'Greg is a rhino' but not both then Bernhard is white. There is little chance that if either 'John went to the hallway' or 'Greg is a rhino' but not both then Brian is a lion. It is unlikely that if 'Greg is a rhino and John went to the hallway' then Lily is a frog.",
        "valid"
    ],
    [
        0.4017480711142222,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '570'}",
        "There is a better than even chance that John dropped the apple. There is a better than even chance that Bernhard is a lion. It is probable that Julius is a swan. It is unlikely that if 'Julius is a swan and Bernhard is a lion' then Mary went to the bedroom. It is improbable that if either 'Bernhard is a lion' or 'John dropped the apple' but not both then Brian is a frog. There is a very good chance that if either 'John dropped the apple' or 'Julius is a swan' but not both then Lily is a rhino.",
        "valid"
    ],
    [
        0.4017024089892705,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '784'}",
        "It is improbable that Greg is a frog. There is a very good chance that Julius is a swan. There is little chance that John moved to the office. It is certain that if 'John moved to the office and Greg is a frog' then Lily is gray. It is probably the case that if 'Greg is a frog and John moved to the office' then Jessica is a cat. It is certain that if 'Julius is a swan' or 'Greg is a frog' or both then Brian is a lion.",
        "valid"
    ],
    [
        0.4016844282547633,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '671'}",
        "It is impossible that 'Greg is a rhino' or 'Brian is yellow' or both.",
        "valid"
    ],
    [
        0.40168005724747974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '477'}",
        "It is probably the case that Greg is white. We believe that Jessica is a mouse. There is little chance that Mary left the football. There is almost no chance that if either 'Jessica is a mouse' or 'Greg is white' but not both then Julius is a swan. It is certain that if either 'Mary left the football' or 'Greg is white' but not both then Winona is a sheep. It is unlikely that if either 'Greg is white' or 'Jessica is a mouse' but not both then John dropped the apple.",
        "valid"
    ],
    [
        0.40165957311789197,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '165'}",
        "It is certain that Mary picked up the milk. Chances are about even that Brian is a frog. It is certain that Sandra left the milk. It is certain that if 'Sandra left the milk and Brian is a frog' then Julius is a swan. It is probable that if either 'Mary picked up the milk' or 'Brian is a frog' but not both then Bernhard is green. It is certain that if either 'Brian is a frog' or 'Mary picked up the milk' but not both then Jeff went to the hallway.",
        "valid"
    ],
    [
        0.4016485462586085,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '753'}",
        "It is highly likely that Greg is gray. There is a better than even chance that Mary left the milk. It is likely that Brian is green. It is highly likely that if 'Brian is green' or 'Greg is gray' or both then Jeff dropped the apple. It is certain that if either 'Brian is green' or 'Greg is gray' but not both then Julius is a rhino. It is probably not the case that if 'Brian is green and Mary left the milk' then Lily is a swan.",
        "valid"
    ],
    [
        0.4015579770008723,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '571'}",
        "It is improbable that Bernhard is a lion. It is unlikely that Mary went to the garden. There is almost no chance that Brian is white. It is likely that if either 'Mary went to the garden' or 'Bernhard is a lion' but not both then Sandra took the milk. It is probably the case that if either 'Bernhard is a lion' or 'Mary went to the garden' but not both then John put down the apple. It is highly likely that if 'Brian is white' or 'Bernhard is a lion' or both then Jessica is a cat.",
        "valid"
    ],
    [
        0.4015255620082219,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '89'}",
        "There is a very good chance that Greg is a frog. It is likely that Gertrude is a mouse. There is little chance that Lily is white. There is a better than even chance that if either 'Gertrude is a mouse' or 'Greg is a frog' but not both then John got the apple. Chances are slight that if either 'Greg is a frog' or 'Lily is white' but not both then Yann is hungry. It is almost certain that if 'Gertrude is a mouse and Greg is a frog' then Brian is gray.",
        "valid"
    ],
    [
        0.4015202174584071,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '380'}",
        "It is unlikely that 'Winona is a mouse' or 'Brian is a rhino' or both.",
        "valid"
    ],
    [
        0.4015132933855057,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '217'}",
        "There is a better than even chance that Mary grabbed the milk. It is certain that Julius is green. It is improbable that Jessica is a cat. It is probably not the case that if either 'Jessica is a cat' or 'Julius is green' but not both then Brian is a frog. It is impossible that if either 'Mary grabbed the milk' or 'Julius is green' but not both then Lily is a rhino. It is impossible that if 'Mary grabbed the milk' or 'Julius is green' or both then John moved to the garden.",
        "valid"
    ],
    [
        0.4014198233683904,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '152'}",
        "There is almost no chance that 'Julius is gray' or 'Brian is a rhino' or both.",
        "valid"
    ],
    [
        0.4014098346233368,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '683'}",
        "It is improbable that Mary left the milk. It is impossible that Jessica is a cat. We doubt that Brian is gray. It is certain that if 'Jessica is a cat' or 'Brian is gray' or both then John went to the garden. It is certain that if 'Jessica is a cat' or 'Brian is gray' or both then Julius is white. We doubt that if 'Jessica is a cat' or 'Mary left the milk' or both then Lily is green.",
        "valid"
    ],
    [
        0.4013974815607071,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '319'}",
        "There is almost no chance that Gertrude is a sheep. It is probable that Julius is a frog. It is probably the case that John took the apple. It is almost certain that if either 'John took the apple' or 'Gertrude is a sheep' but not both then Lily is a rhino. It is probably the case that if 'Gertrude is a sheep and John took the apple' then Mary went to the kitchen. It is probably not the case that if 'Gertrude is a sheep' or 'John took the apple' or both then Jessica is a cat.",
        "valid"
    ],
    [
        0.4013895442088445,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '791'}",
        "It is improbable that Lily is gray. There is a very good chance that Mary picked up the milk. It is impossible that Brian is a rhino.",
        "valid"
    ],
    [
        0.4013807624578476,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '40'}",
        "There is a better than even chance that John took the milk. It is probably not the case that Bernhard is yellow. It is certain that Brian is a rhino. It is probably the case that if 'Bernhard is yellow' or 'John took the milk' or both then Mary moved to the garden. It is improbable that if 'John took the milk' or 'Bernhard is yellow' or both then Greg is a lion. It is highly unlikely that if either 'John took the milk' or 'Bernhard is yellow' but not both then Winona is a mouse.",
        "valid"
    ],
    [
        0.40134860078493756,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '615'}",
        "It is almost certain that Sandra dropped the milk. Chances are slight that Greg is a lion. It is impossible that Brian is yellow. There is a better than even chance that if 'Sandra dropped the milk and Brian is yellow' then Bernhard is a rhino. It is unlikely that if either 'Brian is yellow' or 'Greg is a lion' but not both then Julius is a swan. It is certain that if 'Sandra dropped the milk' or 'Brian is yellow' or both then Mary moved to the office.",
        "valid"
    ],
    [
        0.4013241430123647,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '680'}",
        "It is highly unlikely that 'Julius is a lion' or 'Bernhard is white' or both.",
        "valid"
    ],
    [
        0.40132225553194684,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '109'}",
        "It is certain that Bernhard is gray. It is probably the case that John put down the apple. There is almost no chance that Lily is white. It is almost certain that if 'John put down the apple' or 'Lily is white' or both then Julius is a swan. It is improbable that if 'Bernhard is gray and John put down the apple' then Brian is a frog. It is highly likely that if 'Bernhard is gray and Lily is white' then Mary left the football.",
        "valid"
    ],
    [
        0.4013109902540843,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '863'}",
        "It is probably the case that Greg is white. It is probably not the case that Winona is a mouse. It is unlikely that Mary left the football. It is almost certain that if either 'Greg is white' or 'Mary left the football' but not both then Sandra is in the kitchen. We believe that if 'Greg is white' or 'Winona is a mouse' or both then Lily is yellow. There is a better than even chance that if 'Greg is white and Winona is a mouse' then John went to the hallway.",
        "valid"
    ],
    [
        0.40130554636319477,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '652'}",
        "It is improbable that Brian is a swan. It is impossible that Daniel got the milk. It is probably not the case that Mary went to the hallway.",
        "valid"
    ],
    [
        0.4012988656759262,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '437'}",
        "It is probably not the case that John went to the bedroom. It is probably the case that Bernhard is a swan. It is highly unlikely that Brian is a rhino. Chances are slight that if 'John went to the bedroom and Brian is a rhino' then Sandra left the football. It is improbable that if either 'Brian is a rhino' or 'Bernhard is a swan' but not both then Mary grabbed the milk. It is probably not the case that if either 'Bernhard is a swan' or 'Brian is a rhino' but not both then Lily is green.",
        "valid"
    ],
    [
        0.40126655002435047,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '366'}",
        "It is impossible that 'Bernhard is a frog' or 'Julius is a swan' or both.",
        "valid"
    ],
    [
        0.4012548277775447,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '21'}",
        "It is likely that Greg is a frog. It is highly likely that Lily is green. It is certain that Bernhard is gray. It is highly unlikely that if 'Greg is a frog' or 'Lily is green' or both then Antoine is hungry. It is highly likely that if 'Bernhard is gray' or 'Greg is a frog' or both then Julius is a swan. There is a very good chance that if either 'Lily is green' or 'Bernhard is gray' but not both then Mary dropped the milk.",
        "valid"
    ],
    [
        0.4012397577365239,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '657'}",
        "There is almost no chance that Jessica is a mouse. It is likely that Julius is a rhino. There is a better than even chance that Jeff went to the bedroom. It is highly likely that if 'Julius is a rhino' or 'Jessica is a mouse' or both then Daniel left the apple. It is probably not the case that if either 'Jeff went to the bedroom' or 'Jessica is a mouse' but not both then Winona is a sheep. There is a very good chance that if either 'Jessica is a mouse' or 'Julius is a rhino' but not both then Greg is a frog.",
        "valid"
    ],
    [
        0.40121472378571826,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '231'}",
        "There is a very good chance that Bernhard is a frog. It is improbable that Julius is a lion. It is probably the case that John went to the garden. It is certain that if either 'John went to the garden' or 'Julius is a lion' but not both then Greg is a frog. It is probable that if 'Bernhard is a frog and John went to the garden' then Daniel got the milk. There is a very good chance that if 'Bernhard is a frog' or 'John went to the garden' or both then Fred discarded the apple.",
        "valid"
    ],
    [
        0.40120966732501984,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '695'}",
        "It is highly unlikely that Gertrude is a mouse. It is impossible that John picked up the apple. It is improbable that Lily is a swan. It is impossible that if 'Gertrude is a mouse and Lily is a swan' then Jessica is a cat. There is almost no chance that if either 'Gertrude is a mouse' or 'Lily is a swan' but not both then Bernhard is gray. It is certain that if 'John picked up the apple and Lily is a swan' then Daniel got the football.",
        "valid"
    ],
    [
        0.4012039750814438,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '844'}",
        "Chances are about even that John took the apple. There is almost no chance that Lily is a swan. It is likely that Mary moved to the office. It is highly unlikely that if 'Mary moved to the office and Lily is a swan' then Julius is a frog. It is likely that if 'Lily is a swan and John took the apple' then Jeff went to the garden. It is improbable that if either 'Lily is a swan' or 'John took the apple' but not both then Brian is a rhino.",
        "valid"
    ],
    [
        0.40120304624239606,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '344'}",
        "Chances are about even that Mary got the football. There is a very good chance that Brian is a rhino. It is improbable that Lily is a swan. It is certain that if either 'Brian is a rhino' or 'Mary got the football' but not both then John moved to the office. It is highly unlikely that if either 'Brian is a rhino' or 'Mary got the football' but not both then Emily is a wolf. It is likely that if either 'Brian is a rhino' or 'Mary got the football' but not both then Sandra left the apple.",
        "valid"
    ],
    [
        0.40100917716821033,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '9'}",
        "We believe that Jason is tired. It is improbable that Greg is white. It is highly likely that Mary left the football. It is probable that if either 'Jason is tired' or 'Mary left the football' but not both then Lily is a frog. It is highly unlikely that if either 'Greg is white' or 'Jason is tired' but not both then Winona is a cat. It is improbable that if 'Greg is white' or 'Jason is tired' or both then John dropped the milk.",
        "valid"
    ],
    [
        0.4010068029165268,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '552'}",
        "It is unlikely that 'Lily is a swan and Brian is white'.",
        "valid"
    ],
    [
        0.4009978324174881,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '38'}",
        "Chances are about even that Lily is gray. There is a better than even chance that Mary got the apple. There is a better than even chance that John dropped the milk. Chances are slight that if 'John dropped the milk and Mary got the apple' then Jessica is a cat. It is highly likely that if 'Mary got the apple and John dropped the milk' then Brian is a rhino. It is probably not the case that if either 'John dropped the milk' or 'Lily is gray' but not both then Julius is a swan.",
        "valid"
    ],
    [
        0.40098848442236584,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '974'}",
        "Chances are slight that Julius is white. It is certain that Mary dropped the milk. It is highly likely that Lily is gray. It is unlikely that if 'Mary dropped the milk' or 'Lily is gray' or both then Jason is tired. It is unlikely that if 'Mary dropped the milk' or 'Lily is gray' or both then Yann is thirsty. It is impossible that if 'Julius is white' or 'Mary dropped the milk' or both then Bill moved to the office.",
        "valid"
    ],
    [
        0.40098049739996594,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '50'}",
        "It is probably not the case that either 'Brian is green' or 'Greg is a rhino' but not both.",
        "valid"
    ],
    [
        0.400943860411644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '147'}",
        "Chances are slight that 'John dropped the milk' or 'Brian is a lion' or both.",
        "valid"
    ],
    [
        0.4009181608756383,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '646'}",
        "It is impossible that 'Brian is a lion and Bernhard is a swan'.",
        "valid"
    ],
    [
        0.4008944382270177,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '273'}",
        "It is highly likely that Jeff put down the milk. It is probably the case that Brian is a rhino. It is probably not the case that Yann is tired. It is probably not the case that if either 'Yann is tired' or 'Jeff put down the milk' but not both then Greg is a frog. It is certain that if 'Yann is tired' or 'Jeff put down the milk' or both then Bernhard is yellow. It is unlikely that if 'Jeff put down the milk' or 'Brian is a rhino' or both then Winona is a sheep.",
        "valid"
    ],
    [
        0.4008033523956935,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '644'}",
        "It is impossible that Fred put down the apple. It is probably not the case that Greg is a swan. It is highly likely that John went to the bedroom. There is a very good chance that if either 'Greg is a swan' or 'John went to the bedroom' but not both then Julius is a swan. It is likely that if 'Fred put down the apple and Greg is a swan' then Winona is a sheep. There is a very good chance that if either 'John went to the bedroom' or 'Fred put down the apple' but not both then Brian is yellow.",
        "valid"
    ],
    [
        0.40074589351813,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '301'}",
        "It is probably not the case that either 'Julius is a lion' or 'Fred is in the cinema' but not both.",
        "valid"
    ],
    [
        0.40068655212720233,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '625'}",
        "It is impossible that 'John took the apple' or 'Brian is a swan' or both.",
        "valid"
    ],
    [
        0.40068158507347107,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '707'}",
        "There is a very good chance that Mary went to the bedroom. It is almost certain that Brian is a lion. There is a very good chance that Greg is green. We doubt that if 'Mary went to the bedroom' or 'Brian is a lion' or both then Lily is a rhino. It is impossible that if 'Brian is a lion and Greg is green' then John left the football. It is probable that if either 'Greg is green' or 'Brian is a lion' but not both then Sandra took the football.",
        "valid"
    ],
    [
        0.4006423006455104,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '22'}",
        "There is a very good chance that Jessica is a sheep. It is probable that Julius is a rhino. It is improbable that Brian is green. It is certain that if either 'Jessica is a sheep' or 'Brian is green' but not both then Jason is bored. It is highly likely that if 'Brian is green and Jessica is a sheep' then Mary left the apple. There is little chance that if either 'Julius is a rhino' or 'Brian is green' but not both then Lily is a swan.",
        "valid"
    ],
    [
        0.40063731869061786,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '791'}",
        "We believe that Julius is a frog. Chances are about even that Brian is green. It is likely that Greg is white. Chances are about even that if either 'Brian is green' or 'Greg is white' but not both then Jason is tired. It is probably the case that if 'Greg is white and Brian is green' then Mary moved to the garden. It is probably the case that if 'Brian is green and Greg is white' then John discarded the apple.",
        "valid"
    ],
    [
        0.40060371657212573,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '547'}",
        "There is almost no chance that 'Bernhard is a rhino' or 'Brian is a swan' or both.",
        "valid"
    ],
    [
        0.4005875736474991,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '767'}",
        "There is almost no chance that 'John took the football' or 'Lily is a rhino' or both.",
        "valid"
    ],
    [
        0.4005190779765447,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '769'}",
        "There is a better than even chance that John got the milk. It is highly likely that Greg is a lion. Chances are about even that Sandra grabbed the apple. We believe that if 'Sandra grabbed the apple' or 'Greg is a lion' or both then Bernhard is white. It is unlikely that if either 'Greg is a lion' or 'John got the milk' but not both then Mary dropped the milk. There is a very good chance that if 'Greg is a lion and John got the milk' then Brian is gray.",
        "valid"
    ],
    [
        0.4005023737748464,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '42'}",
        "It is highly unlikely that 'Julius is a lion' or 'John took the football' or both.",
        "valid"
    ],
    [
        0.40050022800763446,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '499'}",
        "There is little chance that 'Lily is a rhino' or 'Daniel got the milk' or both.",
        "valid"
    ],
    [
        0.40048400064309436,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '249'}",
        "It is highly likely that Winona is a wolf. There is a better than even chance that Lily is green. We doubt that Mary left the football. It is probable that if either 'Mary left the football' or 'Winona is a wolf' but not both then Bernhard is a frog. It is almost certain that if either 'Winona is a wolf' or 'Mary left the football' but not both then John grabbed the apple. It is likely that if either 'Winona is a wolf' or 'Mary left the football' but not both then Brian is white.",
        "valid"
    ],
    [
        0.4004824211200078,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '231'}",
        "Chances are slight that either 'Julius is a lion' or 'Brian is green' but not both.",
        "valid"
    ],
    [
        0.40042045215765637,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '694'}",
        "There is almost no chance that 'Lily is white' or 'Daniel dropped the apple' or both.",
        "valid"
    ],
    [
        0.4003487726052602,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '265'}",
        "It is improbable that John discarded the milk. There is little chance that Brian is a frog. It is unlikely that Lily is a swan.",
        "valid"
    ],
    [
        0.4003053456544876,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '142'}",
        "Chances are slight that Daniel left the apple. It is impossible that Greg is a rhino. It is impossible that Mary went to the office. There is almost no chance that if 'Greg is a rhino' or 'Daniel left the apple' or both then Julius is gray. It is highly likely that if either 'Mary went to the office' or 'Greg is a rhino' but not both then Sandra dropped the milk. It is highly likely that if 'Greg is a rhino and Mary went to the office' then Brian is a swan.",
        "valid"
    ],
    [
        0.4002727617820104,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '449'}",
        "There is almost no chance that Bernhard is gray. Chances are about even that John took the football. It is highly likely that Julius is a frog. There is little chance that if 'Bernhard is gray' or 'John took the football' or both then Mary got the milk. It is likely that if either 'John took the football' or 'Julius is a frog' but not both then Lily is green. It is improbable that if either 'Julius is a frog' or 'John took the football' but not both then Winona is a mouse.",
        "valid"
    ],
    [
        0.40022364258766174,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '629'}",
        "It is likely that Sandra dropped the milk. It is probably the case that Greg is a swan. It is highly likely that Brian is yellow. We doubt that if either 'Greg is a swan' or 'Brian is yellow' but not both then Jessica is a mouse. It is probably the case that if 'Greg is a swan and Brian is yellow' then Daniel left the milk. We believe that if either 'Greg is a swan' or 'Brian is yellow' but not both then Lily is a rhino.",
        "valid"
    ],
    [
        0.4002090245485306,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '370'}",
        "It is probably not the case that 'John left the milk' or 'Lily is a rhino' or both.",
        "valid"
    ],
    [
        0.400162215034167,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '221'}",
        "There is little chance that John grabbed the milk. It is probably not the case that Lily is yellow. It is probably the case that Mary got the football. It is highly likely that if 'Mary got the football and Lily is yellow' then Bernhard is a rhino. It is probable that if 'Mary got the football' or 'John grabbed the milk' or both then Antoine is thirsty. There is almost no chance that if either 'John grabbed the milk' or 'Mary got the football' but not both then Brian is a swan.",
        "valid"
    ],
    [
        0.40015265842278797,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '505'}",
        "It is highly likely that Brian is a lion. It is impossible that Emily is a cat. There is a better than even chance that Mary left the apple.",
        "valid"
    ],
    [
        0.40008796254793805,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '893'}",
        "It is almost certain that Julius is white. It is likely that Brian is gray. There is little chance that Mary took the football. There is little chance that if 'Mary took the football' or 'Brian is gray' or both then Bill left the milk. It is improbable that if either 'Brian is gray' or 'Julius is white' but not both then Jeff discarded the milk. It is unlikely that if 'Brian is gray' or 'Mary took the football' or both then Bernhard is green.",
        "valid"
    ],
    [
        0.4000804126262665,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '237'}",
        "It is probably not the case that Greg is gray. It is impossible that Lily is a swan. It is certain that Jessica is a cat.",
        "valid"
    ],
    [
        0.4000372588634491,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '103'}",
        "It is highly unlikely that 'Brian is a rhino' or 'Jeff discarded the milk' or both.",
        "valid"
    ],
    [
        0.4000282535950343,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '472'}",
        "There is almost no chance that Jessica is a cat. Chances are about even that Mary left the football. It is improbable that Julius is a frog. It is improbable that if either 'Jessica is a cat' or 'Julius is a frog' but not both then Sandra dropped the milk. Chances are about even that if 'Julius is a frog and Jessica is a cat' then Brian is a swan. It is impossible that if either 'Jessica is a cat' or 'Mary left the football' but not both then Bernhard is white.",
        "valid"
    ],
    [
        0.39999692638715106,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '680'}",
        "There is almost no chance that 'Greg is a lion' or 'Lily is green' or both.",
        "valid"
    ],
    [
        0.39995303253332776,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '184'}",
        "There is almost no chance that Greg is yellow. It is probably not the case that Mary went to the kitchen. It is improbable that Lily is a lion. We believe that if 'Mary went to the kitchen' or 'Greg is yellow' or both then Sandra left the football. There is little chance that if 'Lily is a lion' or 'Greg is yellow' or both then Brian is green. There is almost no chance that if 'Mary went to the kitchen' or 'Greg is yellow' or both then John dropped the apple.",
        "valid"
    ],
    [
        0.3999447673559189,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '533'}",
        "It is impossible that 'Brian is white and Winona is a wolf'.",
        "valid"
    ],
    [
        0.39993104835351306,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '198'}",
        "There is a better than even chance that Lily is yellow. It is probably the case that Mary left the football. It is unlikely that Greg is a swan. We doubt that if either 'Greg is a swan' or 'Mary left the football' but not both then Jessica is a sheep. We doubt that if 'Mary left the football and Lily is yellow' then Bernhard is a frog. It is probably not the case that if 'Greg is a swan' or 'Mary left the football' or both then Fred went to the garden.",
        "valid"
    ],
    [
        0.3998977442582448,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '324'}",
        "We doubt that Brian is a swan. There is a better than even chance that Mary is in the hallway. It is probably not the case that Bernhard is gray. It is probably the case that if either 'Bernhard is gray' or 'Brian is a swan' but not both then Jason is tired. It is probably the case that if either 'Mary is in the hallway' or 'Brian is a swan' but not both then Greg is yellow. There is little chance that if 'Brian is a swan and Mary is in the hallway' then John picked up the apple.",
        "valid"
    ],
    [
        0.39982697864373523,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '444'}",
        "It is impossible that 'Bernhard is a swan' or 'Daniel got the milk' or both.",
        "valid"
    ],
    [
        0.3997687002023061,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '369'}",
        "There is a very good chance that John got the apple. Chances are about even that Bernhard is a frog. It is likely that Lily is white. It is certain that if either 'Bernhard is a frog' or 'John got the apple' but not both then Brian is green. It is probably the case that if 'Bernhard is a frog' or 'John got the apple' or both then Julius is a lion. It is highly unlikely that if either 'John got the apple' or 'Bernhard is a frog' but not both then Mary went to the garden.",
        "valid"
    ],
    [
        0.39976736903190613,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '199'}",
        "It is unlikely that Lily is a rhino. It is certain that Emily is a mouse. It is almost certain that Jeff went to the hallway. There is a very good chance that if 'Jeff went to the hallway and Lily is a rhino' then Bernhard is yellow. It is likely that if 'Lily is a rhino' or 'Jeff went to the hallway' or both then Julius is a frog. Chances are slight that if either 'Lily is a rhino' or 'Jeff went to the hallway' but not both then Jason is tired.",
        "valid"
    ],
    [
        0.3997539629538854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '4'}",
        "It is impossible that 'Julius is a lion and Winona is a wolf'.",
        "valid"
    ],
    [
        0.39973371227582294,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '616'}",
        "Chances are about even that Brian is a rhino. It is certain that John moved to the office. There is almost no chance that Greg is white. It is highly unlikely that if either 'John moved to the office' or 'Greg is white' but not both then Winona is a cat. We doubt that if 'Greg is white' or 'John moved to the office' or both then Mary left the football. It is likely that if 'Greg is white and John moved to the office' then Fred discarded the apple.",
        "valid"
    ],
    [
        0.39969979723294574,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '989'}",
        "It is improbable that 'Lily is green' or 'Brian is a rhino' or both.",
        "valid"
    ],
    [
        0.39968016743659973,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '627'}",
        "There is little chance that Lily is a swan. It is likely that Julius is green. It is impossible that Gertrude is a sheep. Chances are about even that if 'Lily is a swan and Julius is green' then Mary went to the office. It is certain that if 'Gertrude is a sheep and Julius is green' then Brian is gray. There is almost no chance that if either 'Lily is a swan' or 'Gertrude is a sheep' but not both then Sandra dropped the milk.",
        "valid"
    ],
    [
        0.399650717775027,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '205'}",
        "It is highly unlikely that Lily is a rhino. Chances are about even that Bill went to the office. It is certain that John is in the garden. It is probable that if 'Bill went to the office and Lily is a rhino' then Sandra left the milk. It is improbable that if either 'Bill went to the office' or 'Lily is a rhino' but not both then Julius is gray. There is almost no chance that if 'Bill went to the office' or 'Lily is a rhino' or both then Daniel put down the milk.",
        "valid"
    ],
    [
        0.39965034027894336,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '560'}",
        "There is almost no chance that either 'Winona is a sheep' or 'Brian is yellow' but not both.",
        "valid"
    ],
    [
        0.3996121386686961,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '428'}",
        "It is probably not the case that either 'Brian is a swan' or 'Sandra took the milk' but not both.",
        "valid"
    ],
    [
        0.39960968991120654,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '739'}",
        "There is almost no chance that either 'Julius is a swan' or 'Winona is a cat' but not both.",
        "valid"
    ],
    [
        0.39956872661908466,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '12'}",
        "It is highly unlikely that either 'Bernhard is a swan' or 'Greg is a frog' but not both.",
        "valid"
    ],
    [
        0.39955128232638043,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '633'}",
        "It is probably not the case that 'Brian is green' or 'Julius is white' or both.",
        "valid"
    ],
    [
        0.3995263526837031,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '73'}",
        "There is little chance that either 'Lily is a rhino' or 'Greg is gray' but not both.",
        "valid"
    ],
    [
        0.3995235711336136,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '771'}",
        "It is likely that Daniel grabbed the milk. There is a better than even chance that Julius is gray. It is impossible that Greg is a swan. There is little chance that if 'Greg is a swan and Julius is gray' then Antoine is bored. It is almost certain that if 'Greg is a swan and Julius is gray' then John moved to the garden. There is a better than even chance that if 'Daniel grabbed the milk and Julius is gray' then Winona is a wolf.",
        "valid"
    ],
    [
        0.3995232234398524,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '130'}",
        "It is improbable that John picked up the apple. It is probably not the case that Lily is gray. It is improbable that Mary went to the office. We doubt that if 'Lily is gray and John picked up the apple' then Gertrude is a cat. It is probably the case that if 'John picked up the apple' or 'Mary went to the office' or both then Brian is a lion. It is highly likely that if either 'Lily is gray' or 'Mary went to the office' but not both then Bernhard is a swan.",
        "valid"
    ],
    [
        0.39951921502749127,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '658'}",
        "It is probably not the case that either 'Jason is tired' or 'Brian is white' but not both.",
        "valid"
    ],
    [
        0.3995075573523839,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '612'}",
        "We doubt that John picked up the apple. It is almost certain that Mary dropped the milk. We believe that Bernhard is white. There is little chance that if either 'Mary dropped the milk' or 'Bernhard is white' but not both then Lily is a rhino. It is highly likely that if 'John picked up the apple and Bernhard is white' then Brian is a swan. There is a better than even chance that if either 'Mary dropped the milk' or 'Bernhard is white' but not both then Julius is gray.",
        "valid"
    ],
    [
        0.3994508534669876,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '947'}",
        "Chances are slight that either 'John put down the milk' or 'Brian is a swan' but not both.",
        "valid"
    ],
    [
        0.3994298130273819,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '747'}",
        "It is unlikely that Daniel took the milk. It is improbable that Sandra left the milk. There is almost no chance that Antoine is thirsty. Chances are slight that if either 'Antoine is thirsty' or 'Daniel took the milk' but not both then Bernhard is green. There is a better than even chance that if either 'Antoine is thirsty' or 'Daniel took the milk' but not both then John dropped the apple. There is little chance that if 'Antoine is thirsty' or 'Daniel took the milk' or both then Greg is a rhino.",
        "valid"
    ],
    [
        0.3993506282567978,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '448'}",
        "There is a better than even chance that Lily is a rhino. It is improbable that Sandra took the milk. It is likely that Brian is a lion.",
        "valid"
    ],
    [
        0.39931510388851166,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '977'}",
        "It is certain that Mary dropped the milk. It is almost certain that John went to the garden. There is almost no chance that Lily is a lion. It is probably not the case that if 'Lily is a lion and John went to the garden' then Jeff left the football. Chances are about even that if 'Lily is a lion' or 'Mary dropped the milk' or both then Brian is green. It is probable that if 'Lily is a lion and Mary dropped the milk' then Julius is a frog.",
        "valid"
    ],
    [
        0.39930573602517444,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '345'}",
        "It is certain that Lily is a swan. There is a better than even chance that Gertrude is a mouse. We believe that Fred put down the apple. Chances are slight that if either 'Gertrude is a mouse' or 'Fred put down the apple' but not both then Brian is green. It is impossible that if 'Lily is a swan' or 'Fred put down the apple' or both then Mary dropped the milk. It is probably the case that if 'Fred put down the apple and Gertrude is a mouse' then Jessica is a cat.",
        "valid"
    ],
    [
        0.399265855550766,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '224'}",
        "It is improbable that 'Julius is a lion and Brian is a swan'.",
        "valid"
    ],
    [
        0.39921678105990094,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '280'}",
        "There is almost no chance that Brian is white. It is impossible that Greg is a rhino. Chances are about even that Mary went to the kitchen.",
        "valid"
    ],
    [
        0.39913150668144226,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '561'}",
        "It is probably not the case that 'Julius is a swan' or 'Greg is white' or both.",
        "valid"
    ],
    [
        0.3991154283285141,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '927'}",
        "Chances are about even that Mary is in the school. It is unlikely that Lily is a lion. It is highly likely that Greg is a rhino.",
        "valid"
    ],
    [
        0.39911040167013806,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '313'}",
        "It is highly unlikely that either 'Winona is a mouse' or 'Lily is white' but not both.",
        "valid"
    ],
    [
        0.3990766257047653,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '965'}",
        "It is impossible that 'Winona is a sheep and Brian is white'.",
        "valid"
    ],
    [
        0.39906321465969086,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '197'}",
        "It is impossible that either 'Brian is a frog' or 'John went to the office' but not both.",
        "valid"
    ],
    [
        0.3990088601907094,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '547'}",
        "It is highly unlikely that either 'Lily is a swan' or 'John grabbed the milk' but not both.",
        "valid"
    ],
    [
        0.39900703728199005,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '894'}",
        "It is probably the case that either 'Greg is yellow' or 'Lily is a swan' but not both.",
        "valid"
    ],
    [
        0.3989112228155136,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '78'}",
        "It is unlikely that Jessica is a mouse. It is impossible that Sumit is tired. It is improbable that Emily is a wolf. It is probable that if 'Sumit is tired' or 'Jessica is a mouse' or both then Julius is yellow. It is probably not the case that if either 'Sumit is tired' or 'Jessica is a mouse' but not both then Lily is a lion. It is probably not the case that if either 'Sumit is tired' or 'Emily is a wolf' but not both then John went to the hallway.",
        "valid"
    ],
    [
        0.3988885184129079,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '171'}",
        "It is almost certain that John is in the garden. It is impossible that Greg is a swan. There is little chance that Emily is a mouse. There is almost no chance that if either 'Emily is a mouse' or 'Greg is a swan' but not both then Yann is hungry. It is probably the case that if 'Greg is a swan' or 'John is in the garden' or both then Mary dropped the apple. It is likely that if 'John is in the garden' or 'Emily is a mouse' or both then Julius is white.",
        "valid"
    ],
    [
        0.39880773425102234,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '485'}",
        "It is probable that Greg is a swan. There is almost no chance that Julius is yellow. We believe that Brian is yellow. There is a very good chance that if 'Brian is yellow' or 'Julius is yellow' or both then Sumit is thirsty. It is probable that if either 'Brian is yellow' or 'Julius is yellow' but not both then John dropped the milk. It is highly likely that if 'Julius is yellow' or 'Greg is a swan' or both then Bill moved to the office.",
        "valid"
    ],
    [
        0.3987753639618556,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '706'}",
        "It is probably the case that Emily is a mouse. There is a very good chance that Bill left the football. Chances are slight that Brian is gray. It is unlikely that if 'Brian is gray and Bill left the football' then Bernhard is a rhino. It is highly unlikely that if 'Brian is gray and Emily is a mouse' then Greg is a lion. There is a very good chance that if 'Bill left the football' or 'Brian is gray' or both then John took the apple.",
        "valid"
    ],
    [
        0.3987753093242645,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '291'}",
        "It is almost certain that Daniel dropped the apple. It is probable that Julius is gray. It is probably not the case that Lily is a lion.",
        "valid"
    ],
    [
        0.3987404356400172,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '539'}",
        "Chances are slight that John took the apple. It is highly unlikely that Emily is a sheep. It is unlikely that Mary dropped the milk. There is almost no chance that if 'Mary dropped the milk' or 'John took the apple' or both then Bill left the football. It is certain that if either 'Mary dropped the milk' or 'John took the apple' but not both then Lily is a frog. It is almost certain that if 'Emily is a sheep' or 'Mary dropped the milk' or both then Bernhard is a swan.",
        "valid"
    ],
    [
        0.3987385978301366,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '579'}",
        "Chances are about even that John went to the garden. It is unlikely that Lily is a rhino. It is probably the case that Mary left the apple. We doubt that if either 'Mary left the apple' or 'John went to the garden' but not both then Yann is tired. It is almost certain that if 'John went to the garden' or 'Lily is a rhino' or both then Gertrude is a sheep. There is a very good chance that if either 'Mary left the apple' or 'Lily is a rhino' but not both then Brian is gray.",
        "valid"
    ],
    [
        0.39871298770109814,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '905'}",
        "It is impossible that 'Julius is a frog and Brian is white'.",
        "valid"
    ],
    [
        0.39871229231357574,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '477'}",
        "There is little chance that Brian is a frog. It is probably the case that Lily is a rhino. It is probably the case that Mary dropped the apple.",
        "valid"
    ],
    [
        0.39871155718962353,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '761'}",
        "Chances are slight that Brian is green. It is probable that John took the football. We doubt that Julius is a swan. It is highly likely that if 'Brian is green' or 'Julius is a swan' or both then Emily is a wolf. It is impossible that if 'Julius is a swan and John took the football' then Mary put down the milk. It is improbable that if 'Julius is a swan' or 'Brian is green' or both then Lily is yellow.",
        "valid"
    ],
    [
        0.3987075338761012,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '544'}",
        "It is likely that Greg is a rhino. We doubt that Julius is gray. Chances are about even that Bill moved to the office. It is impossible that if either 'Julius is gray' or 'Greg is a rhino' but not both then Lily is green. It is highly likely that if 'Greg is a rhino' or 'Julius is gray' or both then Bernhard is yellow. It is unlikely that if either 'Bill moved to the office' or 'Julius is gray' but not both then Mary went to the bedroom.",
        "valid"
    ],
    [
        0.39869657158851624,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '600'}",
        "There is almost no chance that 'Lily is a swan and Brian is gray'.",
        "valid"
    ],
    [
        0.39865800241629284,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '479'}",
        "It is highly unlikely that 'Greg is a frog and Brian is a rhino'.",
        "valid"
    ],
    [
        0.398615504304568,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '143'}",
        "It is almost certain that Julius is a swan. Chances are slight that Greg is a frog. There is little chance that Bill moved to the office. There is a very good chance that if 'Greg is a frog' or 'Julius is a swan' or both then John went to the bedroom. We believe that if 'Greg is a frog' or 'Julius is a swan' or both then Lily is yellow. We believe that if either 'Greg is a frog' or 'Bill moved to the office' but not both then Bernhard is green.",
        "valid"
    ],
    [
        0.3986038068930308,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '349'}",
        "Chances are slight that John discarded the milk. It is certain that Julius is a frog. There is a very good chance that Brian is green. It is probably not the case that if 'John discarded the milk' or 'Julius is a frog' or both then Sandra left the football. It is probable that if 'Brian is green and Julius is a frog' then Lily is a rhino. We doubt that if 'Julius is a frog and Brian is green' then Daniel dropped the apple.",
        "valid"
    ],
    [
        0.3985778788725535,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '389'}",
        "It is highly likely that Sumit is thirsty. There is almost no chance that Winona is a sheep. It is likely that Julius is gray. We believe that if 'Winona is a sheep' or 'Julius is gray' or both then John moved to the office. It is impossible that if either 'Winona is a sheep' or 'Julius is gray' but not both then Mary dropped the apple. It is probable that if 'Julius is gray and Winona is a sheep' then Bernhard is yellow.",
        "valid"
    ],
    [
        0.39855999251206714,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '739'}",
        "It is probably not the case that 'Lily is white' or 'Emily is a wolf' or both.",
        "valid"
    ],
    [
        0.3985442966222763,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '168'}",
        "It is highly unlikely that 'Fred put down the apple' or 'Julius is a lion' or both.",
        "valid"
    ],
    [
        0.398535892367363,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '150'}",
        "It is highly unlikely that either 'Winona is a sheep' or 'Greg is white' but not both.",
        "valid"
    ],
    [
        0.39847799638907117,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '471'}",
        "It is probably not the case that Brian is green. There is little chance that Greg is gray. It is probably not the case that Sandra took the milk. It is likely that if 'Brian is green and Greg is gray' then John went to the garden. It is impossible that if 'Greg is gray and Brian is green' then Gertrude is a sheep. We believe that if 'Sandra took the milk' or 'Greg is gray' or both then Emily is a wolf.",
        "valid"
    ],
    [
        0.3984080106019974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '880'}",
        "It is highly unlikely that Julius is a frog. It is probably the case that Jessica is a sheep. There is almost no chance that Mary picked up the apple. We believe that if 'Julius is a frog and Mary picked up the apple' then John moved to the office. It is almost certain that if 'Mary picked up the apple and Jessica is a sheep' then Bill went to the kitchen. There is almost no chance that if either 'Mary picked up the apple' or 'Jessica is a sheep' but not both then Bernhard is gray.",
        "valid"
    ],
    [
        0.3983811487754186,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '705'}",
        "There is a better than even chance that Bernhard is green. It is highly likely that Lily is a rhino. There is a better than even chance that Brian is a lion. It is highly likely that if 'Brian is a lion and Bernhard is green' then Mary went to the bedroom. It is probably the case that if 'Bernhard is green and Brian is a lion' then Daniel got the milk. It is likely that if either 'Bernhard is green' or 'Brian is a lion' but not both then Sumit is hungry.",
        "valid"
    ],
    [
        0.39837874472141266,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '989'}",
        "It is almost certain that Sumit is bored. We believe that Julius is a rhino. Chances are about even that Bernhard is a swan. It is highly likely that if 'Bernhard is a swan and Sumit is bored' then Winona is a mouse. It is unlikely that if either 'Sumit is bored' or 'Bernhard is a swan' but not both then Lily is white. We doubt that if either 'Bernhard is a swan' or 'Sumit is bored' but not both then Greg is a lion.",
        "valid"
    ],
    [
        0.39833733936150867,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '394'}",
        "It is almost certain that Bernhard is a rhino. It is impossible that Mary dropped the milk. It is highly unlikely that Brian is a lion.",
        "valid"
    ],
    [
        0.3983242412408193,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '258'}",
        "It is probably not the case that John discarded the milk. Chances are about even that Fred is in the office. It is unlikely that Brian is a frog. There is almost no chance that if 'Fred is in the office' or 'Brian is a frog' or both then Sumit is hungry. We believe that if 'John discarded the milk and Brian is a frog' then Winona is a mouse. We believe that if 'John discarded the milk and Fred is in the office' then Bernhard is white.",
        "valid"
    ],
    [
        0.3983204811811447,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '737'}",
        "It is almost certain that Julius is a rhino. It is probably the case that Greg is a lion. It is highly likely that Winona is a cat.",
        "valid"
    ],
    [
        0.3983139097690582,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '513'}",
        "It is highly unlikely that John went to the hallway. It is impossible that Julius is a swan. There is almost no chance that Winona is a wolf. It is probably the case that if 'Julius is a swan' or 'John went to the hallway' or both then Jeff moved to the garden. There is little chance that if either 'Winona is a wolf' or 'John went to the hallway' but not both then Bernhard is gray. It is improbable that if 'Julius is a swan and John went to the hallway' then Mary got the milk.",
        "valid"
    ],
    [
        0.39824484288692474,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '326'}",
        "It is impossible that Jeff left the apple. There is a better than even chance that Mary dropped the milk. There is little chance that Brian is a swan. It is probably not the case that if 'Mary dropped the milk and Brian is a swan' then Emily is a sheep. Chances are about even that if 'Mary dropped the milk and Brian is a swan' then John took the football. There is almost no chance that if either 'Mary dropped the milk' or 'Jeff left the apple' but not both then Bernhard is a rhino.",
        "valid"
    ],
    [
        0.39821866651376087,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '741'}",
        "It is impossible that 'Julius is white and Lily is a frog'.",
        "valid"
    ],
    [
        0.3981529970963796,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '884'}",
        "Chances are slight that Mary went to the garden. Chances are about even that Julius is white. It is certain that Bernhard is gray. Chances are about even that if 'Bernhard is gray' or 'Julius is white' or both then Daniel got the milk. There is a very good chance that if 'Julius is white' or 'Mary went to the garden' or both then Lily is a swan. There is a better than even chance that if 'Julius is white' or 'Mary went to the garden' or both then John took the football.",
        "valid"
    ],
    [
        0.3981401224931081,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '758'}",
        "Chances are about even that Sandra left the apple. It is highly unlikely that Emily is a mouse. It is certain that Mary picked up the milk. It is improbable that if 'Emily is a mouse and Sandra left the apple' then John went to the hallway. There is a better than even chance that if either 'Sandra left the apple' or 'Emily is a mouse' but not both then Julius is a rhino. It is impossible that if 'Mary picked up the milk' or 'Sandra left the apple' or both then Brian is a frog.",
        "valid"
    ],
    [
        0.3980692078669866,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '265'}",
        "It is impossible that 'Julius is a rhino' or 'Gertrude is a sheep' or both.",
        "valid"
    ],
    [
        0.39802605907122296,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '562'}",
        "Chances are slight that either 'Bernhard is a swan' or 'Brian is a rhino' but not both.",
        "valid"
    ],
    [
        0.397999440630277,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '471'}",
        "There is little chance that either 'Brian is white' or 'John left the milk' but not both.",
        "valid"
    ],
    [
        0.3979914039373398,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '617'}",
        "It is probably not the case that either 'Sandra took the football' or 'Brian is a frog' but not both.",
        "valid"
    ],
    [
        0.39796997606754303,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '219'}",
        "Chances are slight that either 'Brian is white' or 'Julius is yellow' but not both.",
        "valid"
    ],
    [
        0.3979405810435613,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '652'}",
        "There is a very good chance that either 'Brian is yellow' or 'Julius is a swan' but not both.",
        "valid"
    ],
    [
        0.39786377052466076,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '643'}",
        "It is probably not the case that either 'Daniel grabbed the apple' or 'Brian is gray' but not both.",
        "valid"
    ],
    [
        0.3978341321150462,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '414'}",
        "It is improbable that Julius is gray. It is unlikely that Mary left the milk. It is impossible that Greg is a swan. It is almost certain that if 'Mary left the milk and Greg is a swan' then Bill moved to the office. There is a very good chance that if either 'Mary left the milk' or 'Julius is gray' but not both then John went to the hallway. It is improbable that if 'Julius is gray' or 'Mary left the milk' or both then Jessica is a cat.",
        "valid"
    ],
    [
        0.3978283852338791,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '239'}",
        "It is improbable that Jeff moved to the garden. It is improbable that Brian is a frog. It is unlikely that Julius is a lion.",
        "valid"
    ],
    [
        0.397706205646197,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '472'}",
        "It is unlikely that 'Brian is a lion' or 'Mary went to the office' or both.",
        "valid"
    ],
    [
        0.3976487418015798,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '562'}",
        "It is probable that Daniel left the milk. It is certain that Bernhard is yellow. It is impossible that Brian is a rhino. It is likely that if 'Brian is a rhino' or 'Bernhard is yellow' or both then Emily is a sheep. It is certain that if 'Bernhard is yellow' or 'Brian is a rhino' or both then Greg is green. There is almost no chance that if 'Daniel left the milk and Bernhard is yellow' then Sandra got the football.",
        "valid"
    ],
    [
        0.39764166871706647,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '262'}",
        "There is little chance that Jason is tired. It is probable that Lily is a swan. It is probably the case that Bernhard is a frog. It is highly unlikely that if 'Lily is a swan and Jason is tired' then Sandra got the milk. We doubt that if 'Jason is tired and Lily is a swan' then Daniel left the apple. It is improbable that if 'Bernhard is a frog' or 'Jason is tired' or both then John went to the kitchen.",
        "valid"
    ],
    [
        0.39760759969552356,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '673'}",
        "It is unlikely that Lily is a frog. It is impossible that John dropped the milk. It is probable that Brian is yellow.",
        "valid"
    ],
    [
        0.39755484461784363,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '782'}",
        "It is improbable that Brian is a rhino. Chances are about even that John grabbed the apple. Chances are about even that Lily is a swan.",
        "valid"
    ],
    [
        0.3974386105934779,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '722'}",
        "It is probably the case that either 'Greg is white' or 'Brian is gray' but not both.",
        "valid"
    ],
    [
        0.3973865459362666,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '607'}",
        "It is probable that Mary went to the bedroom. We doubt that Lily is white. It is unlikely that John left the football. Chances are slight that if 'Lily is white' or 'John left the football' or both then Winona is a wolf. There is little chance that if either 'Lily is white' or 'Mary went to the bedroom' but not both then Yann is tired. We doubt that if 'John left the football and Lily is white' then Greg is a rhino.",
        "valid"
    ],
    [
        0.3973553429047267,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '258'}",
        "It is highly unlikely that Brian is a lion. It is certain that John got the apple. There is almost no chance that Jessica is a cat.",
        "valid"
    ],
    [
        0.3972551574309667,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '788'}",
        "It is probably not the case that 'Julius is a swan' or 'Brian is green' or both.",
        "valid"
    ],
    [
        0.39721619586149853,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '181'}",
        "We doubt that Brian is yellow. It is highly unlikely that Yann is thirsty. It is likely that Bernhard is a frog. We believe that if 'Brian is yellow' or 'Yann is thirsty' or both then Julius is green. It is probably the case that if either 'Brian is yellow' or 'Bernhard is a frog' but not both then Jeff went to the bedroom. We doubt that if either 'Yann is thirsty' or 'Brian is yellow' but not both then Mary dropped the milk.",
        "valid"
    ],
    [
        0.39717113475004834,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '779'}",
        "It is highly likely that Brian is green. There is a very good chance that Gertrude is a sheep. It is almost certain that Julius is white. It is probably the case that if 'Gertrude is a sheep and Julius is white' then Jeff dropped the apple. We doubt that if either 'Brian is green' or 'Gertrude is a sheep' but not both then Mary left the football. It is likely that if either 'Julius is white' or 'Brian is green' but not both then Lily is a rhino.",
        "valid"
    ],
    [
        0.39716072380542755,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '278'}",
        "It is probably not the case that 'John went to the office' or 'Lily is a lion' or both.",
        "valid"
    ],
    [
        0.3971259146928787,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '222'}",
        "It is certain that Greg is a rhino. It is unlikely that Jessica is a cat. Chances are about even that Mary went to the bedroom. It is highly likely that if 'Mary went to the bedroom' or 'Greg is a rhino' or both then Sandra left the milk. It is probably the case that if either 'Greg is a rhino' or 'Mary went to the bedroom' but not both then Bernhard is green. It is likely that if either 'Greg is a rhino' or 'Mary went to the bedroom' but not both then Julius is a lion.",
        "valid"
    ],
    [
        0.39705226322015125,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '897'}",
        "It is certain that Bernhard is a frog. It is unlikely that Greg is yellow. It is probably not the case that Antoine is hungry. It is unlikely that if 'Antoine is hungry' or 'Greg is yellow' or both then Sandra left the apple. We doubt that if either 'Bernhard is a frog' or 'Greg is yellow' but not both then Lily is yellow. Chances are about even that if 'Greg is yellow' or 'Bernhard is a frog' or both then John took the football.",
        "valid"
    ],
    [
        0.3970486770073573,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '99'}",
        "There is almost no chance that Fred went to the garden. It is highly likely that Greg is a swan. We doubt that John discarded the apple. It is probable that if 'John discarded the apple' or 'Fred went to the garden' or both then Lily is white. It is highly unlikely that if either 'Fred went to the garden' or 'John discarded the apple' but not both then Julius is a swan. It is likely that if 'Greg is a swan and John discarded the apple' then Bernhard is a lion.",
        "valid"
    ],
    [
        0.39701365927855176,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '272'}",
        "It is probably not the case that either 'Mary left the football' or 'Brian is a frog' but not both.",
        "valid"
    ],
    [
        0.39696771403153736,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '39'}",
        "There is little chance that Jeff moved to the garden. It is impossible that Julius is gray. There is a very good chance that Bill went to the kitchen. It is highly unlikely that if either 'Jeff moved to the garden' or 'Bill went to the kitchen' but not both then Greg is white. We doubt that if 'Jeff moved to the garden and Bill went to the kitchen' then Lily is a lion. We believe that if 'Jeff moved to the garden' or 'Julius is gray' or both then Bernhard is a rhino.",
        "valid"
    ],
    [
        0.3969293137391408,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '44'}",
        "It is probably the case that Brian is a swan. It is probable that John grabbed the milk. It is improbable that Lily is a frog.",
        "valid"
    ],
    [
        0.396924023826917,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '778'}",
        "There is a very good chance that Bernhard is a swan. We doubt that Brian is green. It is highly likely that Julius is a lion. We doubt that if 'Julius is a lion and Brian is green' then Jeff moved to the office. It is probable that if 'Julius is a lion' or 'Brian is green' or both then John picked up the apple. It is impossible that if 'Brian is green and Julius is a lion' then Lily is gray.",
        "valid"
    ],
    [
        0.396919106443723,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '179'}",
        "It is likely that Mary left the apple. It is certain that Brian is white. It is unlikely that John discarded the milk. There is a better than even chance that if either 'John discarded the milk' or 'Brian is white' but not both then Gertrude is a sheep. It is improbable that if 'Brian is white' or 'Mary left the apple' or both then Bernhard is a frog. It is highly unlikely that if 'Brian is white' or 'Mary left the apple' or both then Jeff went to the garden.",
        "valid"
    ],
    [
        0.39686518410841626,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '222'}",
        "It is impossible that Lily is white. Chances are slight that Bill went to the office. There is a very good chance that Julius is a frog.",
        "valid"
    ],
    [
        0.39683278898398083,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '599'}",
        "We believe that Julius is a frog. It is certain that Mary got the apple. It is almost certain that John moved to the office. It is likely that if 'John moved to the office' or 'Julius is a frog' or both then Fred dropped the milk. There is a very good chance that if 'John moved to the office' or 'Julius is a frog' or both then Brian is white. There is little chance that if 'Julius is a frog' or 'Mary got the apple' or both then Winona is a wolf.",
        "valid"
    ],
    [
        0.3968093693256378,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '721'}",
        "Chances are slight that Mary went to the bedroom. It is probably not the case that Brian is green. There is little chance that Winona is a mouse. It is likely that if either 'Winona is a mouse' or 'Brian is green' but not both then Fred discarded the apple. We believe that if 'Mary went to the bedroom and Winona is a mouse' then Greg is white. It is probably not the case that if 'Winona is a mouse' or 'Brian is green' or both then John took the football.",
        "valid"
    ],
    [
        0.3968084007501602,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '567'}",
        "It is improbable that 'Julius is a swan' or 'Greg is a swan' or both.",
        "valid"
    ],
    [
        0.396777202685674,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '405'}",
        "It is likely that Jessica is a cat. It is almost certain that Bernhard is a frog. It is improbable that John got the milk. There is almost no chance that if either 'Jessica is a cat' or 'John got the milk' but not both then Sandra left the milk. It is likely that if 'John got the milk' or 'Jessica is a cat' or both then Greg is a swan. There is almost no chance that if 'Bernhard is a frog and Jessica is a cat' then Brian is gray.",
        "valid"
    ],
    [
        0.3967735817035039,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '773'}",
        "Chances are slight that 'Lily is a lion' or 'Jason is tired' or both.",
        "valid"
    ],
    [
        0.39675457775592804,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '68'}",
        "Chances are slight that either 'Bernhard is yellow' or 'Brian is a lion' but not both.",
        "valid"
    ],
    [
        0.3967316597700119,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '388'}",
        "It is unlikely that Jessica is a mouse. It is probably the case that Bernhard is a frog. It is likely that Brian is gray. It is likely that if 'Bernhard is a frog and Jessica is a mouse' then Jeff moved to the garden. It is likely that if 'Brian is gray' or 'Bernhard is a frog' or both then Mary grabbed the milk. Chances are about even that if either 'Bernhard is a frog' or 'Jessica is a mouse' but not both then Julius is a swan.",
        "valid"
    ],
    [
        0.3967098693052928,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '857'}",
        "It is probably not the case that Bernhard is a rhino. We doubt that Julius is a swan. Chances are about even that Mary went to the garden. It is likely that if either 'Bernhard is a rhino' or 'Mary went to the garden' but not both then Bill moved to the office. It is highly likely that if 'Bernhard is a rhino' or 'Julius is a swan' or both then Lily is green. It is highly likely that if 'Julius is a swan' or 'Bernhard is a rhino' or both then John discarded the apple.",
        "valid"
    ],
    [
        0.39670296013355255,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '463'}",
        "There is a very good chance that Greg is a frog. It is certain that Sumit is hungry. It is likely that John dropped the milk. It is impossible that if 'Greg is a frog and John dropped the milk' then Julius is white. There is almost no chance that if 'John dropped the milk' or 'Greg is a frog' or both then Mary went to the garden. It is certain that if either 'Sumit is hungry' or 'John dropped the milk' but not both then Lily is green.",
        "valid"
    ],
    [
        0.39663077394167584,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '266'}",
        "There is a better than even chance that Greg is a swan. It is probably not the case that Jessica is a wolf. It is highly unlikely that Brian is gray.",
        "valid"
    ],
    [
        0.39661458134651184,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '854'}",
        "It is highly likely that Jason is tired. It is probably not the case that Brian is a frog. It is highly unlikely that Mary left the football. It is almost certain that if 'Mary left the football' or 'Brian is a frog' or both then Emily is a wolf. Chances are slight that if 'Mary left the football' or 'Brian is a frog' or both then Julius is a swan. It is improbable that if 'Mary left the football' or 'Jason is tired' or both then Bill went to the garden.",
        "valid"
    ],
    [
        0.3965964615345001,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '769'}",
        "It is probable that Daniel left the apple. There is a better than even chance that Greg is white. Chances are about even that Brian is a lion.",
        "valid"
    ],
    [
        0.39655519525210065,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '52'}",
        "There is almost no chance that 'Julius is a frog' or 'Brian is green' or both.",
        "valid"
    ],
    [
        0.3965377112229665,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '313'}",
        "It is probably the case that Greg is white. We doubt that Jeff left the apple. It is certain that Mary went to the office. It is almost certain that if either 'Mary went to the office' or 'Greg is white' but not both then Julius is a swan. It is highly unlikely that if 'Mary went to the office' or 'Greg is white' or both then Yann is tired. It is highly unlikely that if 'Jeff left the apple' or 'Greg is white' or both then Brian is a lion.",
        "valid"
    ],
    [
        0.39653563996156055,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '676'}",
        "Chances are about even that Julius is a swan. There is almost no chance that Bernhard is white. There is little chance that Sandra got the milk. It is almost certain that if 'Julius is a swan and Sandra got the milk' then John put down the apple. We believe that if either 'Bernhard is white' or 'Sandra got the milk' but not both then Greg is yellow. It is highly likely that if 'Bernhard is white' or 'Julius is a swan' or both then Gertrude is a sheep.",
        "valid"
    ],
    [
        0.3964523524045944,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '5'}",
        "It is unlikely that either 'John discarded the apple' or 'Brian is a swan' but not both.",
        "valid"
    ],
    [
        0.39644913872083026,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '61'}",
        "It is probably not the case that either 'Bernhard is a swan' or 'Daniel got the football' but not both.",
        "valid"
    ],
    [
        0.3964252769947052,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '481'}",
        "We doubt that Julius is a frog. It is highly likely that Jessica is a mouse. Chances are slight that Bernhard is gray. There is almost no chance that if 'Julius is a frog' or 'Bernhard is gray' or both then Mary moved to the office. There is little chance that if 'Jessica is a mouse and Julius is a frog' then Sandra left the milk. It is highly unlikely that if 'Jessica is a mouse and Julius is a frog' then Daniel got the milk.",
        "valid"
    ],
    [
        0.3963928073644638,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '442'}",
        "It is unlikely that Lily is yellow. There is almost no chance that Sandra dropped the milk. It is highly likely that Brian is yellow. It is highly likely that if 'Lily is yellow' or 'Sandra dropped the milk' or both then Greg is white. It is certain that if either 'Brian is yellow' or 'Sandra dropped the milk' but not both then Bernhard is a frog. It is probably the case that if 'Sandra dropped the milk and Brian is yellow' then Mary went to the garden.",
        "valid"
    ],
    [
        0.3963511337836583,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '558'}",
        "It is probable that John left the milk. It is improbable that Greg is white. There is almost no chance that Jessica is a sheep. It is unlikely that if 'Greg is white and Jessica is a sheep' then Jason is tired. It is highly likely that if either 'Greg is white' or 'John left the milk' but not both then Brian is a rhino. It is unlikely that if 'Greg is white and Jessica is a sheep' then Mary took the football.",
        "valid"
    ],
    [
        0.3963188777367274,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '800'}",
        "It is improbable that Lily is yellow. Chances are slight that Sandra left the milk. There is a very good chance that Jessica is a cat. It is probably not the case that if either 'Lily is yellow' or 'Sandra left the milk' but not both then Mary grabbed the milk. It is probable that if either 'Sandra left the milk' or 'Lily is yellow' but not both then John went to the garden. It is certain that if 'Sandra left the milk' or 'Lily is yellow' or both then Brian is a rhino.",
        "valid"
    ],
    [
        0.3962792456150055,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '907'}",
        "It is impossible that either 'Greg is a lion' or 'Jeff moved to the garden' but not both.",
        "valid"
    ],
    [
        0.3962722768386205,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '605'}",
        "It is highly likely that Brian is a rhino. It is probable that Mary took the football. We doubt that Bernhard is yellow. It is probable that if either 'Bernhard is yellow' or 'Brian is a rhino' but not both then Greg is a lion. It is highly unlikely that if 'Bernhard is yellow' or 'Brian is a rhino' or both then Gertrude is a sheep. There is little chance that if 'Mary took the football' or 'Brian is a rhino' or both then John went to the bedroom.",
        "valid"
    ],
    [
        0.39620642364025116,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '871'}",
        "It is probably not the case that 'Mary dropped the milk' or 'Brian is a swan' or both.",
        "valid"
    ],
    [
        0.396123339732488,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '953'}",
        "It is probable that John went to the kitchen. It is probably not the case that Greg is gray. There is little chance that Mary left the apple. It is highly unlikely that if either 'John went to the kitchen' or 'Mary left the apple' but not both then Bernhard is a frog. It is probable that if 'John went to the kitchen and Greg is gray' then Julius is a swan. It is impossible that if either 'Greg is gray' or 'Mary left the apple' but not both then Brian is a rhino.",
        "valid"
    ],
    [
        0.39610380431016284,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '747'}",
        "Chances are slight that 'Lily is white and Brian is a rhino'.",
        "valid"
    ],
    [
        0.3961034764846166,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '532'}",
        "It is highly unlikely that 'Brian is a lion and Gertrude is a sheep'.",
        "valid"
    ],
    [
        0.3960956434408824,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '135'}",
        "We believe that Brian is gray. There is little chance that Bernhard is a frog. There is a very good chance that John went to the garden. It is unlikely that if 'Bernhard is a frog' or 'John went to the garden' or both then Julius is yellow. There is a better than even chance that if 'John went to the garden' or 'Brian is gray' or both then Mary dropped the milk. Chances are about even that if 'John went to the garden' or 'Brian is gray' or both then Lily is green.",
        "valid"
    ],
    [
        0.3960462262233098,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '430'}",
        "It is unlikely that 'Lily is a lion' or 'Sandra got the milk' or both.",
        "valid"
    ],
    [
        0.3959832141796748,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '400'}",
        "There is a very good chance that Greg is a swan. It is likely that Jessica is a cat. It is highly likely that John got the milk. It is likely that if 'Greg is a swan' or 'John got the milk' or both then Emily is a sheep. There is a very good chance that if either 'Jessica is a cat' or 'John got the milk' but not both then Brian is yellow. It is highly unlikely that if 'Greg is a swan and John got the milk' then Mary went to the garden.",
        "valid"
    ],
    [
        0.395969495177269,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '971'}",
        "It is impossible that 'Greg is a lion' or 'John went to the bedroom' or both.",
        "valid"
    ],
    [
        0.3959496517976125,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '134'}",
        "Chances are about even that Sandra dropped the milk. It is impossible that Julius is a swan. There is little chance that Mary put down the apple. Chances are slight that if either 'Mary put down the apple' or 'Julius is a swan' but not both then Bernhard is a frog. It is probably the case that if either 'Julius is a swan' or 'Sandra dropped the milk' but not both then John went to the kitchen. There is a better than even chance that if either 'Julius is a swan' or 'Sandra dropped the milk' but not both then Brian is white.",
        "valid"
    ],
    [
        0.3959295004606247,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '676'}",
        "It is almost certain that either 'Bernhard is a lion' or 'John got the milk' but not both.",
        "valid"
    ],
    [
        0.39590327938397724,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '630'}",
        "It is unlikely that either 'Bernhard is a swan' or 'Greg is a rhino' but not both.",
        "valid"
    ],
    [
        0.3958994795878728,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '215'}",
        "We doubt that John went to the garden. We believe that Lily is a swan. It is impossible that Sandra dropped the milk. It is almost certain that if 'Lily is a swan' or 'Sandra dropped the milk' or both then Brian is green. We doubt that if either 'Lily is a swan' or 'John went to the garden' but not both then Bernhard is a frog. It is almost certain that if 'John went to the garden and Lily is a swan' then Jeff left the football.",
        "valid"
    ],
    [
        0.3958049962917964,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '759'}",
        "It is probable that Bernhard is a swan. It is probably not the case that John discarded the apple. There is a very good chance that Mary went to the kitchen. There is little chance that if 'Mary went to the kitchen' or 'Bernhard is a swan' or both then Julius is a frog. There is a very good chance that if 'Bernhard is a swan and John discarded the apple' then Greg is yellow. It is highly unlikely that if either 'Mary went to the kitchen' or 'Bernhard is a swan' but not both then Lily is a rhino.",
        "valid"
    ],
    [
        0.39580345650513965,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '91'}",
        "It is improbable that 'Julius is white' or 'Greg is a swan' or both.",
        "valid"
    ],
    [
        0.3956810186306636,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '815'}",
        "It is probably not the case that Emily is a wolf. It is almost certain that Sandra left the football. It is certain that Greg is a frog. There is almost no chance that if 'Emily is a wolf and Sandra left the football' then Winona is a mouse. We believe that if 'Sandra left the football and Emily is a wolf' then Mary moved to the garden. It is unlikely that if 'Emily is a wolf' or 'Sandra left the football' or both then Lily is a rhino.",
        "valid"
    ],
    [
        0.3956512858470281,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '702'}",
        "It is impossible that Jeff moved to the garden. There is little chance that Lily is a swan. There is a very good chance that Fred is in the office. It is probably not the case that if either 'Lily is a swan' or 'Fred is in the office' but not both then Sandra dropped the apple. There is a very good chance that if either 'Jeff moved to the garden' or 'Fred is in the office' but not both then Mary went to the bedroom. We doubt that if 'Lily is a swan and Fred is in the office' then Bernhard is a frog.",
        "valid"
    ],
    [
        0.39563517769177753,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '999'}",
        "There is a better than even chance that John grabbed the apple. Chances are slight that Greg is a lion. There is a better than even chance that Bernhard is gray. There is almost no chance that if either 'John grabbed the apple' or 'Greg is a lion' but not both then Daniel got the milk. There is almost no chance that if 'Greg is a lion' or 'John grabbed the apple' or both then Fred went to the garden. There is little chance that if 'John grabbed the apple and Greg is a lion' then Sandra dropped the milk.",
        "valid"
    ],
    [
        0.3955715596675873,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '488'}",
        "It is almost certain that John went to the hallway. There is almost no chance that Jessica is a cat. It is highly likely that Lily is a swan. It is probable that if 'John went to the hallway and Lily is a swan' then Julius is gray. There is a very good chance that if 'John went to the hallway and Jessica is a cat' then Greg is a rhino. Chances are about even that if 'John went to the hallway' or 'Lily is a swan' or both then Mary left the football.",
        "valid"
    ],
    [
        0.395570049683253,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '507'}",
        "It is probable that John took the football. It is unlikely that Mary picked up the apple. It is improbable that Julius is a rhino. It is probably the case that if 'John took the football and Julius is a rhino' then Jessica is a cat. It is almost certain that if either 'Julius is a rhino' or 'Mary picked up the apple' but not both then Winona is a mouse. There is a better than even chance that if 'Julius is a rhino' or 'John took the football' or both then Bernhard is a frog.",
        "valid"
    ],
    [
        0.3955600361029307,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '624'}",
        "Chances are about even that Gertrude is a sheep. It is probably the case that Daniel dropped the apple. There is little chance that Bernhard is white. It is impossible that if 'Daniel dropped the apple and Gertrude is a sheep' then Jessica is a wolf. It is probable that if either 'Daniel dropped the apple' or 'Gertrude is a sheep' but not both then Mary went to the bedroom. It is impossible that if 'Daniel dropped the apple and Bernhard is white' then Lily is a rhino.",
        "valid"
    ],
    [
        0.3955066651105881,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '476'}",
        "It is probably the case that Bernhard is gray. It is probably not the case that Jason is tired. Chances are slight that Lily is yellow. It is improbable that if either 'Lily is yellow' or 'Bernhard is gray' but not both then Mary went to the bedroom. It is highly likely that if 'Jason is tired' or 'Lily is yellow' or both then Brian is a rhino. It is highly unlikely that if 'Bernhard is gray and Lily is yellow' then John grabbed the apple.",
        "valid"
    ],
    [
        0.3954937905073166,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '957'}",
        "Chances are about even that Bernhard is a swan. It is unlikely that Jeff put down the milk. It is impossible that Julius is a frog. It is impossible that if 'Jeff put down the milk' or 'Bernhard is a swan' or both then Bill went to the office. It is likely that if 'Jeff put down the milk and Bernhard is a swan' then Lily is white. It is impossible that if 'Jeff put down the milk and Bernhard is a swan' then John dropped the milk.",
        "valid"
    ],
    [
        0.3954767237106959,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '275'}",
        "Chances are slight that Mary went to the hallway. Chances are about even that Lily is yellow. There is a better than even chance that Winona is a mouse. Chances are about even that if 'Mary went to the hallway' or 'Lily is yellow' or both then John took the apple. There is a better than even chance that if either 'Lily is yellow' or 'Winona is a mouse' but not both then Julius is a swan. There is little chance that if either 'Mary went to the hallway' or 'Lily is yellow' but not both then Sandra dropped the milk.",
        "valid"
    ],
    [
        0.3954668790102005,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '388'}",
        "There is little chance that Lily is a swan. There is a very good chance that Brian is a rhino. It is impossible that John moved to the garden.",
        "valid"
    ],
    [
        0.3954167614380519,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '318'}",
        "It is highly likely that Brian is a swan. It is probably the case that Mary went to the office. There is almost no chance that Jason is tired. It is improbable that if either 'Brian is a swan' or 'Jason is tired' but not both then Julius is gray. We believe that if 'Brian is a swan and Jason is tired' then John moved to the garden. It is almost certain that if 'Mary went to the office' or 'Brian is a swan' or both then Greg is a rhino.",
        "valid"
    ],
    [
        0.3954125791788101,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '406'}",
        "It is highly unlikely that 'Lily is a swan and Greg is white'.",
        "valid"
    ],
    [
        0.3952875981728236,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '809'}",
        "It is highly unlikely that 'Mary left the milk' or 'Brian is a swan' or both.",
        "valid"
    ],
    [
        0.39522089064121246,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '185'}",
        "It is unlikely that Greg is a frog. It is unlikely that Bernhard is yellow. It is probably the case that Sandra grabbed the milk. There is a very good chance that if either 'Greg is a frog' or 'Bernhard is yellow' but not both then Brian is a swan. There is little chance that if 'Bernhard is yellow' or 'Greg is a frog' or both then Mary went to the garden. We doubt that if 'Bernhard is yellow and Greg is a frog' then John picked up the apple.",
        "valid"
    ],
    [
        0.3951977839072545,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '123'}",
        "It is improbable that 'Lily is a swan' or 'John took the apple' or both.",
        "valid"
    ],
    [
        0.3951949228843053,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '891'}",
        "It is highly unlikely that John discarded the milk. There is a better than even chance that Fred is in the cinema. It is probably not the case that Julius is gray. Chances are about even that if 'Fred is in the cinema and Julius is gray' then Mary put down the milk. It is improbable that if 'Julius is gray and Fred is in the cinema' then Bernhard is white. It is probably the case that if either 'John discarded the milk' or 'Julius is gray' but not both then Lily is a swan.",
        "valid"
    ],
    [
        0.3951855997244517,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '886'}",
        "It is probably the case that Emily is a sheep. There is little chance that Bernhard is a frog. It is probable that Lily is a lion.",
        "valid"
    ],
    [
        0.39517559111118317,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '115'}",
        "It is almost certain that 'Brian is a frog' or 'Fred left the football' or both.",
        "valid"
    ],
    [
        0.3951013833284378,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '187'}",
        "It is almost certain that Mary left the milk. It is probable that Bernhard is a frog. There is almost no chance that John discarded the apple. We believe that if 'John discarded the apple and Mary left the milk' then Winona is a cat. It is improbable that if 'Mary left the milk' or 'John discarded the apple' or both then Brian is gray. It is likely that if 'Mary left the milk and John discarded the apple' then Lily is white.",
        "valid"
    ],
    [
        0.3950943847497304,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '246'}",
        "There is almost no chance that Bernhard is a frog. It is impossible that Lily is a swan. It is likely that John picked up the apple.",
        "valid"
    ],
    [
        0.39497993886470795,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '208'}",
        "It is probable that Julius is a lion. It is certain that Gertrude is a cat. It is probable that Mary went to the kitchen. It is probably not the case that if either 'Mary went to the kitchen' or 'Gertrude is a cat' but not both then Brian is yellow. Chances are slight that if either 'Gertrude is a cat' or 'Mary went to the kitchen' but not both then John left the football. It is almost certain that if 'Mary went to the kitchen and Julius is a lion' then Greg is a swan.",
        "valid"
    ],
    [
        0.39496735235055286,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '215'}",
        "There is little chance that Winona is a mouse. Chances are slight that Daniel dropped the apple. It is highly unlikely that Brian is a frog.",
        "valid"
    ],
    [
        0.39495372275511426,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '245'}",
        "عطر و طعم خوبی نداره‌ خیلی کمرنگه مثل قهوه های قدیمی دهه ۷۰ هست که عطر نداشتن یا بیشتر شبیه خاک یا خاک اره بودن. البته کافئینش خوبه. به عنوان قهوه اسپرسو مناسب نیست. بیشتر شبیه قهوه ترک هست",
        "طعم"
    ],
    [
        0.3949463715155919,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '0'}",
        "It is probably not the case that 'Julius is a frog' or 'Mary is in the school' or both.",
        "valid"
    ],
    [
        0.39491312702496845,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '0'}",
        "There is almost no chance that Greg is gray. Chances are slight that John discarded the apple. It is improbable that Sandra got the milk. It is improbable that if 'Greg is gray and Sandra got the milk' then Winona is a mouse. It is likely that if 'Sandra got the milk' or 'Greg is gray' or both then Julius is a swan. There is little chance that if 'John discarded the apple and Sandra got the milk' then Brian is a frog.",
        "valid"
    ],
    [
        0.39487358927726746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '748'}",
        "It is probable that Lily is white. It is unlikely that John took the apple. It is probably not the case that Mary went to the office. It is certain that if 'Lily is white and Mary went to the office' then Greg is yellow. There is almost no chance that if 'John took the apple and Mary went to the office' then Gertrude is a cat. It is likely that if either 'John took the apple' or 'Mary went to the office' but not both then Julius is a frog.",
        "valid"
    ],
    [
        0.39485176901022595,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '149'}",
        "It is almost certain that Jeff left the apple. It is highly unlikely that Julius is a rhino. It is probable that Fred discarded the apple. It is highly unlikely that if 'Fred discarded the apple' or 'Jeff left the apple' or both then Jessica is a mouse. It is probably not the case that if either 'Julius is a rhino' or 'Jeff left the apple' but not both then Bernhard is a swan. It is probably the case that if 'Jeff left the apple and Fred discarded the apple' then Sandra got the football.",
        "valid"
    ],
    [
        0.3948168307542801,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '874'}",
        "It is almost certain that Brian is green. We believe that Winona is a mouse. We doubt that John discarded the apple. It is almost certain that if 'John discarded the apple' or 'Brian is green' or both then Jessica is a sheep. It is improbable that if either 'Winona is a mouse' or 'John discarded the apple' but not both then Sandra left the milk. We believe that if either 'Brian is green' or 'John discarded the apple' but not both then Bill went to the office.",
        "valid"
    ],
    [
        0.3947228292624156,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '211'}",
        "There is little chance that Daniel took the milk. It is likely that Lily is a rhino. It is impossible that Mary is in the school.",
        "valid"
    ],
    [
        0.39466387530167896,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '672'}",
        "It is probably not the case that 'Sumit is hungry' or 'Lily is a swan' or both.",
        "valid"
    ],
    [
        0.3946293542782466,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '498'}",
        "It is impossible that Julius is gray. Chances are slight that Yann is thirsty. There is little chance that John moved to the office. There is a very good chance that if 'Yann is thirsty' or 'John moved to the office' or both then Jessica is a cat. It is impossible that if 'Yann is thirsty and John moved to the office' then Brian is a rhino. It is impossible that if 'Julius is gray and Yann is thirsty' then Sandra put down the milk.",
        "valid"
    ],
    [
        0.3945458432038625,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '346'}",
        "There is a better than even chance that Bill left the milk. It is highly unlikely that Bernhard is white. It is unlikely that Greg is a rhino. It is improbable that if 'Greg is a rhino and Bernhard is white' then John dropped the milk. We doubt that if 'Bill left the milk and Greg is a rhino' then Jeff went to the garden. There is little chance that if 'Bill left the milk' or 'Greg is a rhino' or both then Mary got the football.",
        "valid"
    ],
    [
        0.3945193936427434,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '549'}",
        "It is almost certain that John put down the milk. It is probably the case that Bernhard is a frog. It is unlikely that Jeff went to the garden. It is probable that if 'John put down the milk' or 'Bernhard is a frog' or both then Brian is yellow. It is probably not the case that if either 'Bernhard is a frog' or 'John put down the milk' but not both then Greg is white. It is probable that if 'John put down the milk' or 'Jeff went to the garden' or both then Julius is a rhino.",
        "valid"
    ],
    [
        0.39451246460278827,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '928'}",
        "It is improbable that 'Greg is a lion' or 'Julius is green' or both.",
        "valid"
    ],
    [
        0.3945062706867854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '598'}",
        "It is probably the case that either 'Brian is a frog' or 'Bill went to the garden' but not both.",
        "valid"
    ],
    [
        0.39446120460828143,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '542'}",
        "Chances are slight that either 'Mary left the football' or 'Lily is a swan' but not both.",
        "valid"
    ],
    [
        0.39444181819756824,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '430'}",
        "There is little chance that Lily is yellow. There is little chance that Yann is tired. Chances are slight that Julius is gray. It is likely that if either 'Yann is tired' or 'Lily is yellow' but not both then Mary went to the bedroom. Chances are about even that if either 'Yann is tired' or 'Julius is gray' but not both then Greg is a rhino. It is likely that if 'Julius is gray and Lily is yellow' then Sandra left the milk.",
        "valid"
    ],
    [
        0.3943996677796046,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '203'}",
        "There is little chance that either 'Mary put down the apple' or 'Lily is a lion' but not both.",
        "valid"
    ],
    [
        0.39424513280391693,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '275'}",
        "There is almost no chance that 'Gertrude is a sheep' or 'Brian is white' or both.",
        "valid"
    ],
    [
        0.3941827118396759,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '785'}",
        "There is almost no chance that either 'Greg is a lion' or 'Mary went to the office' but not both.",
        "valid"
    ],
    [
        0.39415348569552106,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '84'}",
        "It is impossible that either 'Bernhard is gray' or 'Lily is yellow' but not both.",
        "valid"
    ],
    [
        0.3941459556420644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '623'}",
        "There is a better than even chance that Greg is gray. It is improbable that Mary got the football. It is improbable that Fred dropped the milk. It is probable that if either 'Fred dropped the milk' or 'Mary got the football' but not both then Brian is green. There is almost no chance that if either 'Fred dropped the milk' or 'Greg is gray' but not both then Julius is a lion. It is probable that if either 'Mary got the football' or 'Fred dropped the milk' but not both then John went to the kitchen.",
        "valid"
    ],
    [
        0.3941328227519989,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '638'}",
        "Chances are slight that Jessica is a sheep. There is a better than even chance that Mary went to the office. It is almost certain that John got the apple. It is highly unlikely that if 'John got the apple and Mary went to the office' then Greg is a lion. It is highly likely that if 'Mary went to the office' or 'Jessica is a sheep' or both then Brian is a rhino. There is little chance that if either 'John got the apple' or 'Jessica is a sheep' but not both then Bernhard is yellow.",
        "valid"
    ],
    [
        0.3940997173388799,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '799'}",
        "It is highly likely that Jessica is a sheep. There is little chance that Emily is a wolf. Chances are slight that Julius is gray. There is a better than even chance that if 'Jessica is a sheep' or 'Emily is a wolf' or both then John moved to the office. Chances are about even that if 'Emily is a wolf and Jessica is a sheep' then Sandra got the milk. It is highly unlikely that if 'Emily is a wolf and Jessica is a sheep' then Brian is a frog.",
        "valid"
    ],
    [
        0.39408551156520844,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '712'}",
        "It is improbable that Lily is green. It is impossible that John went to the hallway. There is a better than even chance that Julius is gray. There is a very good chance that if 'Lily is green and Julius is gray' then Bill left the milk. It is certain that if 'Julius is gray and John went to the hallway' then Sandra got the football. It is probably not the case that if 'John went to the hallway and Lily is green' then Greg is a rhino.",
        "valid"
    ],
    [
        0.3940838724374771,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '211'}",
        "It is unlikely that Daniel took the football. Chances are slight that Julius is a swan. It is improbable that Bernhard is yellow. It is probable that if either 'Daniel took the football' or 'Bernhard is yellow' but not both then Gertrude is a cat. It is probably the case that if 'Julius is a swan' or 'Daniel took the football' or both then John went to the garden. There is a better than even chance that if 'Daniel took the football and Julius is a swan' then Winona is a mouse.",
        "valid"
    ],
    [
        0.39408311744530994,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '567'}",
        "It is unlikely that 'Brian is a swan' or 'John put down the apple' or both.",
        "valid"
    ],
    [
        0.3940800925095876,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '597'}",
        "It is impossible that either 'Greg is gray' or 'Bernhard is a swan' but not both.",
        "valid"
    ],
    [
        0.3940603584051132,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '549'}",
        "There is almost no chance that 'Bernhard is a rhino and Lily is a swan'.",
        "valid"
    ],
    [
        0.39405249059200287,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '312'}",
        "It is probably not the case that either 'Greg is a swan' or 'John took the football' but not both.",
        "valid"
    ],
    [
        0.3940226336320241,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '744'}",
        "There is almost no chance that Jessica is a cat. There is almost no chance that Jason is tired. Chances are about even that Lily is green. There is a better than even chance that if 'Lily is green' or 'Jessica is a cat' or both then Mary grabbed the milk. It is likely that if 'Lily is green and Jessica is a cat' then Julius is a frog. It is probably not the case that if either 'Lily is green' or 'Jessica is a cat' but not both then John went to the garden.",
        "valid"
    ],
    [
        0.39400696257750195,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '139'}",
        "It is probably not the case that 'Brian is yellow' or 'Mary dropped the milk' or both.",
        "valid"
    ],
    [
        0.3939937502145767,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '228'}",
        "It is almost certain that Sumit is bored. Chances are slight that Brian is a frog. It is probable that Bernhard is yellow. It is impossible that if either 'Sumit is bored' or 'Bernhard is yellow' but not both then John dropped the milk. It is improbable that if either 'Sumit is bored' or 'Bernhard is yellow' but not both then Lily is a frog. It is probably not the case that if 'Brian is a frog' or 'Bernhard is yellow' or both then Mary got the football.",
        "valid"
    ],
    [
        0.39395901560783386,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '741'}",
        "It is probably the case that Daniel dropped the apple. There is almost no chance that Lily is green. There is almost no chance that Jessica is a cat. It is unlikely that if either 'Lily is green' or 'Jessica is a cat' but not both then Bernhard is gray. Chances are slight that if 'Daniel dropped the apple and Lily is green' then Julius is a rhino. It is improbable that if either 'Lily is green' or 'Jessica is a cat' but not both then John went to the kitchen.",
        "valid"
    ],
    [
        0.3939442088206609,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '932'}",
        "There is little chance that either 'Lily is a rhino' or 'Bernhard is gray' but not both.",
        "valid"
    ],
    [
        0.3939296156167984,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '153'}",
        "Потом ― о детях (наши фоты), кого больше любят, и Лиля ― о маме, которая любила ее явно больше, но Эльзу ― тоже, конечно…",
        "correct"
    ],
    [
        0.39389824370543164,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '289'}",
        "It is probable that Winona is a mouse. It is probably not the case that Bernhard is green. It is likely that John discarded the apple. We doubt that if 'John discarded the apple' or 'Winona is a mouse' or both then Lily is green. It is probably the case that if 'Winona is a mouse and Bernhard is green' then Greg is gray. There is a better than even chance that if either 'Bernhard is green' or 'Winona is a mouse' but not both then Brian is yellow.",
        "valid"
    ],
    [
        0.3938671996196111,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '869'}",
        "It is unlikely that 'Lily is a lion' or 'John went to the office' or both.",
        "valid"
    ],
    [
        0.3938586463530858,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '392'}",
        "There is almost no chance that 'Julius is gray and Lily is a lion'.",
        "valid"
    ],
    [
        0.3938576231400172,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '36'}",
        "There is a better than even chance that Sumit is thirsty. We doubt that Greg is a rhino. Chances are slight that John went to the garden. It is almost certain that if 'Sumit is thirsty' or 'John went to the garden' or both then Lily is a lion. There is almost no chance that if 'Sumit is thirsty and Greg is a rhino' then Bernhard is a swan. It is almost certain that if 'Sumit is thirsty' or 'John went to the garden' or both then Brian is a frog.",
        "valid"
    ],
    [
        0.3938373227914174,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '446'}",
        "It is certain that Greg is a rhino. It is probably the case that Julius is a swan. It is probably not the case that Gertrude is a mouse.",
        "valid"
    ],
    [
        0.3938270757595698,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '521'}",
        "Chances are about even that John moved to the garden. We doubt that Sumit is hungry. It is probably the case that Greg is a frog. It is impossible that if either 'Greg is a frog' or 'Sumit is hungry' but not both then Mary got the football. It is highly unlikely that if either 'Sumit is hungry' or 'John moved to the garden' but not both then Brian is gray. It is probably not the case that if 'Sumit is hungry' or 'Greg is a frog' or both then Yann is thirsty.",
        "valid"
    ],
    [
        0.3938174347082774,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '944'}",
        "It is highly unlikely that either 'John grabbed the apple' or 'Brian is white' but not both.",
        "valid"
    ],
    [
        0.39375971257686615,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '127'}",
        "There is a very good chance that Gertrude is a sheep. It is probably not the case that Bernhard is a lion. It is almost certain that Lily is a swan.",
        "valid"
    ],
    [
        0.3937510997056961,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '144'}",
        "It is impossible that 'John went to the garden' or 'Brian is a rhino' or both.",
        "valid"
    ],
    [
        0.39368270337581635,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '417'}",
        "It is highly unlikely that either 'Lily is white' or 'Bill moved to the office' but not both.",
        "valid"
    ],
    [
        0.3935614377260208,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '566'}",
        "It is certain that John went to the office. It is impossible that Greg is a frog. Chances are about even that Brian is white.",
        "valid"
    ],
    [
        0.3935601810614268,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '720'}",
        "It is unlikely that Bernhard is a rhino. There is a better than even chance that Greg is a swan. It is likely that Mary dropped the milk. There is a very good chance that if 'Bernhard is a rhino' or 'Greg is a swan' or both then Sumit is thirsty. Chances are slight that if 'Bernhard is a rhino' or 'Mary dropped the milk' or both then Fred went to the garden. There is almost no chance that if 'Greg is a swan' or 'Bernhard is a rhino' or both then Emily is a cat.",
        "valid"
    ],
    [
        0.39353888233502704,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '934'}",
        "Chances are about even that Sandra left the apple. It is certain that John moved to the office. There is little chance that Brian is a rhino. It is probably not the case that if 'Brian is a rhino' or 'Sandra left the apple' or both then Bernhard is gray. It is unlikely that if either 'Brian is a rhino' or 'Sandra left the apple' but not both then Greg is a frog. It is certain that if either 'Sandra left the apple' or 'John moved to the office' but not both then Julius is yellow.",
        "valid"
    ],
    [
        0.3935302048921585,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '731'}",
        "We believe that Bernhard is a rhino. It is likely that Greg is a swan. It is unlikely that Mary went to the office. It is probable that if 'Greg is a swan and Bernhard is a rhino' then Antoine is hungry. It is improbable that if 'Mary went to the office and Bernhard is a rhino' then John left the milk. It is highly unlikely that if 'Greg is a swan' or 'Bernhard is a rhino' or both then Lily is yellow.",
        "valid"
    ],
    [
        0.39349691569805145,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '125'}",
        "There is almost no chance that Winona is a mouse. Chances are about even that Fred went to the garden. It is probably not the case that Greg is a lion.",
        "valid"
    ],
    [
        0.39348416527112323,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '208'}",
        "It is probably not the case that either 'Winona is a cat' or 'Mary got the football' but not both.",
        "valid"
    ],
    [
        0.3934756815433502,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '427'}",
        "It is highly likely that Bernhard is a frog. It is improbable that Emily is a wolf. It is likely that John went to the bedroom. It is probably the case that if 'Bernhard is a frog and John went to the bedroom' then Brian is a rhino. It is certain that if either 'Bernhard is a frog' or 'Emily is a wolf' but not both then Mary dropped the apple. It is probable that if either 'Bernhard is a frog' or 'John went to the bedroom' but not both then Lily is yellow.",
        "valid"
    ],
    [
        0.39347412685553235,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '768'}",
        "It is impossible that either 'Mary put down the apple' or 'Daniel got the milk' but not both.",
        "valid"
    ],
    [
        0.3934626678625743,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '692'}",
        "It is improbable that John dropped the apple. We believe that Greg is a rhino. There is a better than even chance that Jeff left the football. It is probably the case that if 'John dropped the apple' or 'Greg is a rhino' or both then Emily is a cat. Chances are about even that if either 'Jeff left the football' or 'Greg is a rhino' but not both then Julius is white. It is highly likely that if either 'Greg is a rhino' or 'Jeff left the football' but not both then Mary got the football.",
        "valid"
    ],
    [
        0.39339498182137805,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '664'}",
        "It is probably not the case that either 'Lily is gray' or 'John went to the hallway' but not both.",
        "valid"
    ],
    [
        0.393317108352979,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '842'}",
        "There is almost no chance that Sandra took the football. We believe that Brian is white. There is a better than even chance that Lily is a rhino.",
        "valid"
    ],
    [
        0.39313680430253345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '912'}",
        "It is almost certain that Jeff moved to the office. It is highly unlikely that Lily is white. It is likely that John dropped the milk. Chances are slight that if either 'John dropped the milk' or 'Lily is white' but not both then Jessica is a cat. It is probably the case that if 'Jeff moved to the office' or 'Lily is white' or both then Mary went to the garden. We believe that if 'Lily is white and Jeff moved to the office' then Brian is a lion.",
        "valid"
    ],
    [
        0.3930523494879405,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '372'}",
        "There is almost no chance that either 'Lily is a frog' or 'John went to the garden' but not both.",
        "valid"
    ],
    [
        0.39302850763003033,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '732'}",
        "It is certain that Julius is gray. It is probably not the case that Bernhard is green. There is almost no chance that Brian is yellow. There is a very good chance that if 'Bernhard is green' or 'Julius is gray' or both then Sumit is thirsty. Chances are about even that if 'Bernhard is green and Julius is gray' then Greg is gray. It is highly unlikely that if either 'Julius is gray' or 'Brian is yellow' but not both then John left the milk.",
        "valid"
    ],
    [
        0.39300810794035596,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '63'}",
        "Человек не должен делать этого в одиночку», — заявил кларк, отметив, что болельщики могут понять футболиста-гея из команды, которую они поддерживают, но в то же время могут не принять гомосексуалиста из другого клуба",
        "correct"
    ],
    [
        0.3929094523191452,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '105'}",
        "There is almost no chance that either 'Jeff went to the bedroom' or 'Julius is a lion' but not both.",
        "valid"
    ],
    [
        0.39288360873858136,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '97'}",
        "It is probably not the case that 'Greg is a swan' or 'Emily is a cat' or both.",
        "valid"
    ],
    [
        0.3928382694721222,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '401'}",
        "It is impossible that either 'Fred is in the cinema' or 'Greg is a swan' but not both.",
        "valid"
    ],
    [
        0.39281921088695526,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '497'}",
        "It is improbable that either 'Bernhard is a frog' or 'Daniel took the apple' but not both.",
        "valid"
    ],
    [
        0.3928067535161972,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '389'}",
        "It is probably not the case that Brian is white. It is highly unlikely that Lily is yellow. There is a very good chance that Sandra is in the kitchen.",
        "valid"
    ],
    [
        0.39273952941099805,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '152'}",
        "Потом ― о детях (наши фоты), кого больше любят, и Лиля ― о маме, которая любила ее явно больше, но Эльзу ― тоже, конечно…",
        "incorrect"
    ],
    [
        0.39272906879583996,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '795'}",
        "It is certain that Mary went to the bedroom. It is almost certain that Greg is gray. Chances are slight that Bernhard is a rhino. It is probable that if either 'Mary went to the bedroom' or 'Greg is gray' but not both then Daniel took the milk. There is almost no chance that if either 'Greg is gray' or 'Mary went to the bedroom' but not both then Jeff moved to the office. There is a very good chance that if either 'Bernhard is a rhino' or 'Greg is gray' but not both then Julius is white.",
        "valid"
    ],
    [
        0.3926735818386078,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '851'}",
        "It is highly likely that Bernhard is a rhino. It is highly likely that Julius is a swan. There is little chance that Lily is a lion.",
        "valid"
    ],
    [
        0.3926643232504527,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '98'}",
        "There is almost no chance that John went to the garden. It is probably the case that Sandra got the football. It is almost certain that Brian is a swan. It is unlikely that if 'Sandra got the football and John went to the garden' then Julius is a lion. It is unlikely that if 'Sandra got the football' or 'John went to the garden' or both then Greg is a frog. There is a very good chance that if 'Sandra got the football' or 'Brian is a swan' or both then Fred dropped the milk.",
        "valid"
    ],
    [
        0.3926624556382497,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '5'}",
        "We doubt that Brian is a rhino. It is likely that Bernhard is yellow. It is certain that Greg is white. It is unlikely that if 'Bernhard is yellow and Brian is a rhino' then Jeff moved to the garden. There is a very good chance that if 'Brian is a rhino and Bernhard is yellow' then John left the milk. There is a better than even chance that if 'Bernhard is yellow' or 'Brian is a rhino' or both then Mary went to the kitchen.",
        "valid"
    ],
    [
        0.39264539380868274,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '684'}",
        "It is highly unlikely that 'Lily is gray and Greg is a frog'.",
        "valid"
    ],
    [
        0.392625297109286,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '443'}",
        "Chances are about even that Sandra took the apple. It is almost certain that Lily is a lion. There is a better than even chance that Julius is a rhino.",
        "valid"
    ],
    [
        0.39261290431022644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '873'}",
        "It is probably not the case that either 'Mary got the milk' or 'Brian is green' but not both.",
        "valid"
    ],
    [
        0.3925536721944809,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '554'}",
        "There is little chance that John picked up the apple. It is probably not the case that Bernhard is green. Chances are slight that Greg is yellow. It is highly unlikely that if 'John picked up the apple and Greg is yellow' then Mary dropped the milk. We doubt that if either 'John picked up the apple' or 'Bernhard is green' but not both then Lily is a rhino. It is unlikely that if 'Bernhard is green and Greg is yellow' then Julius is a lion.",
        "valid"
    ],
    [
        0.39253805577754974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '726'}",
        "It is impossible that 'Greg is a swan and Brian is gray'.",
        "valid"
    ],
    [
        0.392512783408165,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '515'}",
        "We believe that Sumit is hungry. It is likely that Julius is a rhino. It is certain that Greg is white. There is a better than even chance that if either 'Greg is white' or 'Sumit is hungry' but not both then Mary went to the hallway. We doubt that if 'Greg is white and Sumit is hungry' then Fred discarded the apple. There is almost no chance that if 'Julius is a rhino' or 'Sumit is hungry' or both then Jason is tired.",
        "valid"
    ],
    [
        0.39244984090328217,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '319'}",
        "It is probably not the case that 'Lily is white' or 'Jeff went to the garden' or both.",
        "valid"
    ],
    [
        0.39243607223033905,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '248'}",
        "It is highly likely that Lily is green. Chances are about even that Julius is gray. There is a very good chance that Bernhard is green. It is probably the case that if 'Lily is green' or 'Julius is gray' or both then John moved to the garden. It is highly likely that if 'Bernhard is green and Lily is green' then Greg is a lion. We doubt that if 'Julius is gray' or 'Lily is green' or both then Mary grabbed the milk.",
        "valid"
    ],
    [
        0.3924234062433243,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '160'}",
        "It is probably the case that either 'Bernhard is gray' or 'Julius is a frog' but not both.",
        "valid"
    ],
    [
        0.3923865606387456,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '342'}",
        "It is improbable that Fred dropped the apple. It is improbable that Bernhard is white. There is little chance that Sandra put down the milk. There is a better than even chance that if 'Bernhard is white' or 'Fred dropped the apple' or both then Greg is a swan. It is probable that if 'Sandra put down the milk' or 'Fred dropped the apple' or both then Julius is a lion. It is probably not the case that if either 'Bernhard is white' or 'Sandra put down the milk' but not both then Brian is yellow.",
        "valid"
    ],
    [
        0.39235934615135193,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '574'}",
        "There is a better than even chance that Mary got the milk. It is highly unlikely that Bernhard is a frog. It is impossible that Greg is a rhino.",
        "valid"
    ],
    [
        0.3923584173123042,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '488'}",
        "It is probably the case that either 'Lily is a frog' or 'John moved to the office' but not both.",
        "valid"
    ],
    [
        0.39233871797720593,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '180'}",
        "It is probably not the case that 'Julius is a swan' or 'John discarded the apple' or both.",
        "valid"
    ],
    [
        0.39232338468233746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '267'}",
        "It is improbable that 'Julius is gray' or 'Lily is yellow' or both.",
        "valid"
    ],
    [
        0.3922903637091319,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '862'}",
        "It is probable that Lily is a lion. It is probably the case that John grabbed the apple. Chances are slight that Julius is yellow. We believe that if 'John grabbed the apple and Lily is a lion' then Fred is in the cinema. There is little chance that if 'Lily is a lion and Julius is yellow' then Sandra took the football. It is highly unlikely that if 'John grabbed the apple and Julius is yellow' then Bill went to the office.",
        "valid"
    ],
    [
        0.3922884116570155,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '678'}",
        "It is unlikely that 'John put down the apple' or 'Brian is white' or both.",
        "valid"
    ],
    [
        0.3922865043083827,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '537'}",
        "Chances are slight that either 'Bernhard is a rhino' or 'Greg is white' but not both.",
        "valid"
    ],
    [
        0.3922865043083827,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '950'}",
        "Chances are slight that either 'Bernhard is a rhino' or 'Greg is white' but not both.",
        "valid"
    ],
    [
        0.3922361185153325,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '343'}",
        "It is probably not the case that 'John moved to the garden' or 'Lily is a swan' or both.",
        "valid"
    ],
    [
        0.3922012547651927,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '450'}",
        "We doubt that John grabbed the apple. It is probably not the case that Julius is a rhino. We believe that Lily is a swan.",
        "valid"
    ],
    [
        0.39216601351896924,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '163'}",
        "It is almost certain that John got the milk. It is almost certain that Lily is yellow. It is impossible that Winona is a mouse.",
        "valid"
    ],
    [
        0.39213261008262634,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '787'}",
        "There is little chance that Mary dropped the apple. We believe that Brian is a rhino. Chances are slight that Bill went to the kitchen. It is highly unlikely that if 'Brian is a rhino and Mary dropped the apple' then John is in the garden. It is highly unlikely that if 'Brian is a rhino and Mary dropped the apple' then Julius is yellow. It is highly likely that if either 'Bill went to the kitchen' or 'Brian is a rhino' but not both then Greg is gray.",
        "valid"
    ],
    [
        0.39209135870138806,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '569'}",
        "It is impossible that Julius is a swan. There is a better than even chance that Brian is gray. It is likely that John dropped the apple.",
        "valid"
    ],
    [
        0.3920626789331436,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '168'}",
        "It is highly unlikely that Lily is a lion. There is a very good chance that Brian is green. Chances are slight that John left the football.",
        "valid"
    ],
    [
        0.39202820758024853,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '195'}",
        "There is a very good chance that Greg is a lion. It is highly unlikely that Sandra left the football. Chances are slight that Yann is thirsty. It is improbable that if 'Sandra left the football and Greg is a lion' then Bernhard is gray. There is little chance that if 'Greg is a lion' or 'Yann is thirsty' or both then Daniel dropped the milk. We believe that if 'Greg is a lion and Sandra left the football' then John went to the garden.",
        "valid"
    ],
    [
        0.39197570582230884,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '223'}",
        "It is impossible that Bernhard is yellow. It is probable that Jessica is a wolf. It is certain that Mary is in the hallway. Chances are about even that if either 'Jessica is a wolf' or 'Mary is in the hallway' but not both then John went to the office. We doubt that if either 'Mary is in the hallway' or 'Bernhard is yellow' but not both then Brian is a lion. Chances are slight that if 'Jessica is a wolf' or 'Mary is in the hallway' or both then Greg is a rhino.",
        "valid"
    ],
    [
        0.3919736643632253,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '221'}",
        "It is probably not the case that 'Julius is a swan' or 'Fred went to the garden' or both.",
        "valid"
    ],
    [
        0.39196255803108215,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '875'}",
        "There is little chance that either 'John got the milk' or 'Julius is white' but not both.",
        "valid"
    ],
    [
        0.3919549733400345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '922'}",
        "It is improbable that either 'Brian is green' or 'Mary discarded the milk' but not both.",
        "valid"
    ],
    [
        0.3919358750184377,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '850'}",
        "Chances are about even that Greg is a swan. Chances are about even that Bernhard is white. We doubt that John dropped the apple. It is probable that if either 'John dropped the apple' or 'Bernhard is white' but not both then Brian is green. It is highly likely that if 'Bernhard is white and John dropped the apple' then Mary went to the office. It is certain that if 'Bernhard is white and Greg is a swan' then Lily is a frog.",
        "valid"
    ],
    [
        0.39190177619457245,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '293'}",
        "There is almost no chance that either 'Sandra left the milk' or 'Lily is a rhino' but not both.",
        "valid"
    ],
    [
        0.3918883949518204,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '948'}",
        "It is impossible that Lily is yellow. It is almost certain that Jeff moved to the garden. There is a better than even chance that Brian is white.",
        "valid"
    ],
    [
        0.3918671061595281,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '581'}",
        "It is highly unlikely that 'Julius is a lion and Daniel got the milk'.",
        "valid"
    ],
    [
        0.3918224920829137,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '820'}",
        "Chances are about even that Brian is white. It is probably not the case that John left the milk. It is likely that Bernhard is a rhino.",
        "valid"
    ],
    [
        0.39164911210536957,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '949'}",
        "It is highly likely that Lily is a swan. We doubt that John took the apple. Chances are about even that Julius is a rhino.",
        "valid"
    ],
    [
        0.39162786304950714,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '189'}",
        "There is a very good chance that Bernhard is a rhino. There is little chance that Lily is green. There is a very good chance that Mary got the milk. There is a better than even chance that if 'Mary got the milk' or 'Lily is green' or both then Greg is a swan. We believe that if 'Mary got the milk and Lily is green' then John moved to the garden. It is probable that if 'Mary got the milk' or 'Lily is green' or both then Gertrude is a cat.",
        "valid"
    ],
    [
        0.39159002900123596,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '298'}",
        "There is a better than even chance that Mary left the football. It is improbable that Greg is yellow. It is almost certain that Julius is white. Chances are slight that if either 'Julius is white' or 'Greg is yellow' but not both then Fred put down the apple. It is unlikely that if 'Mary left the football and Julius is white' then Jessica is a sheep. There is little chance that if 'Mary left the football' or 'Greg is yellow' or both then Brian is yellow.",
        "valid"
    ],
    [
        0.3915601670742035,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '34'}",
        "It is impossible that 'Emily is a mouse' or 'Brian is yellow' or both.",
        "valid"
    ],
    [
        0.39148620267709094,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '179'}",
        "It is unlikely that either 'John got the apple' or 'Julius is white' but not both.",
        "valid"
    ],
    [
        0.39144404232501984,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '724'}",
        "There is a very good chance that John dropped the apple. We believe that Brian is a swan. It is certain that Emily is a wolf. It is highly likely that if 'John dropped the apple and Brian is a swan' then Lily is gray. It is highly likely that if either 'Brian is a swan' or 'John dropped the apple' but not both then Mary went to the bedroom. Chances are about even that if either 'Brian is a swan' or 'Emily is a wolf' but not both then Julius is green.",
        "valid"
    ],
    [
        0.3913768380880356,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '160'}",
        "It is improbable that John went to the garden. It is highly likely that Greg is green. It is highly likely that Julius is gray. It is highly unlikely that if either 'John went to the garden' or 'Julius is gray' but not both then Emily is a wolf. There is little chance that if 'Greg is green' or 'Julius is gray' or both then Brian is gray. It is impossible that if 'John went to the garden and Julius is gray' then Mary is in the hallway.",
        "valid"
    ],
    [
        0.39130627115567523,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '424'}",
        "It is impossible that either 'Emily is a mouse' or 'Julius is gray' but not both.",
        "valid"
    ],
    [
        0.391287033756574,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '957'}",
        "It is highly unlikely that 'Brian is yellow' or 'Jeff discarded the milk' or both.",
        "valid"
    ],
    [
        0.39126435418923694,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '849'}",
        "It is impossible that Mary got the football. There is little chance that John went to the hallway. It is unlikely that Julius is gray. Chances are about even that if 'John went to the hallway and Mary got the football' then Lily is green. There is a better than even chance that if 'Mary got the football' or 'Julius is gray' or both then Brian is a swan. It is improbable that if 'John went to the hallway and Julius is gray' then Jessica is a mouse.",
        "valid"
    ],
    [
        0.39123957355817157,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '278'}",
        "It is probably not the case that 'Greg is a swan' or 'Jessica is a mouse' or both.",
        "valid"
    ],
    [
        0.39119572937488556,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '493'}",
        "It is probable that Brian is green. There is a better than even chance that Mary went to the hallway. It is likely that Julius is white. It is unlikely that if 'Brian is green' or 'Julius is white' or both then Bernhard is a frog. There is a very good chance that if either 'Mary went to the hallway' or 'Brian is green' but not both then Daniel took the milk. It is unlikely that if 'Mary went to the hallway and Julius is white' then Sandra left the football.",
        "valid"
    ],
    [
        0.3911693940560023,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '451'}",
        "It is probably the case that John put down the milk. There is a better than even chance that Jeff dropped the apple. We believe that Jason is thirsty. There is a better than even chance that if 'John put down the milk' or 'Jason is thirsty' or both then Lily is gray. It is probable that if 'Jeff dropped the apple' or 'Jason is thirsty' or both then Daniel got the football. It is highly unlikely that if either 'Jason is thirsty' or 'John put down the milk' but not both then Julius is a swan.",
        "valid"
    ],
    [
        0.3911674867073695,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '297'}",
        "There is a better than even chance that Bernhard is a swan. It is improbable that Brian is yellow. Chances are about even that John put down the milk. We believe that if 'John put down the milk and Bernhard is a swan' then Jeff moved to the garden. It is unlikely that if either 'Bernhard is a swan' or 'Brian is yellow' but not both then Mary went to the hallway. We doubt that if either 'Brian is yellow' or 'Bernhard is a swan' but not both then Gertrude is a mouse.",
        "valid"
    ],
    [
        0.3911591072877248,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '252'}",
        "It is impossible that Jessica is a wolf. It is unlikely that Brian is a swan. It is impossible that John went to the office.",
        "valid"
    ],
    [
        0.3911379923423131,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '897'}",
        "It is improbable that 'Julius is white' or 'John took the milk' or both.",
        "valid"
    ],
    [
        0.39106932779153186,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '885'}",
        "It is improbable that John dropped the apple. There is little chance that Lily is yellow. It is almost certain that Mary went to the office. It is improbable that if 'John dropped the apple' or 'Lily is yellow' or both then Julius is gray. There is a better than even chance that if either 'Mary went to the office' or 'John dropped the apple' but not both then Winona is a sheep. We doubt that if 'John dropped the apple' or 'Lily is yellow' or both then Brian is a rhino.",
        "valid"
    ],
    [
        0.3910403698682785,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '523'}",
        "It is almost certain that either 'Julius is a rhino' or 'John picked up the apple' but not both.",
        "valid"
    ],
    [
        0.3910166770219803,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '749'}",
        "There is almost no chance that 'Greg is a lion and Emily is a sheep'.",
        "valid"
    ],
    [
        0.3910039613644282,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '594'}",
        "It is likely that Bernhard is a frog. It is impossible that Yann is tired. It is impossible that Mary went to the kitchen. Chances are about even that if 'Bernhard is a frog' or 'Yann is tired' or both then Gertrude is a cat. Chances are slight that if 'Mary went to the kitchen and Bernhard is a frog' then Daniel took the apple. Chances are about even that if either 'Yann is tired' or 'Bernhard is a frog' but not both then Jason is bored.",
        "valid"
    ],
    [
        0.3909766922394435,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '913'}",
        "It is improbable that 'Brian is a swan' or 'John went to the garden' or both.",
        "valid"
    ],
    [
        0.39096665879090625,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '743'}",
        "It is impossible that 'Sumit is thirsty' or 'Brian is yellow' or both.",
        "valid"
    ],
    [
        0.3909047146638234,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '745'}",
        "It is highly likely that either 'Brian is green' or 'John got the milk' but not both.",
        "valid"
    ],
    [
        0.3908773362636566,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '734'}",
        "It is certain that Jeff dropped the apple. It is highly likely that Julius is gray. It is unlikely that Daniel left the milk. There is almost no chance that if either 'Daniel left the milk' or 'Julius is gray' but not both then Fred is in the cinema. There is almost no chance that if 'Daniel left the milk and Jeff dropped the apple' then Brian is a frog. There is almost no chance that if 'Jeff dropped the apple' or 'Julius is gray' or both then Mary went to the bedroom.",
        "valid"
    ],
    [
        0.3907888283332189,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '608'}",
        "We believe that Mary went to the bedroom. It is likely that Greg is a swan. It is probably not the case that John left the milk. Chances are slight that if 'Greg is a swan and Mary went to the bedroom' then Gertrude is a mouse. Chances are slight that if either 'Greg is a swan' or 'Mary went to the bedroom' but not both then Julius is a lion. We doubt that if 'John left the milk and Greg is a swan' then Bernhard is yellow.",
        "valid"
    ],
    [
        0.3907475421826045,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '990'}",
        "It is impossible that either 'Mary picked up the milk' or 'Bernhard is a rhino' but not both.",
        "valid"
    ],
    [
        0.3907380352417628,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '188'}",
        "There is almost no chance that either 'Greg is a frog' or 'John put down the apple' but not both.",
        "valid"
    ],
    [
        0.3906715214252472,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '610'}",
        "There is a better than even chance that Greg is a swan. There is almost no chance that Julius is a frog. It is certain that Mary dropped the milk.",
        "valid"
    ],
    [
        0.3906530986229579,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '18'}",
        "It is probably the case that either 'Mary took the football' or 'Julius is a frog' but not both.",
        "valid"
    ],
    [
        0.39063015580177307,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '807'}",
        "It is probably not the case that either 'Julius is white' or 'John went to the office' but not both.",
        "valid"
    ],
    [
        0.3906300912300746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '746'}",
        "Chances are slight that 'Lily is green' or 'Brian is yellow' or both.",
        "valid"
    ],
    [
        0.3905847767988841,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '70'}",
        "There is a very good chance that Jessica is a cat. It is probable that Brian is yellow. It is certain that Mary went to the kitchen. It is certain that if either 'Brian is yellow' or 'Jessica is a cat' but not both then Greg is white. It is highly unlikely that if 'Jessica is a cat and Mary went to the kitchen' then Yann is hungry. It is improbable that if 'Brian is yellow' or 'Jessica is a cat' or both then Julius is green.",
        "valid"
    ],
    [
        0.3904899259408315,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '54'}",
        "It is certain that Brian is green. It is almost certain that Julius is a lion. It is likely that Daniel took the milk.",
        "valid"
    ],
    [
        0.3904516448577245,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '839'}",
        "It is impossible that John dropped the apple. It is highly likely that Mary went to the bedroom. Chances are slight that Greg is a rhino. It is probably the case that if 'Greg is a rhino' or 'Mary went to the bedroom' or both then Lily is a lion. It is almost certain that if 'John dropped the apple and Mary went to the bedroom' then Gertrude is a mouse. It is probably not the case that if 'John dropped the apple and Mary went to the bedroom' then Bernhard is gray.",
        "valid"
    ],
    [
        0.39037489394346875,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '903'}",
        "It is highly unlikely that Jessica is a mouse. Chances are about even that Brian is yellow. There is little chance that Greg is green. It is probably not the case that if 'Greg is green' or 'Jessica is a mouse' or both then Gertrude is a sheep. Chances are slight that if 'Greg is green' or 'Jessica is a mouse' or both then John went to the office. It is improbable that if either 'Brian is yellow' or 'Jessica is a mouse' but not both then Bernhard is a frog.",
        "valid"
    ],
    [
        0.39037226140499115,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '54'}",
        "There is almost no chance that Mary dropped the milk. It is highly likely that John went to the garden. It is improbable that Bernhard is a rhino. It is highly unlikely that if 'John went to the garden' or 'Mary dropped the milk' or both then Sandra grabbed the apple. It is unlikely that if either 'Bernhard is a rhino' or 'Mary dropped the milk' but not both then Lily is a swan. It is unlikely that if 'Mary dropped the milk and Bernhard is a rhino' then Brian is a lion.",
        "valid"
    ],
    [
        0.39032094677289325,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '809'}",
        "It is unlikely that either 'Daniel left the apple' or 'Julius is gray' but not both.",
        "valid"
    ],
    [
        0.39027536908785504,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '536'}",
        "It is highly likely that Brian is a swan. Chances are slight that Greg is a frog. It is highly unlikely that Mary went to the bedroom.",
        "valid"
    ],
    [
        0.3902666022380193,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '601'}",
        "It is certain that John got the apple. There is almost no chance that Greg is a rhino. There is little chance that Mary left the football. Chances are slight that if 'Greg is a rhino' or 'John got the apple' or both then Bernhard is yellow. There is little chance that if 'Mary left the football' or 'John got the apple' or both then Sumit is bored. It is certain that if either 'John got the apple' or 'Mary left the football' but not both then Bill went to the kitchen.",
        "valid"
    ],
    [
        0.3902606815099716,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '394'}",
        "Chances are slight that Mary left the apple. It is highly unlikely that Brian is green. It is probably the case that John went to the office. It is impossible that if 'Mary left the apple' or 'Brian is green' or both then Julius is a frog. There is a better than even chance that if 'John went to the office' or 'Brian is green' or both then Jessica is a mouse. There is almost no chance that if either 'John went to the office' or 'Mary left the apple' but not both then Greg is a rhino.",
        "valid"
    ],
    [
        0.39023658633232117,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '778'}",
        "\"― Брат моего друга ― он непрофессионально занимается этим, но регулярно.\"",
        "correct"
    ],
    [
        0.3901940236488978,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '50'}",
        "Chances are about even that Mary moved to the office. It is highly unlikely that Brian is yellow. We believe that Greg is gray. There is almost no chance that if 'Mary moved to the office' or 'Greg is gray' or both then Gertrude is a cat. It is improbable that if 'Brian is yellow' or 'Greg is gray' or both then Bill left the milk. There is almost no chance that if 'Brian is yellow' or 'Greg is gray' or both then Emily is a sheep.",
        "valid"
    ],
    [
        0.39017896354198456,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '257'}",
        "It is impossible that 'Greg is a rhino and Bernhard is a frog'.",
        "valid"
    ],
    [
        0.39013971388339996,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '121'}",
        "It is certain that either 'Greg is gray' or 'Julius is a swan' but not both.",
        "valid"
    ],
    [
        0.39002228776613873,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '205'}",
        "Поскольку же это так, мысль о реальности, которая остается недоступной не только данному фактическому уровню познания, но и всякому направленному на предмет познавательному взору, не содержит ни малейшего противоречия и хотя не может быть достоверно доказана, но преподносится нам как нечто правдоподобное и вероятное",
        "correct"
    ],
    [
        0.38996130724747974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '356'}",
        "It is highly unlikely that 'Gertrude is a mouse and Brian is a lion'.",
        "valid"
    ],
    [
        0.38993216554323834,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '94'}",
        "It is certain that Sandra left the apple. There is almost no chance that Greg is a rhino. It is certain that Brian is green. We doubt that if 'Brian is green and Sandra left the apple' then Lily is white. There is a better than even chance that if 'Sandra left the apple' or 'Brian is green' or both then Sumit is tired. It is highly unlikely that if 'Sandra left the apple' or 'Greg is a rhino' or both then Bernhard is a swan.",
        "valid"
    ],
    [
        0.38992274800936383,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '530'}",
        "It is probably not the case that 'Brian is green' or 'Emily is a cat' or both.",
        "valid"
    ],
    [
        0.3899175276358922,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '767'}",
        "It is probably not the case that 'Greg is yellow' or 'Julius is white' or both.",
        "valid"
    ],
    [
        0.38983255128065747,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '550'}",
        "Chances are about even that Greg is a swan. It is certain that Brian is gray. There is almost no chance that Bernhard is green. It is highly likely that if 'Bernhard is green and Brian is gray' then Jessica is a cat. There is a very good chance that if either 'Brian is gray' or 'Bernhard is green' but not both then Sandra left the milk. Chances are slight that if 'Bernhard is green' or 'Brian is gray' or both then John picked up the apple.",
        "valid"
    ],
    [
        0.38980600734551746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '565'}",
        "We doubt that Bernhard is white. It is unlikely that Julius is gray. There is almost no chance that Mary moved to the office. There is almost no chance that if 'Julius is gray and Bernhard is white' then Jessica is a mouse. Chances are slight that if 'Mary moved to the office' or 'Julius is gray' or both then Lily is a rhino. It is likely that if 'Bernhard is white and Mary moved to the office' then John left the milk.",
        "valid"
    ],
    [
        0.38972315192222595,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '128'}",
        "It is impossible that Mary took the milk. It is probably not the case that Lily is green. There is almost no chance that Emily is a mouse.",
        "valid"
    ],
    [
        0.3896973878145218,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '396'}",
        "We believe that Mary dropped the milk. It is impossible that Gertrude is a cat. It is probably the case that John went to the kitchen. It is almost certain that if 'John went to the kitchen' or 'Gertrude is a cat' or both then Winona is a sheep. It is impossible that if 'Gertrude is a cat' or 'John went to the kitchen' or both then Lily is white. Chances are about even that if 'Mary dropped the milk and John went to the kitchen' then Bernhard is a swan.",
        "valid"
    ],
    [
        0.38964008788267773,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '760'}",
        "It is improbable that Daniel took the apple. It is probably not the case that John moved to the office. We doubt that Mary went to the office. There is almost no chance that if 'Mary went to the office and John moved to the office' then Brian is yellow. It is probable that if 'Mary went to the office' or 'John moved to the office' or both then Gertrude is a mouse. We doubt that if either 'Mary went to the office' or 'Daniel took the apple' but not both then Bernhard is a frog.",
        "valid"
    ],
    [
        0.38960563639799756,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '962'}",
        "We doubt that John dropped the milk. Chances are slight that Brian is a swan. It is highly likely that Bernhard is green. It is improbable that if either 'John dropped the milk' or 'Brian is a swan' but not both then Mary got the apple. It is probable that if 'John dropped the milk and Bernhard is green' then Julius is gray. It is impossible that if 'Bernhard is green and John dropped the milk' then Winona is a sheep.",
        "valid"
    ],
    [
        0.38960332175095874,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '310'}",
        "We doubt that Mary left the football. It is impossible that Greg is white. It is impossible that John moved to the office. It is certain that if 'Mary left the football and Greg is white' then Yann is hungry. There is little chance that if 'Greg is white and Mary left the football' then Emily is a mouse. It is almost certain that if either 'Greg is white' or 'John moved to the office' but not both then Bill got the milk there.",
        "valid"
    ],
    [
        0.38960205018520355,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '916'}",
        "It is probably not the case that Mary is in the bathroom. There is almost no chance that Sandra got the milk. It is probably not the case that Lily is green.",
        "valid"
    ],
    [
        0.38959090908368427,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '670'}",
        "It is improbable that 'Brian is a swan and Julius is gray'.",
        "valid"
    ],
    [
        0.3895897964636485,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '751'}",
        "It is highly likely that Mary left the apple. It is unlikely that Greg is white. Chances are about even that Lily is a rhino.",
        "valid"
    ],
    [
        0.3894605338573456,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '130'}",
        "There is a better than even chance that Emily is a sheep. It is improbable that Julius is a frog. It is impossible that Sandra got the milk.",
        "valid"
    ],
    [
        0.3894554525613785,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '697'}",
        "We believe that Brian is gray. It is almost certain that Greg is a rhino. Chances are about even that Gertrude is a wolf.",
        "valid"
    ],
    [
        0.38934863607088727,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '775'}",
        "Chances are slight that 'Mary left the milk' or 'Lily is a rhino' or both.",
        "valid"
    ],
    [
        0.3891323109467824,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '888'}",
        "There is a better than even chance that Lily is gray. It is unlikely that Winona is a wolf. It is unlikely that Greg is green.",
        "valid"
    ],
    [
        0.38897429406642914,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '110'}",
        "It is unlikely that Bernhard is yellow. It is probably the case that Mary went to the garden. We believe that Julius is a swan. It is probably the case that if 'Mary went to the garden' or 'Bernhard is yellow' or both then Lily is green. There is little chance that if 'Mary went to the garden and Bernhard is yellow' then Sumit is hungry. Chances are about even that if 'Mary went to the garden' or 'Julius is a swan' or both then Brian is a frog.",
        "valid"
    ],
    [
        0.38894347846508026,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '745'}",
        "It is certain that Julius is a swan. It is probably the case that Bernhard is green. It is highly unlikely that Lily is white.",
        "valid"
    ],
    [
        0.3888854036728541,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '911'}",
        "It is highly unlikely that 'Daniel dropped the apple and Lily is a rhino'.",
        "valid"
    ],
    [
        0.38887551923592883,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '777'}",
        "It is probable that John put down the apple. It is improbable that Bernhard is a lion. There is a better than even chance that Sandra dropped the milk. There is a better than even chance that if 'Sandra dropped the milk' or 'John put down the apple' or both then Antoine is hungry. It is probably not the case that if either 'Sandra dropped the milk' or 'John put down the apple' but not both then Brian is a swan. It is highly likely that if 'John put down the apple and Sandra dropped the milk' then Jeff moved to the garden.",
        "valid"
    ],
    [
        0.38887548943360645,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '440'}",
        "It is probably the case that Sandra grabbed the apple. It is highly unlikely that Bernhard is gray. We believe that Brian is white. There is little chance that if 'Bernhard is gray' or 'Sandra grabbed the apple' or both then Mary left the football. It is almost certain that if 'Bernhard is gray' or 'Sandra grabbed the apple' or both then Lily is green. It is certain that if either 'Sandra grabbed the apple' or 'Brian is white' but not both then Julius is a swan.",
        "valid"
    ],
    [
        0.38884598513444263,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '906'}",
        "It is impossible that Gertrude is a sheep. We doubt that Mary dropped the milk. There is little chance that John put down the apple. It is certain that if 'Gertrude is a sheep' or 'Mary dropped the milk' or both then Jason is tired. There is little chance that if 'Gertrude is a sheep' or 'John put down the apple' or both then Bernhard is white. Chances are about even that if either 'Mary dropped the milk' or 'Gertrude is a sheep' but not both then Greg is a swan.",
        "valid"
    ],
    [
        0.38884026805559796,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '349'}",
        "\"Поэтому торговля без кассы, которой нередко злоупотребляют на рынках, может оказаться для покупателя… козырной картой.\"",
        "incorrect"
    ],
    [
        0.38879317541917163,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '382'}",
        "It is highly unlikely that John dropped the apple. It is highly likely that Bernhard is a swan. It is improbable that Mary went to the garden. It is probably not the case that if 'John dropped the apple' or 'Mary went to the garden' or both then Lily is a frog. There is a very good chance that if either 'John dropped the apple' or 'Bernhard is a swan' but not both then Greg is a rhino. Chances are about even that if 'Mary went to the garden' or 'Bernhard is a swan' or both then Jason is tired.",
        "valid"
    ],
    [
        0.3887875924507777,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '363'}",
        "It is probably the case that Julius is gray. It is unlikely that John moved to the garden. It is almost certain that Greg is a lion.",
        "valid"
    ],
    [
        0.3887825657924016,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '229'}",
        "It is improbable that Bernhard is a swan. It is likely that Mary discarded the milk. We doubt that Jessica is a mouse. There is a very good chance that if 'Mary discarded the milk' or 'Bernhard is a swan' or both then Julius is white. There is little chance that if 'Mary discarded the milk' or 'Jessica is a mouse' or both then Jeff went to the bedroom. There is little chance that if 'Jessica is a mouse' or 'Mary discarded the milk' or both then Greg is yellow.",
        "valid"
    ],
    [
        0.3887757360935211,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '626'}",
        "It is certain that either 'Bernhard is a frog' or 'Winona is a cat' but not both.",
        "valid"
    ],
    [
        0.38873115678628284,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '787'}",
        "It is impossible that either 'Emily is a sheep' or 'John dropped the milk' but not both.",
        "valid"
    ],
    [
        0.38872432212034863,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '528'}",
        "It is probably not the case that either 'Bernhard is green' or 'Daniel got the milk' but not both.",
        "valid"
    ],
    [
        0.3886219213406245,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '311'}",
        "There is almost no chance that 'Bernhard is a swan' or 'Yann is thirsty' or both.",
        "valid"
    ],
    [
        0.38858209550380707,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '835'}",
        "It is highly unlikely that either 'Bernhard is white' or 'Julius is gray' but not both.",
        "valid"
    ],
    [
        0.3885531077782313,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '912'}",
        "There is a very good chance that Emily is a wolf. It is probably the case that Brian is a frog. Chances are slight that John got the milk.",
        "valid"
    ],
    [
        0.3885512202978134,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '984'}",
        "It is almost certain that John went to the garden. It is almost certain that Emily is a sheep. There is little chance that Brian is green. There is a very good chance that if 'John went to the garden' or 'Emily is a sheep' or both then Sandra took the apple. It is almost certain that if 'Emily is a sheep' or 'Brian is green' or both then Bernhard is gray. It is probably the case that if either 'Emily is a sheep' or 'John went to the garden' but not both then Julius is a frog.",
        "valid"
    ],
    [
        0.388547216852506,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '51'}",
        "It is likely that Bernhard is a swan. There is a better than even chance that Mary moved to the garden. Chances are slight that Emily is a mouse. Chances are slight that if 'Bernhard is a swan and Mary moved to the garden' then Brian is gray. It is impossible that if either 'Bernhard is a swan' or 'Mary moved to the garden' but not both then Sandra left the apple. There is almost no chance that if either 'Emily is a mouse' or 'Mary moved to the garden' but not both then Julius is a rhino.",
        "valid"
    ],
    [
        0.38847113649050397,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '779'}",
        "It is probably not the case that Bernhard is gray. Chances are about even that Mary dropped the milk. There is a very good chance that Lily is a swan.",
        "valid"
    ],
    [
        0.3884397049744924,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '960'}",
        "There is little chance that 'Julius is a lion' or 'Fred went to the garden' or both.",
        "valid"
    ],
    [
        0.38843175768852234,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '487'}",
        "We believe that John went to the garden. It is highly unlikely that Sandra dropped the milk. There is a better than even chance that Lily is a rhino. We doubt that if 'Sandra dropped the milk' or 'John went to the garden' or both then Bernhard is green. There is little chance that if 'Lily is a rhino and John went to the garden' then Brian is white. Chances are about even that if 'Lily is a rhino and John went to the garden' then Mary is in the school.",
        "valid"
    ],
    [
        0.38843004902203876,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '302'}",
        "It is almost certain that Mary went to the kitchen. It is certain that Lily is a swan. There is a better than even chance that Julius is white.",
        "valid"
    ],
    [
        0.38839973509311676,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '212'}",
        "It is highly likely that Julius is a lion. It is impossible that Fred moved to the office. It is certain that Bernhard is a frog.",
        "valid"
    ],
    [
        0.3883740206559499,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '982'}",
        "There is a better than even chance that Sandra left the milk. It is unlikely that Greg is green. It is impossible that John moved to the garden. It is almost certain that if 'John moved to the garden and Sandra left the milk' then Bernhard is gray. There is little chance that if 'Greg is green and Sandra left the milk' then Lily is a swan. It is unlikely that if either 'Sandra left the milk' or 'Greg is green' but not both then Julius is a lion.",
        "valid"
    ],
    [
        0.3883300522963206,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '484'}",
        "It is certain that John went to the kitchen. It is highly likely that Lily is gray. It is probably not the case that Greg is a rhino.",
        "valid"
    ],
    [
        0.3882957647244136,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '620'}",
        "It is probably the case that Greg is green. We believe that Emily is a sheep. It is probably the case that Mary went to the garden. It is certain that if either 'Emily is a sheep' or 'Greg is green' but not both then Julius is yellow. We doubt that if 'Emily is a sheep and Mary went to the garden' then Lily is a frog. It is probable that if 'Greg is green and Mary went to the garden' then Bernhard is gray.",
        "valid"
    ],
    [
        0.3882588893175125,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '600'}",
        "There is little chance that Sandra left the milk. It is highly unlikely that Brian is white. We believe that Julius is a frog.",
        "valid"
    ],
    [
        0.38825055460135144,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '775'}",
        "There is little chance that Julius is white. There is a very good chance that Fred went to the office. It is almost certain that Greg is yellow. It is certain that if 'Julius is white' or 'Fred went to the office' or both then Sandra grabbed the apple. It is highly likely that if 'Fred went to the office' or 'Greg is yellow' or both then Jessica is a mouse. It is certain that if 'Fred went to the office' or 'Julius is white' or both then Brian is a rhino.",
        "valid"
    ],
    [
        0.3882301151752472,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '232'}",
        "It is highly likely that Antoine is thirsty. There is a better than even chance that Jessica is a mouse. It is almost certain that Sandra left the apple. It is highly unlikely that if 'Antoine is thirsty' or 'Jessica is a mouse' or both then Lily is gray. It is impossible that if 'Jessica is a mouse and Antoine is thirsty' then Bernhard is a swan. It is highly likely that if 'Sandra left the apple and Antoine is thirsty' then Mary moved to the office.",
        "valid"
    ],
    [
        0.3881909598906835,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '280'}",
        "It is certain that Sumit is tired. We doubt that John went to the bedroom. There is little chance that Daniel took the football. It is probably the case that if 'John went to the bedroom and Daniel took the football' then Bernhard is yellow. There is a very good chance that if 'John went to the bedroom and Sumit is tired' then Julius is a swan. It is probably the case that if either 'John went to the bedroom' or 'Daniel took the football' but not both then Lily is a swan.",
        "valid"
    ],
    [
        0.38816553850968677,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '302'}",
        "It is almost certain that John went to the hallway. It is probably not the case that Bernhard is green. We doubt that Julius is white. It is probable that if either 'Bernhard is green' or 'Julius is white' but not both then Greg is a swan. It is highly likely that if 'Bernhard is green and Julius is white' then Mary picked up the milk. It is probable that if 'Bernhard is green and John went to the hallway' then Lily is gray.",
        "valid"
    ],
    [
        0.38815073668956757,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '942'}",
        "Chances are about even that Fred is in the cinema. It is highly unlikely that Julius is yellow. Chances are slight that Mary got the football. We believe that if either 'Julius is yellow' or 'Mary got the football' but not both then Greg is a rhino. It is likely that if 'Julius is yellow and Fred is in the cinema' then John went to the garden. There is a better than even chance that if 'Mary got the football' or 'Julius is yellow' or both then Bernhard is a swan.",
        "valid"
    ],
    [
        0.38807162642478943,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '509'}",
        "There is little chance that either 'Bernhard is green' or 'Lily is a frog' but not both.",
        "valid"
    ],
    [
        0.3880666345357895,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '67'}",
        "It is highly likely that Lily is green. It is almost certain that Daniel took the apple. There is a very good chance that John moved to the office. There is little chance that if 'Lily is green and John moved to the office' then Mary went to the office. It is almost certain that if either 'Daniel took the apple' or 'John moved to the office' but not both then Julius is a swan. Chances are slight that if 'Daniel took the apple and John moved to the office' then Jessica is a wolf.",
        "valid"
    ],
    [
        0.3880486438671748,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '107'}",
        "It is probable that Brian is white. It is probably not the case that Fred went to the garden. It is highly unlikely that Sandra left the football. Chances are about even that if 'Sandra left the football' or 'Fred went to the garden' or both then Jason is tired. It is almost certain that if 'Fred went to the garden' or 'Sandra left the football' or both then Greg is a lion. Chances are slight that if 'Sandra left the football and Fred went to the garden' then Bernhard is yellow.",
        "valid"
    ],
    [
        0.3880355457464854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '573'}",
        "It is improbable that Fred is in the cinema. It is probably the case that Julius is green. It is probably not the case that Lily is a frog.",
        "valid"
    ],
    [
        0.38801277180512744,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '845'}",
        "There is little chance that 'Brian is a rhino' or 'Sandra dropped the milk' or both.",
        "valid"
    ],
    [
        0.38798028727372486,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '604'}",
        "It is probably the case that Bernhard is green. It is highly likely that Greg is a rhino. It is highly likely that Brian is gray. It is probable that if 'Bernhard is green' or 'Greg is a rhino' or both then Julius is yellow. We doubt that if 'Brian is gray' or 'Greg is a rhino' or both then Jessica is a cat. It is improbable that if 'Bernhard is green' or 'Greg is a rhino' or both then John moved to the office.",
        "valid"
    ],
    [
        0.38795824348926544,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '230'}",
        "There is little chance that Bernhard is a rhino. There is a better than even chance that Winona is a wolf. It is highly unlikely that Jeff moved to the garden. It is highly likely that if 'Winona is a wolf' or 'Bernhard is a rhino' or both then Julius is white. There is little chance that if 'Bernhard is a rhino and Jeff moved to the garden' then John got the apple. Chances are slight that if 'Bernhard is a rhino and Jeff moved to the garden' then Lily is green.",
        "valid"
    ],
    [
        0.38794059058030445,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '23'}",
        "We doubt that Lily is a frog. It is almost certain that Greg is gray. It is improbable that John went to the office.",
        "valid"
    ],
    [
        0.38792236149311066,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '217'}",
        "It is impossible that Mary dropped the milk. It is probably the case that Lily is white. It is probable that John got the apple.",
        "valid"
    ],
    [
        0.3878837575515111,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '644'}",
        "It is certain that 'Brian is white' or 'Mary left the football' or both.",
        "valid"
    ],
    [
        0.3878726661205292,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '757'}",
        "It is almost certain that 'Lily is a rhino and Bernhard is a frog'.",
        "valid"
    ],
    [
        0.38786765933036804,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '642'}",
        "It is unlikely that Bernhard is a frog. Chances are about even that Gertrude is a sheep. It is probably not the case that Mary dropped the apple. It is probably not the case that if 'Gertrude is a sheep' or 'Bernhard is a frog' or both then Jeff went to the hallway. It is probably not the case that if 'Gertrude is a sheep' or 'Bernhard is a frog' or both then John moved to the garden. Chances are slight that if 'Bernhard is a frog' or 'Gertrude is a sheep' or both then Jessica is a cat.",
        "valid"
    ],
    [
        0.3878577301899592,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '486'}",
        "Chances are slight that Jessica is a mouse. It is highly likely that Bernhard is a frog. It is impossible that John moved to the office. It is probably the case that if 'Jessica is a mouse and Bernhard is a frog' then Mary went to the kitchen. It is unlikely that if 'Jessica is a mouse' or 'John moved to the office' or both then Brian is gray. It is impossible that if 'Bernhard is a frog' or 'Jessica is a mouse' or both then Sandra left the football.",
        "valid"
    ],
    [
        0.38784709572792053,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '360'}",
        "There is a better than even chance that John went to the bedroom. It is probable that Brian is a rhino. It is improbable that Julius is white.",
        "valid"
    ],
    [
        0.38782723248004913,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '829'}",
        "It is impossible that 'John took the apple and Brian is a frog'.",
        "valid"
    ],
    [
        0.3878246645132701,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '160'}",
        "«Чтобы не пропадало, пьяный катил по крутобережью зарождающегося болота тележное колесо, которое всегда при случае, мало ли что бывает вдруг, обязательно пригодится, на память о лошади, которой не может быть",
        "incorrect"
    ],
    [
        0.3878191461165746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '837'}",
        "'Greg is a frog' or 'Jessica is a cat' or both.",
        "valid"
    ],
    [
        0.38776925206184387,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '847'}",
        "It is certain that either 'Lily is a lion' or 'John moved to the garden' but not both.",
        "valid"
    ],
    [
        0.38775255779425305,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '917'}",
        "There is almost no chance that Mary took the milk. It is likely that Fred put down the apple. There is a better than even chance that Bernhard is a rhino. We doubt that if 'Mary took the milk and Bernhard is a rhino' then Lily is green. Chances are about even that if 'Fred put down the apple and Bernhard is a rhino' then Jeff moved to the office. It is certain that if 'Bernhard is a rhino' or 'Mary took the milk' or both then Winona is a cat.",
        "valid"
    ],
    [
        0.38771846890449524,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '236'}",
        "It is probably the case that Gertrude is a cat. It is probably not the case that Bernhard is a rhino. There is little chance that John got the apple. There is almost no chance that if either 'John got the apple' or 'Bernhard is a rhino' but not both then Jessica is a cat. We doubt that if 'Gertrude is a cat' or 'John got the apple' or both then Sandra dropped the milk. It is highly unlikely that if either 'Gertrude is a cat' or 'Bernhard is a rhino' but not both then Mary moved to the office.",
        "valid"
    ],
    [
        0.3876767059167226,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '142'}",
        "Вещь, то есть реальность ens, обнаруженная человеком, такова, что он не мыслит о себе, весь погруженный в ту «вечную жизнь», о приверженности которой писал Роджер Бэкон",
        "correct"
    ],
    [
        0.38766146699587506,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '296'}",
        "We doubt that John got the apple. It is highly unlikely that Emily is a mouse. We believe that Mary went to the hallway. It is almost certain that if 'John got the apple and Emily is a mouse' then Bernhard is white. There is a better than even chance that if 'Mary went to the hallway and John got the apple' then Lily is gray. There is a better than even chance that if 'Emily is a mouse' or 'John got the apple' or both then Brian is a swan.",
        "valid"
    ],
    [
        0.3876045693953832,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '468'}",
        "It is probably the case that Mary put down the apple. It is almost certain that Sandra grabbed the milk. There is a better than even chance that John went to the garden. It is probably not the case that if 'Sandra grabbed the milk' or 'Mary put down the apple' or both then Jessica is a cat. It is probably the case that if 'John went to the garden' or 'Sandra grabbed the milk' or both then Julius is a rhino. It is impossible that if 'Sandra grabbed the milk and Mary put down the apple' then Greg is a swan.",
        "valid"
    ],
    [
        0.387555792927742,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '227'}",
        "Chances are slight that either 'Mary left the football' or 'Julius is a frog' but not both.",
        "valid"
    ],
    [
        0.3875402758518855,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '724'}",
        "It is probably not the case that Mary moved to the garden. It is almost certain that John dropped the apple. There is a better than even chance that Lily is a lion.",
        "valid"
    ],
    [
        0.38752757012844086,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '538'}",
        "There is a better than even chance that Bernhard is gray. There is little chance that Julius is green. Chances are slight that Greg is a frog. It is unlikely that if either 'Julius is green' or 'Greg is a frog' but not both then Gertrude is a cat. There is little chance that if either 'Greg is a frog' or 'Bernhard is gray' but not both then Sandra dropped the apple. It is highly unlikely that if 'Greg is a frog' or 'Julius is green' or both then Bill left the football.",
        "valid"
    ],
    [
        0.38739539682865143,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '975'}",
        "It is impossible that John discarded the apple. It is certain that Greg is a frog. There is a better than even chance that Brian is yellow.",
        "valid"
    ],
    [
        0.3873753895362218,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '944'}",
        "We believe that John took the football. It is almost certain that Julius is yellow. It is probably not the case that Mary went to the bedroom. It is improbable that if 'Mary went to the bedroom and Julius is yellow' then Bernhard is white. There is a better than even chance that if either 'Julius is yellow' or 'Mary went to the bedroom' but not both then Sandra got the milk. There is a better than even chance that if either 'Mary went to the bedroom' or 'Julius is yellow' but not both then Greg is a frog.",
        "valid"
    ],
    [
        0.38731110592683154,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '865'}",
        "It is likely that John went to the garden. It is highly likely that Fred is in the cinema. It is probably not the case that Mary grabbed the milk. Chances are slight that if either 'Fred is in the cinema' or 'John went to the garden' but not both then Greg is a swan. It is impossible that if either 'Fred is in the cinema' or 'John went to the garden' but not both then Bernhard is a lion. There is a very good chance that if either 'Mary grabbed the milk' or 'Fred is in the cinema' but not both then Gertrude is a mouse.",
        "valid"
    ],
    [
        0.38723800083001453,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '33'}",
        "It is likely that Brian is a frog. It is impossible that Greg is yellow. There is a very good chance that Mary left the football.",
        "valid"
    ],
    [
        0.3871533026297887,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '476'}",
        "It is impossible that Sumit is thirsty. We doubt that Lily is a frog. It is highly unlikely that Mary is in the hallway.",
        "valid"
    ],
    [
        0.3871299127737681,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '810'}",
        "We believe that John went to the hallway. There is little chance that Mary left the football. It is certain that Bernhard is yellow. It is almost certain that if either 'Mary left the football' or 'John went to the hallway' but not both then Brian is a rhino. Chances are about even that if 'Bernhard is yellow' or 'Mary left the football' or both then Winona is a wolf. It is likely that if 'Mary left the football' or 'John went to the hallway' or both then Lily is a lion.",
        "valid"
    ],
    [
        0.38712843755880993,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '385'}",
        "'Bernhard is a swan' or 'Greg is a rhino' or both.",
        "valid"
    ],
    [
        0.3871232370535533,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '913'}",
        "Chances are slight that Bill moved to the office. Chances are about even that John went to the garden. There is almost no chance that Greg is a rhino. Chances are slight that if 'John went to the garden' or 'Greg is a rhino' or both then Bernhard is yellow. It is almost certain that if 'Bill moved to the office and Greg is a rhino' then Mary dropped the milk. It is almost certain that if either 'John went to the garden' or 'Bill moved to the office' but not both then Brian is a frog.",
        "valid"
    ],
    [
        0.3870786378781001,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '822'}",
        "We doubt that John moved to the garden. There is little chance that Sandra left the apple. It is probable that Daniel took the milk. It is impossible that if 'Sandra left the apple' or 'Daniel took the milk' or both then Brian is a swan. It is probable that if 'Daniel took the milk and Sandra left the apple' then Mary went to the bedroom. It is highly unlikely that if either 'Sandra left the apple' or 'John moved to the garden' but not both then Gertrude is a sheep.",
        "valid"
    ],
    [
        0.38698748250802356,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '816'}",
        "Chances are slight that Winona is a wolf. It is certain that Mary dropped the apple. It is highly unlikely that Julius is a frog.",
        "valid"
    ],
    [
        0.38696908454100293,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '340'}",
        "It is certain that Brian is a lion. There is a better than even chance that Greg is yellow. There is a very good chance that John moved to the garden.",
        "valid"
    ],
    [
        0.3869609534740448,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '563'}",
        "Chances are about even that Sandra took the milk. It is probably not the case that Gertrude is a wolf. It is highly likely that Mary went to the bedroom. It is likely that if either 'Mary went to the bedroom' or 'Sandra took the milk' but not both then Julius is gray. It is almost certain that if 'Mary went to the bedroom' or 'Gertrude is a wolf' or both then Brian is a swan. It is highly likely that if 'Mary went to the bedroom and Sandra took the milk' then Greg is a swan.",
        "valid"
    ],
    [
        0.3869447559118271,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '31'}",
        "It is likely that either 'Sumit is bored' or 'Brian is white' but not both.",
        "valid"
    ],
    [
        0.38686764736970264,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '175'}",
        "There is almost no chance that Brian is gray. There is almost no chance that Bernhard is gray. It is unlikely that John left the apple. Chances are slight that if 'Bernhard is gray' or 'John left the apple' or both then Jeff moved to the office. It is likely that if 'John left the apple and Brian is gray' then Lily is white. There is a very good chance that if 'John left the apple' or 'Brian is gray' or both then Mary went to the garden.",
        "valid"
    ],
    [
        0.38683106005191803,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '403'}",
        "It is unlikely that 'Bernhard is a swan' or 'Brian is yellow' or both.",
        "valid"
    ],
    [
        0.38681770364443463,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '133'}",
        "It is improbable that 'Mary picked up the milk' or 'Julius is a rhino' or both.",
        "valid"
    ],
    [
        0.3868023256460826,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '497'}",
        "شیرینه و اصلا شبیه آب زرشک آلبالویی که از آبمیوه فروشی ها می گیری نیست خیلی بد مزه ست فقط برای یکبار تجربه کردن خوبه نه بیشتر",
        "طعم"
    ],
    [
        0.3867735415697098,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '710'}",
        "It is impossible that 'Julius is a lion and Mary dropped the milk'.",
        "valid"
    ],
    [
        0.38671717047691345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '592'}",
        "Chances are slight that Lily is a frog. There is a very good chance that Mary dropped the apple. It is impossible that John picked up the apple.",
        "valid"
    ],
    [
        0.3864583671092987,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '70'}",
        "It is probable that Lily is a lion. Chances are slight that Brian is green. It is probable that Mary is in the hallway.",
        "valid"
    ],
    [
        0.38639699916044873,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '621'}",
        "Chances are about even that Mary is in the bathroom. It is almost certain that Sumit is tired. It is highly unlikely that Brian is green. It is probably not the case that if 'Mary is in the bathroom and Sumit is tired' then Jessica is a sheep. It is probably not the case that if either 'Sumit is tired' or 'Mary is in the bathroom' but not both then Sandra got the football. It is probable that if either 'Brian is green' or 'Mary is in the bathroom' but not both then Bernhard is yellow.",
        "valid"
    ],
    [
        0.38639214138189953,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '725'}",
        "It is probable that Brian is green. We doubt that Gertrude is a mouse. It is improbable that John discarded the apple. It is highly unlikely that if 'John discarded the apple' or 'Brian is green' or both then Julius is a swan. It is likely that if either 'John discarded the apple' or 'Gertrude is a mouse' but not both then Sandra dropped the milk. It is impossible that if either 'John discarded the apple' or 'Brian is green' but not both then Mary moved to the garden.",
        "valid"
    ],
    [
        0.3863779952128728,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '917'}",
        "It is probably not the case that either 'Jessica is a cat' or 'Daniel dropped the milk' but not both.",
        "valid"
    ],
    [
        0.38635800778865814,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '244'}",
        "It is probably not the case that Lily is white. It is probable that Brian is green. We believe that John moved to the garden.",
        "valid"
    ],
    [
        0.38630834221839905,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '273'}",
        "Сага «Город костей» Кассандры Клэр  — история о девушке, которая однажды выяснила, что она не просто неприметная жительница Бруклина, а полуангел, оберегающий человечество от зла, причем потомственный",
        "correct"
    ],
    [
        0.38630573948224384,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '674'}",
        "It is improbable that either 'Greg is a frog' or 'John went to the office' but not both.",
        "valid"
    ],
    [
        0.38627247512340546,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '593'}",
        "Chances are slight that John went to the garden. It is certain that Gertrude is a mouse. There is a very good chance that Bernhard is a swan. It is probably not the case that if 'Bernhard is a swan and John went to the garden' then Sandra dropped the milk. There is a very good chance that if either 'John went to the garden' or 'Gertrude is a mouse' but not both then Brian is a rhino. Chances are about even that if 'Gertrude is a mouse and John went to the garden' then Greg is a lion.",
        "valid"
    ],
    [
        0.3862402141094208,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '799'}",
        "It is impossible that 'John got the apple' or 'Bernhard is white' or both.",
        "valid"
    ],
    [
        0.38621645669142407,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '701'}",
        "Chances are slight that Brian is a rhino. There is almost no chance that John moved to the garden. There is a very good chance that Bernhard is green. There is a very good chance that if 'Bernhard is green and John moved to the garden' then Lily is yellow. It is probably not the case that if either 'Brian is a rhino' or 'Bernhard is green' but not both then Mary left the football. It is highly likely that if 'Bernhard is green' or 'John moved to the garden' or both then Julius is a frog.",
        "valid"
    ],
    [
        0.3861699253320694,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '463'}",
        "Согласно определению Алесандра Оболонского: «Слух есть некая разновидность информации, которая распространяется исключительно по неформальным каналам и направлена на удовлетворение некоей реальной информационной потребности, не удовлетворяемой иными способами»",
        "correct"
    ],
    [
        0.3861394077539444,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '730'}",
        "It is probably not the case that 'Bernhard is gray' or 'Daniel took the apple' or both.",
        "valid"
    ],
    [
        0.3861228923002879,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '838'}",
        "It is improbable that either 'Brian is gray' or 'Mary went to the office' but not both.",
        "valid"
    ],
    [
        0.3860342800617218,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '966'}",
        "It is probably the case that either 'Brian is yellow' or 'Sandra grabbed the milk' but not both.",
        "valid"
    ],
    [
        0.38600535690784454,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '58'}",
        "Chances are about even that either 'Lily is gray' or 'Mary dropped the milk' but not both.",
        "valid"
    ],
    [
        0.38600247104962665,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '132'}",
        "Chances are about even that John put down the apple. It is probably not the case that Bernhard is a frog. It is unlikely that Mary got the football. It is unlikely that if either 'John put down the apple' or 'Mary got the football' but not both then Bill moved to the office. It is improbable that if 'Bernhard is a frog' or 'John put down the apple' or both then Jessica is a cat. It is unlikely that if 'Bernhard is a frog and John put down the apple' then Greg is white.",
        "valid"
    ],
    [
        0.38599151869614917,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '954'}",
        "It is certain that Sandra left the milk. It is certain that Bernhard is gray. It is unlikely that John picked up the apple. There is little chance that if 'Sandra left the milk and John picked up the apple' then Greg is a frog. It is highly likely that if either 'John picked up the apple' or 'Bernhard is gray' but not both then Brian is green. We doubt that if 'John picked up the apple' or 'Bernhard is gray' or both then Mary went to the bedroom.",
        "valid"
    ],
    [
        0.3859129597743352,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '862'}",
        "It is almost certain that either 'Julius is white' or 'Gertrude is a mouse' but not both.",
        "valid"
    ],
    [
        0.385906641681989,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '354'}",
        "It is highly unlikely that Julius is a swan. There is a very good chance that Bernhard is green. We believe that John picked up the milk. It is highly unlikely that if 'Julius is a swan and John picked up the milk' then Mary went to the office. It is impossible that if 'Julius is a swan' or 'John picked up the milk' or both then Sandra dropped the apple. It is almost certain that if 'John picked up the milk and Bernhard is green' then Jeff left the apple.",
        "valid"
    ],
    [
        0.3858712464570999,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '317'}",
        "It is probably not the case that John went to the garden. It is highly unlikely that Emily is a cat. It is highly likely that Lily is green. It is likely that if 'Lily is green and John went to the garden' then Bernhard is a swan. We doubt that if 'Emily is a cat' or 'John went to the garden' or both then Sandra left the milk. There is a better than even chance that if either 'John went to the garden' or 'Emily is a cat' but not both then Fred is in the cinema.",
        "valid"
    ],
    [
        0.3858654350042343,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '695'}",
        "It is highly likely that Sandra got the milk. It is impossible that Gertrude is a sheep. There is a better than even chance that Brian is a rhino.",
        "valid"
    ],
    [
        0.385773037870725,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '213'}",
        "It is impossible that 'John discarded the apple' or 'Daniel took the football' or both.",
        "valid"
    ],
    [
        0.38573554654916126,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '271'}",
        "There is almost no chance that Jeff discarded the milk. It is highly likely that Lily is green. It is probable that Brian is white.",
        "valid"
    ],
    [
        0.38569476703802746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '831'}",
        "There is little chance that John took the football. It is probable that Lily is a lion. There is little chance that Emily is a mouse.",
        "valid"
    ],
    [
        0.3856813659270604,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '818'}",
        "It is likely that Brian is white. We believe that Greg is yellow. We believe that Julius is a rhino.",
        "valid"
    ],
    [
        0.38565726578235626,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '894'}",
        "It is probably not the case that Greg is gray. There is a very good chance that John moved to the office. We believe that Lily is a swan.",
        "valid"
    ],
    [
        0.3856450965007146,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '956'}",
        "It is highly unlikely that 'Julius is a frog and Brian is yellow'.",
        "valid"
    ],
    [
        0.38550420105457306,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '74'}",
        "It is highly unlikely that 'Bernhard is a frog' or 'John took the milk' or both.",
        "valid"
    ],
    [
        0.38547568023204803,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '374'}",
        "It is certain that either 'Daniel left the milk' or 'Gertrude is a wolf' but not both.",
        "valid"
    ],
    [
        0.38546644151210785,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '935'}",
        "It is unlikely that Lily is white. Chances are slight that John went to the office. It is likely that Bernhard is white.",
        "valid"
    ],
    [
        0.385463684797287,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '532'}",
        "It is improbable that Greg is a rhino. It is probably not the case that Mary moved to the office. It is highly unlikely that Lily is green.",
        "valid"
    ],
    [
        0.38546258707841236,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '570'}",
        "It is highly unlikely that Greg is a rhino. We doubt that Lily is green. It is highly unlikely that Bernhard is gray.",
        "valid"
    ],
    [
        0.3854591300090154,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '657'}",
        "It is almost certain that either 'Brian is white' or 'Mary moved to the garden' but not both.",
        "valid"
    ],
    [
        0.38542331258455914,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '933'}",
        "It is highly unlikely that either 'Lily is yellow' or 'Bernhard is green' but not both.",
        "valid"
    ],
    [
        0.3854067176580429,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '456'}",
        "We believe that Mary moved to the office. We believe that Jessica is a mouse. It is highly unlikely that Daniel got the apple. Chances are slight that if either 'Daniel got the apple' or 'Mary moved to the office' but not both then Yann is thirsty. It is probably not the case that if 'Jessica is a mouse' or 'Mary moved to the office' or both then Brian is gray. There is a very good chance that if 'Mary moved to the office and Jessica is a mouse' then Jeff discarded the milk.",
        "valid"
    ],
    [
        0.3852889637152354,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '999'}",
        "It is probably the case that Winona is a cat. It is probable that Brian is white. It is almost certain that Sandra put down the milk.",
        "valid"
    ],
    [
        0.38523225486278534,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '365'}",
        "It is almost certain that Bernhard is gray. It is probably the case that Bill went to the bedroom. It is highly likely that Greg is white. It is highly unlikely that if 'Bill went to the bedroom and Bernhard is gray' then Julius is a rhino. There is little chance that if 'Greg is white and Bernhard is gray' then Mary moved to the office. Chances are slight that if 'Bill went to the bedroom and Greg is white' then John discarded the milk.",
        "valid"
    ],
    [
        0.38520898918310803,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '89'}",
        "It is probably not the case that either 'Mary moved to the office' or 'Greg is a rhino' but not both.",
        "valid"
    ],
    [
        0.385192150870959,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '58'}",
        "We doubt that Bernhard is yellow. It is almost certain that Emily is a wolf. It is improbable that Daniel grabbed the apple. It is improbable that if 'Emily is a wolf and Bernhard is yellow' then Greg is a lion. Chances are slight that if 'Bernhard is yellow and Emily is a wolf' then Jason is tired. It is likely that if either 'Bernhard is yellow' or 'Daniel grabbed the apple' but not both then John went to the hallway.",
        "valid"
    ],
    [
        0.38518959780534107,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '836'}",
        "It is probably not the case that either 'John took the apple' or 'Julius is yellow' but not both.",
        "valid"
    ],
    [
        0.38517682751019794,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '390'}",
        "There is almost no chance that either 'Mary went to the kitchen' or 'Greg is a rhino' but not both.",
        "valid"
    ],
    [
        0.3851458926995595,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '263'}",
        "It is probably not the case that either 'Bernhard is a swan' or 'Jessica is a cat' but not both.",
        "valid"
    ],
    [
        0.38510504364967346,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '832'}",
        "Chances are about even that Jeff went to the hallway. There is almost no chance that Brian is a lion. It is probable that Bernhard is a swan.",
        "valid"
    ],
    [
        0.3850872069597244,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '295'}",
        "It is likely that Julius is a frog. There is little chance that Bernhard is yellow. There is almost no chance that Brian is white.",
        "valid"
    ],
    [
        0.3850807845592499,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '112'}",
        "There is a better than even chance that Sandra dropped the milk. It is highly likely that Bernhard is a swan. There is a better than even chance that Greg is a frog. It is highly likely that if either 'Sandra dropped the milk' or 'Greg is a frog' but not both then Brian is yellow. There is a better than even chance that if 'Greg is a frog' or 'Bernhard is a swan' or both then Julius is a rhino. There is a better than even chance that if 'Greg is a frog and Sandra dropped the milk' then John left the apple.",
        "valid"
    ],
    [
        0.3850727428992589,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '512'}",
        "It is certain that Brian is green. It is probably the case that Lily is yellow. There is a very good chance that Daniel took the football.",
        "valid"
    ],
    [
        0.38498421013355255,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '17'}",
        "We doubt that either 'Lily is white' or 'Gertrude is a cat' but not both.",
        "valid"
    ],
    [
        0.3848995467027028,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '993'}",
        "Chances are slight that 'Brian is a lion and Gertrude is a mouse'.",
        "valid"
    ],
    [
        0.3848744332790375,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '554'}",
        "It is probably not the case that either 'Bernhard is a frog' or 'John dropped the apple' but not both.",
        "valid"
    ],
    [
        0.38486360510190326,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '491'}",
        "It is probably the case that Julius is a frog. It is improbable that Gertrude is a cat. It is highly likely that Bernhard is green. Chances are about even that if 'Bernhard is green' or 'Julius is a frog' or both then Sumit is hungry. It is probable that if 'Julius is a frog' or 'Gertrude is a cat' or both then Brian is yellow. There is a better than even chance that if 'Gertrude is a cat and Julius is a frog' then Mary grabbed the milk.",
        "valid"
    ],
    [
        0.38478665550549823,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '323'}",
        "А имя Оле он сам себе взял, когда стал совершеннолетним, очевидно, в память о бабушке, которая так его называла в детстве",
        "correct"
    ],
    [
        0.38478665550549823,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '324'}",
        "А имя Оле он сам себе взял, когда стал совершеннолетним, очевидно, в память о бабушке, которая так его называла в детстве",
        "correct"
    ],
    [
        0.38474664588769275,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '294'}",
        "There is a very good chance that Bernhard is gray. There is almost no chance that Sandra is in the kitchen. Chances are about even that Lily is yellow. It is probable that if 'Bernhard is gray and Sandra is in the kitchen' then Greg is a swan. There is a very good chance that if either 'Sandra is in the kitchen' or 'Bernhard is gray' but not both then Julius is a rhino. It is highly unlikely that if either 'Bernhard is gray' or 'Sandra is in the kitchen' but not both then John went to the hallway.",
        "valid"
    ],
    [
        0.384735311071078,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '643'}",
        "It is probably not the case that 'Mary took the milk' or 'Emily is a wolf' or both.",
        "valid"
    ],
    [
        0.38465844591458637,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '759'}",
        "It is highly unlikely that either 'John moved to the office' or 'Greg is a rhino' but not both.",
        "valid"
    ],
    [
        0.3846539755662282,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '501'}",
        "There is almost no chance that John went to the kitchen. There is a better than even chance that Bernhard is white. It is highly unlikely that Brian is a rhino.",
        "valid"
    ],
    [
        0.3845869451761246,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '876'}",
        "It is almost certain that 'John discarded the apple' or 'Greg is a frog' or both.",
        "valid"
    ],
    [
        0.3845315823952357,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '439'}",
        "It is probably not the case that either 'Julius is gray' or 'Sumit is bored' but not both.",
        "valid"
    ],
    [
        0.3844581296046575,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '589'}",
        "There is little chance that either 'Brian is green' or 'Jessica is a cat' but not both.",
        "valid"
    ],
    [
        0.3844498544931412,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '725'}",
        "There is a very good chance that 'Lily is gray' or 'Yann is tired' or both.",
        "valid"
    ],
    [
        0.3844476292530696,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '389'}",
        "Наверное, есть какая-то черта личности, которая позволяет одним людям легко переносить такие вещи, а другим - с трудом?",
        "incorrect"
    ],
    [
        0.38433266679445904,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '434'}",
        "It is unlikely that Brian is green. It is impossible that Jeff moved to the garden. We doubt that Mary went to the office. It is certain that if 'Brian is green' or 'Jeff moved to the garden' or both then Daniel dropped the apple. It is likely that if 'Brian is green' or 'Jeff moved to the garden' or both then Sandra left the milk. It is highly likely that if 'Jeff moved to the garden and Brian is green' then Greg is gray.",
        "valid"
    ],
    [
        0.3842771003643672,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '367'}",
        "Chances are about even that Brian is white. There is a better than even chance that Mary left the milk. Chances are slight that John dropped the apple.",
        "valid"
    ],
    [
        0.3841996341943741,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '885'}",
        "Chances are slight that Emily is a mouse. It is likely that Brian is yellow. There is a very good chance that Lily is a swan.",
        "valid"
    ],
    [
        0.3841947615146637,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '173'}",
        "It is probably not the case that Gertrude is a mouse. There is a very good chance that Julius is a frog. It is likely that Greg is gray.",
        "valid"
    ],
    [
        0.3841705669959386,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '469'}",
        "It is highly unlikely that either 'John got the apple' or 'Greg is gray' but not both.",
        "valid"
    ],
    [
        0.38412635028362274,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '677'}",
        "It is likely that Sandra left the football. It is unlikely that Julius is a frog. It is almost certain that Antoine is bored. It is certain that if either 'Julius is a frog' or 'Sandra left the football' but not both then Sumit is tired. It is likely that if 'Antoine is bored and Julius is a frog' then Greg is white. There is a better than even chance that if 'Sandra left the football' or 'Antoine is bored' or both then Mary moved to the office.",
        "valid"
    ],
    [
        0.38410887618859607,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '284'}",
        "Chances are slight that Julius is a lion. There is almost no chance that Mary grabbed the milk. It is unlikely that John went to the hallway.",
        "valid"
    ],
    [
        0.3841037650903066,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '857'}",
        "It is highly unlikely that either 'Greg is white' or 'Bill went to the garden' but not both.",
        "valid"
    ],
    [
        0.3841008047262828,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '551'}",
        "It is likely that Bernhard is gray. We doubt that Sandra dropped the milk. It is probably not the case that John discarded the apple. It is probable that if either 'Sandra dropped the milk' or 'Bernhard is gray' but not both then Mary went to the garden. Chances are about even that if either 'John discarded the apple' or 'Sandra dropped the milk' but not both then Greg is a rhino. It is unlikely that if either 'Sandra dropped the milk' or 'Bernhard is gray' but not both then Julius is white.",
        "valid"
    ],
    [
        0.3840399732192357,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '14'}",
        "It is highly unlikely that either 'Mary went to the hallway' or 'Brian is yellow' but not both.",
        "valid"
    ],
    [
        0.3840061277151108,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '407'}",
        "It is unlikely that 'Mary got the milk' or 'Bernhard is a frog' or both.",
        "valid"
    ],
    [
        0.3838701496521632,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '234'}",
        "It is unlikely that Greg is yellow. There is almost no chance that Jessica is a mouse. Chances are about even that Mary went to the bedroom. It is impossible that if 'Jessica is a mouse and Greg is yellow' then Bernhard is white. It is almost certain that if 'Greg is yellow and Mary went to the bedroom' then John moved to the garden. There is little chance that if 'Mary went to the bedroom and Greg is yellow' then Winona is a sheep.",
        "valid"
    ],
    [
        0.38383560876051587,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '828'}",
        "We believe that John moved to the garden. It is probable that Mary went to the office. There is a better than even chance that Jeff discarded the milk. It is highly likely that if 'Mary went to the office' or 'John moved to the garden' or both then Bernhard is gray. It is impossible that if either 'Mary went to the office' or 'Jeff discarded the milk' but not both then Julius is a swan. It is almost certain that if 'John moved to the garden' or 'Jeff discarded the milk' or both then Lily is green.",
        "valid"
    ],
    [
        0.3838140666484833,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '471'}",
        "«В текущих условиях развития экономики Сбербанк показал достаточно отличный результат, несмотря на маленькую чистую прибыль, причины которой вполне объяснимы», — считает аналитик ИФК «Метрополь» Марк Рубинштейн",
        "correct"
    ],
    [
        0.3837502102057139,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '341'}",
        "It is almost certain that Brian is yellow. It is improbable that Mary put down the apple. It is improbable that Winona is a wolf.",
        "valid"
    ],
    [
        0.3837126741806666,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '174'}",
        "It is highly unlikely that John moved to the office. It is almost certain that Lily is green. It is improbable that Mary got the football. It is probable that if either 'Mary got the football' or 'John moved to the office' but not both then Bernhard is white. It is probably not the case that if 'John moved to the office and Mary got the football' then Sandra dropped the milk. There is almost no chance that if 'Lily is green and Mary got the football' then Julius is gray.",
        "valid"
    ],
    [
        0.3836867908636729,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '464'}",
        "Все то, чем дорожил Клим в прежней недалекой жизни, все, чем гордился, упивался и тщеславился, - свободное свое искусство, которым создавал он людям праздник, краса и чистота игры, которой он служил, и вечное, с огромным гандикапом, первенство, которое никто не мог оспорить, - мгновенно стало незначительным, пустым, и то же самое, он чуял это ясно, сейчас испытывал любой из тысячи бойцов - с равновеликой чистотой чувства",
        "incorrect"
    ],
    [
        0.3836636890967687,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '873'}",
        "There is little chance that Bill went to the garden. It is impossible that John discarded the apple. It is probably the case that Bernhard is a frog. It is highly likely that if 'Bernhard is a frog and John discarded the apple' then Mary left the football. It is probable that if 'Bernhard is a frog' or 'John discarded the apple' or both then Greg is a frog. Chances are about even that if 'Bill went to the garden' or 'John discarded the apple' or both then Sandra got the football.",
        "valid"
    ],
    [
        0.3836541920900345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '515'}",
        "It is impossible that 'Brian is a swan and John went to the hallway'.",
        "valid"
    ],
    [
        0.38361477355162305,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '191'}",
        "It is likely that Mary took the milk. It is almost certain that Lily is white. We believe that Julius is a frog.",
        "valid"
    ],
    [
        0.38359645505746204,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '59'}",
        "It is almost certain that Greg is a lion. It is probably not the case that Mary went to the office. It is highly likely that Sandra got the football.",
        "valid"
    ],
    [
        0.38355350991090137,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '976'}",
        "It is improbable that 'Brian is green' or 'John left the apple' or both.",
        "valid"
    ],
    [
        0.38353977104028064,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '762'}",
        "We doubt that Mary discarded the milk. It is certain that Fred went to the office. We doubt that Jessica is a mouse. It is improbable that if either 'Mary discarded the milk' or 'Fred went to the office' but not both then Daniel left the apple. It is impossible that if 'Fred went to the office' or 'Jessica is a mouse' or both then Julius is yellow. It is improbable that if either 'Mary discarded the milk' or 'Fred went to the office' but not both then Jeff moved to the garden.",
        "valid"
    ],
    [
        0.3834342360496521,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '482'}",
        "И Лурия, и другой столь же юный его коллега, а впоследствии не менее знаменитый Алексей Леонтьев, сразу же обнаружили в нем такой запас свежих идей и такую зрелость мысли, которая далеко опережала их собственную",
        "incorrect"
    ],
    [
        0.3834238102038701,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '939'}",
        "It is probably not the case that either 'Sandra took the football' or 'Lily is green' but not both.",
        "valid"
    ],
    [
        0.38330189883708954,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '733'}",
        "It is probably the case that Winona is a mouse. It is probable that John got the milk. It is unlikely that Bernhard is a frog.",
        "valid"
    ],
    [
        0.38327325383822125,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '690'}",
        "It is impossible that either 'Mary is in the hallway' or 'Lily is green' but not both.",
        "valid"
    ],
    [
        0.38324899474779767,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '220'}",
        "It is probably the case that Jeff went to the bedroom. It is certain that Julius is gray. Chances are about even that Bernhard is gray. Chances are slight that if 'Bernhard is gray and Jeff went to the bedroom' then Sumit is thirsty. There is a better than even chance that if 'Jeff went to the bedroom' or 'Julius is gray' or both then Greg is a frog. There is almost no chance that if 'Julius is gray and Jeff went to the bedroom' then John grabbed the apple.",
        "valid"
    ],
    [
        0.3832471619049708,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '626'}",
        "It is certain that Julius is gray. It is probable that Sandra left the football. We believe that Bernhard is a frog. There is little chance that if 'Bernhard is a frog and Julius is gray' then Brian is green. It is highly likely that if 'Julius is gray and Bernhard is a frog' then Jessica is a cat. There is almost no chance that if 'Sandra left the football' or 'Bernhard is a frog' or both then Fred went to the office.",
        "valid"
    ],
    [
        0.3832161525885264,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '4'}",
        "It is probably not the case that either 'Julius is yellow' or 'Sumit is hungry' but not both.",
        "valid"
    ],
    [
        0.38319239020347595,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '101'}",
        "There is little chance that Brian is green. It is improbable that Sandra dropped the apple. There is a very good chance that John went to the kitchen. Chances are slight that if 'Sandra dropped the apple' or 'Brian is green' or both then Bernhard is a lion. It is impossible that if 'Sandra dropped the apple and John went to the kitchen' then Lily is a frog. There is little chance that if 'John went to the kitchen' or 'Brian is green' or both then Mary moved to the garden.",
        "valid"
    ],
    [
        0.38318226238091785,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '28'}",
        "It is unlikely that 'Sandra dropped the milk' or 'Greg is a frog' or both.",
        "valid"
    ],
    [
        0.3831266462802887,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '274'}",
        "Chances are slight that 'John discarded the apple' or 'Daniel got the milk' or both.",
        "valid"
    ],
    [
        0.3830898354450862,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '718'}",
        "There is a very good chance that Mary got the football. It is probable that Jeff moved to the office. Chances are slight that Greg is a rhino. It is highly unlikely that if 'Greg is a rhino and Mary got the football' then Bernhard is yellow. We doubt that if 'Mary got the football' or 'Jeff moved to the office' or both then Lily is white. There is a better than even chance that if either 'Jeff moved to the office' or 'Mary got the football' but not both then John put down the apple.",
        "valid"
    ],
    [
        0.3830837955077489,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '938'}",
        "There is a very good chance that Winona is a sheep. It is almost certain that Julius is white. It is unlikely that Sandra got the milk.",
        "valid"
    ],
    [
        0.3830813417832057,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '513'}",
        "It is probably not the case that 'Bill moved to the office' or 'Julius is gray' or both.",
        "valid"
    ],
    [
        0.3830530146757762,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '769'}",
        "«Казалось бы, такая схема упрощает жизнь ресурсников ― им не нужно юридически общаться с каждым жильцом; УК получает стимул снижать потери ресурсов во внутридомовых сетях, а жильцам удобно, что УК выступает защитником их интересов перед РСО и выполняет функцию «единого окна». Жильцы оплачивают счета, выставленные УК. Та, собрав деньги, 20-40% оставляет себе, остальное передает в адрес поставщиков ресурсов",
        "correct"
    ],
    [
        0.38302158812681836,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '134'}",
        "It is highly likely that 'Lily is a swan' or 'John moved to the office' or both.",
        "valid"
    ],
    [
        0.3829977810382843,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '252'}",
        "این مربا اصلا کیفیت مطلوبی نداره. ماده اون سرشار از ژلاتین و برخی اوقات تکه های ریزی به اسم هلو. به هیچ عنوان پیشنهاد نمی کنم",
        "طعم"
    ],
    [
        0.3827989200750987,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '279'}",
        "It is certain that John went to the hallway. There is a better than even chance that Mary left the football. It is unlikely that Yann is tired. It is probable that if either 'Yann is tired' or 'John went to the hallway' but not both then Daniel got the apple. It is almost certain that if 'Yann is tired and John went to the hallway' then Sandra is in the kitchen. We believe that if either 'Yann is tired' or 'John went to the hallway' but not both then Bernhard is white.",
        "valid"
    ],
    [
        0.3827941765387853,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '351'}",
        "There is little chance that John went to the kitchen. It is unlikely that Lily is a frog. It is improbable that Mary took the football.",
        "valid"
    ],
    [
        0.3827819377183914,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '244'}",
        "We doubt that Jeff left the apple. There is a better than even chance that Greg is a frog. It is almost certain that Julius is yellow. There is a better than even chance that if 'Julius is yellow and Greg is a frog' then Jason is tired. It is highly unlikely that if 'Jeff left the apple' or 'Greg is a frog' or both then John moved to the office. It is likely that if 'Julius is yellow' or 'Jeff left the apple' or both then Mary discarded the apple.",
        "valid"
    ],
    [
        0.38274287680784863,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '926'}",
        "It is almost certain that Emily is a wolf. It is highly likely that Greg is green. There is little chance that Mary dropped the milk. There is little chance that if 'Greg is green' or 'Emily is a wolf' or both then Bill moved to the office. It is probable that if 'Mary dropped the milk and Emily is a wolf' then John went to the kitchen. There is a better than even chance that if 'Mary dropped the milk and Emily is a wolf' then Julius is white.",
        "valid"
    ],
    [
        0.3827088177204132,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '692'}",
        "There is little chance that Emily is a mouse. Chances are about even that Brian is a rhino. There is a very good chance that John took the apple.",
        "valid"
    ],
    [
        0.3826468537251155,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '411'}",
        "There is almost no chance that 'Julius is yellow' or 'John got the apple' or both.",
        "valid"
    ],
    [
        0.38246303300062817,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '707'}",
        "There is almost no chance that either 'Brian is yellow' or 'Bernhard is green' but not both.",
        "valid"
    ],
    [
        0.3823881894350052,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '375'}",
        "There is almost no chance that 'Mary got the football and Brian is white'.",
        "valid"
    ],
    [
        0.382369468609492,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '827'}",
        "It is almost certain that Bernhard is green. It is almost certain that John went to the kitchen. It is improbable that Jason is tired. There is little chance that if 'Jason is tired and John went to the kitchen' then Lily is white. There is little chance that if 'John went to the kitchen' or 'Jason is tired' or both then Mary got the football. It is certain that if 'Jason is tired' or 'Bernhard is green' or both then Greg is a swan.",
        "valid"
    ],
    [
        0.38236603140830994,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '566'}",
        "It is improbable that Julius is green. It is impossible that Sandra grabbed the apple. It is highly unlikely that John went to the hallway. It is probably the case that if 'Sandra grabbed the apple and John went to the hallway' then Mary left the football. It is highly unlikely that if either 'Julius is green' or 'John went to the hallway' but not both then Gertrude is a wolf. It is highly likely that if 'John went to the hallway' or 'Julius is green' or both then Brian is white.",
        "valid"
    ],
    [
        0.3823529879252116,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '456'}",
        "Нет, та родина, которая у всех нас, которая одна шестая часть суши, которая земля, а вовсе не то, что думают завсегдатаи московских ресторанов и баров с японской кухней, у них есть",
        "correct"
    ],
    [
        0.3823529879252116,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '457'}",
        "Нет, та родина, которая у всех нас, которая одна шестая часть суши, которая земля, а вовсе не то, что думают завсегдатаи московских ресторанов и баров с японской кухней, у них есть",
        "correct"
    ],
    [
        0.38226623833179474,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '579'}",
        "We doubt that John discarded the apple. It is almost certain that Lily is a swan. There is a better than even chance that Mary left the milk.",
        "valid"
    ],
    [
        0.38210340837637585,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '392'}",
        "It is improbable that 'John went to the bedroom' or 'Julius is white' or both.",
        "valid"
    ],
    [
        0.382071112593015,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '492'}",
        "It is highly unlikely that either 'Bill left the milk' or 'Bernhard is yellow' but not both.",
        "valid"
    ],
    [
        0.38200780749320984,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '642'}",
        "It is probably not the case that 'Emily is a wolf' or 'John discarded the apple' or both.",
        "valid"
    ],
    [
        0.38200036187966663,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '801'}",
        "It is improbable that either 'Sandra dropped the milk' or 'Greg is a swan' but not both.",
        "valid"
    ],
    [
        0.38197123010953266,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '602'}",
        "It is highly likely that Julius is a swan. There is a very good chance that Mary went to the garden. It is highly likely that Brian is a rhino.",
        "valid"
    ],
    [
        0.3819686671098073,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '336'}",
        "It is probably the case that either 'Mary took the milk' or 'John put down the milk' but not both.",
        "valid"
    ],
    [
        0.38192645212014514,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '219'}",
        "It is probably not the case that Jessica is a mouse. Chances are about even that Mary grabbed the milk. It is probable that Greg is a swan.",
        "valid"
    ],
    [
        0.38190852105617523,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '315'}",
        "There is a very good chance that Fred is in the school. It is improbable that Julius is a frog. There is almost no chance that John left the milk.",
        "valid"
    ],
    [
        0.38189736505349475,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '372'}",
        "Chances are slight that Bernhard is green. It is unlikely that Lily is yellow. It is likely that John discarded the apple. It is likely that if 'John discarded the apple' or 'Lily is yellow' or both then Fred moved to the office. It is probably not the case that if 'Bernhard is green and Lily is yellow' then Brian is a lion. It is highly likely that if 'Bernhard is green and Lily is yellow' then Mary went to the hallway.",
        "valid"
    ],
    [
        0.38186292846997577,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '768'}",
        "«Казалось бы, такая схема упрощает жизнь ресурсников ― им не нужно юридически общаться с каждым жильцом; УК получает стимул снижать потери ресурсов во внутридомовых сетях, а жильцам удобно, что УК выступает защитником их интересов перед РСО и выполняет функцию «единого окна». Жильцы оплачивают счета, выставленные УК. Та, собрав деньги, 20-40% оставляет себе, остальное передает в адрес поставщиков ресурсов",
        "incorrect"
    ],
    [
        0.3817484676837921,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '18'}",
        "― сам не пойму, ― отвечал будущий джамхух, ― у меня почему-то никогда не получается жвачка из травы, которую съел",
        "incorrect"
    ],
    [
        0.3817448963721593,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '709'}",
        "It is almost certain that either 'Greg is a rhino' or 'John went to the bedroom' but not both.",
        "valid"
    ],
    [
        0.3816551814476649,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '706'}",
        "There is almost no chance that Mary took the milk. Chances are slight that Bernhard is white. It is certain that Greg is a frog.",
        "valid"
    ],
    [
        0.3815946926673253,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '919'}",
        "It is probably not the case that 'Bernhard is white' or 'Sandra got the milk' or both.",
        "valid"
    ],
    [
        0.3815418134133021,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '175'}",
        "We believe that John left the apple. There is almost no chance that Lily is a swan. It is impossible that Gertrude is a cat.",
        "valid"
    ],
    [
        0.38153980672359467,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '110'}",
        "It is probably not the case that either 'Bernhard is a swan' or 'Mary went to the hallway' but not both.",
        "valid"
    ],
    [
        0.3814890533685684,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '735'}",
        "It is highly unlikely that 'Brian is a swan and John took the apple'.",
        "valid"
    ],
    [
        0.38148195048173267,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '902'}",
        "It is probable that Bill went to the kitchen. It is probably the case that Lily is gray. It is certain that Greg is a frog.",
        "valid"
    ],
    [
        0.3812301903963089,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '322'}",
        "It is probably not the case that 'Mary dropped the apple' or 'Lily is green' or both.",
        "valid"
    ],
    [
        0.3812221984068553,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '720'}",
        "It is almost certain that 'Gertrude is a sheep' or 'Julius is a swan' or both.",
        "valid"
    ],
    [
        0.38116785883903503,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '806'}",
        "It is improbable that Fred left the football. Chances are slight that Brian is a frog. We doubt that Mary took the milk.",
        "valid"
    ],
    [
        0.3811597873767217,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '686'}",
        "It is almost certain that John moved to the office. There is little chance that Greg is yellow. There is little chance that Mary went to the kitchen. Chances are slight that if 'Greg is yellow and John moved to the office' then Sandra got the milk. It is probably not the case that if 'Greg is yellow' or 'John moved to the office' or both then Julius is a frog. We doubt that if 'Mary went to the kitchen' or 'John moved to the office' or both then Bernhard is a frog.",
        "valid"
    ],
    [
        0.3810749500989914,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '106'}",
        "There is almost no chance that 'Daniel dropped the apple and Greg is a rhino'.",
        "valid"
    ],
    [
        0.38103465735912323,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '420'}",
        "It is highly unlikely that Bernhard is green. It is probably not the case that John went to the garden. It is impossible that Lily is a frog.",
        "valid"
    ],
    [
        0.381024291117986,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '555'}",
        "There is almost no chance that Sandra left the football. It is probable that Jessica is a cat. It is unlikely that Mary moved to the office. It is likely that if either 'Sandra left the football' or 'Mary moved to the office' but not both then Julius is a rhino. Chances are slight that if 'Jessica is a cat' or 'Mary moved to the office' or both then Brian is white. It is improbable that if either 'Mary moved to the office' or 'Sandra left the football' but not both then John dropped the apple.",
        "valid"
    ],
    [
        0.3809618105491002,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '840'}",
        "There is almost no chance that Bernhard is green. It is impossible that Gertrude is a sheep. It is impossible that John dropped the apple. It is almost certain that if 'Bernhard is green and John dropped the apple' then Julius is a rhino. There is little chance that if 'Bernhard is green' or 'John dropped the apple' or both then Greg is gray. It is probably not the case that if either 'Bernhard is green' or 'Gertrude is a sheep' but not both then Sandra got the milk.",
        "valid"
    ],
    [
        0.3808688173691432,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '559'}",
        "Chances are about even that Greg is yellow. Chances are about even that Jessica is a cat. It is unlikely that Julius is a rhino.",
        "valid"
    ],
    [
        0.38083549837271374,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '32'}",
        "We doubt that Mary went to the office. It is certain that Daniel dropped the apple. We believe that Julius is white. It is improbable that if 'Mary went to the office and Daniel dropped the apple' then Greg is a rhino. It is highly likely that if 'Mary went to the office and Daniel dropped the apple' then Bernhard is green. It is unlikely that if 'Mary went to the office and Daniel dropped the apple' then Lily is a swan.",
        "valid"
    ],
    [
        0.3807322680950165,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '576'}",
        "It is probably not the case that 'Fred went to the garden and Brian is a frog'.",
        "valid"
    ],
    [
        0.3807293673356374,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '808'}",
        "There is almost no chance that either 'Greg is yellow' or 'Emily is a mouse' but not both.",
        "valid"
    ],
    [
        0.3806710292895635,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '985'}",
        "There is almost no chance that 'Greg is white' or 'Mary went to the kitchen' or both.",
        "valid"
    ],
    [
        0.38063280781110126,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '18'}",
        "Chances are slight that Sandra left the milk. It is unlikely that Bill went to the garden. It is probably the case that John picked up the milk. Chances are about even that if 'Bill went to the garden and Sandra left the milk' then Greg is a frog. There is a very good chance that if 'Sandra left the milk and Bill went to the garden' then Lily is yellow. Chances are slight that if 'Sandra left the milk and John picked up the milk' then Bernhard is green.",
        "valid"
    ],
    [
        0.38060108323891956,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '789'}",
        "It is impossible that either 'Jeff went to the bedroom' or 'Jessica is a mouse' but not both.",
        "valid"
    ],
    [
        0.38059499363104504,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '67'}",
        "It is certain that Bernhard is a frog. It is impossible that Greg is white. It is certain that John went to the bedroom.",
        "valid"
    ],
    [
        0.3805796851714452,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '895'}",
        "It is impossible that Brian is a swan. It is likely that Julius is gray. It is likely that Lily is a lion. It is almost certain that if either 'Julius is gray' or 'Brian is a swan' but not both then Greg is yellow. It is certain that if 'Lily is a lion' or 'Brian is a swan' or both then John got the apple. Chances are about even that if either 'Julius is gray' or 'Lily is a lion' but not both then Mary dropped the milk.",
        "invalid"
    ],
    [
        0.3805081397294998,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '260'}",
        "It is impossible that 'Daniel left the milk and Greg is yellow'.",
        "valid"
    ],
    [
        0.3804575055837631,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '310'}",
        "We doubt that Mary grabbed the milk. It is probably not the case that Fred went to the garden. We believe that Greg is a lion.",
        "valid"
    ],
    [
        0.3803063631057739,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '426'}",
        "Классная оторопела от Севиной наглости, наступила минутная пауза, хоть рекламу включай, и тут произошло такое, отчего я потом долго смеялась: Лизка, которая всегда ловко увиливала от наказаний за наши совместные шалости, в наступившей тишине робко произнесла: «И мне…»",
        "incorrect"
    ],
    [
        0.3802991559108098,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '184'}",
        "It is probably not the case that 'Mary picked up the milk' or 'John put down the apple' or both.",
        "valid"
    ],
    [
        0.3802263488372167,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '236'}",
        "It is probably not the case that Mary took the milk. It is unlikely that Bernhard is yellow. It is highly likely that Greg is a swan.",
        "valid"
    ],
    [
        0.3802037586768468,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '568'}",
        "Chances are about even that Julius is a swan. It is probably the case that Gertrude is a sheep. Chances are about even that John dropped the milk.",
        "valid"
    ],
    [
        0.3801986922820409,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '655'}",
        "There is almost no chance that 'Lily is green' or 'John grabbed the apple' or both.",
        "valid"
    ],
    [
        0.3801944702863693,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '11'}",
        "It is highly unlikely that Fred put down the apple. It is probably the case that Gertrude is a cat. It is probably the case that John went to the kitchen. It is almost certain that if 'John went to the kitchen and Fred put down the apple' then Bill left the football. We doubt that if 'John went to the kitchen and Gertrude is a cat' then Greg is a rhino. We doubt that if 'John went to the kitchen' or 'Fred put down the apple' or both then Jeff discarded the milk.",
        "valid"
    ],
    [
        0.38012442489465076,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '93'}",
        "There is a very good chance that Mary went to the office. It is probable that Antoine is bored. It is highly likely that Julius is green. It is probable that if 'Julius is green' or 'Mary went to the office' or both then Lily is a swan. It is certain that if 'Mary went to the office' or 'Antoine is bored' or both then Emily is a mouse. It is highly likely that if 'Julius is green and Antoine is bored' then Sandra left the milk.",
        "valid"
    ],
    [
        0.38012364506721497,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '762'}",
        "Ставку на возрастную категорию «0-8» компания объясняет спецификой выбора одежды: решения о покупке одежды для маленьких детей принимают родители, поэтому подход в дизайне коллекций рассчитан именно на взрослых",
        "correct"
    ],
    [
        0.3800889601310094,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '276'}",
        "It is highly unlikely that John took the apple. It is probably not the case that Mary grabbed the milk. We doubt that Julius is gray.",
        "valid"
    ],
    [
        0.38002686699231464,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '64'}",
        "It is highly unlikely that 'Mary left the apple' or 'Bernhard is a frog' or both.",
        "valid"
    ],
    [
        0.37989825507005054,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '700'}",
        "There is a very good chance that Bernhard is a rhino. There is little chance that Fred went to the garden. There is a very good chance that Lily is a lion.",
        "valid"
    ],
    [
        0.37984571357568103,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '887'}",
        "It is probably not the case that either 'Gertrude is a sheep' or 'Greg is green' but not both.",
        "valid"
    ],
    [
        0.37976621588071185,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '194'}",
        "Chances are slight that John left the football. It is almost certain that Emily is a mouse. It is improbable that Greg is green. It is impossible that if 'Emily is a mouse and Greg is green' then Sandra got the milk. Chances are about even that if 'John left the football' or 'Greg is green' or both then Jeff went to the garden. Chances are about even that if 'John left the football and Emily is a mouse' then Brian is yellow.",
        "valid"
    ],
    [
        0.37976037462552387,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '522'}",
        "Zum Gesang:  Dazu gibt es nicht viel zu sagen - alles Negative wäre unzutreffend und jeder, der mit Loreena McKennitt vertraut ist, weiß, dass es nichts Vergleichbares gibt.",
        "counterfactual"
    ],
    [
        0.37976037462552387,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '522'}",
        "Zum Gesang:  Dazu gibt es nicht viel zu sagen - alles Negative wäre unzutreffend und jeder, der mit Loreena McKennitt vertraut ist, weiß, dass es nichts Vergleichbares gibt.",
        "counterfactual"
    ],
    [
        0.37973422805468243,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '436'}",
        "It is impossible that 'Lily is a frog and Bill moved to the office'.",
        "valid"
    ],
    [
        0.37973155577977497,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '32'}",
        "Трудно сказать, есть-ли какая-нибудь вещь изъ одежды, которая впервые здѣсь произведена была; за исключеніемъ развѣ половиковъ изъ коровьей шерсти, да, можетъ бытъ, нѣсколькихъ мелочей, нѣтъ ничего, что явилось бы непосредственнымъ крестьянскимъ творчествомъ",
        "incorrect"
    ],
    [
        0.3797059158484141,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '594'}",
        "It is improbable that Gertrude is a mouse. It is probably not the case that Mary left the football. It is probably the case that Julius is white.",
        "valid"
    ],
    [
        0.37969954311847687,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '846'}",
        "It is improbable that 'Mary went to the kitchen' or 'Brian is yellow' or both.",
        "valid"
    ],
    [
        0.37964555621147156,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '638'}",
        "Питер Гринуэй, полагающий, что солидные бюджеты развращают режиссёров и мешают мыслить самостоятельно, пожалуй, прав, несмотря на то, что сам этого правила не придерживается",
        "correct"
    ],
    [
        0.37964468201001483,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '708'}",
        "It is probably not the case that Bill went to the bedroom. It is highly unlikely that Brian is yellow. It is unlikely that Gertrude is a sheep.",
        "valid"
    ],
    [
        0.37958528101444244,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '36'}",
        "It is probably not the case that either 'Yann is bored' or 'Sandra left the milk' but not both.",
        "valid"
    ],
    [
        0.37952381869157154,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '911'}",
        "It is impossible that Winona is a sheep. There is little chance that Emily is a wolf. We doubt that Brian is a lion. It is highly likely that if 'Brian is a lion and Winona is a sheep' then Bernhard is white. We believe that if 'Winona is a sheep' or 'Brian is a lion' or both then Fred discarded the apple. It is likely that if 'Brian is a lion and Winona is a sheep' then John left the football.",
        "invalid"
    ],
    [
        0.3794076293706894,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '32'}",
        "Chances are slight that either 'John picked up the apple' or 'Greg is gray' but not both.",
        "valid"
    ],
    [
        0.37921279668807983,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '462'}",
        "Оно наличествует как предельная возможность связи, которую никакое фактически существующее общество не может реализовать",
        "correct"
    ],
    [
        0.3791867991288503,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '95'}",
        "It is probably not the case that either 'John went to the office' or 'Jeff discarded the milk' but not both.",
        "valid"
    ],
    [
        0.3791651874780655,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '920'}",
        "There is a very good chance that Brian is yellow. It is improbable that Mary took the milk. It is unlikely that Jessica is a mouse.",
        "valid"
    ],
    [
        0.37914993862311047,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '659'}",
        "It is probable that Julius is a swan. There is a very good chance that Daniel dropped the apple. It is almost certain that Bill went to the kitchen.",
        "valid"
    ],
    [
        0.3789990295966466,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '154'}",
        "It is impossible that Fred is in the school. It is probable that Julius is yellow. Chances are about even that John went to the garden.",
        "valid"
    ],
    [
        0.37893769641717273,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '804'}",
        "It is highly likely that Greg is a rhino. There is little chance that John left the milk. It is highly likely that Emily is a mouse.",
        "valid"
    ],
    [
        0.37884417176246643,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '137'}",
        "It is almost certain that Brian is green. It is probably the case that John picked up the apple. It is highly likely that Lily is yellow.",
        "valid"
    ],
    [
        0.3787667204936345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '491'}",
        "It is probably not the case that 'John got the football' or 'Mary picked up the apple' or both.",
        "valid"
    ],
    [
        0.3787449548641841,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '386'}",
        "Chances are slight that Julius is a lion. It is probable that John moved to the garden. There is little chance that Bernhard is a swan.",
        "valid"
    ],
    [
        0.37869857251644135,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '929'}",
        "It is certain that Lily is yellow. It is unlikely that Bernhard is a lion. There is little chance that Gertrude is a cat.",
        "valid"
    ],
    [
        0.37866005301475525,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '559'}",
        "It is unlikely that Sumit is bored. We doubt that Bernhard is white. We believe that Jason is tired. It is probably not the case that if either 'Sumit is bored' or 'Jason is tired' but not both then Brian is yellow. There is little chance that if 'Jason is tired' or 'Sumit is bored' or both then Sandra left the milk. It is highly likely that if 'Bernhard is white' or 'Sumit is bored' or both then John grabbed the apple.",
        "valid"
    ],
    [
        0.3785821944475174,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '705'}",
        "Chances are about even that Sandra left the milk. It is almost certain that Greg is white. It is unlikely that Bernhard is a rhino.",
        "valid"
    ],
    [
        0.37851689755916595,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '665'}",
        "It is impossible that either 'Sandra left the milk' or 'Mary got the football' but not both.",
        "valid"
    ],
    [
        0.378511776526769,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '4'}",
        "Вся ватага представляла на этот раз одну дружную, согласную артель, из среды которой выделялись только две фигуры, по-видимому, не принимавшие живого участия в общей попойке, где всякий встречный ― по обыкновению русского человека ― гость и побратим, святая душа",
        "correct"
    ],
    [
        0.378511776526769,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '37'}",
        "Вся ватага представляла на этот раз одну дружную, согласную артель, из среды которой выделялись только две фигуры, по-видимому, не принимавшие живого участия в общей попойке, где всякий встречный ― по обыкновению русского человека ― гость и побратим, святая душа",
        "correct"
    ],
    [
        0.3784969300031662,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '190'}",
        "There is almost no chance that either 'John moved to the office' or 'Julius is gray' but not both.",
        "valid"
    ],
    [
        0.3784554700056712,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '637'}",
        "Питер Гринуэй, полагающий, что солидные бюджеты развращают режиссёров и мешают мыслить самостоятельно, пожалуй, прав, несмотря на то, что сам этого правила не придерживается",
        "incorrect"
    ],
    [
        0.3784194439649582,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '649'}",
        "It is unlikely that 'Jason is tired' or 'Daniel dropped the apple' or both.",
        "valid"
    ],
    [
        0.37833501398563385,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '951'}",
        "It is probably not the case that 'Bernhard is a frog and Emily is a sheep'.",
        "valid"
    ],
    [
        0.3782788614432017,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '520'}",
        "There is a very good chance that Greg is gray. It is unlikely that Bernhard is a rhino. Chances are about even that Emily is a sheep.",
        "valid"
    ],
    [
        0.378270482023557,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '192'}",
        "It is certain that 'Daniel got the football' or 'John left the football' or both.",
        "valid"
    ],
    [
        0.37824976940949756,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '15'}",
        "There is almost no chance that Jeff went to the garden. It is certain that Lily is white. Chances are about even that John put down the apple.",
        "valid"
    ],
    [
        0.3781089435021083,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '503'}",
        "It is probably not the case that 'Greg is gray' or 'John went to the garden' or both.",
        "valid"
    ],
    [
        0.3780306080977122,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '968'}",
        "It is improbable that Mary went to the bedroom. We doubt that Greg is a swan. There is a better than even chance that Bernhard is a rhino.",
        "valid"
    ],
    [
        0.3780227104822795,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '461'}",
        "Оно наличествует как предельная возможность связи, которую никакое фактически существующее общество не может реализовать",
        "incorrect"
    ],
    [
        0.3779504746198654,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '966'}",
        "Chances are slight that Julius is gray. It is certain that Lily is a swan. We believe that Mary went to the office.",
        "valid"
    ],
    [
        0.3779303928216298,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '972'}",
        "It is unlikely that 'Jeff left the apple' or 'Bernhard is a frog' or both.",
        "valid"
    ],
    [
        0.3778586685657501,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '37'}",
        "It is highly unlikely that either 'Mary went to the office' or 'Brian is green' but not both.",
        "valid"
    ],
    [
        0.3778550873200099,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '490'}",
        "It is probably not the case that either 'John left the football' or 'Mary went to the hallway' but not both.",
        "valid"
    ],
    [
        0.37785326441129047,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '850'}",
        "We doubt that Bernhard is gray. It is improbable that Greg is a frog. It is impossible that Mary discarded the apple.",
        "valid"
    ],
    [
        0.3778034696976344,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '682'}",
        "We believe that Mary left the football. It is probably not the case that John put down the apple. It is unlikely that Bernhard is green. We doubt that if either 'Mary left the football' or 'Bernhard is green' but not both then Julius is white. It is probably not the case that if either 'Bernhard is green' or 'John put down the apple' but not both then Gertrude is a mouse. Chances are slight that if 'Mary left the football' or 'John put down the apple' or both then Brian is green.",
        "valid"
    ],
    [
        0.37779879073301953,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '859'}",
        "It is probable that Mary went to the bedroom. Chances are slight that John got the football. It is probably not the case that Brian is white.",
        "valid"
    ],
    [
        0.3776794373989105,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '116'}",
        "It is improbable that 'Lily is yellow' or 'Mary went to the garden' or both.",
        "valid"
    ],
    [
        0.37762018541495007,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '210'}",
        "It is unlikely that Lily is a rhino. There is a very good chance that Mary went to the garden. There is little chance that Bernhard is gray.",
        "valid"
    ],
    [
        0.3776168078184128,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '354'}",
        "It is highly unlikely that either 'Fred is in the school' or 'Mary went to the bedroom' but not both.",
        "valid"
    ],
    [
        0.37759679059187573,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '14'}",
        "اصلا خرید این جای را توصیه نمی‌کنم. البته پسندیدن طعم و عطر چای یک امر سلیقه‌ای است ولی از نظر من این چای بیش از حد معطر است و اصلا طعم چای نمی‌دهد. این چای از نوع کله مورچه‌ای می‌باشد. من اصلا توصیه نمی‌کنم.",
        "طعم"
    ],
    [
        0.3775937060515086,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '586'}",
        "It is improbable that either 'Julius is yellow' or 'Bernhard is green' but not both.",
        "valid"
    ],
    [
        0.37757058441638947,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '933'}",
        "There is a better than even chance that John moved to the office. It is highly unlikely that Lily is a rhino. It is unlikely that Jeff dropped the apple.",
        "valid"
    ],
    [
        0.37753284970919293,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '266'}",
        "В прокуратуре полагают, что информация о продаже, которая «находилась в свободном доступе для неограниченного круга лиц», нарушает закон о рекламе, поскольку «является недобросовестной рекламой, побуждает потребителей к совершению правонарушений»",
        "incorrect"
    ],
    [
        0.3774101237456004,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '682'}",
        "Chances are slight that 'Jason is tired' or 'Daniel took the football' or both.",
        "valid"
    ],
    [
        0.377407302459081,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '71'}",
        "It is highly unlikely that either 'Emily is a sheep' or 'John went to the office' but not both.",
        "valid"
    ],
    [
        0.37737440566221875,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '544'}",
        "There is almost no chance that either 'Jeff left the football' or 'Greg is gray' but not both.",
        "valid"
    ],
    [
        0.3771515240271886,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '750'}",
        "There is a very good chance that Bernhard is gray. It is unlikely that Sandra left the milk. It is impossible that Greg is a frog.",
        "valid"
    ],
    [
        0.37701654930909473,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '85'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.05::factA.\n  0.6::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3770110805829366,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '508'}",
        "При подобном подходе в поле зрения, естественно, оказывается только та часть проблемы, которая находится на переднем плане, видна, что называется, невооружённым глазом, но которая не перестаёт от этого быть лишь одной из многих…",
        "correct"
    ],
    [
        0.3769816706577937,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '216'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.25::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3769775281349818,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '914'}",
        "There is little chance that Brian is a frog. It is probably the case that Daniel got the milk. There is a better than even chance that Julius is a lion. It is probably not the case that if either 'Julius is a lion' or 'Brian is a frog' but not both then Emily is a mouse. There is little chance that if either 'Daniel got the milk' or 'Brian is a frog' but not both then Lily is green. There is a better than even chance that if 'Julius is a lion' or 'Daniel got the milk' or both then Mary moved to the office.",
        "invalid"
    ],
    [
        0.37697548667589825,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '454'}",
        "Chances are slight that Bernhard is a swan. It is improbable that John discarded the apple. There is little chance that Lily is yellow.",
        "valid"
    ],
    [
        0.3769577443599701,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '884'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.1::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.376957505941391,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '88'}",
        "We believe that Sandra left the milk. It is probably not the case that Julius is a swan. There is little chance that Mary picked up the milk.",
        "valid"
    ],
    [
        0.37695516149202984,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '790'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.25::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37694576382637024,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '609'}",
        "We believe that Yann is bored. We believe that Julius is yellow. There is little chance that Mary went to the bedroom. It is improbable that if 'Mary went to the bedroom and Julius is yellow' then Sandra left the milk. It is almost certain that if 'Julius is yellow' or 'Yann is bored' or both then John moved to the office. Chances are slight that if either 'Yann is bored' or 'Julius is yellow' but not both then Bernhard is green.",
        "valid"
    ],
    [
        0.3768702099720637,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '344'}",
        "It is highly likely that either 'John got the milk' or 'Bill went to the office' but not both.",
        "valid"
    ],
    [
        0.37686318655808765,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '572'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.1::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37684614459673565,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '838'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.7::factB.\n  0.5::factC.\n  %hop1\n  0.1::factX:-and(factA,factC).\n  0.95::factY:-or(factC,factB).\n  0.1::factZ:-or(factA,factB).\n\n  %hop2\n  conclusion:-and(factA,factZ).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3768237332503001,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '25'}",
        "There is a better than even chance that Sandra took the milk. It is almost certain that John left the football. Chances are about even that Mary went to the office. There is a very good chance that if 'John left the football and Sandra took the milk' then Greg is green. Chances are about even that if 'Sandra took the milk and Mary went to the office' then Brian is yellow. We believe that if either 'Sandra took the milk' or 'John left the football' but not both then Julius is a swan.",
        "valid"
    ],
    [
        0.3768065969149272,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '719'}",
        "«Неврозы воспитывают в детях гиперопекающие родители, делая их неспособными ко взрослой жизни",
        "correct"
    ],
    [
        0.3767472008864085,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '463'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.95::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3767448316017787,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '599'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.95::factA.\n  0.6::factB.\n  0.75::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3766922851403554,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '575'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.7::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3766763557990392,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '517'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.95::factA.\n  0.7::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3766614894072215,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '608'}",
        "Chances are slight that John went to the bedroom. It is almost certain that Daniel took the milk. Chances are slight that Julius is yellow.",
        "valid"
    ],
    [
        0.3766549477974574,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '165'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.95::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3766047805547714,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '260'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.25::factA.\n  0.6::factB.\n  0.7::factC.\n  %hop1\n  0.5::factX:-or(factB,factA).\n  0.1::factY:-xor(factA,factC).\n  0.25::factZ:-and(factC,factB).\n\n  %hop2\n  conclusion:-and(factB,factX).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3765862435102463,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '119'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.95::factA.\n  0.7::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3765602807203929,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '331'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  1.0::factB.\n  0.75::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37651656568050385,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '771'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.2::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3764243423938751,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '210'}",
        "There is almost no chance that 'Bernhard is green and Lily is a swan'.",
        "valid"
    ],
    [
        0.3764052440722783,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '900'}",
        "It is highly likely that Greg is green. It is almost certain that Brian is gray. It is almost certain that Bernhard is a frog.",
        "valid"
    ],
    [
        0.37639659146467846,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '218'}",
        "It is probably not the case that either 'Bill moved to the office' or 'Mary discarded the apple' but not both.",
        "valid"
    ],
    [
        0.37635987997055054,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '357'}",
        "It is probable that Mary got the milk. It is highly unlikely that Julius is a rhino. It is improbable that Yann is hungry.",
        "valid"
    ],
    [
        0.37635839978853863,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '422'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  1.0::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37634863952795666,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '9'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.7::factB.\n  0.05::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3763277033964793,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '27'}",
        "It is probably not the case that 'Bernhard is white and Brian is green'.",
        "valid"
    ],
    [
        0.37631896138191223,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '329'}",
        "Кроме того, для простоты выбора потребителей будет обнародована информация о продукции, которую они производят», – рассказал RBC daily Иван Блоков",
        "correct"
    ],
    [
        0.3762676517168681,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '881'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  1.0::factB.\n  0.7::factC.\n  %hop1\n  0.1::factX:-and(factC,factA).\n  0.0::factY:-and(factA,factC).\n  0.7::factZ:-xor(factC,factB).\n\n  %hop2\n  conclusion:-xor(factY,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.376250296831131,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '682'}",
        "Как все отставные подполковники, мой дядя заведовал техникой безопасности на фабрике \"Луч\" (Полковники возглавляют отделы кадров).  Возможно, он разбирался в технике безопасности, это не исключено",
        "correct"
    ],
    [
        0.3762407451868057,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '798'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.1::factB.\n  0.05::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3762283573547999,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '950'}",
        "It is unlikely that Daniel got the football. It is highly likely that John went to the garden. It is highly unlikely that Greg is white.",
        "valid"
    ],
    [
        0.37621961037317914,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '483'}",
        "There is almost no chance that 'Bernhard is gray' or 'John got the apple' or both.",
        "valid"
    ],
    [
        0.3762135903040568,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '634'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.25::factA.\n  0.2::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37619200348854065,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '148'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.75::factA.\n  0.7::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37618838250637054,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '494'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.05::factA.\n  0.1::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3761871010065079,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '113'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.75::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37615696092446643,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '772'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.7::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37614503006140393,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '96'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.1::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37613578140735626,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '253'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.75::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.376082385579745,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '783'}",
        "There is almost no chance that 'Julius is a lion and Sandra left the football'.",
        "valid"
    ],
    [
        0.37607267995675403,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '187'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.95::factA.\n  0.7::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-xor(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37607215841611225,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '11'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  1.0::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37602562208970386,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '651'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.05::factA.\n  0.6::factB.\n  0.7::factC.\n  %hop1\n  0.6::factX:-or(factB,factC).\n  0.1::factY:-and(factA,factB).\n  0.8::factZ:-xor(factC,factB).\n\n  %hop2\n  conclusion:-and(factX,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3760146051645279,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '421'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.5::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37600836157798767,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '115'}",
        "Но самой удачливой оказалась врач айнур ибрагимова из москвы, которая первой дозвонилась до нас и сказала правильные ответы: 1) школу пифагора посещали 28 человек",
        "correct"
    ],
    [
        0.37600820263226825,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '679'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.75::factA.\n  0.6::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37598592539628345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '93'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.05::factA.\n  0.7::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.375964676340421,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '273'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.05::factA.\n  0.75::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37596099078655243,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '683'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.7::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37595932682355243,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '361'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.05::factA.\n  0.9::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3759271154801051,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '653'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.5::factA.\n  0.9::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3759211053450902,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '629'}",
        "It is probably not the case that Mary dropped the apple. It is certain that Greg is yellow. There is almost no chance that John put down the milk.",
        "valid"
    ],
    [
        0.3759043167034785,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '251'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.1::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3758925547202428,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '164'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.9::factA.\n  0.6::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37587956090768176,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '332'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  1.0::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3758559972047806,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '277'}",
        "Да и не получалось раньше (Об исторической победе голубых над врачами читайте Гей-революция, о необходимости которой все время говорили секс-меньшевики, совершилась)",
        "correct"
    ],
    [
        0.3758543183406194,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '672'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.9::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37584713101387024,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '355'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.05::factA.\n  0.1::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37584248185157776,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '12'}",
        "Центральные герои передачи ― брат и сестра из семьи, которую принято называть неблагополучной",
        "correct"
    ],
    [
        0.37584248185157776,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '133'}",
        "Центральные герои передачи ― брат и сестра из семьи, которую принято называть неблагополучной",
        "correct"
    ],
    [
        0.37580325702826184,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '188'}",
        "It is almost certain that Brian is a swan. It is unlikely that Winona is a wolf. We believe that Bernhard is a lion. It is highly unlikely that if either 'Winona is a wolf' or 'Bernhard is a lion' but not both then Lily is white. It is probable that if either 'Winona is a wolf' or 'Bernhard is a lion' but not both then John discarded the apple. It is highly unlikely that if 'Winona is a wolf and Bernhard is a lion' then Greg is gray.",
        "invalid"
    ],
    [
        0.37580035626888275,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '286'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.6::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3757968445618947,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '571'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.1::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37578892707824707,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '785'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.75::factA.\n  0.25::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3757399767637253,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '508'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.6::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37572066982587177,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '425'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.5::factA.\n  0.0::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3757171332836151,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '124'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  1.0::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3756910264492035,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '129'}",
        "There is almost no chance that Greg is yellow. It is highly likely that Bernhard is white. It is probably not the case that Mary picked up the apple.",
        "valid"
    ],
    [
        0.37568633258342743,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '146'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.1::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3756713916858037,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '525'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.95::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37566518286863965,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '373'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.2::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37566080192724866,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '953'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.1::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3756401042143504,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '458'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.5::factA.\n  0.6::factB.\n  0.75::factC.\n  \n\n  %hop2\n  conclusion:-xor(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3756232460339864,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '425'}",
        "Удивительно, но основная мысль статьи, которую я тупо выразила в заголовке, так никого и не взволновала, все почему-то решили, что я по злобе охаяла школу и учительский коллектив",
        "correct"
    ],
    [
        0.37562217315038043,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '595'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.75::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37561651070912677,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '720'}",
        "«Неврозы воспитывают в детях гиперопекающие родители, делая их неспособными ко взрослой жизни",
        "incorrect"
    ],
    [
        0.37559405465920764,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '752'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.2::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3755696515242259,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '849'}",
        "There is a very good chance that Sandra left the milk. It is impossible that Mary went to the bedroom. It is probably the case that Greg is a frog.",
        "valid"
    ],
    [
        0.37555697560310364,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '825'}",
        "Chances are about even that either 'Julius is white' or 'Mary moved to the garden' but not both.",
        "valid"
    ],
    [
        0.3755532205104828,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '963'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.7::factB.\n  0.25::factC.\n  %hop1\n  0.95::factX:-and(factA,factC).\n  0.1::factY:-xor(factA,factB).\n  0.8::factZ:-xor(factC,factA).\n\n  %hop2\n  conclusion:-and(factX,factZ).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3755469520886739,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '526'}",
        "General question; I put *not* in parentheses because I might find it more helpful to know when *not* to, rather than when I should.\n\nI guess this could also lead to the question: \"How do I know that I'm in love with someone?\", but I won't ask that since it's supposedly different for everyone.\n\nWhile the question is general, I suppose it wouldn't hurt to provide context as to why I'm asking this question:\n\n#Context\n\nAbout a year ago I met this girl at uni camp. Initially I was indifferent (I think), but after hanging out for a while in the first month, I found myself thinking about her **ALOT**. Also found myself denying that I love her, but, maybe I really do?\n\nAnyway, we haven't really done much together, if at all. From what I remember, there's the excursion with other friends to some fun place (BOUNCEinc), and a dinner *\"date\"* (what makes something a date anyway?), but that's it. I do/did try to converse with her through IM, but it's never satisfying because she *always* stops responding without warning (I presume she's just busy whenever that happens, but maybe I'm fooling myself? I mean, the notifications are *right there*, wth?)\n\nFast forward a year later, to now, still wondering if I should tell her, and when. The doubt is mostly because we haven't interacted much and I feel it might make the situation.....awkward, but also because I suspect she's already in a relationship (not certain).\n\nRight now, I'm thinking of calling her up and offering my time to chat over some coffee or something; see how that goes.\n\nSo, what should I do? Confess? Don't speak of it? Talk her into some night(s) out? Am I even playing the dating game (right)?\n\n##context",
        "Accuracy"
    ],
    [
        0.3755375991264979,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '269'}",
        "It is highly unlikely that 'Fred went to the garden and Brian is a swan'.",
        "valid"
    ],
    [
        0.3755231748024623,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '131'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.75::factA.\n  0.7::factB.\n  0.25::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3755202442407608,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '576'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.95::factA.\n  0.1::factB.\n  1.0::factC.\n  %hop1\n  0.05::factX:-or(factA,factB).\n  0.9::factY:-or(factA,factC).\n  0.95::factZ:-and(factA,factC).\n\n  %hop2\n  conclusion:-and(factC,factZ).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37551914652188617,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '101'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.75::factA.\n  0.7::factB.\n  0.05::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3755090882380803,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '200'}",
        "It is probable that Emily is a mouse. It is impossible that Sandra put down the milk. It is highly likely that Daniel dropped the apple.",
        "valid"
    ],
    [
        0.3754957616329193,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '226'}",
        "Звуковая метода, о практичности которой Матвей Николаич до того времени не имел никакого ясного понятия, просто очаровала его",
        "correct"
    ],
    [
        0.3754834284385045,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '22'}",
        "It is almost certain that Mary took the milk. It is probable that Julius is yellow. There is almost no chance that Jessica is a mouse.",
        "valid"
    ],
    [
        0.3754812926054001,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '609'}",
        "It is probably not the case that John left the milk. Chances are about even that Mary went to the bedroom. There is a very good chance that Daniel took the football.",
        "valid"
    ],
    [
        0.375461886326472,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '742'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.6::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3754357894261678,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '660'}",
        "There is a very good chance that John went to the bedroom. We believe that Bernhard is a rhino. There is almost no chance that Julius is a swan.",
        "valid"
    ],
    [
        0.37540628015995026,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '416'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.75::factA.\n  0.05::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3753779282172521,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '890'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.2::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-xor(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37531394759813946,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '828'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.7::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3753090600172679,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '638'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.1::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-xor(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3752417018016179,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '882'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.6::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-xor(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3752245505650838,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '942'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.02::factB.\n  0.05::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37521789968013763,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '465'}",
        "Добрых сносил мучения молча, заставив сменные бригады дознавателей уже с каким-то суеверным ужасом глядеть в немой крестьянский лик, простой, скуластый, выдававший, казалось бы, всю низменность натуры, которую легко сломать, - что это за такие люди?",
        "correct"
    ],
    [
        0.37521789968013763,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '466'}",
        "Добрых сносил мучения молча, заставив сменные бригады дознавателей уже с каким-то суеверным ужасом глядеть в немой крестьянский лик, простой, скуластый, выдававший, казалось бы, всю низменность натуры, которую легко сломать, - что это за такие люди?",
        "correct"
    ],
    [
        0.3752177705367406,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '209'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.0::factA.\n  0.05::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-xor(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3751859913269679,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '482'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.0::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3751741151014964,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '748'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.95::factA.\n  0.0::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3751410444577535,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '334'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.25::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3751288751761119,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '330'}",
        "Кроме того, для простоты выбора потребителей будет обнародована информация о продукции, которую они производят», – рассказал RBC daily Иван Блоков",
        "incorrect"
    ],
    [
        0.3751274844010671,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '621'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.95::factA.\n  0.2::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37508435547351837,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '582'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.75::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.375067134698232,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '288'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.5::factB.\n  0.75::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3750416586796443,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '627'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.1::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-xor(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3749811053276062,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '478'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.0::factA.\n  0.75::factB.\n  0.02::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3749796350797017,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '941'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.2::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37490680317083996,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '79'}",
        "It is probably not the case that Lily is a lion. It is almost certain that Emily is a mouse. It is likely that Brian is a swan. It is unlikely that if 'Brian is a swan and Lily is a lion' then Fred went to the garden. There is a better than even chance that if either 'Emily is a mouse' or 'Brian is a swan' but not both then Mary took the football. It is improbable that if 'Lily is a lion' or 'Brian is a swan' or both then Greg is a rhino.",
        "invalid"
    ],
    [
        0.37488873302936554,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '309'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.2::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37487565477689105,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '908'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.1::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3748275587956111,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '727'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.75::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-xor(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37481879194577533,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '793'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.2::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3748182753721873,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '114'}",
        "Но самой удачливой оказалась врач айнур ибрагимова из москвы, которая первой дозвонилась до нас и сказала правильные ответы: 1) школу пифагора посещали 28 человек",
        "incorrect"
    ],
    [
        0.37476613620917004,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '317'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.5::factA.\n  0.05::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37474407255649567,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '810'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.1::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3746929218371709,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '418'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.9::factA.\n  1.0::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37467792133490246,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '368'}",
        "We believe that Bernhard is a swan. Chances are slight that Julius is a rhino. We believe that Mary got the apple.",
        "valid"
    ],
    [
        0.37466635803381604,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '805'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.2::factB.\n  0.05::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3746523956457774,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '13'}",
        "Центральные герои передачи ― брат и сестра из семьи, которую принято называть неблагополучной",
        "incorrect"
    ],
    [
        0.3746523956457774,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '134'}",
        "Центральные герои передачи ― брат и сестра из семьи, которую принято называть неблагополучной",
        "incorrect"
    ],
    [
        0.37462978065013885,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '551'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.02::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3746265321969986,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '92'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.6::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37460467716058093,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '541'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.75::factA.\n  0.02::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3745364894469579,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '803'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.9::factB.\n  0.0::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37446418901284534,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '256'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.5::factA.\n  0.75::factB.\n  0.75::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37445633113384247,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '307'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.1::factB.\n  0.8::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37442437807718915,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '273'}",
        "بسیار چرب معلومه که درصد زیادی قلوگاه گوسفندی داره به شدت هم بوی چربی میده و باید با کلی ادویه طعم دار بشه",
        "طعم"
    ],
    [
        0.3744017034769058,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '460'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.02::factA.\n  0.75::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3743973026672999,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '914'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.95::factB.\n  0.9::factC.\n  \n\n  %hop2\n  conclusion:-xor(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3743838220834732,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '102'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.1::factB.\n  0.6::factC.\n  \n\n  %hop2\n  conclusion:-xor(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3743787507216136,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '623'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.95::factB.\n  1.0::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3743772159020106,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '872'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.9::factA.\n  0.25::factB.\n  0.25::factC.\n  \n\n  %hop2\n  conclusion:-xor(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37437296907107037,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '320'}",
        "\"If you ever wondered about the evidence for those hot and/or smelly creams for arthritis pain, this column drove home a \"\"healthy skeptic\"\" perspective, emphasizing, for the most part, that \"\"there’s no good evidence that any over-the-counter rub or cream offers real relief for arthritis,\"\" according to one source. We say \"\"for the most part\"\" because it ended oddly, allowing some broad, vague, unsubstantiated and unquantified claims — \"\"seem to help some people…can give you temporary relief.\"\" We also wish the column had given a glimpse of the regulatory oversight that allows claims like \"\"deep penetrating pain relief\"\" or \"\"proven clinical effectiveness in treating arthritis pain\"\" when the column itself kept repeating:   \"\"no good evidence\"\"   \"\"results that do exist have been far from convincing\"\"   \"\"no better than placebo\"\"   \"\"relief was minor and didn’t show up until four weeks of treatment\"\"  \"\"the effect is usually either too fleeting or too mild to notice\"\"   \"\"there’s no known pathway they could take to ease arthritis pain.\"\"\"",
        "true"
    ],
    [
        0.3743549237648646,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '229'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.9::factA.\n  0.2::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3743514170249303,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '735'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.02::factA.\n  0.2::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-or(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3743495891491572,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '171'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.0::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-xor(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.374337837100029,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '316'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.02::factA.\n  0.6::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3743377203742663,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '353'}",
        "incorrect",
        "оправы"
    ],
    [
        0.374319131175677,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '181'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.6::factA.\n  0.02::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-or(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37430594861507416,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '602'}",
        "It is certain that Brian is a swan. There is little chance that Greg is a rhino. It is certain that Julius is a frog. There is almost no chance that if either 'Brian is a swan' or 'Julius is a frog' but not both then Jessica is a cat. It is almost certain that if either 'Brian is a swan' or 'Julius is a frog' but not both then Sandra got the milk. There is almost no chance that if 'Brian is a swan' or 'Julius is a frog' or both then Mary went to the office.",
        "invalid"
    ],
    [
        0.37430567542711896,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '225'}",
        "Звуковая метода, о практичности которой Матвей Николаич до того времени не имел никакого ясного понятия, просто очаровала его",
        "incorrect"
    ],
    [
        0.3743017017841339,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '325'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.02::factA.\n  0.2::factB.\n  0.1::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37425817052523297,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '404'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.05::factB.\n  0.0::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3742176791032155,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '730'}",
        "Write an excellent summary of the given text.\n\nTitle: Is there any easy way to find out who this person is?\n\nText: The other day I was working my normal retail job selling computers. A rather normal looking mid 20's guy approached me asking for help. After answering a few normal questions I figured he was not really going to buy a laptop and was there for some other reason. After some prodding he decides to tell me that he owns some e-commerce company and isn't sure if there are any positions available, but he likes my personality and will let me know if anything turns up. I got a call from him today asking if we want to meet up for coffee or something to discuss potential job offers. This is where I finally decided it was pretty sketchy. Obviously I won't take things any further with him until I decide if he's legit or not. I have his phone number and his first name, but other than that I can't remember the name of the company or anything else. Is there any way I can track the phone number and find out anything about this guy?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3741996834675471,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '417'}",
        "It is impossible that Mary got the apple. There is a very good chance that Brian is green. There is almost no chance that John left the football.",
        "valid"
    ],
    [
        0.37419139842192334,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '375'}",
        "Но эту двухчастную классификацию Аристотель вынужден усложнить, превратить в трехчастную, выделив еще одну, промежуточную часть души, которая отвечает не мыслительной, а нравственной добродетели",
        "correct"
    ],
    [
        0.37419139842192334,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '376'}",
        "Но эту двухчастную классификацию Аристотель вынужден усложнить, превратить в трехчастную, выделив еще одну, промежуточную часть души, которая отвечает не мыслительной, а нравственной добродетели",
        "correct"
    ],
    [
        0.37418249249458313,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '62'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.8::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-xor(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3741775055726369,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '240'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  1.0::factA.\n  0.8::factB.\n  0.05::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37410639226436615,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '848'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.7::factA.\n  0.02::factB.\n  0.05::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3740265866120656,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '331'}",
        "Вторая супруга, о красоте которой ходили легенды, родила ему пятерых сыновей: Алехандро, Антонио, Анжело, Александера и Диего",
        "correct"
    ],
    [
        0.3740077366431554,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '967'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.02::factA.\n  0.2::factB.\n  0.5::factC.\n  \n\n  %hop2\n  conclusion:-xor(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37392843266328174,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '702'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.02::factA.\n  0.25::factB.\n  0.75::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37383662660916644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '442'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.2::factB.\n  0.9::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3737761775652568,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '736'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.2::factB.\n  0.8::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37362053990364075,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '550'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.8::factB.\n  0.95::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3735900471607844,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '456'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.5::factA.\n  0.9::factB.\n  0.02::factC.\n  \n\n  %hop2\n  conclusion:-xor(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37346674005190533,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '108'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.02::factA.\n  0.02::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-and(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.37344389657179516,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '744'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.1::factA.\n  0.02::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3732796013355255,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '20'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.7::factB.\n  0.2::factC.\n  \n\n  %hop2\n  conclusion:-xor(factA,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3731573323408763,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '132'}",
        "It is improbable that Gertrude is a mouse. There is a very good chance that Brian is yellow. It is highly likely that Bernhard is a rhino.",
        "valid"
    ],
    [
        0.37310610711574554,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '780'}",
        "It is probably the case that Emily is a cat. Chances are about even that Lily is white. It is certain that John got the milk. Chances are slight that if either 'Emily is a cat' or 'John got the milk' but not both then Brian is a rhino. It is unlikely that if either 'Lily is white' or 'John got the milk' but not both then Greg is a swan. It is impossible that if either 'Lily is white' or 'John got the milk' but not both then Mary went to the bedroom.",
        "invalid"
    ],
    [
        0.37309296429157257,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '470'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.9::factA.\n  0.7::factB.\n  0.8::factC.\n  \n\n  %hop2\n  conclusion:-and(factC,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3729938119649887,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '228'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.9::factA.\n  0.8::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factA).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3729613572359085,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '68'}",
        "It is almost certain that Jessica is a cat. It is certain that Lily is a lion. It is highly unlikely that Julius is white. It is almost certain that if 'Lily is a lion and Jessica is a cat' then Brian is yellow. There is little chance that if either 'Lily is a lion' or 'Julius is white' but not both then Greg is a frog. It is highly unlikely that if either 'Lily is a lion' or 'Julius is white' but not both then John took the apple.",
        "invalid"
    ],
    [
        0.37288301686445874,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '613'}",
        "It is unlikely that Greg is gray. It is probably not the case that Winona is a sheep. It is impossible that Lily is a swan. It is highly unlikely that if either 'Greg is gray' or 'Lily is a swan' but not both then Fred dropped the milk. It is probable that if either 'Greg is gray' or 'Winona is a sheep' but not both then Julius is white. Chances are about even that if 'Greg is gray and Lily is a swan' then Brian is a lion.",
        "invalid"
    ],
    [
        0.37287382284800213,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '932'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.2::factA.\n  0.9::factB.\n  0.8::factC.\n  \n\n  %hop2\n  conclusion:-and(factB,factC).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3727506548166275,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '133'}",
        "It is highly unlikely that either 'Lily is a rhino' or 'Brian is a frog' but not both.",
        "invalid"
    ],
    [
        0.3727143580714862,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '35'}",
        "Финальная история - женщины, которая хочет усыновить ребенка: она рассказывает, как долго пыталась забеременеть, как это сложно, даже когда очень хочешь и есть доступ к современной медицине",
        "correct"
    ],
    [
        0.3727143580714862,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '410'}",
        "Финальная история - женщины, которая хочет усыновить ребенка: она рассказывает, как долго пыталась забеременеть, как это сложно, даже когда очень хочешь и есть доступ к современной медицине",
        "correct"
    ],
    [
        0.37246466676394147,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '909'}",
        "منهای اینکه یکسری چیزارو خیلی مستقیم مطرح میکنه که یه کم آزاردهنده میشه ولی در مجموع و در انتهای فیلم مفهوم خوبیو میرسونه. بازی جواد عزتی هم مثل همیشه خوبه و به نظرم جزو نقاط مثبته کاره اما متاسفانه نیوشا ضیغمی انتخاب خوبی نبود برای این نقش.",
        "صدا"
    ],
    [
        0.37244002521038055,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '961'}",
        "\n  and(A,B) :- A,B.\n  or(A,B) :- A;B.\n  nand(A,B) :- not(and(A,B)).\n  nor(A,B) :- not(or(A,B)).\n  xor(A,B) :- or(A,B), nand(A,B).\n\n  %hop0\n  0.8::factA.\n  0.02::factB.\n  0.7::factC.\n  \n\n  %hop2\n  conclusion:-xor(factA,factB).\n\n  query(conclusion).\n  ",
        "valid"
    ],
    [
        0.3723546763261159,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '651'}",
        "نسبت به بقیه چایی های زعفرانی که تا حالاخوردم این از همه بدتر بود... فکر کنم برای چند روزی ظرف زعفران را پهلوش گذاشتند که یه کمی بو بگیره... اصلا خوب نیست.. نمی دونم چطور بعضی دوستان گفتند خوبه...",
        "طعم"
    ],
    [
        0.3723476429780324,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '116'}",
        "*** цитата: «из девочки, которая, как все ее сверстницы, мечтала о муже и детях, она превратилась в затравленную тень, считавшую себя несчастной и опозоренной»",
        "correct"
    ],
    [
        0.37221962710221607,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '774'}",
        "\"А он, Хмельков, не был уродом, он был человеком.\"",
        "correct"
    ],
    [
        0.37219685812791187,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '238'}",
        "It is probably not the case that Brian is a swan. It is certain that Greg is a rhino. It is highly unlikely that Lily is a lion.",
        "invalid"
    ],
    [
        0.3721184730529785,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '577'}",
        "با کمال احترام به نظر بقیه دوستان از نظر من کاملا بد طعم و نسبت به محصولات سابق این برند خیلی فاصله داره، تنها حس مابع بی طعم ولی گاز دار رو تجربه میکنید طعم نوشابه های قبل رو برداشت نمیکنید.",
        "نوشابه"
    ],
    [
        0.37205085655053455,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '437'}",
        "Write an excellent summary of the given text.\n\nTitle: Is it normal that I still haven't met my boyfriend's parents?\n\nText: I'm 20 (F) and he's 20 as well. We've been together for a year and a couple months.\n\nA trivial problem, but it's been bugging me:\n\nHis parents don't know we're dating.\n\nHe hasn't met my parents yet either. I was originally going to wait until we've dated a year to make sure we're not just a fling before bringing him home. (My parents are kind of picky with the guys I like.) Now that I'm okay with my parents knowing about him, I'm concerned that he isn't.\n\nHe says he doesn't want to burden his parents with the knowledge that he's dating. His dad has been ill for several years and his mom is busting her ass taking care of him and his little sister. Maybe in another year, he said, but definitely not now.\n\nNow, my parents are perfectly healthy so as much as I try to strain my imagination, I cannot relate. *Can you guys tell me if it's normal that he plans to keep our relationship hidden from his parents for at least another year, likely more?*\n\nTo clarify, my parents don't know about him either, so I know this seems hypocritical of me. But I'm okay with introducing him now; I've brought it up to him several times. I haven't because I don't want to introduce him as a longterm part of my life to my parents if he's not serious about us.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.37191612521807355,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '141'}",
        "Днём 25-го Ленин заявил на сессии Петросовета: «Рабочая и крестьянская революция, о необходимости которой всё время говорили большевики, свершилась",
        "incorrect"
    ],
    [
        0.37174226343631744,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '548'}",
        "It is probably not the case that 'Brian is a lion' or 'Winona is a sheep' or both.",
        "invalid"
    ],
    [
        0.3717178553342819,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '541'}",
        "['Калверт-Льюин', 'дубль']",
        "correct"
    ],
    [
        0.37170473237832385,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '749'}",
        "There is almost no chance that Brian is a rhino. There is almost no chance that Antoine is thirsty. There is little chance that Greg is a swan. There is a better than even chance that if 'Brian is a rhino and Greg is a swan' then Bernhard is a frog. It is certain that if either 'Brian is a rhino' or 'Antoine is thirsty' but not both then John picked up the milk. There is almost no chance that if 'Brian is a rhino and Greg is a swan' then Mary left the football.",
        "invalid"
    ],
    [
        0.37152427186568576,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '411'}",
        "Финальная история - женщины, которая хочет усыновить ребенка: она рассказывает, как долго пыталась забеременеть, как это сложно, даже когда очень хочешь и есть доступ к современной медицине",
        "incorrect"
    ],
    [
        0.3715238769849141,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '782'}",
        "Write an excellent summary of the given text.\n\nTitle: Do you think it's justifiable to not like  when my parents go through my stuff?\n\nText: I don't have anything illegal or something I shouldn't have.It's just that I don't particularly like anyone going through my stuff. This includes but isn't limited to- bedroom,computers,other electronics, and my bookbag.I'll let them do it, but I always stand over their shoulder, parent or not\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3715038945277532,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '321'}",
        "It is probably not the case that either 'Greg is a swan' or 'Brian is a lion' but not both.",
        "invalid"
    ],
    [
        0.3714437832434972,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '819'}",
        "این شیر مزه خوبی ندارد و البته این موضوع سلیقه ای است.",
        "طعم"
    ],
    [
        0.37105703850587207,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '773'}",
        "There is almost no chance that 'Brian is white' or 'Lily is white' or both.",
        "invalid"
    ],
    [
        0.3710259944200516,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '689'}",
        "It is highly unlikely that either 'Lily is a swan' or 'Brian is a rhino' but not both.",
        "invalid"
    ],
    [
        0.3710237095753352,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '138'}",
        "It is certain that Jessica is a sheep. There is little chance that Lily is a rhino. It is impossible that Julius is a frog. We doubt that if 'Jessica is a sheep' or 'Lily is a rhino' or both then Antoine is hungry. It is improbable that if 'Jessica is a sheep and Julius is a frog' then Mary went to the office. It is unlikely that if either 'Jessica is a sheep' or 'Julius is a frog' but not both then Bernhard is gray.",
        "invalid"
    ],
    [
        0.3707846949497859,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '192'}",
        "It is highly unlikely that either 'Lily is a swan' or 'Brian is white' but not both.",
        "invalid"
    ],
    [
        0.37075164914131165,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '665'}",
        "А вокруг была совсем другая, обыденная жизнь, в которой все барахтались, как умели, мелко грешили и сплетничали, и, хотя подросшие деревья закрывали участки от посторонних глаз, спрятать все тайны они не могли, и причастный купавинской повести временных лет Колюня знал, что у соседки справа муж алкоголик, а соседа наискосок день и ночь пилит жена, требуя продать дачу и купить кооперативную квартиру в Зеленограде, что лечившего его от ожога доктора, Гошиного папу, доброго душевного человека, у которого, первого на их улочке, была машина, жена прогнала",
        "correct"
    ],
    [
        0.3707219163576762,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '224'}",
        "Это так и было: благодетельная особа эта, встретившая и приветствовавшая меня в моем затруднительном положении посреди комнаты, была та самая Агата, о доброте которой говорила maman",
        "correct"
    ],
    [
        0.370645930369695,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'chegeka.raw', 'row_id': '337'}",
        "\"Правда, только правда и ничего, кроме правды\" — так она и вошла в английское право",
        "Правда"
    ],
    [
        0.37055468062559765,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '161'}",
        "سلام، کلا این کارخانه را خیلی قبول ندارم... بهترین نوع شیر پاستوریزه و کم چرب می باشد",
        "طعم"
    ],
    [
        0.37052108347415924,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '157'}",
        "It is probable that either 'Brian is a lion' or 'Lily is a frog' but not both.",
        "invalid"
    ],
    [
        0.3704606170455615,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '100'}",
        "Вам не кажется странной ситуация, при которой тренер национальной команды регулярно вызывает защитника вейича из «томи», которая заняла 11-е место, и при этом полностью игнорирует вас, чемпиона россии?",
        "incorrect"
    ],
    [
        0.3704243302345276,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '22'}",
        "Доклад Милова-Немцова ― это декларация о лояльности, которая сводится к тому, чтобы оставаться в прежней политической нише, обличать, призывать, заклинать и не признавать никакой ответственности перед той частью общества, которая доверила и все еще доверяет Немцову и прочим «людям с раньшего времени» представлять свою политическую позицию",
        "correct"
    ],
    [
        0.3704243302345276,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '306'}",
        "Доклад Милова-Немцова ― это декларация о лояльности, которая сводится к тому, чтобы оставаться в прежней политической нише, обличать, призывать, заклинать и не признавать никакой ответственности перед той частью общества, которая доверила и все еще доверяет Немцову и прочим «людям с раньшего времени» представлять свою политическую позицию",
        "correct"
    ],
    [
        0.37039447327454883,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '852'}",
        "It is probably not the case that 'Brian is white' or 'Lily is a swan' or both.",
        "invalid"
    ],
    [
        0.37036457161108655,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '650'}",
        "It is probably not the case that 'Brian is white' or 'Lily is a frog' or both.",
        "invalid"
    ],
    [
        0.37017423411210376,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '532'}",
        "این محصول کیفیت خوبی نداشت و من از خرید آن پشیمان شدم و دیگه ازش نمی خرم چه معنی دارای تو تن ماهی پولک ماهی دیده بشه گوشت ماهی شم سفت بود مثل لاستیک",
        "طعم"
    ],
    [
        0.3699824760357539,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '797'}",
        "It is highly likely that Julius is a lion. It is impossible that Winona is a wolf. It is probable that Gertrude is a sheep. It is unlikely that if 'Winona is a wolf' or 'Gertrude is a sheep' or both then Antoine is thirsty. It is probably not the case that if 'Julius is a lion' or 'Gertrude is a sheep' or both then Mary took the football. We doubt that if either 'Winona is a wolf' or 'Julius is a lion' but not both then John went to the bedroom.",
        "invalid"
    ],
    [
        0.3699439937869708,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '446'}",
        "Не случайно говорят, что между идеей и ее реализацией лежит «долина смерти», которую нужно преодолеть",
        "correct"
    ],
    [
        0.3698245386282603,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '154'}",
        "این گوشت چرخ کرده دنبه فراوانی قاطی دارد و بدون اینکه اصلا روغن به غذا اضافه کنی، غذا واقعا چرب می شود. و طبیعتاً حجم آن پس از سرخ کردن به شدت کاهش می یابد، چون مقدار فراوان دنبه آن به صورت روغن آب می شود. اصلا توصیه نمی کنم.",
        "طعم"
    ],
    [
        0.36971814433733624,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '339'}",
        "This viral news story is a good example of a poorly executed bait and switch. It provides results of an actual study to gain credibility before switching into unsubstantiated, unverifiable, and illogical claims, forcing a connection that — like “Dr. Olivia Bader-Lee” herself — will not appear, no matter how hard you look for it.",
        "false"
    ],
    [
        0.3696411922574043,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '11'}",
        "Получается, что лучшей будет названа либо актриса из картины, которой никто в россии пока не видел, либо актриса из телефильма, либо покойная уже актриса из картины, смонтированной из недоснятого материала и тоже практически нигде не показанной",
        "correct"
    ],
    [
        0.3695646673440933,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '530'}",
        "It is highly likely that Brian is a frog. There is almost no chance that John got the apple. It is highly likely that Greg is a lion. We believe that if either 'John got the apple' or 'Greg is a lion' but not both then Sandra put down the milk. It is probably not the case that if 'John got the apple' or 'Greg is a lion' or both then Gertrude is a cat. We believe that if 'John got the apple and Greg is a lion' then Julius is a rhino.",
        "invalid"
    ],
    [
        0.36951765914758045,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '328'}",
        "It is probably the case that Winona is a wolf. It is probably not the case that Lily is a frog. It is probable that Mary dropped the milk. It is probable that if either 'Mary dropped the milk' or 'Winona is a wolf' but not both then Greg is a lion. It is likely that if either 'Winona is a wolf' or 'Lily is a frog' but not both then Bill went to the garden. It is unlikely that if 'Mary dropped the milk' or 'Lily is a frog' or both then Brian is a rhino.",
        "invalid"
    ],
    [
        0.36946244537830353,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '437'}",
        "It is probably not the case that 'Brian is a frog' or 'Lily is white' or both.",
        "invalid"
    ],
    [
        0.3693831314643224,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '300'}",
        "It is probably not the case that Brian is white. It is probably not the case that Mary went to the bedroom. We doubt that Lily is a rhino. It is probable that if 'Mary went to the bedroom' or 'Lily is a rhino' or both then Julius is a frog. There is little chance that if either 'Lily is a rhino' or 'Brian is white' but not both then Jessica is a mouse. It is probable that if either 'Lily is a rhino' or 'Mary went to the bedroom' but not both then Bernhard is gray.",
        "invalid"
    ],
    [
        0.36936285595099133,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '213'}",
        "В этом предрассудке мы встречаем ту же старую мысль о гармонии, которая будто бы и может, и должна достигаться каждой правильной формой быта",
        "incorrect"
    ],
    [
        0.36923016607761383,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '795'}",
        "Сыновья Илия были негодяями ― они не знали Господа",
        "correct"
    ],
    [
        0.3691554938753446,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '432'}",
        "Жена Нелли, которой Сергей Палыч пересказал свой сон, была возмущена: «У тебя никогда не были руки скользкими",
        "incorrect"
    ],
    [
        0.36915204922358197,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '91'}",
        "مربا البالو که بیشتر اب خیلی غلیظ البالو هست،اصلا البالو دیده نمیشه،خیلی هم شیرینه",
        "طعم"
    ],
    [
        0.3690340518951416,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '336'}",
        "متاسفانه قبل از خرید با دقت مشخصات کالا رو مطالعه نکردم... شدت کمبود کیفیت ماچا به کنار، محصول خارجی این کالا با ۲ برابر وزن ماچا (و احتمال ۱۰۰٪ کیفیت بیشتر) قیمت کمتری دارد... واقعا متاسفم از تولید کالا ملی...",
        "طعم"
    ],
    [
        0.36896609763304394,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '470'}",
        "We doubt that Julius is a swan. There is a better than even chance that Bernhard is a frog. There is a better than even chance that Lily is a rhino. It is almost certain that if either 'Julius is a swan' or 'Lily is a rhino' but not both then Emily is a wolf. There is a very good chance that if 'Lily is a rhino' or 'Bernhard is a frog' or both then John went to the kitchen. We believe that if 'Bernhard is a frog and Julius is a swan' then Jessica is a sheep.",
        "invalid"
    ],
    [
        0.36885394155979156,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '495'}",
        "Трудно даже представить ту степень наивности, которой надо обладать, чтобы надеяться на возможность получить доступ к этим технологиям",
        "correct"
    ],
    [
        0.3687234967947006,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '610'}",
        "Chances are slight that Brian is a lion. It is improbable that Greg is gray. There is a very good chance that Julius is a frog. It is likely that if 'Julius is a frog and Brian is a lion' then Daniel dropped the milk. There is a better than even chance that if either 'Greg is gray' or 'Julius is a frog' but not both then John moved to the office. It is unlikely that if 'Greg is gray and Brian is a lion' then Lily is a swan.",
        "invalid"
    ],
    [
        0.3686898897091548,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '323'}",
        "It is impossible that 'Winona is a wolf' or 'Brian is a frog' or both.",
        "invalid"
    ],
    [
        0.36865557730197906,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '320'}",
        "It is impossible that 'Lily is white' or 'Julius is a lion' or both.",
        "invalid"
    ],
    [
        0.36860009531180066,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '581'}",
        "We doubt that Greg is a frog. It is likely that John discarded the apple. It is highly unlikely that Winona is a mouse. It is unlikely that if 'Winona is a mouse' or 'John discarded the apple' or both then Brian is a swan. It is probably not the case that if 'Winona is a mouse and Greg is a frog' then Julius is a swan. We believe that if 'Greg is a frog' or 'Winona is a mouse' or both then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.3685842951138814,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '338'}",
        "This legend is a tricky subject to tackle, because it’s based upon the fine (and often confusing) distinction between actual death and declared death. For example, if a seriously-injured victim of an automobile accident were loaded into a ambulance and died en route to the hospital, he generally would not be officially declared dead until he arrived at the hospital and was examined by a doctor. The difference in time between the actual physical death of the patient and the declaration of death by the doctor is the discrepancy on which this legend turns. So, the claim here is not that no one has ever actually died on Disney theme park property, but whether Disney can legitimately make the claim that “no one has ever died at a Disney park” because they ensure that any declaration of death takes place outside of park property. As such, there are really two questions which must be answered:   The first question is difficult to answer, because obviously Disney isn’t going to discuss such a sensitive issue. Some former Disney employees have reported that the “no one dies on Disney property” maxim is indeed a company policy; that, as suggested in the book Inside the Mouse, “if guests have the nerve to die, they wait, like unwanted calories, until they’ve crossed the line and can do so safely off the property”:  We had a guy last summer who went to EPCOT, stood in front of the golf ball, took a gun, and blew his head off. But he didn’t die. He stood right there in front of all those tourists and went “cluck” and brains blew everywhere. But he didn’t die there. The medic told me that they are not allowed to let them die there. Keep them alive by artificial means until they’re off Disney property, like there’s an imaginary line in the road and they go, “He’s alive, he’s alive, he’s dead.”  In all fairness, however, it should be noted that in some jurisdictions once paramedics begin life-saving efforts they cannot discontinue those efforts until the patient has been transported to a medical facility, even if the patient is obviously dead; therefore, what someone might interpret as “flogging a dead body” to delay a determination of death could actually be a legally required procedure. Moreover, the sprawling size and relative isolation of the Walt Disney World complex in Florida make it imperative that persons in need of urgent medical attention be loaded into helicopters and transported to hospitals as quickly as possible. The combination of these two factors makes it rather unlikely that anyone would actually be declared dead on Walt Disney World property, regardless of how The Walt Disney Company felt about the matter. Declared deaths on Disney property apparently have happened before, however, as reported by the New York Times in an article about a 1984 plane crash in the EPCOT parking lot:  A man was pronounced dead at the scene. A woman and a 2-year-old child died after being taken to a hospitals. The two survivors, a 3-year-old girl and a 5-year-old boy, were listed in critical condition at Orlando Regional Medical Center. In California as well, news accounts have mentioned instances where accident victims were declared dead while on Disneyland property, as in this 1985 Los Angeles Times report of a girl who was crushed to death under the wheels of a tour bus in the Disneyland parking lot:  The identity of the girl, who was pronounced dead at the scene, was not released pending notification of her parents, according to Sgt. Larry Kurtz. The driver of the bus was not held.",
        "false"
    ],
    [
        0.3684782286485036,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '258'}",
        "Write an excellent summary of the given text.\n\nTitle: Me [23F] with mycoworker [33M] married father of 3, how to evade his attentions?\n\nText: Hello all of you,\n\nLong time lurker etc, here is my issue: i started a PhD in engineering a year ago, and am in an all male laboratory with age ranges from 23 (me) to 35 ish. Therefore everyone is great friends with the others and all goes well. Or does it? \n\nIt doesn't. Jay is 33, married and father of 3 kids, and he and I are the only smokers, therefore we take our breaks together. **In the past few weeks** I have felt that he is being very \"affectionate\", generally standing too close to me and trying to touch me whenever he can get away with it, very innocently.\n\nFor instance he'll ask for my lighters and brush my fingers with his, he is also encroaching in my personal space: he inches forward, i inch back, and we can literally move meters away from the original spot where we stood like that). \n\nOur lab has a professional IM program and he often starts conversations which i do my best to cut short, but he does that more and more often. He uses pet names (the kind that can pass as casual such as \"cocotte\" - we're french), etc.\n\nI have a boyfriend (all my colleagues know that) and I have told him about it, and he was concerned and asked me to be careful, but did not really know **how to de-escalate what is apparently starting to escalate**.\n\nWhich is why I come here for advice: how can i de-escalate in a way that won't make Jay wounded in his pride (I'm worried he'd start a rumor on how I tried to sleep with him or smth out of spite and ruin my professional life, **I still have 2 years of PhD to complete**) ?\n\nNB: names were obviously changed\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3684345732132594,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '253'}",
        "It is impossible that either 'Winona is a wolf' or 'Greg is a lion' but not both.",
        "invalid"
    ],
    [
        0.3683060755332311,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '409'}",
        "It is likely that Greg is a rhino. It is probable that Lily is a swan. It is highly unlikely that Daniel dropped the apple. It is probably the case that if 'Lily is a swan and Greg is a rhino' then Mary went to the kitchen. It is unlikely that if 'Lily is a swan' or 'Greg is a rhino' or both then Bernhard is a frog. Chances are slight that if either 'Daniel dropped the apple' or 'Greg is a rhino' but not both then Brian is a lion.",
        "invalid"
    ],
    [
        0.3682646031181018,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '151'}",
        "То ли от того, что с момента написания первой тетрадки прошло много времени, то ли от того, что меня мучила эта мысль о книжке, которую я пишу, пишу и всё никак не могу написать ― я вдруг ясно понял, что окончательно забыл и перепутал ― что было на самом деле, а что мне кто-то рассказал или я придумал",
        "correct"
    ],
    [
        0.36824839810530346,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '798'}",
        "There is a better than even chance that Julius is a lion. It is impossible that Mary got the football. We doubt that Bernhard is a rhino. It is probably the case that if either 'Mary got the football' or 'Julius is a lion' but not both then Winona is a sheep. It is probably the case that if 'Mary got the football and Bernhard is a rhino' then Fred put down the apple. It is improbable that if 'Julius is a lion' or 'Mary got the football' or both then Brian is a swan.",
        "invalid"
    ],
    [
        0.36820634206136066,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '133'}",
        "برند نام آشنا و محصولات با کیفیت،نیازی به تعریف نداره همه محصولات تک ماکارون عالی هست",
        "طعم"
    ],
    [
        0.3681895583868027,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '806'}",
        "It is almost certain that Bernhard is white. We doubt that Brian is a rhino. It is likely that Lily is a swan. Chances are about even that if 'Brian is a rhino' or 'Bernhard is white' or both then Greg is a frog. There is a very good chance that if 'Brian is a rhino' or 'Bernhard is white' or both then Sandra dropped the milk. We believe that if 'Bernhard is white' or 'Lily is a swan' or both then John left the football.",
        "invalid"
    ],
    [
        0.3681382089853287,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '593'}",
        "It is improbable that either 'Greg is a lion' or 'Lily is a frog' but not both.",
        "invalid"
    ],
    [
        0.36808261026938754,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '524'}",
        "У Бродского к этим стихиям добавляется еще и стихия воды, которая на самом деле не вполне природная, так как относится все-таки к идее времени-вечности, отражения в нем",
        "correct"
    ],
    [
        0.36800602575143176,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '112'}",
        "- это замечательные люди ― артур николаевич чилингаров и подруга из америки, которая очень помогла мне, когда я была там",
        "incorrect"
    ],
    [
        0.3680030554533005,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '355'}",
        "Над этим уровнем строится логическая и функциональная сущность БД, которая «не знает», как он устроен",
        "incorrect"
    ],
    [
        0.36791469156742096,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '920'}",
        "Chances are about even that Brian is white. It is unlikely that Winona is a cat. We believe that Bernhard is a rhino. There is almost no chance that if 'Winona is a cat' or 'Bernhard is a rhino' or both then Emily is a mouse. It is probably not the case that if 'Bernhard is a rhino and Winona is a cat' then Lily is a swan. Chances are slight that if either 'Brian is white' or 'Bernhard is a rhino' but not both then Mary dropped the milk.",
        "invalid"
    ],
    [
        0.3678070455789566,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '281'}",
        "It is almost certain that Bernhard is a rhino. It is impossible that Julius is white. It is improbable that Lily is a frog. We doubt that if 'Lily is a frog and Bernhard is a rhino' then Gertrude is a cat. It is unlikely that if either 'Julius is white' or 'Bernhard is a rhino' but not both then Greg is green. It is probable that if 'Bernhard is a rhino' or 'Lily is a frog' or both then John dropped the apple.",
        "invalid"
    ],
    [
        0.3677477240562439,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '378'}",
        "بنده دو تا عدد سفارش دادم . در هنگام دریافت ماهی بصورت عدم منجمد دریافت گردید و بر روی آن خونابه راه افتاده بود . در هنگام مصرف و بعد از شستشو بوی بسیار نامطبوع از آن متصاعد شده و قابل استفاده نبود .",
        "طعم"
    ],
    [
        0.3676670541365941,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '589'}",
        "Р. Мертон считал факт добровольного ухода из жизни видом ретретизма",
        "correct"
    ],
    [
        0.3676638553539912,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '494'}",
        "Трудно даже представить ту степень наивности, которой надо обладать, чтобы надеяться на возможность получить доступ к этим технологиям",
        "incorrect"
    ],
    [
        0.36760371426741284,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '290'}",
        "It is impossible that 'Daniel got the football' or 'Brian is a frog' or both.",
        "invalid"
    ],
    [
        0.36738210419813794,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '648'}",
        "It is highly likely that Daniel got the milk. There is a very good chance that Bill went to the garden. It is impossible that Brian is gray. It is probably not the case that if either 'Bill went to the garden' or 'Daniel got the milk' but not both then Julius is a swan. It is highly likely that if either 'Daniel got the milk' or 'Brian is gray' but not both then Lily is yellow. We believe that if 'Brian is gray' or 'Bill went to the garden' or both then Greg is green.",
        "invalid"
    ],
    [
        0.3673778623342514,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '7'}",
        "Однако маша петрова из москвы, которой не хватает и 3000 дол в месяц, считает себя бедной (зарабатывая 3000) а ася смирнова из… цка, (с доходом 50 дол), не считает.",
        "correct"
    ],
    [
        0.367371844748656,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '271'}",
        "Это история о вдове, которая с трудом воспитывает сына с синдромом дефицита внимания",
        "incorrect"
    ],
    [
        0.36736511687437695,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '981'}",
        "با این‌که می‌شد گفت یک جورهایی فیلم در نیامده، به دل من بسیار نشست. سفری زنانه و پایین‌ها و بالایش، با بازی خوب لیلا حاتمی و موسیقی خیلی خوب پورناظری و همایون شجریان. در مجموع به نظرم حمید نعمت اله فیلمساز قابلی است.",
        "صدا"
    ],
    [
        0.3673454523086548,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '269'}",
        "همشه بنده از نوشابه کاله استفاده میکنم به خاطر قندی که توش هست و از شیر درست میشه و هیچ فرقی با نوشابه های دیگه نداره",
        "نوشابه"
    ],
    [
        0.36734408636887866,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '613'}",
        "It is unlikely that 'Lily is a swan' or 'Brian is white' or both.",
        "invalid"
    ],
    [
        0.3672274798154831,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '767'}",
        "Из-за такого численного перевеса складывается ощущение, что это дети выгуливают взрослых, а не взрослые детей",
        "correct"
    ],
    [
        0.36718706289927167,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '223'}",
        "С вашего позволения, милая маменька, я приобрету ту пустошь, о покупке которой так часто мечтал покойный дяденька",
        "correct"
    ],
    [
        0.3671836008628209,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '975'}",
        "It is probable that Julius is a frog. We doubt that Greg is a swan. It is almost certain that Winona is a wolf. There is a better than even chance that if 'Winona is a wolf and Greg is a swan' then Emily is a mouse. We believe that if 'Winona is a wolf and Julius is a frog' then Sandra dropped the milk. There is almost no chance that if 'Winona is a wolf' or 'Julius is a frog' or both then John picked up the apple.",
        "invalid"
    ],
    [
        0.367105836669604,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '788'}",
        "It is unlikely that Julius is a swan. It is highly likely that John left the milk. It is highly unlikely that Brian is a swan. We believe that if 'Brian is a swan' or 'Julius is a swan' or both then Gertrude is a sheep. It is probably the case that if either 'Julius is a swan' or 'Brian is a swan' but not both then Lily is a lion. There is almost no chance that if 'Julius is a swan and Brian is a swan' then Mary went to the hallway.",
        "invalid"
    ],
    [
        0.3670411209265391,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '361'}",
        "Если отец Катулла дружил с этим Цезарем, то для него это ровным счётом ничего не значило, кроме того, что и на мирного веронца могла распространяться часть опасности, которой была наполнена жизнь римского друга в кровавые времена диктатора Суллы и жестокой смуты, последовавшей за его кончиной",
        "correct"
    ],
    [
        0.36701588829358417,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '953'}",
        "(1) Двое друзей, Леандр и Криспин, приходят в незнакомый городок. (2) Положение их довольно затруднительно, поскольку они совершенно без денег. (3) Криспин, более изворотливый и неунывающий, нежели Леандр, исполнен решимости раздобыть денег и даже разбогатеть, для чего предлагает дерзкий план. (4) Леандр должен выдать себя за богатого и знатного человека, приехавшего в город по важному государственному делу, а об остальном под видом его слуги позаботится Криспин. (5) Леандру не очень по душе эта затея: его пугают возможные последствия подобного обмана, но он сдаётся перед настойчивостью приятеля, понимая, что положение у них безвыходное. (6) Друзья стучатся в дверь гостиницы и просят лучшие комнаты и обильный ужин. (7) Хозяин сначала относится к ним недоверчиво, но заносчивость Криспина и его напористость убеждают трактирщика, что перед ним важные господа. (8) Вскоре приходят Арлекин, местный поэт, и его Друг Капитан. (9) Не один раз они ели в долг в этой гостинице и надеются поужинать тут и сегодня. (10) Однако терпение трактирщика иссякло, и он отказывается их кормить. (11) Сметливый Криспин решает привлечь Арлекина и Капитана на свою сторону, делая вид, что ему известны блестящие стихи Арлекина и смелые подвиги Капитана. (12) Он тут же приказывает накормить Арлекина и Капитана ужином за счёт Леандра, и трактирщик не смеет отказать: он уже усвоил, что этим знатным господам ни в чём нельзя перечить.",
        "False"
    ],
    [
        0.36701584855715436,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '951'}",
        "(1) Двое друзей, Леандр и Криспин, приходят в незнакомый городок. (2) Положение их довольно затруднительно, поскольку они совершенно без денег. (3) Криспин, более изворотливый и неунывающий, нежели Леандр, исполнен решимости раздобыть денег и даже разбогатеть, для чего предлагает дерзкий план. (4) Леандр должен выдать себя за богатого и знатного человека, приехавшего в город по важному государственному делу, а об остальном под видом его слуги позаботится Криспин. (5) Леандру не очень по душе эта затея: его пугают возможные последствия подобного обмана, но он сдаётся перед настойчивостью приятеля, понимая, что положение у них безвыходное. (6) Друзья стучатся в дверь гостиницы и просят лучшие комнаты и обильный ужин. (7) Хозяин сначала относится к ним недоверчиво, но заносчивость Криспина и его напористость убеждают трактирщика, что перед ним важные господа. (8) Вскоре приходят Арлекин, местный поэт, и его Друг Капитан. (9) Не один раз они ели в долг в этой гостинице и надеются поужинать тут и сегодня. (10) Однако терпение трактирщика иссякло, и он отказывается их кормить. (11) Сметливый Криспин решает привлечь Арлекина и Капитана на свою сторону, делая вид, что ему известны блестящие стихи Арлекина и смелые подвиги Капитана. (12) Он тут же приказывает накормить Арлекина и Капитана ужином за счёт Леандра, и трактирщик не смеет отказать: он уже усвоил, что этим знатным господам ни в чём нельзя перечить.",
        "False"
    ],
    [
        0.3668925240635872,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '523'}",
        "У Бродского к этим стихиям добавляется еще и стихия воды, которая на самом деле не вполне природная, так как относится все-таки к идее времени-вечности, отражения в нем",
        "incorrect"
    ],
    [
        0.36687126259009045,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '776'}",
        "It is impossible that Julius is a swan. There is a better than even chance that Bernhard is white. There is a very good chance that Mary took the football. It is probably the case that if either 'Mary took the football' or 'Julius is a swan' but not both then Emily is a cat. We doubt that if 'Mary took the football' or 'Julius is a swan' or both then John discarded the milk. It is improbable that if either 'Julius is a swan' or 'Mary took the football' but not both then Lily is a frog.",
        "invalid"
    ],
    [
        0.36671169102191925,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '392'}",
        "چندین بار این محصول را خریدم با توجه به اینکه روغن نداره خیلی بهتره واسه سلامتی",
        "طعم"
    ],
    [
        0.3666578084230423,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '755'}",
        "It is impossible that Mary went to the kitchen. There is a better than even chance that Lily is gray. We believe that Brian is a frog. There is almost no chance that if 'Mary went to the kitchen' or 'Lily is gray' or both then Bernhard is white. It is highly unlikely that if either 'Brian is a frog' or 'Lily is gray' but not both then John picked up the apple. It is impossible that if 'Lily is gray and Mary went to the kitchen' then Greg is a rhino.",
        "invalid"
    ],
    [
        0.36654719710350037,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '177'}",
        "Two friends, one dating the ex of the other, are having problems. Friend A is fine with Friend B dating his ex, but Friend B is not fine with Friend A seeing his ex.",
        "Accuracy"
    ],
    [
        0.3665241499741872,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '149'}",
        "Альтернативная служба, о необходимости которой сейчас заговорили с удвоенной силой, у брата артиста какая-никакая, а была",
        "correct"
    ],
    [
        0.3665057569742203,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '536'}",
        "We believe that Winona is a sheep. There is a very good chance that Greg is a swan. There is little chance that Yann is hungry. It is highly likely that if 'Winona is a sheep and Greg is a swan' then John grabbed the milk. It is almost certain that if either 'Greg is a swan' or 'Winona is a sheep' but not both then Julius is a rhino. It is probably not the case that if either 'Greg is a swan' or 'Winona is a sheep' but not both then Mary got the football.",
        "invalid"
    ],
    [
        0.3664835939804713,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '183'}",
        "There is a very good chance that Brian is white. It is impossible that Daniel took the apple. Chances are about even that Greg is a swan. It is unlikely that if 'Greg is a swan' or 'Daniel took the apple' or both then Julius is yellow. There is almost no chance that if 'Brian is white' or 'Greg is a swan' or both then John moved to the office. It is probably the case that if either 'Brian is white' or 'Greg is a swan' but not both then Bernhard is a rhino.",
        "invalid"
    ],
    [
        0.36646414299805957,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '363'}",
        "It is impossible that Brian is white. Chances are slight that Bernhard is gray. There is little chance that John got the apple. It is almost certain that if 'John got the apple and Bernhard is gray' then Winona is a mouse. Chances are about even that if either 'John got the apple' or 'Bernhard is gray' but not both then Mary took the milk. It is highly likely that if 'John got the apple' or 'Brian is white' or both then Greg is a lion.",
        "invalid"
    ],
    [
        0.366456205646197,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '80'}",
        "There is little chance that Greg is a lion. It is probably not the case that Emily is a wolf. We believe that Fred put down the apple. It is certain that if either 'Greg is a lion' or 'Fred put down the apple' but not both then Bernhard is green. It is improbable that if either 'Greg is a lion' or 'Fred put down the apple' but not both then Jason is bored. It is unlikely that if either 'Greg is a lion' or 'Emily is a wolf' but not both then Brian is a rhino.",
        "invalid"
    ],
    [
        0.36643099784851074,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '188'}",
        "Не знать, что деготь дает береза, ― это значит половину не знать о березе, которую вы так хорошо расписали и даже соком напоили и стихи приводили, а о дегте ни слова!",
        "incorrect"
    ],
    [
        0.36638172964255017,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '782'}",
        "It is almost certain that Greg is gray. It is probable that Emily is a wolf. There is almost no chance that Brian is a frog. It is highly unlikely that if 'Brian is a frog' or 'Greg is gray' or both then Mary moved to the garden. Chances are about even that if either 'Brian is a frog' or 'Greg is gray' but not both then Julius is yellow. There is a very good chance that if either 'Greg is gray' or 'Brian is a frog' but not both then Daniel got the football.",
        "invalid"
    ],
    [
        0.3663600633541743,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '475'}",
        "Girl is conflicted about whether or not to continue a relationship with a guy who is great when things are good but is often not good enough to make up for past mistakes.",
        "Accuracy"
    ],
    [
        0.3663577387730281,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '522'}",
        "It is highly unlikely that either 'Lily is a swan' or 'Julius is a frog' but not both.",
        "invalid"
    ],
    [
        0.36634444693724316,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '331'}",
        "It is impossible that either 'Julius is gray' or 'Lily is a lion' but not both.",
        "invalid"
    ],
    [
        0.36625517904758453,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '842'}",
        "It is probably not the case that Brian is a rhino. Chances are about even that Julius is a swan. It is probably not the case that Bernhard is yellow. It is probably not the case that if either 'Brian is a rhino' or 'Julius is a swan' but not both then Greg is gray. It is highly likely that if 'Julius is a swan' or 'Bernhard is yellow' or both then John took the football. It is probably not the case that if either 'Brian is a rhino' or 'Bernhard is yellow' but not both then Winona is a wolf.",
        "invalid"
    ],
    [
        0.3662484437227249,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '111'}",
        "It is probable that Julius is a frog. It is almost certain that Brian is a rhino. There is almost no chance that Jessica is a cat. We doubt that if 'Julius is a frog' or 'Jessica is a cat' or both then Greg is white. We believe that if either 'Julius is a frog' or 'Jessica is a cat' but not both then Mary left the football. We believe that if 'Jessica is a cat and Brian is a rhino' then John took the apple.",
        "invalid"
    ],
    [
        0.3661509305238724,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '282'}",
        "It is impossible that 'Brian is yellow' or 'Lily is a swan' or both.",
        "invalid"
    ],
    [
        0.36603255569934845,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '170'}",
        "It is unlikely that 'Julius is a frog' or 'Brian is a lion' or both.",
        "invalid"
    ],
    [
        0.36602577318747836,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '193'}",
        "Торговец охал и стенал, жаловался на разорение, но ничего толком сообщить нам не мог, так как ехал не из Аррабоны, а возвращался в этот город, где оставалась часть его семьи, об участи которой он очень беспокоился",
        "correct"
    ],
    [
        0.36602147420247394,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '511'}",
        "روغن به نسبت خوبیه و از یه برند معتبره. البته بهتره که مصرف روغنو کاهش بدیم.",
        "طعم"
    ],
    [
        0.365966076652209,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '588'}",
        "It is probably not the case that either 'Lily is a lion' or 'Brian is yellow' but not both.",
        "invalid"
    ],
    [
        0.36592646439870197,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '292'}",
        "(1) В давние времена лев, который был королём трёх тысяч лесов, взял себе в жёны лису. (2) Вскоре у них родился сын, да такой, что и на лиса не похож, и львом его не назовёшь. (3) С виду он был вроде совсем как лев, да только, вместо того чтобы рычать по-львиному, лаял по-лисьи. (4) Когда сын стал подрастать, отец лев призвал его к себе и сказал: — Сын мой! (5) Ты велик и силён телом, но от своей матери лисы получил презренный голос. (6) В твоём голосе нет величия, и он не подобает моему царственному отпрыску. (7) Если звери услышат, как ты лаешь по-лисьи, они не станут с тобой считаться. (8) Поэтому уж лучше совсем помалкивай и не подавай голоса. (9) Тогда я смогу даровать тебе тысячу лесов. (10) Сын запомнил наставления льва. (11) Но однажды вышло так, что он их нарушил. (12) Как-то, когда собралось много зверей, сыну льва очень захотелось подать голос. (13) Он не выдержал и, забыв наказ отца, звонко залаял по-лисьи. (14) Среди зверей поднялся смех, когда они услыхали, как тоненько, по-лисьи лает такой большой и сильный зверь. (15) И тогда отец лев сказал ему: — Если бы ты, сынок, молчал, как я тебе наказывал,— получил бы тысячу лесов. (16) А теперь вижу, что ты не достоин этих лесов, раз не смог унять своей болтливости. (17) Так вот и не получил сын льва тысячи лесов, а люди с тех пор стали говорить: «Молчание — тысячи стоит».",
        "False"
    ],
    [
        0.36592646439870197,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '293'}",
        "(1) В давние времена лев, который был королём трёх тысяч лесов, взял себе в жёны лису. (2) Вскоре у них родился сын, да такой, что и на лиса не похож, и львом его не назовёшь. (3) С виду он был вроде совсем как лев, да только, вместо того чтобы рычать по-львиному, лаял по-лисьи. (4) Когда сын стал подрастать, отец лев призвал его к себе и сказал: — Сын мой! (5) Ты велик и силён телом, но от своей матери лисы получил презренный голос. (6) В твоём голосе нет величия, и он не подобает моему царственному отпрыску. (7) Если звери услышат, как ты лаешь по-лисьи, они не станут с тобой считаться. (8) Поэтому уж лучше совсем помалкивай и не подавай голоса. (9) Тогда я смогу даровать тебе тысячу лесов. (10) Сын запомнил наставления льва. (11) Но однажды вышло так, что он их нарушил. (12) Как-то, когда собралось много зверей, сыну льва очень захотелось подать голос. (13) Он не выдержал и, забыв наказ отца, звонко залаял по-лисьи. (14) Среди зверей поднялся смех, когда они услыхали, как тоненько, по-лисьи лает такой большой и сильный зверь. (15) И тогда отец лев сказал ему: — Если бы ты, сынок, молчал, как я тебе наказывал,— получил бы тысячу лесов. (16) А теперь вижу, что ты не достоин этих лесов, раз не смог унять своей болтливости. (17) Так вот и не получил сын льва тысячи лесов, а люди с тех пор стали говорить: «Молчание — тысячи стоит».",
        "False"
    ],
    [
        0.3659110963344574,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '816'}",
        "Dennis Lyon was a genetic train wreck. Cancer was ravaging his liver, lungs, bones and brain, and tests showed so many tumor mutations that drugs targeting one or two wouldn’t do much good. It seemed like very bad news, yet his doctors were encouraged.",
        "true"
    ],
    [
        0.36567433178424835,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '95'}",
        "It is improbable that Winona is a wolf. It is highly likely that Lily is a frog. It is probable that Brian is green. It is almost certain that if 'Lily is a frog' or 'Winona is a wolf' or both then Sandra dropped the apple. It is highly unlikely that if either 'Lily is a frog' or 'Winona is a wolf' but not both then Greg is a frog. It is almost certain that if either 'Lily is a frog' or 'Brian is green' but not both then Bernhard is a rhino.",
        "invalid"
    ],
    [
        0.3656611094872157,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '635'}",
        "It is almost certain that Bernhard is gray. There is a very good chance that Greg is yellow. It is probably the case that Lily is a lion. It is probable that if either 'Bernhard is gray' or 'Lily is a lion' but not both then Emily is a sheep. It is highly unlikely that if either 'Bernhard is gray' or 'Lily is a lion' but not both then Julius is a swan. There is a better than even chance that if 'Lily is a lion' or 'Bernhard is gray' or both then Mary got the apple.",
        "invalid"
    ],
    [
        0.3655570099751155,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '647'}",
        "It is impossible that Julius is green. It is probably not the case that Greg is a lion. It is improbable that Brian is white. There is a better than even chance that if 'Brian is white and Greg is a lion' then Fred went to the garden. Chances are slight that if either 'Julius is green' or 'Greg is a lion' but not both then Mary left the football. It is impossible that if either 'Julius is green' or 'Greg is a lion' but not both then Jessica is a mouse.",
        "invalid"
    ],
    [
        0.36553414165973663,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '737'}",
        "There is a very good chance that Bernhard is a frog. It is impossible that Brian is a lion. We doubt that Gertrude is a mouse. Chances are about even that if 'Brian is a lion and Bernhard is a frog' then Lily is yellow. It is unlikely that if 'Gertrude is a mouse and Bernhard is a frog' then John left the football. We doubt that if either 'Brian is a lion' or 'Bernhard is a frog' but not both then Greg is a swan.",
        "invalid"
    ],
    [
        0.3654887229204178,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '400'}",
        "نباید بگن کنجد و کانولا باید صادقانه طبق جلد محصول گفته بشه کنجد، کانولا و آفتابگردان که بسیار ارزانتر تموم میشه اگرچه اطلاعات روی جلد هم وقتی درصد مخلوطسازی مشخص نیست اشکال داره",
        "کلی"
    ],
    [
        0.3654848486185074,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '531'}",
        "There is almost no chance that 'Greg is a swan' or 'Lily is a lion' or both.",
        "invalid"
    ],
    [
        0.36543366809686023,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '475'}",
        "There is a very good chance that Daniel grabbed the milk. We believe that Julius is a rhino. There is a very good chance that Lily is a lion. There is a very good chance that if 'Lily is a lion' or 'Daniel grabbed the milk' or both then Brian is white. Chances are about even that if 'Julius is a rhino' or 'Daniel grabbed the milk' or both then John took the apple. It is impossible that if 'Daniel grabbed the milk' or 'Julius is a rhino' or both then Mary went to the office.",
        "invalid"
    ],
    [
        0.3654330025116603,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '788'}",
        "Более того, иногда родители не рассказывали детям про их происхождение",
        "correct"
    ],
    [
        0.36537688970565796,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '350'}",
        "\"Но почему же тогда могила без ограды, которая отделяет личное сакральное пространство от публичного?\"",
        "correct"
    ],
    [
        0.3653356780608495,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '611'}",
        "There is almost no chance that 'Julius is a lion' or 'Lily is a swan' or both.",
        "invalid"
    ],
    [
        0.36533422768116,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '506'}",
        "Нюрка, которая по Витькиному приказу к этому моменту уже почти слезла с завалинки, сообразила, что Витька злится теперь не на нее, а на чужих пацанов",
        "correct"
    ],
    [
        0.3653249591588974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '366'}",
        "It is probably the case that Greg is gray. It is unlikely that Brian is a swan. It is probable that Daniel got the milk. It is probably not the case that if 'Greg is gray and Brian is a swan' then Yann is tired. There is a very good chance that if 'Daniel got the milk and Brian is a swan' then Bernhard is a rhino. There is almost no chance that if 'Daniel got the milk' or 'Greg is gray' or both then Emily is a wolf.",
        "invalid"
    ],
    [
        0.36530635257562,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '685'}",
        "It is unlikely that Bernhard is white. There is little chance that Julius is a lion. It is improbable that John picked up the apple. We doubt that if either 'Julius is a lion' or 'John picked up the apple' but not both then Jeff moved to the garden. It is probable that if either 'John picked up the apple' or 'Julius is a lion' but not both then Lily is a frog. It is impossible that if 'Julius is a lion and John picked up the apple' then Mary left the football.",
        "invalid"
    ],
    [
        0.3653012712796529,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '966'}",
        "Write an excellent summary of the given text.\n\nTitle: When your closest friends complain about life, how much is too much?\n\nText: We're both in our mid/late twenties and I've known him for at least 15 years. These days it seems that most of what he says are complaints about various things: his job, living situation, family, etc.\n\nHe's my closest friend, and I get that I need to be there for him. But this past weekend he went on for 40 minutes talking about his living arrangement (his landlord raised the rent and he fortuitously ended up moving back to his previous apartment). We had additional company that night--two other friends that we've known for about 3 years.\n\nHe tends to do this whenever we talk--30 minutes to an hour of complaining. We don't talk often or see each other every day so I would say I'm hearing this once or twice a week. This actually makes it worse because in the little time we're together, I only hear him complain.\n\nI wonder how everyone else deals with this. What are your thresholds?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.365301010509332,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '754'}",
        "\"[Наталья Колоколова, жен] Нормальные заказчики, расторгают контракты с нерадивыми подрядчиками!!!\"",
        "correct"
    ],
    [
        0.36529254416624707,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '517'}",
        "'Brian is a rhino' or 'Greg is a lion' or both.",
        "invalid"
    ],
    [
        0.36514075597127277,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '779'}",
        "Наверняка вот в чем сила автора ― он может легко устроить судьбу персонажа!",
        "correct"
    ],
    [
        0.36513935029506683,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '395'}",
        "We doubt that Greg is a frog. There is almost no chance that Bernhard is yellow. It is almost certain that Brian is a swan. It is almost certain that if 'Bernhard is yellow and Greg is a frog' then Sumit is thirsty. We believe that if 'Greg is a frog' or 'Bernhard is yellow' or both then Julius is a lion. Chances are about even that if either 'Brian is a swan' or 'Bernhard is yellow' but not both then Lily is white.",
        "invalid"
    ],
    [
        0.3650946294267972,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '741'}",
        "предки",
        "incorrect"
    ],
    [
        0.3650626291831334,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '448'}",
        "It is almost certain that Winona is a mouse. Chances are slight that Lily is a frog. It is highly likely that Bill went to the kitchen. It is probably not the case that if either 'Bill went to the kitchen' or 'Lily is a frog' but not both then Bernhard is gray. It is probable that if 'Lily is a frog and Bill went to the kitchen' then John discarded the milk. Chances are about even that if 'Bill went to the kitchen and Winona is a mouse' then Julius is green.",
        "invalid"
    ],
    [
        0.36496852338314056,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '155'}",
        "There is a better than even chance that Lily is a rhino. It is certain that Greg is yellow. It is almost certain that Bernhard is a lion. It is probably not the case that if 'Greg is yellow and Bernhard is a lion' then John dropped the milk. It is probably not the case that if 'Greg is yellow' or 'Bernhard is a lion' or both then Brian is a swan. There is little chance that if 'Bernhard is a lion' or 'Lily is a rhino' or both then Mary went to the bedroom.",
        "invalid"
    ],
    [
        0.3649614229798317,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '483'}",
        "عسل بسیار با کیفیتی بود بسیار بهتر از طمع عسل های بسته بندی تو بازار من که راضی بودم عسل هیچ تعریف واحد و بخصوصی در مزه نداره، اما این طمع خوشایند داره",
        "طعم"
    ],
    [
        0.3649353136618932,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '678'}",
        "It is impossible that Emily is a mouse. It is probable that Greg is a rhino. There is little chance that Sandra got the milk. It is probable that if 'Emily is a mouse' or 'Greg is a rhino' or both then Julius is a lion. It is probably not the case that if either 'Emily is a mouse' or 'Greg is a rhino' but not both then Mary went to the hallway. Chances are slight that if 'Greg is a rhino' or 'Sandra got the milk' or both then Bernhard is a swan.",
        "invalid"
    ],
    [
        0.36492293576399487,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '879'}",
        "There is almost no chance that 'Julius is a swan' or 'Lily is a lion' or both.",
        "invalid"
    ],
    [
        0.36489827930927277,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '616'}",
        "It is probably not the case that either 'Lily is a frog' or 'Greg is white' but not both.",
        "invalid"
    ],
    [
        0.36481326321760815,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '79'}",
        "It is probably not the case that either 'Brian is a rhino' or 'Julius is a swan' but not both.",
        "invalid"
    ],
    [
        0.36475997666517895,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '341'}",
        "Chances are about even that Greg is white. It is improbable that Gertrude is a cat. It is unlikely that Lily is a frog. It is impossible that if either 'Gertrude is a cat' or 'Lily is a frog' but not both then Bernhard is a lion. It is almost certain that if either 'Lily is a frog' or 'Gertrude is a cat' but not both then Brian is a swan. There is almost no chance that if 'Lily is a frog and Gertrude is a cat' then Mary went to the garden.",
        "invalid"
    ],
    [
        0.36471190055211383,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '522'}",
        "В «везение» придется включить не только его собственную гибель, но и смерть Нюши, которая, обезножевши к концу жизни, то ли сгорит, то ли задохнется от дыма во время пожара ее парижской квартиры",
        "incorrect"
    ],
    [
        0.36467184623082477,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '776'}",
        "\"Но не забыл Иван, как Параскева сыну его помогла.\"",
        "correct"
    ],
    [
        0.36462461451689404,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '294'}",
        "It is highly unlikely that 'Lily is a lion' or 'Julius is a swan' or both.",
        "invalid"
    ],
    [
        0.36460454265276593,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '431'}",
        "Драгана создала себе жизнь, равной которой еще никто не проживал: все в ней было взвешено, все отмерено и закреплено, и я идеально вписался в эту картину - служил самым обыкновенным развлечением для нее, нечто вроде быстрого лекарства от одиночества и скуки, от болезней, приступы которых были коротки и исчезали слишком быстро",
        "correct"
    ],
    [
        0.3646023745338122,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '405'}",
        "Объясняют им на пальцах, что бутылка водки, которую они покупают, стоит гораздо…",
        "correct"
    ],
    [
        0.3646003057559331,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '832'}",
        "It is highly unlikely that 'Brian is a lion' or 'Lily is yellow' or both.",
        "invalid"
    ],
    [
        0.364598015944163,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '300'}",
        "[{'follow_up_question': 'Is this person your representative (if you have one), such as a lawyer, friend, family member or someone from an advice centre?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.3645850072304408,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '242'}",
        "It is unlikely that Julius is a lion. It is probable that Brian is white. There is almost no chance that Lily is a rhino.",
        "invalid"
    ],
    [
        0.36455164353052777,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '370'}",
        "This is not accurate. The parents are not dependent on him, well not as far as this post states.",
        "Accuracy"
    ],
    [
        0.36447690924008685,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '374'}",
        "Write an excellent summary of the given text.\n\nTitle: Me [23/F] with bf [24 M] of 7 months; he's renting out his basement apt. to a woman. Am I wrong to be uncomfortable?\n\nText: My boyfriend of 7 months bought a house 2 months ago without the need to rent the basement out.  Now he says he has to in order to make ends meet (which isn't necessarily true, I think he just doesn't want to have less than he's comfortable with, which I understand) he needs to rent the place out.  After many failed attempts of getting another dude to move in (tenant looking, and deciding not to take it), he is now considering having a woman move in close who is close to our age.   He is considering this before other options of lowering the rent, or using other sources besides Craigslist.\n\nI am uncomfortable because we had a talk before he made this decision that this would make me uncomfortable, and he agreed he'd feel the same way if the roles were reversed.\n\nNow that he's feeling the pressure, he is having a woman look at the place tonight. I expressed how uncomfortable I am with this because they will have a shared space, and I do not live there... and he is still doing it, regardless of the promise he made me in the beginning and fully knowing how uncomfortable I am.\n\nHe even said that if I moved in with guys he would not be ok with this.  My question is, I guess: Am I being unreasonable, or is he putting me in a very uncomfortable position?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.36436471343040466,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '508'}",
        "iste.Kublal. een kleinzoon van Dsjlnglsehan.Wa» ongetwijfeld een 𝘼𝙯𝙞𝙖𝙩𝙞𝙨𝙘𝙝 despoot, me» all» luimen van dergelijk» heeren, maar tocb, afkom",
        "𝘼𝙯𝙞𝙖𝙩𝙞𝙨𝙘𝙝"
    ],
    [
        0.36432719975709915,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '297'}",
        "Конечно, в данной ситуации не идет речь о прокуратуре, которая время от времени привлекает к ответственности чиновников, как правило, низшего звена «за злоупотребление должностными полномочиями» в сфере ЖКХ",
        "correct"
    ],
    [
        0.3642981027563413,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '275'}",
        "Воздействие этого постоянно повторяющегося, а потому и наиболее эффективного напоминания самим себе: «Я буду низведен до такого же жалкого состояния, если совершу аналогичное преступление», гораздо сильнее, чем мысль о смерти, которую люди всегда представляют себе в туманной дали»",
        "correct"
    ],
    [
        0.364295427997907,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '797'}",
        "There is almost no chance that 'Daniel put down the milk' or 'Lily is a lion' or both.",
        "invalid"
    ],
    [
        0.3642503097653389,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '672'}",
        "Андрей слюнявил одну папиросу за другой, суетился так, будто ищет билет на через минуту отходящий поезд, и курилка, этот клуб любителей истины, сочувствовала ему, гонцы прочесали ряды читального зала и нашли свердловчанина, который и поведал ему об уральском самородке",
        "correct"
    ],
    [
        0.36419478555520374,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '391'}",
        "We believe that Lily is a rhino. It is highly likely that Emily is a mouse. We believe that Julius is a frog. We believe that if either 'Lily is a rhino' or 'Julius is a frog' but not both then Winona is a wolf. There is a better than even chance that if 'Emily is a mouse and Lily is a rhino' then Sandra dropped the milk. Chances are about even that if 'Emily is a mouse and Lily is a rhino' then John discarded the apple.",
        "invalid"
    ],
    [
        0.36416688064734143,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '971'}",
        "It is unlikely that Julius is a lion. There is almost no chance that Winona is a sheep. We doubt that Lily is yellow. We doubt that if 'Lily is yellow' or 'Julius is a lion' or both then Emily is a cat. It is improbable that if 'Julius is a lion and Winona is a sheep' then Greg is green. Chances are slight that if 'Julius is a lion' or 'Winona is a sheep' or both then Mary went to the hallway.",
        "invalid"
    ],
    [
        0.3641441414753596,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '505'}",
        "Нюрка, которая по Витькиному приказу к этому моменту уже почти слезла с завалинки, сообразила, что Витька злится теперь не на нее, а на чужих пацанов",
        "incorrect"
    ],
    [
        0.36412791907787323,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '714'}",
        "It is certain that Mary took the milk. There is a very good chance that Greg is a rhino. It is almost certain that Brian is white. It is probable that if either 'Brian is white' or 'Mary took the milk' but not both then Lily is yellow. It is impossible that if 'Mary took the milk and Brian is white' then Bernhard is yellow. It is unlikely that if 'Mary took the milk' or 'Greg is a rhino' or both then Jason is tired.",
        "invalid"
    ],
    [
        0.36406053602695465,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '534'}",
        "There is a better than even chance that Lily is white. It is almost certain that Sandra got the football. It is impossible that Greg is white. We believe that if 'Greg is white and Lily is white' then Daniel took the apple. It is probable that if 'Lily is white' or 'Sandra got the football' or both then Bernhard is a lion. Chances are slight that if 'Lily is white' or 'Greg is white' or both then John went to the bedroom.",
        "invalid"
    ],
    [
        0.364050214489301,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '877'}",
        "It is probably not the case that Julius is a swan. It is probably not the case that Mary went to the bedroom. It is highly unlikely that Daniel put down the milk. There is almost no chance that if either 'Mary went to the bedroom' or 'Julius is a swan' but not both then Bernhard is white. Chances are slight that if 'Mary went to the bedroom' or 'Julius is a swan' or both then Lily is gray. There is little chance that if 'Julius is a swan and Daniel put down the milk' then Brian is a frog.",
        "invalid"
    ],
    [
        0.36404124399026233,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '125'}",
        "Сотрудник российской “тиссенкрупп материалс” (ткм) признает, что практически вся никелированная нержавейка из европы, которая продается в россии, стоит дешевле, чем продукция «мечела»",
        "correct"
    ],
    [
        0.3639986465374629,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '404'}",
        "It is highly unlikely that Jason is tired. We believe that Lily is a swan. There is almost no chance that John left the football. We believe that if 'John left the football' or 'Lily is a swan' or both then Julius is a frog. It is certain that if either 'John left the football' or 'Lily is a swan' but not both then Brian is white. There is little chance that if 'Jason is tired and Lily is a swan' then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.36398565272490185,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '972'}",
        "We believe that Greg is a frog. It is certain that Mary got the apple. There is a very good chance that Lily is a rhino. Chances are about even that if 'Greg is a frog' or 'Mary got the apple' or both then Winona is a wolf. There is a very good chance that if 'Mary got the apple and Lily is a rhino' then Brian is yellow. We believe that if either 'Mary got the apple' or 'Lily is a rhino' but not both then Julius is a frog.",
        "invalid"
    ],
    [
        0.3639547179142634,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '309'}",
        "It is probably not the case that John took the football. It is improbable that Julius is gray. It is improbable that Lily is a frog. There is a very good chance that if 'John took the football' or 'Julius is gray' or both then Bernhard is white. We believe that if 'John took the football' or 'Lily is a frog' or both then Mary went to the kitchen. It is unlikely that if 'Lily is a frog' or 'Julius is gray' or both then Greg is gray.",
        "invalid"
    ],
    [
        0.3639118621746699,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '796'}",
        "\"The story provided cost estimates for a couple of neurofeedback treatment regimens. It also indicated euphemistically that it is not paid for by insurance companies. Although the story points out that there has not been enough study of neurofeedback to know whether claims of benefits are justified, it highlights an anecdote of a family who believes the treatment helped their child. Without any countervailing examples, this sort of personal story overwhelms the dry statements of doubt, leaving an unbalanced impression. In considering this criterion, perhaps the most troubling aspect of the story is that it jumps from one condition to the other. Is the treatment good for autism, ADHD and other attention issues, cognition in old age? It’s a red flag when proponents of a treatment claim, in essence, that it’s good for whatever ails you. We will give the story the benefit of the doubt on this criterion because it did at least mentions that there are potential harms, but the story would have been better if it had given more detail about the type and frequency of harms. It should have also clearly noted that risks exist even when a treatment is supervised by a skilled practitioner.One of the potential harms raised is this uNPRoven treatment may be favored over proven options like behavioral therapy and medication. The story mentioned readily available neurofeedback packages while at the same time had stern warning from a society spokesperson that people can have seizures or anxiety attacks if they use equipment that they get from ebay and use without supervision. No information about how commonly problems such as these occur. In trying to give readers an overview of the available evidence on neurofeedback, the story fails to give readers enough information to judge the quality of the research. Most of the references to studies fail to note whether they were randomized controlled trials or something less rigorous. Although the story includes sharp comments from experts who note the paucity of evidence on neurofeedback treatments for serious conditions, it blunders by allowing a researcher to claim prematurely that participants in his trial are showing improvement, even though the results have yet to be released or reviewed by others. It also seems odd that the story portrays the National Institute of Mental Health as a \"\"former skeptic\"\" of neurofeedback, simply because the institute is sponsoring a trial. Studying something is not the same as supporting it, after all, isn’t putting something to the test exactly what a skeptic does? The story did not engage in overt disease mongering. The story included quotes from advocates as well as skeptics about benefit to be obtained through neurofeedback treatment. Although the story includes one comment refering to proven treatments, readers are short-changed by the lack of detail or any discussion of the weight of evidence backing alternatives as comapred to the vague and scarcely studied claims of benefit from neurofeedback. The story mentioned that there are 7,500 mental health professionals that offer neurofeedback services. The story seemed to provide a nice history of neurofeedback devices from the 1960’s. The story does not appear to be based on a news release.\"",
        "true"
    ],
    [
        0.36386069158713025,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '320'}",
        "We believe that Julius is yellow. It is almost certain that Lily is a swan. It is unlikely that Winona is a sheep. It is probably not the case that if 'Winona is a sheep and Lily is a swan' then Emily is a wolf. It is certain that if either 'Winona is a sheep' or 'Lily is a swan' but not both then John grabbed the milk. It is certain that if 'Winona is a sheep and Lily is a swan' then Daniel left the football.",
        "invalid"
    ],
    [
        0.3638487209876378,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '112'}",
        "'Greg is a lion' or 'Brian is a swan' or both.",
        "invalid"
    ],
    [
        0.363829846183459,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '190'}",
        "It is probably not the case that 'Brian is a swan' or 'Julius is white' or both.",
        "invalid"
    ],
    [
        0.3638179451227188,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '778'}",
        "It is highly unlikely that 'Greg is a swan' or 'Lily is a frog' or both.",
        "invalid"
    ],
    [
        0.3637654185295105,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '17'}",
        "― одним словом, ― продолжал он, ― не успел большеусый выйти на берег, как к нему бросились поскребышев, кремлевский врач и начальник охраны, неся на руках полотенце, запасные кальсоны, запасные галифе, сапоги и всякую мелочь из одежды, которую не упомнишь",
        "correct"
    ],
    [
        0.36376364529132843,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '25'}",
        "elukkiger' gekozen jgfJan: de.-Heer Labberton, die zich óp Lenige ' 𝙄𝙣𝙙𝙤-heilisclic talen heeft toè'gé» ?legd, waarover .ik echter niet bevo",
        "𝙄𝙣𝙙𝙤"
    ],
    [
        0.36369384825229645,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '283'}",
        "“He’s not one of those owners who wants to be seen everywhere. He’s just one of the fans,” said Bryant. The NBA star gives his owner a hug before every game for luck “and maybe some of the success” of the slender Los Angles surgeon who built a fortune exceeding $7 billion as a biotechnology entrepreneur. For all Soon-Shiong’s success, the South African emigre and son of a Chinese herbal doctor remains relatively unknown in Los Angeles, a city that thrives on status and celebrity. That’s likely to change soon. In recent weeks, he emerged as a likely bidder for fellow billionaire Philip Anschutz’s sports and entertainment unit AEG, owner of 100 venues worldwide and sports teams like the Los Angeles Kings hockey franchise and the L.A. Galaxy soccer team, not to mention a 20 percent stake in the Lakers. And on Wednesday in Washington DC, Soon-Shiong and his L.A.-based NantHealth will unveil a joint venture with Verizon, Intel, Blue Shield of California and others to create a nationwide system for doctors to share DNA and other data on cancer patients. It will enable doctors to do genetic analysis of a patient’s tumor in less than a minute — a job that now can take from eight to 10 weeks. “This is something the federal government should have done, but we waited and waited for them,” Soon-Shiong told Reuters in an interview. “It’s unconscionable that cancer patients get the wrong diagnosis 30 percent of the time and that it takes so long to treat them with appropriate drugs for their cancer.”  Soon-Shiong emigrated to the United States more than three decades ago with his wife Michele Chan, an actress who had a starring role in 80’s show “Danger Bay” that aired on CBS and the Disney Channel and guest roles on “ MacGyver.” Since then, he has methodically climbed the ladder of success by adroitly mixing science and business. He created drugs to fight diabetes and breast cancer and then sold the companies that produced them for a combined $8.6 billion. In the four years since selling those companies, he quietly spent more than $400 million of his own money to build a national fiber optic network that would link cancer clinics throughout the country — the groundwork for the health superhighway. Soon-Shiong’s philanthropy was in evidence at his West Los Angeles office. The new superhighway was illustrated on a flow chart in a conference room where staffers edited a video of it on a nearby TV set. In the lobby was a model of the campus surrounding the Saint John’s Health Center, to which he has given $135 million to build a biotech research center and sports medicine clinic. “There are few Patrick Soon-Shiongs in this world,” said retired General Wesley Clark, who has served with him on non-profit boards. “A brilliant doctor, a great businessman and someone who is very patriotic. He understands what it means to give back to his country.”  Elsewhere, Los Angeles bears the mark of Soon-Shiong’s largesse and his fixation on healthcare. He and his wife operate the Chan Soon-Shiong Family Foundation, which last year endowed a chair at the University of Southern California Viterbi School of Engineering to support research in engineering and medicine. In 2009, after watching TV footage of a woman dying on the emergency room floor because doctors didn’t notice her, he guaranteed $100 million to underwrite efforts to reopen Martin Luther King Hospital. The hospital, which has since reopened, serves the city’s low-income population. The coming months may mark the public convergence of his private passions: health, sports, philanthropy and his adopted city. He wants to buy AEG in large part because he plans to build a $1.2 billion football stadium to return pro football to the nation’s second largest city. Owning a National Football League team, he said, would give him a platform to promote wellness by having players mentor younger fans on exercise and healthy eating, and sharing training and medical techniques with local doctors. Until recently, Soon-Shiong kept a low profile. He and his wife did not want their name in a press release when they first donated $23 million to Saint John’s in 2007 to build a biomedical facility, recalled medical center president Lou Lazatin. “Finally, they agreed when I told them it would help my marketing,” Lazatin said. Soon-Shiong’s business career started in the early 1980s with the help of the National Aeronautics and Space Administration, which gave him $2 million for stem cell research that could one day help treat injuries during space travel. At the time, he was a surgeon at a hospital affiliated with the University of California, Los Angeles. With the money, he opened a small lab near a veteran’s hospital, where he developed treatments to reduce diabetes in pancreatic transplant patients and a cancer-fighting drug that doubled the response rate for the treatment of breast cancer. His climb was not without bumps. In 1999, his brother Terrence filed a complex suit claiming Patrick Soon-Shiong neglected work on a diabetes drug being developed by a startup in which Terrence had invested. But an arbitrator found in Patrick Soon-Shiong’s favor, and he declined to answer questions about the matter. By 2008, Patrick Soon-Shiong controlled 82 percent of APP Pharmaceuticals, the company he started to develop injectable drugs to treat cancer and other illnesses. Soon-Shiong sold the company for $5.6 billion to Germany’s Fresenuis Kabi Pharmaceuticals, netting him $4.6 billion. In 2010, he sold Abraxis BioScience, which he had spun off from APP in 2007, to pharmaceutical company Celgene Corp. for $2.9 billion. His 82 percent stake was worth $2.4 billion. Soon-Shiong paid Celgene $135 million for NantWorks, where he had begun the work of creating his planned high-tech health delivery network. He contacted potential partners for the venture, including meeting AEG owner Anschutz, with whom he spent a day in the Denver suburb of Aurora touring the Anshutz Medical Campus. Soon-Shiong also bought or provided seed money to small technology companies to aid in that effort. He paid $20 million to buy a controlling interest in KeyOn Communications, which provides wireless broadband service for rural markets, and another $10 million to a stake in Raptor Networks Technology, which makes switching equipment for high speed networks. “He watches every detail. I get emails from him at 2:30 in the morning, said Stephen Berman, CEO of toy maker JAAKS Pacific, which is licensing technology from one of Soon-Shiong’s companies to make interactive toys. He gives more than just money, says songwriter Burt Bacharach, whose son went to private school with Soon-Shiong’s daughter. Soon-Shiong showed up unannounced at Cedars Sinai Hospital one day, says Bacharach, to help doctors find the right combination of drugs to treat the musician’s son, who had a persistent staph infection. For L.A.’s richest man, that patient visit was a brief return to the role of physician that he insists he one day will resume.",
        "true"
    ],
    [
        0.3636621783177058,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '259'}",
        "It is highly unlikely that Brian is a rhino. Chances are slight that Jessica is a sheep. It is probable that John went to the garden. There is a very good chance that if either 'Brian is a rhino' or 'John went to the garden' but not both then Greg is white. It is highly unlikely that if 'John went to the garden' or 'Brian is a rhino' or both then Lily is a swan. We believe that if 'John went to the garden and Brian is a rhino' then Julius is a frog.",
        "invalid"
    ],
    [
        0.3636484096447627,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '431'}",
        "It is improbable that 'Julius is a lion' or 'Brian is white' or both.",
        "invalid"
    ],
    [
        0.36362626900275546,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '371'}",
        "این چای بدون عطره و زودم دم میاد. بسته بندی و کیفیتشم خوبه. اگه چای بدون عطر می خواین اینو سفارش بدین ولی اگه می خواین عطر دار باشه مدل معطرشو بگیرین. در کل گلستان کیفیت بالایی داره.ممنون دیجی کالا",
        "طعم"
    ],
    [
        0.3635920931895574,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '330'}",
        "It is probably the case that John got the apple. There is a better than even chance that Daniel left the football. We doubt that Julius is a lion. It is almost certain that if either 'John got the apple' or 'Julius is a lion' but not both then Brian is gray. We believe that if 'John got the apple and Daniel left the football' then Lily is white. There is almost no chance that if 'Daniel left the football and Julius is a lion' then Bill went to the bedroom.",
        "invalid"
    ],
    [
        0.3635836988687515,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '150'}",
        "It is certain that Mary left the football. Chances are slight that Daniel grabbed the milk. It is highly unlikely that Julius is white. It is impossible that if 'Daniel grabbed the milk and Mary left the football' then Lily is a swan. It is impossible that if either 'Mary left the football' or 'Julius is white' but not both then Winona is a wolf. We doubt that if 'Julius is white' or 'Mary left the football' or both then John got the apple.",
        "invalid"
    ],
    [
        0.36356256157159805,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '430'}",
        "В том, что Борька получил-таки аттестат зрелости, была весомая заслуга Елки, которая уговорила папочку простить матершинников",
        "incorrect"
    ],
    [
        0.3635277599096298,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '85'}",
        "It is impossible that Greg is a rhino. We believe that Mary discarded the milk. It is almost certain that John went to the office. There is a better than even chance that if 'John went to the office' or 'Greg is a rhino' or both then Emily is a mouse. It is improbable that if 'Mary discarded the milk' or 'Greg is a rhino' or both then Winona is a sheep. There is a very good chance that if 'Mary discarded the milk' or 'Greg is a rhino' or both then Brian is a swan.",
        "invalid"
    ],
    [
        0.3635270694891612,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '960'}",
        "k waar het verband uit is. is geen volk meer.Met is ongctwujfcld 𝙝𝙞𝙨𝙩𝙤𝙧𝙞𝙨𝙘𝙝 juist, dat er verscheidene' volken zijn. waar het natuurlijk ver",
        "𝙝𝙞𝙨𝙩𝙤𝙧𝙞𝙨𝙘𝙝"
    ],
    [
        0.363500898083051,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '432'}",
        "It is probably not the case that either 'Daniel took the apple' or 'Lily is a swan' but not both.",
        "invalid"
    ],
    [
        0.363500898083051,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '877'}",
        "It is probably not the case that either 'Daniel took the apple' or 'Lily is a swan' but not both.",
        "invalid"
    ],
    [
        0.36347955962022144,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '923'}",
        "There is a better than even chance that Lily is a swan. It is highly likely that Mary took the football. There is almost no chance that Brian is green. Chances are about even that if either 'Mary took the football' or 'Lily is a swan' but not both then Winona is a wolf. It is highly likely that if either 'Lily is a swan' or 'Mary took the football' but not both then Jessica is a cat. It is highly likely that if either 'Lily is a swan' or 'Mary took the football' but not both then Julius is a frog.",
        "invalid"
    ],
    [
        0.36347537736097973,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '673'}",
        "Если верить трепушке школьнице, китель этот приобретён на толкучке и Синицын ходил в нём на танцы, что, конечно, сущая ерунда, война кончилась не так давно, многие фронтовики носят кителя за неимением гражданских костюмов",
        "correct"
    ],
    [
        0.3634437322616577,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '518'}",
        "Write an excellent summary of the given text.\n\nTitle: [28/F] Some sensible relationship and professional advice please? Re: older guy who's highly accomplished in my field.\n\nText: I'm a young lawyer. A couple of months ago, I and another female coworker were sent to an out-of-town assignment. We were joined in by a partner of an international firm; we'll call him \"John.\" John is single, maybe in his late 40s, and as mentioned, highly accomplished in his field. Notwithstanding, this guy is incredibly down-to-earth and we ended up getting along really well, as if we've been old friends. Thanks to my mousy female co-lawyer who'd rather stay in her hotel room after work, John and I were left alone in the evening to just hang out over drinks. Being incredibly intelligent and having lived all over the world, this guy blew my mind. He's so intellectually stimulating but at the same time, we laugh at the same stupid jokes, and I think these two things are what made me attracted to him. Nothing physical happened during the trip, though.\n\nFast forward to today, when we're both back to our respective cities, we're still exchanging e-mails: what's happening in our lives lately, photos, jokes, etc. I like him for sure, but I'm not entirely certain if he likes me back or if he's just being friendly.\n\nApart from the he-likes-me-he-likes-me-not guessing game, I'm also brooding about how John is in the position of giving me the opportunity of joining his firm. That'll be huge for me. The thing is, I'm not shabby looking. It's very easy for male clients and other people I work with to fall for me. On several occasions, I admittedly attempted to use my charms and be flirty to possibly gain career advantages, but all those attempts ended with me falling flat on my face. With John, I have no intentions of flirting with him just to land a job in his firm, both because (1) I know it won't work; and (2) I'm sincerely into this guy.\n\nIn conclusion, please, please, please lend me your insights on how I could get the man and get the job at the same time.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.36342738817135495,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '765'}",
        "Когда тарелки наполняются супом, она раздает им ломтики черного хлеба, по одному на ребенка… Запах свежего ржаного хлеба, втянутый зрячими ноздрями… Дети отщипывают кусочки. Другая работница, повариха, почти всегда молчит, когда она все же открывает рот, Сулико кажется, что за преградой гнилых зубов у нее ничего нет ― сплошная пустота",
        "correct"
    ],
    [
        0.36342738817135495,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '766'}",
        "Когда тарелки наполняются супом, она раздает им ломтики черного хлеба, по одному на ребенка… Запах свежего ржаного хлеба, втянутый зрячими ноздрями… Дети отщипывают кусочки. Другая работница, повариха, почти всегда молчит, когда она все же открывает рот, Сулико кажется, что за преградой гнилых зубов у нее ничего нет ― сплошная пустота",
        "correct"
    ],
    [
        0.36335571110248566,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '984'}",
        "It is probably not the case that either 'Greg is a lion' or 'Winona is a cat' but not both.",
        "invalid"
    ],
    [
        0.36334533989429474,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '662'}",
        "There is a better than even chance that Winona is a mouse. There is little chance that Brian is a swan. It is impossible that Lily is a frog.",
        "invalid"
    ],
    [
        0.3633277763923009,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '565'}",
        "It is unlikely that Greg is a lion. It is probably not the case that Brian is white. It is highly likely that Julius is a swan.",
        "invalid"
    ],
    [
        0.36330002049605054,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '843'}",
        "Chances are slight that Julius is a lion. It is likely that Jessica is a cat. It is probably the case that John dropped the apple. It is unlikely that if 'Julius is a lion and John dropped the apple' then Lily is a rhino. There is little chance that if 'Jessica is a cat' or 'Julius is a lion' or both then Fred is in the office. We doubt that if either 'Julius is a lion' or 'John dropped the apple' but not both then Brian is white.",
        "invalid"
    ],
    [
        0.363283375898997,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '619'}",
        "\"No discussion of costs — a big hole when we’re talking about treatments that are highly profitable for specialists and are often sought out for cosmetic reasons and not because of any health risk. The benefits discussed in this story were ALL anecdotal. In addition, the story reports on a newly approved pharmaceutical intervention without citing any success rates, absolute or relative. Not satisfactory. The story doesn’t get specific as to how often harms should be expected with the various treatments discussed, but it does mention some of the more common problems that can occur, including recurrence of the varicose vein or the creation of new varicose veins in the same area. Still, the story goes to significant lengths to make readers think this is a benign procedure (including a quote about one patient feeling a \"\"a little tiny pinch\"\"), when long-term consequences of superficial vein ablation on risks of deep vein issues such as clots are unknown. Overall, because the story didn’t give any sense of the scope of the problems – how often someone considering the various approaches may experience harms if they do – we must rule this unsatisfactory. The story doesn’t spend much time discussing the complexities of the medical evidence, but in its defense, it does make sure to provide specifics regarding which treatments are FDA-approved and which are being used off-label. This is in and of itself a key indicator of the strength of the data supporting different treatments. Still, the story goes a bit off course when it compares the effectiveness of different treatments without citing any data. It quotes an expert who says that newer, more expensive radio-frequency and laser treatments are \"\"a heck of a lot better than surgery” for treatment of underlying varicose veins. But we would expect such an assessment from someone who developed a laser treatment for varicose veins, as this expert apparently did. What would be more compelling is some reference to studies showing that these new treatments improve outcomes compared with conventional surgery–but no such information was provided. In fact, recent reviews suggest that while these newer treatments may work as well as surgery in the short term, current studies haven’t followed patients long enough to determine which is more effective over the long term. The story claims that doctors believe everyone with varicose veins should seek out medical care. Excerpt: Really? How many doctors? Who are these doctors? Are they doctors who stand to gain from treating this condition? This is a terribly misleading generalization. While it is true that a minority of patients are at risk of more serious medical problems related to their varicose veins, the vast majority of people have nothing to fear and don’t need to see a doctor. The article should have emphasized the benign nature of most varicose veins and identified the uncommon circumstances under which people should seek out medical attention for potential health risks. Although the story gets high marks for tapping a number of expert sources, it should have done more to identify potential conflicts of interest. One expert who supports laser surgery is appropriately identified as the developer of a laser technique, but Dr. Robert Weiss, another expert quoted in the story, is identified only as the director of the Maryland Laser, Skin and Vein Institute. If fails to mention that he is also a consultant to Medicis Pharmaceuticals, which manufactures Asclera, a drug recently approved by the FDA which is discussed in the story. To avoid the appearance of any bias, the story should have disclosed this relationship. It also should have tried to get a comment from someone who doesn’t benefit financially from these procedures. The story discusses surgery for varicose veins in the past tense, suggesting that it is no longer used. (\"\"It entailed ripping out the groin-to-ankle vein with a wire via an incision.\"\") In fact, as discussed above, the supposed long-term superiority of newer techniques over surgery has not yet been proven, and surgery still has a place in the treatment of certain types of varicose veins, especially larger veins. The story also failed to mention lifestyle changes, such as weight loss or avoiding standing or sitting for long periods, which are typically the first line treatment for this condition. As the story was in the fashion section, they should have also mentioned makeup, hosiery, etc, in addition to therapeutic interventions that a doctor might recommend. The story provides very specific information as to the availability of different treatments for varicose veins in the U.S. The story doesn’t suggest that any of these treatments are more novel than is actually the case. It’s clear that this story isn’t based on a news release.\"",
        "false"
    ],
    [
        0.36322908103466034,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '360'}",
        "It is probable that Bernhard is a swan. Chances are about even that Lily is a rhino. Chances are slight that Sandra left the apple. We believe that if either 'Lily is a rhino' or 'Sandra left the apple' but not both then John put down the milk. It is almost certain that if either 'Lily is a rhino' or 'Sandra left the apple' but not both then Julius is a lion. It is likely that if either 'Bernhard is a swan' or 'Lily is a rhino' but not both then Brian is yellow.",
        "invalid"
    ],
    [
        0.36319148043791455,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '673'}",
        "It is improbable that Julius is a swan. It is improbable that Bernhard is a frog. It is likely that Mary picked up the apple. Chances are about even that if either 'Julius is a swan' or 'Mary picked up the apple' but not both then Winona is a mouse. It is highly unlikely that if 'Mary picked up the apple' or 'Bernhard is a frog' or both then Greg is a swan. It is unlikely that if 'Julius is a swan' or 'Mary picked up the apple' or both then Brian is a lion.",
        "invalid"
    ],
    [
        0.3631744136412938,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '734'}",
        "It is unlikely that either 'Lily is a lion' or 'Daniel left the milk' but not both.",
        "invalid"
    ],
    [
        0.363167479634285,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '303'}",
        "Chances are about even that Greg is a lion. It is improbable that Julius is gray. It is almost certain that John moved to the garden. It is likely that if 'Greg is a lion and Julius is gray' then Yann is hungry. It is certain that if either 'John moved to the garden' or 'Julius is gray' but not both then Sandra got the milk. We doubt that if 'Julius is gray' or 'Greg is a lion' or both then Lily is a swan.",
        "invalid"
    ],
    [
        0.3631371135512988,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '296'}",
        "Конечно, в данной ситуации не идет речь о прокуратуре, которая время от времени привлекает к ответственности чиновников, как правило, низшего звена «за злоупотребление должностными полномочиями» в сфере ЖКХ",
        "incorrect"
    ],
    [
        0.36311860382556915,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '37'}",
        "В этом фрагменте есть вызов, есть доля риторики, которая несколько портит стихотворение, но все-таки в нем нет фальши, и первая строчка, предполагающая вылиться в ожидаемый в общем-то надрыв, в финале закономерно превращается в недоумение",
        "correct"
    ],
    [
        0.36311860382556915,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '474'}",
        "В этом фрагменте есть вызов, есть доля риторики, которая несколько портит стихотворение, но все-таки в нем нет фальши, и первая строчка, предполагающая вылиться в ожидаемый в общем-то надрыв, в финале закономерно превращается в недоумение",
        "correct"
    ],
    [
        0.36311008036136627,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '954'}",
        "It is highly unlikely that 'Lily is gray' or 'Brian is a rhino' or both.",
        "invalid"
    ],
    [
        0.3631080165505409,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '274'}",
        "Воздействие этого постоянно повторяющегося, а потому и наиболее эффективного напоминания самим себе: «Я буду низведен до такого же жалкого состояния, если совершу аналогичное преступление», гораздо сильнее, чем мысль о смерти, которую люди всегда представляют себе в туманной дали»",
        "incorrect"
    ],
    [
        0.36310294767220813,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '497'}",
        "It is almost certain that Greg is a rhino. It is likely that Brian is yellow. We believe that Julius is a frog. There is almost no chance that if 'Brian is yellow and Greg is a rhino' then John put down the milk. It is unlikely that if either 'Julius is a frog' or 'Brian is yellow' but not both then Mary went to the kitchen. It is probable that if either 'Julius is a frog' or 'Greg is a rhino' but not both then Daniel got the football.",
        "invalid"
    ],
    [
        0.36304791768391925,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '735'}",
        "عالی خیلی با کیفیت بحثی باقی نموند فقط شخصا دوست دارم مربا شیرینیش کم باشه",
        "طعم"
    ],
    [
        0.3630378743012746,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '512'}",
        "- В академической, - в который раз уточняла злая Анька, которой показалось, что ее теннисист смотрит на Маринку",
        "correct"
    ],
    [
        0.36296790341536206,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '358'}",
        "It is likely that Lily is a swan. It is likely that Fred went to the garden. It is impossible that Julius is a frog. We believe that if 'Julius is a frog' or 'Fred went to the garden' or both then Bernhard is a lion. It is improbable that if 'Julius is a frog and Lily is a swan' then John picked up the apple. Chances are slight that if either 'Fred went to the garden' or 'Lily is a swan' but not both then Mary put down the apple.",
        "invalid"
    ],
    [
        0.36293235917886096,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '973'}",
        "There is almost no chance that 'Brian is white' or 'Lily is yellow' or both.",
        "invalid"
    ],
    [
        0.362851157784462,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '124'}",
        "Сотрудник российской “тиссенкрупп материалс” (ткм) признает, что практически вся никелированная нержавейка из европы, которая продается в россии, стоит дешевле, чем продукция «мечела»",
        "incorrect"
    ],
    [
        0.3628430167833964,
        "{'dataset_id': 'cos_e', 'config_id': 'v1.0', 'row_id': '428'}",
        "The painter explained how he never achieved a flawless portrait, he said this was because all people are what?",
        "imperfect"
    ],
    [
        0.3628359039624532,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '783'}",
        "братья",
        "correct"
    ],
    [
        0.3628192295630773,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '826'}",
        "It is highly unlikely that 'Lily is a lion and Brian is a rhino'.",
        "invalid"
    ],
    [
        0.3628124346335729,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '306'}",
        "It is probable that John got the milk. Chances are slight that Brian is yellow. Chances are about even that Greg is white. There is a very good chance that if 'Greg is white' or 'Brian is yellow' or both then Mary dropped the milk. It is almost certain that if either 'Brian is yellow' or 'John got the milk' but not both then Winona is a wolf. It is probably not the case that if either 'John got the milk' or 'Greg is white' but not both then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.3627930358052254,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '785'}",
        "Это ссыльные возвращались с рудников… они все были похожи на моего отца,,",
        "correct"
    ],
    [
        0.3627861738204956,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '973'}",
        "This is not accurate. The grilfriend is the one who purchased a card for the author, not the other way around.",
        "Accuracy"
    ],
    [
        0.36273089051246643,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '640'}",
        "От иностранных коллег я знаю, что многие спортсмены заработали бронхиты, ангины, риниты, ― рассказывает Дмитриев",
        "correct"
    ],
    [
        0.36271226902802783,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '756'}",
        "طعم قهوه اصلا قابل مقایسه با قهوهای هم رده خارجی خود نیست.",
        "طعم"
    ],
    [
        0.36260491112867993,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '528'}",
        "It is unlikely that Bernhard is a frog. It is impossible that Brian is a swan. It is probably the case that John moved to the garden. It is probably the case that if either 'John moved to the garden' or 'Bernhard is a frog' but not both then Winona is a wolf. It is impossible that if 'John moved to the garden and Bernhard is a frog' then Lily is gray. It is highly likely that if 'John moved to the garden' or 'Bernhard is a frog' or both then Mary left the apple.",
        "invalid"
    ],
    [
        0.36254456142584485,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '151'}",
        "کسانی که مزه نعنا رو دوست دارن بخرن. کمی هم طعم لیمو میده و به ذائقه افراد بستگی داره. برای ما متوسط بود.",
        "نوشابه"
    ],
    [
        0.362541563808918,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '390'}",
        "Тогдашняя зеленка, видимо, была не чета нынешней, которая одна сплошная химия и больше ничего",
        "incorrect"
    ],
    [
        0.3623968760172526,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '236'}",
        "Если речь о мебели, которую дороже хранить, чем продавать, логично сразу перейти к публичному предложению",
        "correct"
    ],
    [
        0.36237098276615143,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '662'}",
        "Chances are about even that Greg is a frog. It is certain that Lily is a lion. It is probably not the case that Mary went to the office. It is highly unlikely that if either 'Lily is a lion' or 'Mary went to the office' but not both then Fred left the apple. We believe that if 'Mary went to the office and Greg is a frog' then Julius is white. It is improbable that if 'Greg is a frog and Mary went to the office' then Bernhard is a swan.",
        "invalid"
    ],
    [
        0.36237028737862903,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '308'}",
        "There is almost no chance that either 'Brian is white' or 'Daniel left the milk' but not both.",
        "invalid"
    ],
    [
        0.36235739290714264,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '969'}",
        "We doubt that Fred dropped the milk. It is almost certain that Julius is a lion. It is improbable that Lily is a frog. There is almost no chance that if either 'Julius is a lion' or 'Lily is a frog' but not both then Daniel got the football. It is highly unlikely that if 'Lily is a frog' or 'Fred dropped the milk' or both then Mary went to the hallway. It is almost certain that if 'Fred dropped the milk and Julius is a lion' then Bernhard is a rhino.",
        "invalid"
    ],
    [
        0.3623088151216507,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '120'}",
        "There is little chance that Greg is a rhino. It is almost certain that John went to the hallway. It is impossible that Mary got the apple. It is probably not the case that if 'Greg is a rhino' or 'Mary got the apple' or both then Lily is green. There is little chance that if either 'Mary got the apple' or 'Greg is a rhino' but not both then Sandra took the milk. It is impossible that if either 'Mary got the apple' or 'Greg is a rhino' but not both then Bernhard is a frog.",
        "invalid"
    ],
    [
        0.3622420976559321,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '489'}",
        "We doubt that Bernhard is a frog. It is certain that Greg is a swan. It is highly likely that Mary left the milk. It is highly unlikely that if 'Mary left the milk and Greg is a swan' then Brian is a rhino. There is almost no chance that if either 'Bernhard is a frog' or 'Mary left the milk' but not both then Lily is green. There is almost no chance that if either 'Greg is a swan' or 'Bernhard is a frog' but not both then John discarded the apple.",
        "invalid"
    ],
    [
        0.36223141352335614,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '662'}",
        "\"Если бы техники проверяли самолёты как следует, а лётчики не пускали к штурвалу детей…\"",
        "correct"
    ],
    [
        0.36213773985703784,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '496'}",
        "We believe that Bernhard is a swan. It is probably the case that Lily is a rhino. It is probably not the case that Jeff left the football. There is a better than even chance that if 'Lily is a rhino and Jeff left the football' then Brian is gray. It is almost certain that if either 'Lily is a rhino' or 'Jeff left the football' but not both then John took the football. It is probably not the case that if 'Jeff left the football' or 'Bernhard is a swan' or both then Sandra put down the milk.",
        "invalid"
    ],
    [
        0.36208444833755493,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '670'}",
        "\"Derartiges fehlt bei \\\\\"\"Ronin\\\\\"\" leider völlig; die Gespräche verlaufen dermaßen uninspiriert, dass man meinen könnte, die Drehbuchautoren (J. D. Zeik & D. Mamet) hätten aus einer Lostrommel blindlings typische Actionfilm-Phrasen gezogen und diese in mehr oder minder beliebiger Weise in eine einschlägige Standardvorlage eingeflochten.\"",
        "counterfactual"
    ],
    [
        0.36208444833755493,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '670'}",
        "\"Derartiges fehlt bei \\\\\"\"Ronin\\\\\"\" leider völlig; die Gespräche verlaufen dermaßen uninspiriert, dass man meinen könnte, die Drehbuchautoren (J. D. Zeik & D. Mamet) hätten aus einer Lostrommel blindlings typische Actionfilm-Phrasen gezogen und diese in mehr oder minder beliebiger Weise in eine einschlägige Standardvorlage eingeflochten.\"",
        "counterfactual"
    ],
    [
        0.3620682309071223,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '92'}",
        "It is highly likely that Brian is white. It is probably not the case that Greg is a rhino. It is unlikely that Mary left the milk. We doubt that if 'Mary left the milk and Greg is a rhino' then Gertrude is a sheep. There is a better than even chance that if 'Brian is white' or 'Mary left the milk' or both then Bill went to the office. It is highly unlikely that if 'Brian is white' or 'Greg is a rhino' or both then John picked up the milk.",
        "invalid"
    ],
    [
        0.3620038777589798,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '38'}",
        "Как бы то ни было, новая борьба с соседом опять закончилась изгнанием ставки ростислава из рязани, которую долгорукий теперь отдал своему знаменитому сыну андрею",
        "correct"
    ],
    [
        0.36198635399341583,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '996'}",
        "It is probable that Lily is a frog. There is a very good chance that Bernhard is a frog. It is probably not the case that Brian is a swan.",
        "invalid"
    ],
    [
        0.3619716316461563,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '288'}",
        "It is unlikely that Fred left the football. We believe that Lily is a swan. It is improbable that Bernhard is a rhino. It is unlikely that if 'Fred left the football' or 'Bernhard is a rhino' or both then Mary is in the school. There is a better than even chance that if either 'Bernhard is a rhino' or 'Lily is a swan' but not both then Jessica is a mouse. It is impossible that if 'Lily is a swan' or 'Fred left the football' or both then Julius is gray.",
        "invalid"
    ],
    [
        0.36196304857730865,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '279'}",
        "Write an excellent summary of the given text.\n\nTitle: I [23F] am not comfortable with my friend [23F] having my brother be a part of her wedding while I am also supposed to be part of her wedding.\n\nText: Okay, so I [23F] have known 'B' [23F] since I was about six. We were best friends for several years - our lives have taken us down different paths, but we are still pretty close. She met a guy over the internet about four years ago, who recently moved from New Zealand to B.C to be with her and they are getting married. I'm going to be a bridesmaid in her wedding.. Or so I thought until just now. Since her fiancé moved out here, he has become friends with my older brother. I did not know this, and just now found out that my brother is going to be a groomsmen in their wedding. I understand this is not my wedding, this is not my day. But, I cannot be a part of this. \n\nI hate my older brother. I do not have a single ounce of love or respect for him. I would be perfectly happy never seeing him or acknowledging his existence for the rest of my life. Our mother abused me, and he joined her in doing so. He did not protect me when his friend molested me when I was sixteen. I could give many reasons as to why I loathe this vermin of a person, but it does not matter. The bottom line is that I made a decision to never have this person in my life in any way at all ever again. \n\nI want to go to the wedding and be there for my friend, to be there to share this special day in her life.  But, I can't see him. I have no idea what to say or do at this point.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.36195052166779834,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '442'}",
        "Если рок-радиостанции до сих пор не нашли на альбоме «Игла» песни, которую можно смело ставить в эфир, значит, они опасаются, что людям не понравятся дурацкие тексты про какую-то челку и дискотеку, дикция вокалиста или простые аккорды",
        "correct"
    ],
    [
        0.36195052166779834,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '443'}",
        "Если рок-радиостанции до сих пор не нашли на альбоме «Игла» песни, которую можно смело ставить в эфир, значит, они опасаются, что людям не понравятся дурацкие тексты про какую-то челку и дискотеку, дикция вокалиста или простые аккорды",
        "correct"
    ],
    [
        0.36192865669727325,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '502'}",
        "It is almost certain that Jessica is a cat. It is improbable that Greg is a lion. There is a better than even chance that John went to the hallway. It is impossible that if 'John went to the hallway and Greg is a lion' then Bernhard is a swan. There is almost no chance that if 'John went to the hallway' or 'Greg is a lion' or both then Emily is a sheep. It is impossible that if 'Jessica is a cat and Greg is a lion' then Brian is a rhino.",
        "invalid"
    ],
    [
        0.3619285176197688,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '473'}",
        "В этом фрагменте есть вызов, есть доля риторики, которая несколько портит стихотворение, но все-таки в нем нет фальши, и первая строчка, предполагающая вылиться в ожидаемый в общем-то надрыв, в финале закономерно превращается в недоумение",
        "incorrect"
    ],
    [
        0.3618893474340439,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '457'}",
        "There is a very good chance that either 'Brian is a frog' or 'Julius is a swan' but not both.",
        "invalid"
    ],
    [
        0.36172853658596676,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '246'}",
        "Это история о дружбе, которая пробивается сквозь стену подозрений, испытаний и даже предательств",
        "correct"
    ],
    [
        0.36172567307949066,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '467'}",
        "It is likely that Greg is a lion. It is probable that Yann is thirsty. There is little chance that Daniel left the apple. We believe that if 'Daniel left the apple' or 'Yann is thirsty' or both then Julius is a rhino. It is almost certain that if either 'Greg is a lion' or 'Yann is thirsty' but not both then Lily is green. It is certain that if either 'Greg is a lion' or 'Daniel left the apple' but not both then Mary got the football.",
        "invalid"
    ],
    [
        0.3617158830165863,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '818'}",
        "['We examined the contributions of genetic factors and the family environment to human fatness in a sample of 540 adult Danish adoptees who were selected from a population of 3580 and divided into four weight classes: thin, median weight, overweight, and obese.', 'There was a strong relation between the weight class of the adoptees and the body-mass index of their biologic parents - for the mothers, P less than 0.0001; for the fathers, P less than 0.02.', 'There was no relation between the weight class of the adoptees and the body-mass index of their adoptive parents.', 'Cumulative distributions of the body-mass index of parents showed similar results; there was a strong relation between the body-mass index of biologic parents and adoptee weight class and no relation between the index of adoptive parents and adoptee weight class.', 'Furthermore, the relation between biologic parents and adoptees was not confined to the obesity weight class, but was present across the whole range of body fatness - from very thin to very fat.', 'We conclude that genetic influences have an important role in determining human fatness in adults, whereas the family environment alone has no apparent effect.']",
        "False"
    ],
    [
        0.3616405477126439,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '262'}",
        "It is highly unlikely that either 'Lily is a swan' or 'Daniel put down the milk' but not both.",
        "invalid"
    ],
    [
        0.36163436869780224,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '930'}",
        "It is certain that John went to the garden. It is almost certain that Lily is gray. It is impossible that Mary took the milk. Chances are about even that if either 'John went to the garden' or 'Mary took the milk' but not both then Julius is a lion. We believe that if 'Lily is gray' or 'Mary took the milk' or both then Brian is a rhino. It is highly unlikely that if either 'John went to the garden' or 'Mary took the milk' but not both then Fred left the apple.",
        "invalid"
    ],
    [
        0.3616323744257291,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '25'}",
        "«вы увидите», ― отвечал державин и, приехав домой, написал оду «на возвращение армии графа зубова из персии», которую не мог, разумеется, напечатать, но в списках пустил по городу",
        "correct"
    ],
    [
        0.36161354680856067,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '200'}",
        "В основе представления о нем лежат реальные сведения о Цейлоне, однако, у ал-Хоризми он появился под влиянием арабской версии повести об Александре, которая именно в эту эпоху, как установил Мжик, сделалась особенно популярной среди арабов",
        "correct"
    ],
    [
        0.3616023013989131,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '214'}",
        "В «Известиях» статья о Раде, которая обвиняется в союзе с французским правительством",
        "correct"
    ],
    [
        0.36157991240421933,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '407'}",
        "Накануне ночью его опять перевозили (он, пребывавший в кротовьей тьме, не понимал уже времени суток, просто когда его в наручниках, с завязанными глазами, выволакивали и заталкивали в машину, кожей лица чувствовал ночную свежесть, сухой смолистый запах ливанского кедра, звездную благодать природы, которую человек, это гнусное животное, нимало не ценит)",
        "incorrect"
    ],
    [
        0.3615430146455765,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '1'}",
        "Chances are slight that Lily is a frog. We doubt that Brian is yellow. It is probably not the case that Mary went to the garden. We believe that if 'Lily is a frog and Brian is yellow' then Julius is gray. It is certain that if 'Brian is yellow and Mary went to the garden' then Daniel took the milk. There is a better than even chance that if 'Lily is a frog' or 'Brian is yellow' or both then Sandra left the milk.",
        "invalid"
    ],
    [
        0.3615408043066661,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '639'}",
        "От иностранных коллег я знаю, что многие спортсмены заработали бронхиты, ангины, риниты, ― рассказывает Дмитриев",
        "incorrect"
    ],
    [
        0.36150049169858295,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '730'}",
        "\"Maybe the disconnect between journalist and reader is best (worst) seen in this line from the story:  \"\"The group of statins that showed the greatest effect in reducing risk are classified as lipophilic.\"\" All statins are lipophilic. And the story gave readers no definition, no explanation of what lipophilic even means. So it’s like a high school term paper where the student slips in big words to impress the teacher. Readers should not be impressed. Over and over again we see the same flaws in health care journalism stories. These are not just academic issues. These flaws expose stories that simply fail to communicate vital information to readers.\"",
        "false"
    ],
    [
        0.361494575937589,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '833'}",
        "'Lily is white' or 'Brian is a rhino' or both.",
        "invalid"
    ],
    [
        0.3614754229784012,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '540'}",
        "There is almost no chance that Lily is a rhino. There is little chance that Bernhard is a lion. It is probable that Mary went to the bedroom. It is probably the case that if either 'Bernhard is a lion' or 'Mary went to the bedroom' but not both then Julius is yellow. It is almost certain that if 'Lily is a rhino and Bernhard is a lion' then Fred is in the cinema. It is probably the case that if 'Lily is a rhino' or 'Bernhard is a lion' or both then Bill left the milk.",
        "invalid"
    ],
    [
        0.36146772652864456,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '671'}",
        "Незадолго до того он исполнил главную роль в фильме \"\"Тяжёлые перчатки\"\" ― и вполне мог числить себя по артистическому цеху\t  Наши матчи собирали аншлаги\t  И знаменитого боксёра приветствовали особенно рьяно ― кричали: \"\"Нокаут",
        "correct"
    ],
    [
        0.3614018112421036,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '867'}",
        "There is a better than even chance that Greg is a rhino. It is unlikely that John dropped the milk. It is probably not the case that Daniel got the apple. There is a very good chance that if either 'John dropped the milk' or 'Greg is a rhino' but not both then Fred is in the office. There is a better than even chance that if 'John dropped the milk' or 'Daniel got the apple' or both then Lily is a lion. It is almost certain that if 'Daniel got the apple and Greg is a rhino' then Brian is white.",
        "invalid"
    ],
    [
        0.3614003558953603,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '90'}",
        "The summary says that the person registered an email we a different first and last name which is incorrect. The only difference between the emails is that the other person used their middle initial.",
        "Accuracy"
    ],
    [
        0.36136890947818756,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '402'}",
        "There is a very good chance that Daniel left the milk. It is impossible that Julius is yellow. We doubt that John got the apple. It is highly likely that if 'Julius is yellow and Daniel left the milk' then Greg is a lion. It is unlikely that if either 'John got the apple' or 'Daniel left the milk' but not both then Brian is green. It is highly unlikely that if either 'Julius is yellow' or 'Daniel left the milk' but not both then Winona is a mouse.",
        "invalid"
    ],
    [
        0.361353541413943,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '586'}",
        "It is probably not the case that either 'Brian is a rhino' or 'Lily is yellow' but not both.",
        "invalid"
    ],
    [
        0.3613458126783371,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '644'}",
        "سلام دوستان بدرد نمیخوره نه طعم داره نه رنگ من پیشنهاد نمیکنم.",
        "طعم"
    ],
    [
        0.3613039130965869,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '25'}",
        "incorrect",
        "правда"
    ],
    [
        0.3613039130965869,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '312'}",
        "incorrect",
        "правда"
    ],
    [
        0.36130115886529285,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '987'}",
        "It is highly unlikely that 'Lily is a swan' or 'Bernhard is a lion' or both.",
        "invalid"
    ],
    [
        0.3612930128971736,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '752'}",
        "There is little chance that Mary went to the kitchen. We believe that Winona is a sheep. It is unlikely that Lily is a swan. It is almost certain that if 'Winona is a sheep' or 'Mary went to the kitchen' or both then Brian is a swan. Chances are slight that if 'Winona is a sheep' or 'Lily is a swan' or both then John moved to the garden. There is little chance that if 'Mary went to the kitchen' or 'Lily is a swan' or both then Julius is gray.",
        "invalid"
    ],
    [
        0.36123213668664295,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '561'}",
        "\"No one disputes that Kenyon was on duty for 96 straight hours, Kenyon had some opportunity for sleep and it’s likely he did. But he doesn’t remember when that was, or for how long. He only recalls sleeping during the last 7 of the 96 hours The question that Doughty Tweeted: \"\"@Jorge_Elorza still think your plan is safe?\"\" was fair to ask, even if the public was not at risk as both Pare and the captain assert. (Further, Pare disputes Doughty’s charge that the plan is a \"\"disaster!!!\"\") But without clarification, Doughty’s suggestion that Kenyon \"\"worked 96 hours straight\"\" could leave the impression that Kenyon never slept. He did sleep. To be more accurate, Doughty could have said that Kenyon had been \"\"on duty\"\" for 96 hours. The job, by its nature,  involves a mixture of sleep and work.\"",
        "true"
    ],
    [
        0.36123118301232654,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '424'}",
        "It is probably not the case that 'Lily is a swan' or 'Bernhard is a rhino' or both.",
        "invalid"
    ],
    [
        0.36121632158756256,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '730'}",
        "Chances are about even that Bernhard is a lion. Chances are slight that Brian is gray. We doubt that Jessica is a cat. It is highly unlikely that if 'Bernhard is a lion and Brian is gray' then Lily is a swan. We doubt that if 'Bernhard is a lion' or 'Jessica is a cat' or both then Greg is white. It is certain that if 'Jessica is a cat' or 'Bernhard is a lion' or both then Daniel left the milk.",
        "invalid"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '0'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '2'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '5'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '16'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '17'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '18'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '20'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '28'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '29'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '30'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '32'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '40'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '41'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '51'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '1'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '2'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '6'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '8'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '10'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '13'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '15'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '19'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '20'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '21'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '27'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '29'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '30'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '31'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '33'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '34'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '39'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '42'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '48'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '52'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '58'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '59'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '64'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '65'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '66'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '71'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '73'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '74'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '76'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '82'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '86'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '89'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '90'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '94'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '95'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '102'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '105'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '107'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '108'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '110'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '113'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '117'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '119'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '120'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '127'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '129'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '130'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '132'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '135'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '138'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '143'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '148'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '155'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '156'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '157'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '159'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '161'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '164'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '167'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '169'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '170'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '171'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '173'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '174'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '175'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '178'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '181'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '182'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '183'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '184'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '185'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '187'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '190'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '192'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '196'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '198'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '199'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '202'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '203'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '204'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '206'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '210'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '212'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '215'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '222'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '228'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '230'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '232'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '233'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '243'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '247'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '248'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '250'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '253'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '255'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '258'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '259'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '260'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '262'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '265'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '268'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '269'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '279'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '281'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '282'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '287'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '289'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '290'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '292'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '293'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '294'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '299'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '301'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '303'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '308'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '313'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '315'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '317'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '320'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '326'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '327'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '333'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '339'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '341'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '343'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '346'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '356'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '357'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '359'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '362'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '363'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '365'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '366'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '368'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '371'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '374'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '380'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '381'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '382'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '383'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '385'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '391'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '394'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '396'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '398'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '399'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '401'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '403'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '412'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '414'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '416'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '420'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '421'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '422'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '424'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '433'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '434'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '437'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '440'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '441'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '448'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '449'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '450'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '451'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '453'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '454'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '468'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '470'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '472'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '477'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '478'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '479'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '484'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '486'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '487'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '489'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '490'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '491'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '498'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '500'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '502'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '503'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '507'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '510'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '515'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '516'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '521'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '527'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '529'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '530'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '531'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '533'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '635'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '643'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '644'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '647'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '651'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '652'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '653'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '656'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '660'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '663'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '668'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '675'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '679'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '684'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '687'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '690'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '694'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '702'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '703'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '706'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '710'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '714'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '717'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '721'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '724'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '727'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '728'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '730'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '733'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '735'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '737'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '739'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '745'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '746'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '748'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '753'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '755'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36116555084784824,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '757'}",
        "incorrect",
        "incorrect"
    ],
    [
        0.36114682257175446,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '235'}",
        "It is improbable that Brian is a lion. Chances are about even that Bernhard is a frog. Chances are about even that Mary went to the office. We doubt that if 'Mary went to the office' or 'Brian is a lion' or both then John discarded the apple. There is a very good chance that if either 'Brian is a lion' or 'Mary went to the office' but not both then Sandra took the football. Chances are about even that if 'Brian is a lion' or 'Bernhard is a frog' or both then Greg is a rhino.",
        "invalid"
    ],
    [
        0.361128365000089,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '855'}",
        "We believe that Brian is yellow. There is almost no chance that Mary discarded the milk. It is almost certain that Lily is a lion. It is improbable that if 'Mary discarded the milk and Lily is a lion' then John went to the hallway. It is probable that if either 'Lily is a lion' or 'Mary discarded the milk' but not both then Bernhard is white. It is highly unlikely that if 'Brian is yellow and Mary discarded the milk' then Jeff dropped the apple.",
        "invalid"
    ],
    [
        0.36108162502447766,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '243'}",
        "It is improbable that 'Lily is a frog' or 'Julius is a rhino' or both.",
        "invalid"
    ],
    [
        0.3610753466685613,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '29'}",
        "It is highly unlikely that 'Brian is a lion' or 'John took the football' or both.",
        "invalid"
    ],
    [
        0.3610306829214096,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '21'}",
        "نظر شما در مورد عطر، بو، و طعم این شیر چیست؟",
        "طعم"
    ],
    [
        0.3610306829214096,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '231'}",
        "نظر شما در مورد عطر، بو، و طعم این شیر چیست؟",
        "طعم"
    ],
    [
        0.3610306829214096,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '308'}",
        "نظر شما در مورد عطر، بو، و طعم این شیر چیست؟",
        "طعم"
    ],
    [
        0.3610306829214096,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '707'}",
        "نظر شما در مورد عطر، بو، و طعم این شیر چیست؟",
        "طعم"
    ],
    [
        0.36095504959424335,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '520'}",
        "Ей-Богу, не помню, какие мои слова и о чем вызвали эту суровую отповедь в письме далекого 1962 года, но - не важно: важна сила убежденности, которой и на тот раз томил меня мой товарищ",
        "correct"
    ],
    [
        0.36090777814388275,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '276'}",
        "Главная политическая сенсация, о неотвратимости которой все время говорили знатоки-эксперты, так и не состоялась",
        "correct"
    ],
    [
        0.3608984400828679,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '708'}",
        "There is little chance that Gertrude is a mouse. We believe that Brian is a frog. Chances are about even that Julius is a lion. It is highly likely that if either 'Gertrude is a mouse' or 'Julius is a lion' but not both then Mary left the football. It is certain that if 'Gertrude is a mouse and Brian is a frog' then John went to the kitchen. It is likely that if either 'Julius is a lion' or 'Brian is a frog' but not both then Lily is yellow.",
        "invalid"
    ],
    [
        0.36084417005379993,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '830'}",
        "It is probably not the case that either 'Brian is white' or 'Lily is green' but not both.",
        "invalid"
    ],
    [
        0.36084214349587757,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '587'}",
        "It is unlikely that Bernhard is gray. We doubt that Greg is a frog. It is probable that Daniel grabbed the milk. It is probable that if either 'Greg is a frog' or 'Bernhard is gray' but not both then Brian is a swan. Chances are slight that if either 'Greg is a frog' or 'Daniel grabbed the milk' but not both then John discarded the apple. It is almost certain that if 'Greg is a frog' or 'Bernhard is gray' or both then Mary dropped the milk.",
        "invalid"
    ],
    [
        0.36082786818345386,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '371'}",
        "It is highly unlikely that Greg is yellow. It is probably the case that Brian is white. We doubt that Bernhard is a swan. It is probably not the case that if 'Greg is yellow' or 'Brian is white' or both then Mary grabbed the milk. Chances are slight that if 'Brian is white' or 'Greg is yellow' or both then Julius is a frog. We doubt that if either 'Bernhard is a swan' or 'Brian is white' but not both then John went to the kitchen.",
        "invalid"
    ],
    [
        0.3607873469591141,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '233'}",
        "It is highly likely that Brian is a rhino. It is probably the case that Greg is white. Chances are about even that John went to the hallway. It is probable that if 'Brian is a rhino and Greg is white' then Julius is yellow. It is unlikely that if either 'John went to the hallway' or 'Greg is white' but not both then Lily is a swan. It is highly likely that if either 'Greg is white' or 'John went to the hallway' but not both then Emily is a mouse.",
        "invalid"
    ],
    [
        0.3606523722410202,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '687'}",
        "It is highly likely that Gertrude is a cat. It is improbable that Bernhard is a swan. There is almost no chance that Brian is a lion. Chances are slight that if either 'Bernhard is a swan' or 'Gertrude is a cat' but not both then Winona is a sheep. Chances are slight that if 'Brian is a lion and Bernhard is a swan' then Greg is white. It is probably the case that if either 'Brian is a lion' or 'Gertrude is a cat' but not both then Mary moved to the garden.",
        "invalid"
    ],
    [
        0.36065148810545605,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '797'}",
        "«Я растратила все свои духи на разных людишек — чтобы они хорошо пахли",
        "correct"
    ],
    [
        0.36064037680625916,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '249'}",
        "\"The company behind the product undoubtedly has done market research about how much of this product it might sell and at what price. At a minimum, that information should have been included here. It presents the benefits in both relative and absolute terms in the second paragraph of the story. It would be nice to have a NNT or number needed to treat in here. It also would be nice to see the range of performance after using the drug. Did some of the men on placebo have gains in ejaculation time that were unusually high? Did some on the drug have no gain or even a loss of time? It’s also not clear how the researchers knew what the \"\"no drug\"\" ejaculation time was, how they were chosen for the research or whether they fell into a particular age bracket. The story did a \"\"satisfactory\"\" job quantifying the benefits, not a perfect job. And in an imperfect world of health stories, this part of the story was actually above average. It talks about the potential side effects, but it limits that discussion to what the study found in a very small group of men. Are there long term effects from lidocaine exposure that have been found in other studies? Does the body build up resistance to lidocaine? This isn’t a short term problem that can be solved with a few weeks of therapy. It is usually a life long problem, and the story should be framed that way both in discussing the benefits and the harms. By using an outside expert to say in the third graph that the findings are \"\"clinically significant,\"\" the story makes it sound as if the case for this drug has already been made. Perhaps Tom Lue gave some context around this comment, but that context is not included. Instead, we are told that patients will be \"\"much happier.\"\" If you have this problem, you are looking up the company’s website to get on their mailing list. But both groups experienced a gain in ejaculation time. Why would that be? And, given that these sexual encounters were self timed, how confident can we be in the results? Another thing that the story never addresses is the idea of optimal time for sex. It also treats this particular sexual dysfunction as a purely single male problem instead of a larger issue of an unsatisfying sexual relationship between a man and his partner. The drug was tested with two people having sex, but the person who did not receive the spray is never taken into account. The men \"\"rated their sexual experiences significantly higher\"\" than those who got placebos. The only reference to the partners is literally the second to the last sentence, \"\"Also, 0.6% of the men’s female partners reported at least some loss of sensation.\"\" We don’t hear anything about the limitations of the study design. It appears to be a quasi-synthesis of 2 clinical trials. There isn’t any caution about the limited or nonexistent peer-review which takes place for an \"\"abstract\"\" at a meeting. Regarding study design, all we know is that researchers took 2 previous trials already made public (would have been helpful to include what the primary findings were) and \"\"combined them with added new data.\"\" This study design is highly suspect. We do not know anything about whether the 2 trials were similar enough to combine, and in what manner they were combined. The section describing premature ejaculation does a better than average job attempting to define the scope of the problem while describing the limitations of the research that has been done in this area. One line could be a model for other journalists to learn from: \"\"Surveys have suggested that as many as 20% to 30% of men may suffer from premature ejaculation, though these figures are often drawn from broadly worded survey questions and may overstate the number of men with significant problems.\"\" The reporter clearly read a lot about the problem and the potential treatments and does a fairly good job synthesizing this information. The story makes it clear that the two outside sources were not involved in this research. It is unclear whether these doctors are involved in any competing research or research into a similar product. There are three full graphs in a 12 graph story about the standard treatments and off-label treatments. I felt like I knew more about the state of premature ejaculation medicine after reading this story than I did about the actual success of these two trials. The story makes it clear, even in the headline, that these are the results of a trial and that there currently is no product even in the FDA pipeline. It also talks about a drug therapy from Johnson & Johnson and where it is being sold. It says at one point in the story that the \"\"findings of both trials had previously been made public.\"\" It would have been nice to know where, how and why. Presumably at previous conferences, and, if so, why is this treatment not already in the FDA pipeline. Reporters should always be wary of scientists, especially corporate ones, who are using the trade show circuit to build momentum for their product instead of following a rigorous peer review process. This story really is all about the novelty, and it does a good job of exploring some of the other treatments available. Clearly, there is no published study. The company involved in the drug did issue this press release (http://www.renalandurologynews.com/novel-treatment-for-premature-ejaculation-shows-promising-results/article/171435/)There are some differences between the numbers used in the story and the numbers in the press release, but it’s not clear how much of this is because of different caveats. (The number of men who actually completed the study, for example, versus all of those who were involved.) The story goes well beyond the release and was finished before the press conference at the AUA meeting.\"",
        "true"
    ],
    [
        0.3605390936136246,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '573'}",
        "There is a very good chance that Brian is yellow. It is probably not the case that Daniel took the apple. It is unlikely that Greg is a frog. It is highly unlikely that if 'Daniel took the apple' or 'Greg is a frog' or both then Bernhard is a swan. It is certain that if 'Greg is a frog' or 'Daniel took the apple' or both then John went to the kitchen. It is improbable that if 'Brian is yellow and Greg is a frog' then Mary picked up the milk.",
        "invalid"
    ],
    [
        0.3605315138896306,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '197'}",
        "It is probably the case that Julius is gray. There is a better than even chance that Bernhard is a frog. Chances are slight that Mary got the apple. Chances are about even that if either 'Julius is gray' or 'Mary got the apple' but not both then Lily is a lion. It is almost certain that if either 'Mary got the apple' or 'Julius is gray' but not both then Gertrude is a cat. It is probable that if either 'Bernhard is a frog' or 'Julius is gray' but not both then Greg is yellow.",
        "invalid"
    ],
    [
        0.36052468915780383,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '547'}",
        "Комплекс",
        "correct"
    ],
    [
        0.3605043739080429,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '738'}",
        "There is almost no chance that 'Bernhard is a swan' or 'Lily is a lion' or both.",
        "invalid"
    ],
    [
        0.36049842337767285,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '147'}",
        "خوب نیست و شیرینی غالبی داره و طعمشم دلچسب نیست و زننده اس",
        "طعم"
    ],
    [
        0.36044541498025257,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '34'}",
        "Author is in a relationship with a beautiful older lady who's great and he sees a future with her but is having doubts because of different ethnic backgrounds",
        "Accuracy"
    ],
    [
        0.3604312688112259,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '139'}",
        "Журнал «Углече поле» выказывает поразительную жизнестойкость, о причине которой я скажу ниже",
        "correct"
    ],
    [
        0.3603766510883967,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '524'}",
        "It is impossible that 'Brian is a frog' or 'Mary got the football' or both.",
        "invalid"
    ],
    [
        0.3603712022304535,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '381'}",
        "\"Dino Baccari said that a Penn State University study found that \"\"electronic cigarettes … are far less addictive than cigarettes.\"\" He's not blowin' smoke. His characterization of the study's conclusion is accurate. But it's important to note that the conclusion is based on an open-to-anyone survey that relied on the recall of e-cigarette users who may have a natural bias toward reporting that the products they've chosen to use are less addicting than the cigarettes they're trying to avoid. Comparable studies support that conclusion. With the limitations in the methodology, we would characterize the statement as accurate, but in need of clarification or additional information. (If you have a claim you’d like PolitiFact Rhode Island to check, email us at [email protected] And follow us on Twitter: @politifactri.)\"",
        "true"
    ],
    [
        0.3603404114643733,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '436'}",
        "There is almost no chance that Emily is a sheep. It is impossible that Lily is yellow. There is little chance that Greg is a rhino. It is probable that if 'Lily is yellow' or 'Emily is a sheep' or both then Daniel dropped the apple. It is highly unlikely that if 'Emily is a sheep' or 'Lily is yellow' or both then Bill went to the garden. It is certain that if 'Lily is yellow and Greg is a rhino' then Bernhard is gray.",
        "invalid"
    ],
    [
        0.3603389213482539,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '245'}",
        "It is highly unlikely that 'Greg is white' or 'Brian is a rhino' or both.",
        "invalid"
    ],
    [
        0.3603379800915718,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '793'}",
        "Но Алекс ответил, что овцы не носят ИД, поэтому их можно",
        "correct"
    ],
    [
        0.3602803299824397,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '646'}",
        "До 1991 года, когда был принят Закон \"\"Об основах налоговой системы РФ\"\", налогового законодательства, по сути, не существовало: сколько и какие налоги платили граждане, для них самих оставалось загадкой",
        "correct"
    ],
    [
        0.3602687368790309,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '413'}",
        "It is certain that Emily is a mouse. It is probably the case that Brian is a rhino. It is impossible that Bernhard is a swan. It is highly likely that if 'Emily is a mouse' or 'Brian is a rhino' or both then Winona is a wolf. It is probable that if 'Emily is a mouse' or 'Brian is a rhino' or both then Mary went to the bedroom. It is probably the case that if 'Bernhard is a swan' or 'Emily is a mouse' or both then Jessica is a sheep.",
        "invalid"
    ],
    [
        0.36022693663835526,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '420'}",
        "مهم ترین علت تمیزی سینک و راحتی چای دم کردن مخصوصا برای مهمانی هاست",
        "طعم"
    ],
    [
        0.3601958304643631,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '925'}",
        "Write an excellent summary of the given text.\n\nTitle: Me [24 F] having trouble with my boyfriends father [50+ M]\n\nText: Hello, \n\nlong story short: my boyfriend and I have been dating for around three years and living together for one year. We're both 24 and are very happy in general. \n\nHis parents are divorced and I really love his mom and siblings. His father and I used to get along fairly well but I feel things are heading south. \n\nIf you look under \"foot in the mouth\" in a dictionary you will see a picture of him. He's is incredibly clumbsy with words and I know that. However, lately it's been getting worse, presumably because we have been spending lots of time together (lots of birthdays and special occasions). \n\nIt often starts with him trying to be funny. We can hanging out after dinner and he will say something \"Holy moly, you eat like >boyfriend<, no wonder you're built so sturdy\". \n\nAfter a while, he might bring up my boyfriends ex and talk about her for a while. Nice memories. Lovely memories. \"You wouldn't know though, cuz you were not there, you know.  \n\nAnd on it goes. Last night I kind of had enough when he started making bad jokes about girls my boyfriend was seeing before me. It's just degrading to all of us. I made my point by changing the topic rather loudly. He went dead silent for the rest of the night. \n\nAm I overreacting? I don't want this to affect my relationship with my boyfriend but I've had enough of his dads shit.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.360188956061999,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '455'}",
        "причины",
        "correct"
    ],
    [
        0.3601853201786677,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '100'}",
        "It is improbable that John discarded the apple. It is impossible that Julius is a swan. It is almost certain that Greg is yellow. It is highly unlikely that if either 'Greg is yellow' or 'Julius is a swan' but not both then Emily is a wolf. It is highly unlikely that if 'Greg is yellow and Julius is a swan' then Bernhard is a frog. There is a better than even chance that if 'Julius is a swan and Greg is yellow' then Lily is a lion.",
        "invalid"
    ],
    [
        0.36015624552965164,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '19'}",
        "История о женщине, которая убила своих детей, или история человека в одной сандалии», — говорится в аннотации",
        "correct"
    ],
    [
        0.36015624552965164,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '251'}",
        "История о женщине, которая убила своих детей, или история человека в одной сандалии», — говорится в аннотации",
        "correct"
    ],
    [
        0.36015624552965164,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '252'}",
        "История о женщине, которая убила своих детей, или история человека в одной сандалии», — говорится в аннотации",
        "correct"
    ],
    [
        0.36013315121332806,
        "{'dataset_id': 'WorkInTheDark/FairytaleQA', 'config_id': 'plain_text', 'row_id': '596'}",
        "\" you need not trouble yourself about that . to tell you the truth i am no woodcutter ! i am one of the great generals of japan . my name is sadamitsu , and i am a vassal of the powerful lord minamoto - no - raiko . he ordered me to go round the country and look for boys who give promise of remarkable strength , so that they may be trained as soldiers for his army . i thought that i could best do this by assuming the disguise of a woodcutter . by good fortune , i have thus unexpectedly come across your son . now if you really wish him to be a samurai , i will take him and present him to the lord raiko as a candidate for his service . what do you say to this ? \" as the kind general gradually unfolded his plan the mother 's heart was filled with a great joy . she saw that here was a wonderful chance of the one wish of her life being fulfilled - that of seeing kintaro a samurai before she died .",
        "sadamitsu ."
    ],
    [
        0.3600800782442093,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '82'}",
        "It is impossible that Jessica is a cat. There is little chance that Lily is a frog. There is a very good chance that Greg is white. It is highly likely that if 'Lily is a frog and Greg is white' then Emily is a mouse. It is probable that if 'Greg is white and Jessica is a cat' then Brian is green. Chances are about even that if 'Lily is a frog and Jessica is a cat' then John went to the garden.",
        "invalid"
    ],
    [
        0.3600517263015111,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '793'}",
        "There is a better than even chance that Bernhard is white. It is impossible that Julius is a swan. It is impossible that Greg is yellow. There is a better than even chance that if either 'Greg is yellow' or 'Julius is a swan' but not both then Sumit is thirsty. There is a better than even chance that if either 'Greg is yellow' or 'Bernhard is white' but not both then John put down the apple. It is probable that if 'Greg is yellow' or 'Bernhard is white' or both then Winona is a wolf.",
        "invalid"
    ],
    [
        0.36001478135585785,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '639'}",
        "Chances are about even that Mary moved to the office. It is probably the case that Julius is a lion. It is probably not the case that Lily is a rhino. It is probable that if either 'Mary moved to the office' or 'Julius is a lion' but not both then Daniel grabbed the apple. It is probably not the case that if either 'Julius is a lion' or 'Lily is a rhino' but not both then Greg is yellow. Chances are slight that if 'Julius is a lion and Mary moved to the office' then Brian is green.",
        "invalid"
    ],
    [
        0.3598969727754593,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '875'}",
        "We believe that Brian is a swan. There is a better than even chance that Fred dropped the milk. It is improbable that John discarded the apple. We doubt that if either 'John discarded the apple' or 'Brian is a swan' but not both then Gertrude is a sheep. There is little chance that if 'Fred dropped the milk' or 'Brian is a swan' or both then Mary moved to the garden. There is a better than even chance that if 'Fred dropped the milk' or 'Brian is a swan' or both then Greg is white.",
        "invalid"
    ],
    [
        0.3598327984412511,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '332'}",
        "It is probably the case that Brian is white. It is improbable that Sandra got the football. It is almost certain that Winona is a sheep. It is certain that if 'Brian is white' or 'Winona is a sheep' or both then Mary moved to the garden. It is probably the case that if either 'Sandra got the football' or 'Brian is white' but not both then Greg is yellow. It is impossible that if 'Brian is white' or 'Sandra got the football' or both then Bill went to the bedroom.",
        "invalid"
    ],
    [
        0.3598166952530543,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '777'}",
        "\"Вам знакомо имя профессора Козырева, астрофизика, его идеи?\"",
        "correct"
    ],
    [
        0.3598096842567126,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '216'}",
        "Она увлекается им исключительно, понимает и знает; она пишет повесть о женщине, которая не в состоянии влюбиться; мы пришли к выводу, что теперь легче жить, так как меньше возможностей для основательной кристаллизации!",
        "correct"
    ],
    [
        0.35979344447453815,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '24'}",
        "Москва, Март 13 (Новый Регион, Владимир Инютин, Ольга Шибанова) – Отставка председателя Центризбиркома Александра Вешнякова, о неотвратимости которой стало известно сегодня, может быть связана с несколькими обстоятельствами",
        "correct"
    ],
    [
        0.35979344447453815,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '310'}",
        "Москва, Март 13 (Новый Регион, Владимир Инютин, Ольга Шибанова) – Отставка председателя Центризбиркома Александра Вешнякова, о неотвратимости которой стало известно сегодня, может быть связана с несколькими обстоятельствами",
        "correct"
    ],
    [
        0.35978513459364575,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '825'}",
        "There is almost no chance that Lily is a rhino. It is almost certain that Winona is a cat. There is almost no chance that Yann is tired. It is likely that if either 'Lily is a rhino' or 'Winona is a cat' but not both then John moved to the office. It is highly unlikely that if 'Winona is a cat' or 'Yann is tired' or both then Julius is white. It is probably not the case that if 'Lily is a rhino and Yann is tired' then Greg is gray.",
        "invalid"
    ],
    [
        0.3597795118888219,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '359'}",
        "Chances are about even that Mary got the football. It is impossible that Greg is a swan. It is highly likely that Brian is white. It is probably the case that if 'Greg is a swan' or 'Mary got the football' or both then John discarded the apple. It is highly likely that if 'Brian is white and Mary got the football' then Jeff went to the garden. It is impossible that if 'Mary got the football' or 'Greg is a swan' or both then Julius is yellow.",
        "invalid"
    ],
    [
        0.35977428654829663,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '589'}",
        "It is highly unlikely that 'Julius is white' or 'Greg is a lion' or both.",
        "invalid"
    ],
    [
        0.35975993424654007,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '189'}",
        "В последние годы все чаще и чаще возникает речь о теории, которая дала бы возможность направленного синтеза лекарственных веществ с заранее известными терапевтическими свойствами",
        "correct"
    ],
    [
        0.35972511768341064,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '214'}",
        "[{'follow_up_question': 'Is this person your representative (if you have one), such as a lawyer, friend, family member or someone from an advice centre?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person the government department or council’s representative (known as the ‘presenting officer’)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person a panel of experts - who they are depends on what the case is about?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.35972511768341064,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '436'}",
        "[{'follow_up_question': 'Is this person your representative (if you have one), such as a lawyer, friend, family member or someone from an advice centre?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person the government department or council’s representative (known as the ‘presenting officer’)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person a panel of experts - who they are depends on what the case is about?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person the judge?', 'follow_up_answer': 'Yes'}]",
        "False"
    ],
    [
        0.35972511768341064,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '871'}",
        "[{'follow_up_question': 'Is this person your representative (if you have one), such as a lawyer, friend, family member or someone from an advice centre?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person the government department or council’s representative (known as the ‘presenting officer’)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person a panel of experts - who they are depends on what the case is about?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is this person the judge?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.35964735349019367,
        "{'dataset_id': 'scitail', 'config_id': 'predictor_format', 'row_id': '509'}",
        "What are the largest known proteins?",
        "titins"
    ],
    [
        0.359624241789182,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '494'}",
        "It is impossible that Mary picked up the milk. There is a better than even chance that Lily is a rhino. There is a very good chance that Sandra left the football. It is probably not the case that if 'Sandra left the football' or 'Mary picked up the milk' or both then Jessica is a cat. Chances are about even that if 'Sandra left the football' or 'Mary picked up the milk' or both then Bernhard is a swan. It is probably not the case that if 'Sandra left the football' or 'Lily is a rhino' or both then John discarded the apple.",
        "invalid"
    ],
    [
        0.35961810251077014,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '511'}",
        "It is probably not the case that 'Lily is a swan and Brian is white'.",
        "invalid"
    ],
    [
        0.35958804190158844,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '678'}",
        "\"This was a very flawed story about the use of rolfing – a form of massage therapy – in two patients – one with tardive dyskinesia-dystonia and the other with nerve damage after back surgery. The piece was built mainly on anecdote, with several major shortcomings. Most notably, there was no description of how rolfing is actually done, no evidence to support its use, and no discussion of quantifiable benefit or harm. There was also no unbiased, independent expert interviewed. A rolfing practitioner is interviewed who promotes his practice via the story. The story also includes a link to a website promoting alternative health services. Including at least one unbiased expert would have substantially strengthened the piece, especially a medical practitioner or researcher who did not stand to benefit from rolfing or similar CAM (complementary and alternative) therapies. Better sources of consumer information would have also strengthened the piece (E.g. http://nccam.nih.gov/health/backgrounds/manipulative.htm)   The story briefly lists unsuccessful trials of muscle relaxants, pain medications and acupuncture in the case of these patients’ experience with chronic pain and movement conditions. Rolfing is touted as \"\"life altering\"\", but both patients still manage chronic pain and movement limitations. While these patients may have found temporary relief via tissue and fascia manipulation, rolfing needs to be placed in the context of evidence-based medical therapies. The story does not list the cost of treatment. This is a great oversight in a story on a complementary therapy, which is typically not covered by health insurance and may need to be part of on-going pain management. While some health insurers may pay a portion of  therapeutic massage for some conditions, there are few regulatory bodies that guide pricing for these therapies.\"",
        "false"
    ],
    [
        0.3595697631438573,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '47'}",
        "There is a better than even chance that Greg is a lion. It is probable that Lily is green. Chances are about even that John went to the garden. It is probable that if 'Greg is a lion' or 'Lily is green' or both then Winona is a sheep. It is unlikely that if either 'John went to the garden' or 'Greg is a lion' but not both then Julius is a swan. It is unlikely that if 'John went to the garden' or 'Lily is green' or both then Brian is yellow.",
        "invalid"
    ],
    [
        0.3595447689294815,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '191'}",
        "It is probably the case that Greg is green. We doubt that Brian is a rhino. We believe that Julius is a frog. There is almost no chance that if 'Julius is a frog and Brian is a rhino' then Gertrude is a sheep. It is highly unlikely that if either 'Greg is green' or 'Brian is a rhino' but not both then Mary moved to the office. It is probable that if either 'Julius is a frog' or 'Greg is green' but not both then Daniel got the milk.",
        "invalid"
    ],
    [
        0.3595433284838994,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '959'}",
        "Chances are slight that Lily is gray. There is a very good chance that Fred moved to the office. It is probably the case that Julius is white. It is impossible that if 'Lily is gray and Julius is white' then Brian is a lion. It is improbable that if either 'Fred moved to the office' or 'Julius is white' but not both then Bernhard is a frog. It is improbable that if 'Julius is white and Lily is gray' then Jessica is a cat.",
        "invalid"
    ],
    [
        0.35952482124169666,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '487'}",
        "آب و رنگ خالی بدون طعم پرتقال. و بر خلاف چیزی که روش نوشته اصلا پالپ نداره. در یک کلام بد",
        "نوشابه"
    ],
    [
        0.35937925179799396,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '384'}",
        "The poster's family is very against his idea of becoming a high school chemistry teacher because of the low pay. He wants to know how he can politely tell his family that this is something he is going to pursue regardless of what they say.",
        "Accuracy"
    ],
    [
        0.35934708019097644,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '516'}",
        "It is unlikely that 'Lily is a swan' or 'Winona is a sheep' or both.",
        "invalid"
    ],
    [
        0.3593437323967616,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '178'}",
        "There is almost no chance that either 'Yann is tired' or 'Lily is a lion' but not both.",
        "invalid"
    ],
    [
        0.3593266283472379,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '201'}",
        "Я твердо убежден, что если моя версия об аварии, которую потерпел «Пионер», верна, то и боеспособность его значительно понизилась в результате того происшествия",
        "correct"
    ],
    [
        0.3593030869960785,
        "{'dataset_id': 'WorkInTheDark/FairytaleQA', 'config_id': 'plain_text', 'row_id': '375'}",
        "' as you have said so much you will have to say a little more , ' retorted the old man , a suspicion of what she meant darting across him ; and the woman , nothing loth , answered as before . ' ah , it was not all for buying or selling that your handsome son has been coming to town every week these many months past . and not by the shortest way , either ! no , it was over the river he rode , and across the hill and past the cottage of miguel the vine - keeper , whose daughter , they say , is the prettiest girl in the whole country side , though she is too white for my taste , ' and then the landlady paused again , and glanced up at the farmer , to see how he was taking it . she did not learn much . he was looking straight before him , his teeth set . but as she ceased to talk , he said quietly , ' go on . ' ' there is not much more to tell , ' replied the landlady , for she suddenly remembered that she must prepare supper for the hungry men who always stopped at the inn on market days , before starting for home , ' but one fine morning they both went to the little church on top of the hill , and were married . my cousin is servant to the priest , and she found out about it and told me . but good - day to you , sir ; here is your horse , and i must hurry off to the kitchen . '",
        ""
    ],
    [
        0.35927606622378033,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '444'}",
        "Так же - Олешье, как некая независимая часть Руси, которую кочевники не трогали набегами и предположительно, там наше Лукоморье",
        "correct"
    ],
    [
        0.3592513749996821,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '967'}",
        "There is a better than even chance that Lily is a lion. We believe that Bernhard is yellow. It is highly likely that Mary moved to the garden. It is certain that if 'Lily is a lion' or 'Mary moved to the garden' or both then Brian is white. Chances are about even that if 'Bernhard is yellow and Lily is a lion' then John took the apple. We believe that if 'Mary moved to the garden' or 'Lily is a lion' or both then Julius is a swan.",
        "invalid"
    ],
    [
        0.3592298924922943,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '885'}",
        "کاملن قابل قبول ... و اینکه باعث میشه آدم به فکر فرو بره. تاثیر خودشُ داره فیلم به اندازه کافی آدمُ تغذیه می کنه و جامعه رو.",
        "صدا"
    ],
    [
        0.35919131338596344,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '743'}",
        "It is probably the case that Bernhard is white. It is probably not the case that Lily is a rhino. It is unlikely that Mary went to the garden. It is highly unlikely that if 'Lily is a rhino and Mary went to the garden' then Brian is a lion. It is improbable that if 'Bernhard is white' or 'Mary went to the garden' or both then Julius is yellow. It is probable that if 'Lily is a rhino' or 'Bernhard is white' or both then Sumit is tired.",
        "invalid"
    ],
    [
        0.35916972657044727,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '481'}",
        "Учёный понял, что поверхность Луны, которая на самом деле может быть достаточно тёмной, кажется нам светлой и яркой лишь благодаря тому, что освещается Солнцем",
        "correct"
    ],
    [
        0.35915196935335797,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '253'}",
        "(1) Джим не может не видеть страшной закомплексованности девушки. (2) Он пытается помочь, убеждает, что её хромота совсем не бросается в глаза, — никто в школе даже не замечал, что она носит специальную обувь. (3) Люди совсем не злые, пытается он втолковать Лауре, особенно когда узнаешь их поближе. (4) Практически у всех что-нибудь да не ладится — не годится считать себя хуже всех. (5) По его мнению, главная проблема Лауры заключается в том, что она вбила себе в голову: только у неё все плохо... (6) Лаура спрашивает про девушку, с которой Джим встречался в школе, — говорили, что они обручились. (7) Узнав, что никакой свадьбы не было и Джим давно уже ee не видел, Лаура вся расцветает. (8) Чувствуется, что в душе ee зародилась робкая надежда. (9) Она показывает Джиму свою коллекцию стеклянных фигурок — высший знак доверия. (10) Среди зверюшек выделяется единорог — вымершее животное, ни на кого не похожее. (11) Джим сразу обращает на него внимание. (12) Тому, наверное, скучно стоять на одной полке с заурядными животными вроде стеклянных лошадок?",
        "False"
    ],
    [
        0.35915196935335797,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '256'}",
        "(1) Джим не может не видеть страшной закомплексованности девушки. (2) Он пытается помочь, убеждает, что её хромота совсем не бросается в глаза, — никто в школе даже не замечал, что она носит специальную обувь. (3) Люди совсем не злые, пытается он втолковать Лауре, особенно когда узнаешь их поближе. (4) Практически у всех что-нибудь да не ладится — не годится считать себя хуже всех. (5) По его мнению, главная проблема Лауры заключается в том, что она вбила себе в голову: только у неё все плохо... (6) Лаура спрашивает про девушку, с которой Джим встречался в школе, — говорили, что они обручились. (7) Узнав, что никакой свадьбы не было и Джим давно уже ee не видел, Лаура вся расцветает. (8) Чувствуется, что в душе ee зародилась робкая надежда. (9) Она показывает Джиму свою коллекцию стеклянных фигурок — высший знак доверия. (10) Среди зверюшек выделяется единорог — вымершее животное, ни на кого не похожее. (11) Джим сразу обращает на него внимание. (12) Тому, наверное, скучно стоять на одной полке с заурядными животными вроде стеклянных лошадок?",
        "False"
    ],
    [
        0.3591204086939494,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '14'}",
        "The text describes a relationship in which the couple constantly fights about petty things. The author feels that there are many deep-rooted issues in the relationship that are unsolvable.",
        "Accuracy"
    ],
    [
        0.3591161519289017,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '70'}",
        "به نسبت عسل های موجود در بازار، کیفیت مناسبی داره همیشه تخفیف داشته باشه خوبه",
        "طعم"
    ],
    [
        0.35909676055113476,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '151'}",
        "It is unlikely that Gertrude is a cat. It is impossible that Julius is a lion. It is impossible that Sandra took the football. It is highly likely that if 'Gertrude is a cat and Julius is a lion' then Lily is a rhino. It is probably not the case that if either 'Julius is a lion' or 'Gertrude is a cat' but not both then Greg is green. It is probably the case that if either 'Julius is a lion' or 'Sandra took the football' but not both then Brian is yellow.",
        "invalid"
    ],
    [
        0.3590579976638158,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '632'}",
        "It is probably not the case that either 'Julius is a swan' or 'Daniel got the football' but not both.",
        "invalid"
    ],
    [
        0.3590552657842636,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '458'}",
        "Chances are slight that Julius is a swan. It is probably not the case that Bernhard is a frog. There is a very good chance that Sandra took the milk. It is highly unlikely that if either 'Sandra took the milk' or 'Bernhard is a frog' but not both then Lily is green. It is certain that if 'Bernhard is a frog and Sandra took the milk' then Greg is a lion. There is a better than even chance that if either 'Julius is a swan' or 'Sandra took the milk' but not both then Fred is in the cinema.",
        "invalid"
    ],
    [
        0.3590472886959712,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '57'}",
        "There is a better than even chance that Greg is white. There is almost no chance that Bernhard is a frog. It is highly likely that Mary left the football. We doubt that if 'Bernhard is a frog and Mary left the football' then Julius is a swan. It is almost certain that if 'Greg is white' or 'Bernhard is a frog' or both then John took the apple. It is probably the case that if either 'Bernhard is a frog' or 'Greg is white' but not both then Winona is a wolf.",
        "invalid"
    ],
    [
        0.35902976989746094,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '705'}",
        "The summary is slightly inaccurate; the poster's father is the one threatening to put down the cat, not both parents.",
        "Accuracy"
    ],
    [
        0.3589980751276016,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '75'}",
        "С ней была подруга, девочка из норвегии, которая в ту ночь собиралась остаться у нас, ― рассказали итальянские   родители   ангелины местным сми",
        "correct"
    ],
    [
        0.35897282262643176,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '200'}",
        "There is almost no chance that Lily is a frog. It is unlikely that Julius is yellow. There is almost no chance that Mary left the apple. It is highly unlikely that if either 'Mary left the apple' or 'Lily is a frog' but not both then Brian is white. Chances are about even that if 'Julius is yellow and Lily is a frog' then Greg is green. There is a very good chance that if 'Mary left the apple' or 'Julius is yellow' or both then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.3589036514361699,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '645'}",
        "There is almost no chance that either 'Julius is green' or 'Brian is a lion' but not both.",
        "invalid"
    ],
    [
        0.35889217754205066,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '57'}",
        "\"Хотя сам Гоша никогда не был скейтером, он и скейт-культура неотделимы.\"",
        "correct"
    ],
    [
        0.35889217754205066,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '775'}",
        "\"Хотя сам Гоша никогда не был скейтером, он и скейт-культура неотделимы.\"",
        "correct"
    ],
    [
        0.35888655483722687,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '637'}",
        "Write an excellent summary of the given text.\n\nTitle: I gave false information in an interview. How can I fix this?\n\nText: Quick background: I have been graduated from college for two years with a degree in finance and accounting. I currently work at a local restaurant as a server. About 3 months ago I left a restaurant that I had worked at for 5 years to work at this current restaurant with more reasonable hours. The move to this restaurant is supposed to be temporary while I search for something in accounting or finance. \n\nFast forward to this morning.  I am interviewing for a position as an auditor with a small firm. The interview is going great. He asks some technical questions and the standard, \"Tell me about a time when...\" type of questions. \n\nThen we start going over my resume. As he is going through it I realize that I had given him an out of date version of the resume which does not have my current employer listed. It still says that I am employed with the previous restaurant that I left about 3 months ago.  I kind of panicked and wasn't sure if I should point out the mistake or not. I was worried about stopping the momentum of the interview/pointing out a glaring mistake on a resume that should be pristine.  In the end I decided to just let it ride and answered questions about the job as if I were still employed there. In my panicked state I figured the two jobs are essentially interchangeable and I've only been at the current place for 3 months so not listing a temporary position on the resume is no big deal. \n\nSo the interview finishes up and I am immediately asked to come back in again to meet the other partners and staff members. It went well. Really well. I can just tell that I have a really good shot at this. Pretty damn excited. \n\nBut now I'm realizing that he will most likely try to verify my employment with the restaurant that I am no longer working for. How can I avoid this from looking like I just lied to him? I feel like I should contact him and explain the mistake but I don't want to look inept or worse shady for not saying anything during the interview. How can I fix this?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3588796357313792,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '781'}",
        "Евреи не обманываются в евреях, они своих видят как облупленных",
        "correct"
    ],
    [
        0.358878826101621,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '23'}",
        "Евангелия сохранили имена некоторых из них: это мария из магдалы, которую господь исцелил от «семи бесов»; мать иоанна и иакова ― саломея; сестра девы марии ― мария клеопова; сусанна; иоанна ― жена хузы, домоправителя антипы",
        "correct"
    ],
    [
        0.35885531703631085,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '899'}",
        "نشون دادن اون همه صحنه درگیری و دعوا با جزییات کامل واقعا لازم نبود... :| حتی اگر کارگردان میخواست که اعصاب بیننده خرد بشه میتونست از راه های دیگه ای استفاده کنه!! همیشه نمایش کامل تمام جزییات خوب نیست",
        "صحنه"
    ],
    [
        0.35880308349927265,
        "{'dataset_id': 'GEM/FairytaleQA', 'config_id': 'default', 'row_id': '596'}",
        "\" you need not trouble yourself about that . to tell you the truth i am no woodcutter ! i am one of the great generals of japan . my name is sadamitsu , and i am a vassal of the powerful lord minamoto - no - raiko . he ordered me to go round the country and look for boys who give promise of remarkable strength , so that they may be trained as soldiers for his army . i thought that i could best do this by assuming the disguise of a woodcutter . by good fortune , i have thus unexpectedly come across your son . now if you really wish him to be a samurai , i will take him and present him to the lord raiko as a candidate for his service . what do you say to this ? \" as the kind general gradually unfolded his plan the mother 's heart was filled with a great joy . she saw that here was a wonderful chance of the one wish of her life being fulfilled - that of seeing kintaro a samurai before she died .",
        "sadamitsu ."
    ],
    [
        0.3587908099095027,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '719'}",
        "There is almost no chance that Lily is yellow. There is almost no chance that Bernhard is white. We doubt that Brian is yellow. It is probably not the case that if 'Lily is yellow and Brian is yellow' then Bill got the milk there. Chances are about even that if 'Lily is yellow' or 'Bernhard is white' or both then Greg is green. It is unlikely that if 'Lily is yellow and Brian is yellow' then Mary left the football.",
        "invalid"
    ],
    [
        0.35879069070021313,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '186'}",
        "Write an excellent summary of the given text.\n\nTitle: My (22/f) boyfriend (23/m) smokes weed pretty regularly, sometimes \"stoned him\" confuses/bothers me\n\nText: So my boy and I have been together for about three months officially, but we were seeing each other fairly exclusively for about two months before that and we've been friends for right around a year. I know him well and pretty much adore the guy.\n\nHe doesn't smoke every day, usually it is more like once or twice a week, but when he does he gets exceptionally stoned. I smoke with him occasionally, probably close to once or twice a month. I don't have a problem with marijuana at all, but I've never been the chill out and smoke a bowl type, I'm too energetic and type A for that to really sound appealing very often. Anyhow, normally he is a pretty affectionate guy, but when he is stoned he isn't very touchy and doesn't respond to my touch as much. In the beginning of our relationship it really worried me, because I didn't realize the correlation and thought that my new awesome boyfriend was losing interest in me. Also, he gets pretty unresponsive in conversation. The other night we had been talking about a problem I had over text, he invited me over to talk about it with him/comfort me later that night. When I showed up he had been smoking, and that made it much harder to get feedback from him like I wanted.\n\nI don't want him to stop, he enjoys it and it is a fairly important thing to him and his friends. Mostly I would just like some kind of heads up if he has been smoking, and maybe to let him know that there are times I'd rather he not smoke (like if he knows I am coming over to talk about a problem with him)\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35871780415376026,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '952'}",
        "It is probably not the case that 'Greg is a lion and Brian is a rhino'.",
        "invalid"
    ],
    [
        0.3586897999048233,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '84'}",
        "The author finds it impossible to stay friends with an ex-lover, and he wonders why. He attributes this to his insecurity and to the fact that the ex is like a drug to him.",
        "Accuracy"
    ],
    [
        0.35867249965667725,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '707'}",
        "Лакеи чистили мундиры графа и сыновей его",
        "correct"
    ],
    [
        0.35864805181821185,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '160'}",
        "Long distance couple in trouble because girlfriend's parents are against the relationship due to the couple's different religions. Girlfriend's grandparents also oppose the relationship but for different reasons.",
        "Accuracy"
    ],
    [
        0.35862642526626587,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '88'}",
        "Write an excellent summary of the given text.\n\nTitle: How to find people that suit my interests?\n\nText: I'm a college student but it's commuting school so there's not really a campus life. It's kinda like high school but with harder courses.\n\nSo I have a fixed class, and I don't really like them. I did my best to befriend them though, since I figured that maybe I'd meet some interesting people through them.\n\nA year has passed, and unfortunately, it appears that the only people I meet through them are lame as well. Their definition of having fun is sitting on their ass all night, smoking cigarettes and talking trash behind each other's back. Other people's lives is also the only subject they know something about, so conversation options are rather limited.\n\nAnd then there's the parties. Every once in a while, we gather around, the girls drink two glasses of wine and spend the rest of the week bragging about how drunk they were. The guys spend an entire month posting Barney Stinson quotes on their facebook page because they almost considered talking to a girl who looked kind of okay.\n\nHm...\n\nI've already spent two paragraphs ranting on about how lame they were. Sorry for that. But they really are lame. It's not my opinion, it's a fact. Cats go meow, cows go moo and my annoying classmates go \"All music sucks apart from this obscure indie band you have to know everything about in order to be a respectable human being\"\n\nThis gets to me, of course. I used to live in a city where I had friends I could relate to. And now, I feel like I'm trapped with the cast of some trashy reality tv show. It's very douchey of me to talk about them like that, I know. But it's just too much. You have to see them to believe it.\n\nSo this is my question. How do I deal with this? Just stop hanging out with them, since it's not fruitful? And find another circle of friends? How would I go about that, anyway? I'm good at meeting people, but I'm not good in turning strangers into friends.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35861382881800336,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '113'}",
        "در واقع برزخی بین چای سیاه و بلوبری است ولی در عین حال هیچکدام نیست. کاملا اسانس بودن را متوجه می شوید و این حس خوبی را به شما نمی دهد",
        "کلی"
    ],
    [
        0.3585914472738902,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '311'}",
        "['Мифологии', 'нацию', 'легенд', 'правда', 'войне', 'основы', 'Системы']",
        "correct"
    ],
    [
        0.3585834602514903,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '494'}",
        "The summary is not exactly accurate; the poster believes that the boyfriend's throwaway account is being used for a porn collection; she has no proof that it's true.",
        "Accuracy"
    ],
    [
        0.3584827457865079,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '189'}",
        "افتضاح تر ازین نمیشه.....۱۰ تومن واسه ۱۱ تا دونه ادامس؟بسته بندی فاجعه....بدون شم فیک بود ...معلوم نیست کجا پرش کردن.....چاپ روش کمرنگ و پلاستیک بی کیفیت.مزه ادامس شیک میده و مزش تو پنج دقیقه میره",
        "طعم"
    ],
    [
        0.3584699382384618,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '272'}",
        "It is probably not the case that Lily is green. Chances are about even that Greg is gray. It is probably not the case that John left the milk. We doubt that if either 'Lily is green' or 'John left the milk' but not both then Sandra took the football. It is probable that if either 'Lily is green' or 'Greg is gray' but not both then Brian is a swan. Chances are about even that if either 'Greg is gray' or 'John left the milk' but not both then Bernhard is white.",
        "invalid"
    ],
    [
        0.35842160880565643,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '111'}",
        "Самое интересное в этой истории ― бумага из москвы, которую прислал во владимир генеральный директор научного центра традиционных методов диагностики и лечения (при росздраве) господин а",
        "correct"
    ],
    [
        0.35839246213436127,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '281'}",
        "It is probably not the case that either 'Brian is yellow' or 'Julius is a frog' but not both.",
        "invalid"
    ],
    [
        0.35833607614040375,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '204'}",
        "There is almost no chance that either 'Bernhard is a swan' or 'Greg is a lion' but not both.",
        "invalid"
    ],
    [
        0.35832277437051135,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '856'}",
        "It is probably not the case that either 'Greg is a swan' or 'Lily is gray' but not both.",
        "invalid"
    ],
    [
        0.3582725077867508,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '88'}",
        "It is unlikely that Lily is yellow. It is probably the case that Julius is green. It is unlikely that Fred dropped the milk. There is a better than even chance that if either 'Lily is yellow' or 'Julius is green' but not both then John put down the apple. We believe that if 'Julius is green' or 'Lily is yellow' or both then Greg is gray. It is impossible that if 'Julius is green' or 'Fred dropped the milk' or both then Brian is a lion.",
        "invalid"
    ],
    [
        0.35824839770793915,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '904'}",
        "It is highly likely that Brian is white. It is impossible that Sandra left the football. It is probably not the case that John put down the apple. It is improbable that if 'Sandra left the football and Brian is white' then Greg is a rhino. We believe that if either 'Brian is white' or 'John put down the apple' but not both then Bernhard is white. It is highly unlikely that if either 'Brian is white' or 'John put down the apple' but not both then Mary went to the hallway.",
        "invalid"
    ],
    [
        0.3582125206788381,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '77'}",
        "There is almost no chance that John picked up the apple. It is almost certain that Bernhard is a rhino. It is highly unlikely that Lily is white. It is probably the case that if 'Lily is white and John picked up the apple' then Greg is a frog. It is certain that if 'John picked up the apple' or 'Bernhard is a rhino' or both then Julius is a swan. It is probable that if 'Bernhard is a rhino and John picked up the apple' then Yann is bored.",
        "invalid"
    ],
    [
        0.35820220907529193,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '525'}",
        "Давно уж русской стала их последняя деревня - Бабёнки, которая и имя-то своё, смешное и непонятное, сменила на нейтральное - «Заречная»",
        "correct"
    ],
    [
        0.35819434622923535,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '123'}",
        "['версий', 'причине', 'вспышки', 'области', 'вода', 'волги']",
        "correct"
    ],
    [
        0.3581880380709966,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '909'}",
        "In 1681 , in partial repayment of a debt , Charles II of England granted Penn a charter for what would become the Pennsylvania colony . Despite the royal charter , Penn bought the land from the local Lenape to be on good terms with the Native Americans and ensure peace for his colony . Penn made a treaty of friendship with Lenape chief Tammany under an elm tree at Shackamaxon , in what is now the city 's Fishtown neighborhood . Penn named the city Philadelphia , which is Greek for `` brotherly love , '' derived from the Ancient Greek terms φίλος phílos ( beloved , dear ) and ἀδελφός adelphós ( brother , brotherly ) . As a Quaker , Penn had experienced religious persecution and wanted his colony to be a place where anyone could worship freely . This tolerance , far more than afforded by most other colonies , led to better relations with the local native tribes and fostered Philadelphia 's rapid growth into America 's most important city .",
        ""
    ],
    [
        0.35816799104213715,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '154'}",
        "['The extreme obesity of the obese (ob/ob) mouse is attributable to mutations in the gene encoding leptin, an adipocyte-specific secreted protein which has profound effects on appetite and energy expenditure.', \"We know of no equivalent evidence regarding leptin's role in the control of fat mass in humans.\", 'We have examined two severely obese children who are members of the same highly consanguineous pedigree.', 'Their serum leptin levels were very low despite their markedly elevated fat mass and, in both, a homozygous frame-shift mutation involving the deletion of a single guanine nucleotide in codon 133 of the gene for leptin was found.', 'The severe obesity found in these congenitally leptin-deficient subjects provides the first genetic evidence that leptin is an important regulator of energy balance in humans.']",
        "False"
    ],
    [
        0.358156755566597,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '961'}",
        "\"Age-related macular degeneration (AMD) is a signficant problem in the elderly. It is a slow, progressive disease that can ultimately lead to blindness over time. Unfortunately, there are few options available for prevention or treatment and this story discusses new evidence showing no benefit in terms of prevent AMD from one option, beta carotene supplements. This story manages to provide the reader with adequate information on the problem of treating AMD and the strength of the available evidence to support the use of supplements. The story adequately describes the strength of the current study and points out some of the limitations. The story also mentions that there is some evidence that beta-carotene raises the risk of lung cancer in smokers, an important harm. The story adequately quantifies the benefit of supplements by providing the actual number of cases of AMD observed in the supplement group compared to the \"\"dummy pill\"\" group. The story does mention that there is no cure for AMD (the \"\"dry\"\" form) and that supplements are really the only option currently available. However, the story misses the main point of the scientific paper, which was that beta carotene supplementation does not appear to prevent AMD in people at usual risk for the disease. In contrast, there is evidence that antioxidant supplements (those tested contain beta carotene as a component) can be used to slow progression of AMD in those who have it. Overall, a good job, and in less than 500 words (496).\"",
        "true"
    ],
    [
        0.35811633865038556,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '713'}",
        "It is impossible that either 'Julius is a frog' or 'Lily is yellow' but not both.",
        "invalid"
    ],
    [
        0.3580597937107086,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '615'}",
        "Write an excellent summary of the given text.\n\nTitle: Ex changed his electric account back to my name (and his SSN) and deleted his name, and now I have collectors calling me because he owes them money... Can I dispute this?\n\nText: I lived in MA with my ex for a year and a half, and originally, we had the electric bill under both of our names. When I moved out in December, I called the company and told them to remove my name, contact info, and payment info from the account and leave his on there. They said they needed him to call, too, so he claimed he did. Today, I was at my parents' house and I got a call from a debt collector at THEIR phone number, which I never provided myself, saying that I owe $150 in past due bills. I managed to log into the account, and found that while his cell number, his SSN, and his email address were on the account, it was under my name and my parents' address. He has been making small payments on the account throughout this time, so I'm sure he did this sometime in the period since I left. My question is, will the electric company drop the charge when I call and explain everything to them on Monday? The debt collector disputed the charge for me, but she seemed to think that I need to contact the police for identity theft even though he wasn't able to use my SSN. Won't the fact that he used his own SSN prove that it wasn't me that set up the account, though? \n\nOr, on the other hand, maybe I should just pay it and close the account. I'm really nervous that he gave them all of my parents' information... he was emotionally abusive towards me and I'm scared that he's just trying to exert control through any avenue he can find. I don't want this to drag out for any length of time, so paying might be the best option. What should I do?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3580414553483327,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '122'}",
        "There is almost no chance that Brian is a rhino. There is little chance that Yann is hungry. There is almost no chance that John left the football. It is probably the case that if either 'John left the football' or 'Brian is a rhino' but not both then Mary moved to the office. There is a very good chance that if 'Yann is hungry' or 'Brian is a rhino' or both then Julius is a swan. It is certain that if either 'Yann is hungry' or 'Brian is a rhino' but not both then Greg is white.",
        "invalid"
    ],
    [
        0.357993687192599,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '156'}",
        "It is certain that either 'Daniel left the milk' or 'Greg is a lion' but not both.",
        "invalid"
    ],
    [
        0.35797610878944397,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '320'}",
        "anwaar uit wij e gënhjk worden geregeerd.: Van rit Washington of ■•𝙞𝙣𝙪𝙞𝙩 Waliitreet?i Of. weet ge niet wat wij met Wal!Strekt bedoelen ? .",
        "𝙞𝙣𝙪𝙞𝙩"
    ],
    [
        0.3579515864451726,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '568'}",
        "There is almost no chance that Jessica is a sheep. Chances are slight that Lily is white. It is impossible that Bill went to the kitchen. It is almost certain that if 'Lily is white and Bill went to the kitchen' then Bernhard is gray. It is improbable that if 'Bill went to the kitchen and Lily is white' then Sandra left the football. There is little chance that if 'Bill went to the kitchen' or 'Jessica is a sheep' or both then Brian is a swan.",
        "invalid"
    ],
    [
        0.35788312057654065,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '603'}",
        "There is almost no chance that Lily is a rhino. It is improbable that Bernhard is white. We doubt that John dropped the apple. It is probably not the case that if 'Lily is a rhino' or 'Bernhard is white' or both then Yann is hungry. It is probable that if 'Lily is a rhino' or 'John dropped the apple' or both then Gertrude is a cat. Chances are about even that if 'Lily is a rhino and Bernhard is white' then Brian is yellow.",
        "invalid"
    ],
    [
        0.3578006327152252,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '785'}",
        "Write an excellent summary of the given text.\n\nTitle: Why does everyone assume all white people are racist?\n\nText: Ok so this is a serious question, I go to a primarily black high school and I am white, i personally am NOT RACIST however I find that a lot of the black people at my school give the white people the \"look\". It's not an intimidating look as much as a \" you know what you did\" look. I live in Florida I was wondering does this happen everywhere or is it just where I live?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35779239734013873,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '0'}",
        "دوستان حتما دقت کنید درقسمت فیله تکه های سبز رنگ داشت که نشان دهنده انتیبیوتیک هایی هست که به مرغ ها میدن و اون تکه سمیه. بیشترشم استخونه من راضی نبودم و دیگه ازین مارو خرید نمیکنم",
        "طعم"
    ],
    [
        0.35775304834047955,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '467'}",
        "['она', 'сестра', 'той']",
        "correct"
    ],
    [
        0.357734277844429,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '202'}",
        "Chances are about even that Mary picked up the milk. It is probably not the case that Julius is a swan. There is little chance that Daniel got the football. It is likely that if either 'Daniel got the football' or 'Julius is a swan' but not both then John went to the kitchen. We believe that if 'Julius is a swan and Daniel got the football' then Emily is a wolf. It is almost certain that if either 'Julius is a swan' or 'Daniel got the football' but not both then Jessica is a cat.",
        "invalid"
    ],
    [
        0.35767989854017895,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '126'}",
        "فک نکنم زیاد طرفدار داشته باشه،آخه خیلی بو میده و طعمشم به نظرم خوب نیست،قوطی دوم رو مجبور شدم با رب گوجه فرنگی و پیاز و ... تفت بدم و سیب زمینی سرخ کرده اضافه کنم تا بشه تحملش کرد....تن ماهی رو به کیلکا ترجیح میدم",
        "طعم"
    ],
    [
        0.3576663186152776,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '892'}",
        "Chances are slight that either 'Gertrude is a sheep' or 'Brian is a lion' but not both.",
        "invalid"
    ],
    [
        0.35766564309597015,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '295'}",
        "There is almost no chance that Lily is yellow. There is little chance that Jason is thirsty. Chances are slight that Greg is a frog. Chances are slight that if 'Lily is yellow and Jason is thirsty' then Bernhard is a rhino. It is probably the case that if either 'Jason is thirsty' or 'Greg is a frog' but not both then Jessica is a sheep. There is almost no chance that if either 'Jason is thirsty' or 'Greg is a frog' but not both then John took the football.",
        "invalid"
    ],
    [
        0.3576277941465378,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '35'}",
        "It is almost certain that Daniel took the apple. We believe that Sandra got the milk. It is certain that Julius is a swan. It is probably not the case that if either 'Daniel took the apple' or 'Sandra got the milk' but not both then Winona is a cat. We doubt that if 'Sandra got the milk' or 'Julius is a swan' or both then Mary is in the hallway. It is probable that if 'Julius is a swan and Daniel took the apple' then Greg is gray.",
        "invalid"
    ],
    [
        0.3576079656680425,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '674'}",
        "Лето в Сочи вступает в свои права с трудом: бывает, что и в июне люди носят плащи ― моросит холодный дождь",
        "correct"
    ],
    [
        0.35751088708639145,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '773'}",
        "\"Димка не был греком, он боялся Гали.\"",
        "correct"
    ],
    [
        0.3574649194876353,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '915'}",
        "There is almost no chance that either 'Bernhard is a frog' or 'Brian is a rhino' but not both.",
        "invalid"
    ],
    [
        0.35745560626188916,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '517'}",
        "Еще 20-25% - это так называемая темная материя, частицы которой пронизывают все вокруг, но очень плохо взаимодействуют с обычным веществом",
        "correct"
    ],
    [
        0.3574492434660594,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '961'}",
        "Chances are slight that Brian is a rhino. Chances are slight that Bill went to the kitchen. It is almost certain that Julius is a swan. It is probably the case that if 'Brian is a rhino' or 'Bill went to the kitchen' or both then Jessica is a mouse. It is certain that if 'Brian is a rhino' or 'Bill went to the kitchen' or both then John got the apple. It is probably the case that if 'Bill went to the kitchen and Julius is a swan' then Mary moved to the garden.",
        "invalid"
    ],
    [
        0.3574012617270152,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '185'}",
        "\"This story unfortuantely reads like a marketing effort on the part of the manufacturer rather than objective reporting on the results of what the authors describe as an early proof of concept trial. The story suggests that the product in question (Souvenaid), \"\"…might be effective in stemming-and perhaps reversing the cognitive tolls of Alzheimer’s. \"\" While this may be true, the published article demonstrated much more limited results, ony demonstrating an improvement in one of six rating scales used.The story presents an inflated view of the study results without any significant provisos. Readers can see a striking difference between the LA Times story and one on ABCNews.com that had many more paragraphs of concerns, caveats and context. There are no effective treatments for Alzheimer’s DIsease. While there are numerous drugs available, their value in the memory loss and dementia associated with Alzheimer’s is limited. A new treatment, especially one based on a nutritional approach would be a welcomed option. However – the headline and the tone of this story raises hopes and expectations unrealistically.\"",
        "false"
    ],
    [
        0.3573314696550369,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '966'}",
        " doch waaraan heeft hij die bekendheid tn danken ?Geheel alleen als 𝙝𝙤𝙢𝙤 novus; terwijl niemand in zijne familie ooit eene betrekking bij de",
        "𝙝𝙤𝙢𝙤"
    ],
    [
        0.3573215554157893,
        "{'dataset_id': 'cos_e', 'config_id': 'v1.0', 'row_id': '34'}",
        "he was lying about something and what he said was untrue",
        "untrue"
    ],
    [
        0.35730497042338055,
        "{'dataset_id': 'blimp', 'config_id': 'adjunct_island', 'row_id': '845'}",
        "Who has Rodney confused without working with Larry?",
        "False"
    ],
    [
        0.35728105902671814,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '137'}",
        "Chances are slight that Bernhard is a rhino. It is highly likely that Bill moved to the office. It is highly likely that Lily is a frog. It is impossible that if 'Bill moved to the office and Bernhard is a rhino' then Brian is a swan. Chances are about even that if 'Lily is a frog' or 'Bernhard is a rhino' or both then John dropped the apple. There is a better than even chance that if 'Lily is a frog' or 'Bill moved to the office' or both then Julius is white.",
        "invalid"
    ],
    [
        0.3572746217250824,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '577'}",
        "Write an excellent summary of the given text.\n\nTitle: My condo is no longer underwater! Now what?\n\nText: I purchased a Condo with an ARM 10 years ago, but have never been able to refinance or sell because until now my LTV has been above 100%(for several years the LTV was >200%) and it was a non-conforming loan. After having paid exorbitant rates for the last 8 year and paying down the loan as fast as possible I finally have the opportunity to do something, but I don't know what to do.\n\nThe loan terms:\n\n40 year ammortization, balloon payment at 30 years\n\n6.54% interest (a few years ago it was 9.54%)\n\nadjusts every 6 months.\n\n$63,217.03 remaining balance.\n\n$445.27/month minimum payment\n\nHOA Fees: $187.50/month\n\nI receive:$700/month rent.\n\nOptions that I see:\n\n1. Continue renting it out and paying down mortgage as fast as possible (at least $1050/month additional principle payment)  (Every extra principle payment seems like a guaranteed 6.54% ROI vs putting the extra money into the stock market and NOT putting it into my mortgage)\n\n2. Sell it. I would lock in my losses and I'm not sure what would happen to my taxes considering that even with depreciation I would be selling at a $70k loss and I wouldn't get any cash from the sale. However, I would be able to put a solid $1000 extra into stocks/bonds per month and get whatever return I can there.\n\n3. Refinance. I could pay it off just far enough to get an 80% LTV conforming loan. Though this may be difficult because the unit above mine sold 4 months ago for 61.5k and last time I checked with a bank they said that it was hard to get loans for under 50k. Interest rates are much lower now and could possibly save me $1200/year.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3572701960802078,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '669'}",
        "It is impossible that Julius is green. Chances are about even that Lily is a rhino. There is a better than even chance that Bernhard is gray. We doubt that if either 'Lily is a rhino' or 'Bernhard is gray' but not both then Daniel dropped the apple. There is a very good chance that if either 'Bernhard is gray' or 'Lily is a rhino' but not both then Mary went to the office. There is a better than even chance that if 'Julius is green and Lily is a rhino' then Brian is a frog.",
        "invalid"
    ],
    [
        0.35725964109102887,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '178'}",
        "It is impossible that either 'Mary left the milk' or 'Greg is a lion' but not both.",
        "invalid"
    ],
    [
        0.35725268224875134,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '500'}",
        "Chances are slight that Greg is yellow. It is unlikely that Winona is a sheep. It is probable that Bernhard is a swan. It is impossible that if 'Bernhard is a swan and Greg is yellow' then Lily is green. It is almost certain that if 'Bernhard is a swan and Greg is yellow' then Antoine is thirsty. It is probably the case that if either 'Winona is a sheep' or 'Bernhard is a swan' but not both then John got the milk.",
        "invalid"
    ],
    [
        0.3572392563025157,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '994'}",
        "It is almost certain that Lily is green. There is a better than even chance that Greg is a frog. There is a better than even chance that Mary went to the kitchen. Chances are slight that if 'Lily is green' or 'Greg is a frog' or both then Julius is a lion. It is highly unlikely that if either 'Greg is a frog' or 'Lily is green' but not both then Emily is a sheep. It is probable that if 'Lily is green and Greg is a frog' then Brian is yellow.",
        "invalid"
    ],
    [
        0.35723164677619934,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '219'}",
        "['It is unclear why disease occurs in only a small proportion of persons carrying common risk alleles of disease susceptibility genes.', \"Here we demonstrate that an interaction between a specific virus infection and a mutation in the Crohn's disease susceptibility gene Atg16L1 induces intestinal pathologies in mice.\", 'This virus-plus-susceptibility gene interaction generated abnormalities in granule packaging and unique patterns of gene expression in Paneth cells.', \"Further, the response to injury induced by the toxic substance dextran sodium sulfate was fundamentally altered to include pathologies resembling aspects of Crohn's disease.\", 'These pathologies triggered by virus-plus-susceptibility gene interaction were dependent on TNFalpha and IFNgamma and were prevented by treatment with broad spectrum antibiotics.', 'Thus, we provide a specific example of how a virus-plus-susceptibility gene interaction can, in combination with additional environmental factors and commensal bacteria, determine the phenotype of hosts carrying common risk alleles for inflammatory disease.']",
        "False"
    ],
    [
        0.3572227905193965,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '583'}",
        "Chances are slight that 'Brian is a rhino' or 'Bernhard is a lion' or both.",
        "invalid"
    ],
    [
        0.35720349351565045,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '814'}",
        "Write an excellent summary of the given text.\n\nTitle: My best friend (Or who used to be my best friend) Barely talks to me anymore, What should i do?\n\nText: So A little more insight to my current situation:\n\nLast year i met a girl and we ended up being really good friends, at least that's what i thought. In about Novemember last year she started going out with one of my friends, which honestly i have no problem with, I only thought of her as a friends maybe a sister you get along with really well.\n\nBut this year things have started to go Not-so-well. First of all early this year i found out that her boyfriend, my friend, was a bit jealous because I'd use to go out to the cinema with her and some friends or she'd come over to my house just to hang out. \n\nSo since that moment I've Noticed that he doesn't leave her side. EVER. That means that whenever I want to invite her over to my house either she gets mad because she knows her boyfriends will get mad, or he comes out of nowhere and says they're busy.\n\nMe and her boyfriend have never really been that close, especially now since i think he hates me because all of this.\n\nNow we haven't hung out in about 10 months, and the fact that we haven't hung out in that much of a long time has got me down a lot. \nI really do not want to lose her, she was a lot of help to me when i was going through rough times and now i need help on what i should do.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35718729595343274,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '886'}",
        "Chances are slight that Greg is gray. We doubt that Brian is a swan. We believe that Daniel dropped the milk. It is almost certain that if 'Brian is a swan' or 'Daniel dropped the milk' or both then Sumit is thirsty. It is highly likely that if 'Greg is gray and Brian is a swan' then Gertrude is a sheep. There is little chance that if 'Greg is gray' or 'Daniel dropped the milk' or both then John went to the office.",
        "invalid"
    ],
    [
        0.35718520482381183,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '334'}",
        "Впрочем, дамам нравится: как и всякая современная сказка о Золушке, которая наконец находит своего принца",
        "correct"
    ],
    [
        0.35715370376904804,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '201'}",
        "It is probably not the case that Mary grabbed the milk. It is probably the case that Sandra dropped the milk. It is impossible that Lily is yellow. It is almost certain that if 'Sandra dropped the milk and Mary grabbed the milk' then Greg is a frog. We believe that if 'Lily is yellow' or 'Mary grabbed the milk' or both then Brian is a swan. It is unlikely that if 'Lily is yellow and Mary grabbed the milk' then Emily is a cat.",
        "invalid"
    ],
    [
        0.35710685948530835,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '433'}",
        "It is highly likely that Lily is a swan. It is highly unlikely that Daniel took the milk. It is improbable that Bernhard is green. We believe that if either 'Bernhard is green' or 'Lily is a swan' but not both then Brian is a frog. It is unlikely that if either 'Daniel took the milk' or 'Bernhard is green' but not both then Sandra got the football. We believe that if 'Lily is a swan and Daniel took the milk' then John dropped the apple.",
        "invalid"
    ],
    [
        0.3571052650610606,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '872'}",
        "حدود امتیاز: ۵ الی ۷  جیرانی همیشه فیلم ژانر رو دوست داره، با اینکه یه جاهایی بیرون می‌زنه و ریتم بسیار بسیار کندی داره ولی من خوشم اومد و هر کی بدش بیاد قطعا کلی دلیل منطقی داره که منم قبول دارم.",
        "کلی"
    ],
    [
        0.3570898175239563,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '532'}",
        "Write an excellent summary of the given text.\n\nTitle: How do I stop being overly attached? [26f]\n\nText: I feel like I'm overly attached to my boyfriend, who's 5 years younger than me. I NEVER used to be like this in previous relationships. \n\nI don't get to see him often. He works M, W, F, S, and goes to school TUES/THURS. He doesn't go out much at all and when he does he usually tells me and I have no problem with it (most of the time). He spends most of all his time at home just listening to music, watching tv, watching movies, etc. The problem is though, whenever I call him, which isn't alot he's so preoccupied in these other things that I'm just blabbing away while he's just \"oh\".. \"yea\"...\"mmhmmm\" and I hate it. Also when I text him, if he doesn't reply within 15 minutes or so I start to get worried. \n\nI freaking hate being like this. I used to be a trusting person to the point where you could cheat on me and I would never suspect a thing. I have problems trusting him, and I have absolutely no reason to. \n\nI feel I am overly attached and because of this I am frequently depressed/angry/sad/anxious etc. I also am wondering if the birth control I'm taking is amplifying my mood of being clingy, etc. I realized that I've been way more emotional while being on birth control than when I wasn't. I'm afraid my overly attached behavior is just going to push him away in the long run, although he assures me he isn't going anywhere and that he loves me. But he's only human and I know he'll only be able to take so much. \n\nI need advice on how to let things go (miniscule, unimportant issues) and quit being overly attached. I'm torn because I've never been this type of person and I hate it. I am also going to stop taking birth control tomorrow, maybe it will help with my moods.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35707273085912067,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '244'}",
        "\"Rundum perfekt wäre der kleine Player, wenn nicht dieses in meinen Augen scheußliche \\\\\"\"Kantendesign\\\\\"\" auf der Oberseite gewählt worden wäre, wodurch das Gerät praktisch nicht integrierbar ist, sondern gesondert oder als letztes von mehreren aufeinanderstehenden Komponenten positioniert werden muss.\"",
        "counterfactual"
    ],
    [
        0.35707273085912067,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '244'}",
        "\"Rundum perfekt wäre der kleine Player, wenn nicht dieses in meinen Augen scheußliche \\\\\"\"Kantendesign\\\\\"\" auf der Oberseite gewählt worden wäre, wodurch das Gerät praktisch nicht integrierbar ist, sondern gesondert oder als letztes von mehreren aufeinanderstehenden Komponenten positioniert werden muss.\"",
        "counterfactual"
    ],
    [
        0.3570402612288793,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'chegeka.raw', 'row_id': '209'}",
        "Александр Шелёмин, Тема 1, ... None",
        "чинара"
    ],
    [
        0.3570283353328705,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '870'}",
        "There is a better than even chance that Daniel dropped the milk. There is little chance that Julius is a lion. We doubt that Jeff left the apple. There is little chance that if 'Jeff left the apple' or 'Julius is a lion' or both then Lily is a rhino. There is a better than even chance that if 'Jeff left the apple and Julius is a lion' then Mary went to the bedroom. It is probably the case that if either 'Julius is a lion' or 'Jeff left the apple' but not both then Bernhard is a frog.",
        "invalid"
    ],
    [
        0.3570219576358795,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '42'}",
        "همیشه عطریشو میخرم ، برای تست گرفتم. عطر نداره ولی خوبه.",
        "طعم"
    ],
    [
        0.3570177952448527,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '291'}",
        "(1) В давние времена лев, который был королём трёх тысяч лесов, взял себе в жёны лису. (2) Вскоре у них родился сын, да такой, что и на лиса не похож, и львом его не назовёшь. (3) С виду он был вроде совсем как лев, да только, вместо того чтобы рычать по-львиному, лаял по-лисьи. (4) Когда сын стал подрастать, отец лев призвал его к себе и сказал: — Сын мой! (5) Ты велик и силён телом, но от своей матери лисы получил презренный голос. (6) В твоём голосе нет величия, и он не подобает моему царственному отпрыску. (7) Если звери услышат, как ты лаешь по-лисьи, они не станут с тобой считаться. (8) Поэтому уж лучше совсем помалкивай и не подавай голоса. (9) Тогда я смогу даровать тебе тысячу лесов. (10) Сын запомнил наставления льва. (11) Но однажды вышло так, что он их нарушил. (12) Как-то, когда собралось много зверей, сыну льва очень захотелось подать голос. (13) Он не выдержал и, забыв наказ отца, звонко залаял по-лисьи. (14) Среди зверей поднялся смех, когда они услыхали, как тоненько, по-лисьи лает такой большой и сильный зверь. (15) И тогда отец лев сказал ему: — Если бы ты, сынок, молчал, как я тебе наказывал,— получил бы тысячу лесов. (16) А теперь вижу, что ты не достоин этих лесов, раз не смог унять своей болтливости. (17) Так вот и не получил сын льва тысячи лесов, а люди с тех пор стали говорить: «Молчание — тысячи стоит».",
        "True"
    ],
    [
        0.3570177952448527,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '294'}",
        "(1) В давние времена лев, который был королём трёх тысяч лесов, взял себе в жёны лису. (2) Вскоре у них родился сын, да такой, что и на лиса не похож, и львом его не назовёшь. (3) С виду он был вроде совсем как лев, да только, вместо того чтобы рычать по-львиному, лаял по-лисьи. (4) Когда сын стал подрастать, отец лев призвал его к себе и сказал: — Сын мой! (5) Ты велик и силён телом, но от своей матери лисы получил презренный голос. (6) В твоём голосе нет величия, и он не подобает моему царственному отпрыску. (7) Если звери услышат, как ты лаешь по-лисьи, они не станут с тобой считаться. (8) Поэтому уж лучше совсем помалкивай и не подавай голоса. (9) Тогда я смогу даровать тебе тысячу лесов. (10) Сын запомнил наставления льва. (11) Но однажды вышло так, что он их нарушил. (12) Как-то, когда собралось много зверей, сыну льва очень захотелось подать голос. (13) Он не выдержал и, забыв наказ отца, звонко залаял по-лисьи. (14) Среди зверей поднялся смех, когда они услыхали, как тоненько, по-лисьи лает такой большой и сильный зверь. (15) И тогда отец лев сказал ему: — Если бы ты, сынок, молчал, как я тебе наказывал,— получил бы тысячу лесов. (16) А теперь вижу, что ты не достоин этих лесов, раз не смог унять своей болтливости. (17) Так вот и не получил сын льва тысячи лесов, а люди с тех пор стали говорить: «Молчание — тысячи стоит».",
        "True"
    ],
    [
        0.3570028096437454,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '916'}",
        "(1) Если вы думаете, что все разъяснилось и Элиза была оправдана в глазах общества, значит, вы не знаете его. (2) Для общества нет ничего приятнее обвинить какую-то женщину в измене, поверить себе и преследовать ее. (3) Княжна Мими обладала каким-то магнетизмом — поэтому присутствующие не верили глазам своим. (4) Им легче было подумать, что это мираж, дьявольское наваждение, чем то, что княжна обманулась, приняв старого барона за Границкого. (5) Тогда родилась неясная, в сущности нелепая мысль, что барон играл тут роль кума. (6) Постепенно все уверились в истинности этого предположения. (7) Настолько, что молодой барон, деверь Элизы и брат старого барона, друг Границкого, уже должен был выслушивать наставления от маркизы де Креки, своей тётушки. (8) Она нашла это знакомство странным, предосудительным, а самого Границкого, который нигде не служил, — подозрительным. (9) Она решительно взяла слово с племянника, что ради брата он выставит Границкого из дома. (10) Она сообщила ему о хитрой интриге, затеянной Границким с баронессою.",
        "False"
    ],
    [
        0.3569801102081935,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '348'}",
        "It is highly unlikely that 'Julius is a frog and Brian is a lion'.",
        "invalid"
    ],
    [
        0.356968233982722,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '841'}",
        "There is almost no chance that Mary grabbed the milk. It is probable that Bernhard is green. It is certain that Lily is a lion. Chances are slight that if either 'Lily is a lion' or 'Bernhard is green' but not both then Brian is yellow. There is a better than even chance that if either 'Lily is a lion' or 'Mary grabbed the milk' but not both then John went to the garden. It is highly unlikely that if either 'Bernhard is green' or 'Mary grabbed the milk' but not both then Julius is a frog.",
        "invalid"
    ],
    [
        0.35696261872847873,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '63'}",
        "اصلا خوشمزه نیست. اگر گوشت داشته باشه، خیلی کمه. بیشترش بنظرم جیگر سفید و آشغال گوشته",
        "طعم"
    ],
    [
        0.35695689419905346,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '616'}",
        "رو کالا نوشته تخم مرغ رسمی اصلا رسمی نیست فقط پوستش قهوه ایه اطلاعات غلطه فقط یکدستو یک انذازه و مرتبه همین",
        "طعم"
    ],
    [
        0.35691260049740475,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '413'}",
        "نظر شما در مورد عطر، بو، و طعم این تن ماهی چیست؟",
        "طعم"
    ],
    [
        0.35691260049740475,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '784'}",
        "نظر شما در مورد عطر، بو، و طعم این تن ماهی چیست؟",
        "طعم"
    ],
    [
        0.35687122245629627,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '292'}",
        "It is impossible that either 'Brian is white' or 'John took the apple' but not both.",
        "invalid"
    ],
    [
        0.35686347881952923,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '683'}",
        "This well written and well researched piece could have been a fantastic service for readers, one of the few stories we’ve seen to examine the medicinal claims being made by cosmetic companies for their products. Instead, it takes its cues from the same marketing it purports to examine. The story deserves credit for asking tough questions, but it should have dug deeper.It should have relied less on the cosmetic industry and its contract research organizations and more on independent experts. There are new “cures” for aging being pitched at the graying population every week, and the skin creams, laser therapies and other treatments can cost thousands with limited proof of long-term benefit. Stories that take on these claims deserve a round of applause. We hope, though, that more stories take a hard look at the way the “evidence” for these therapies is being generated and perhaps manipulated to serve a marketing aim.",
        "false"
    ],
    [
        0.35682174066702527,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '72'}",
        "It is highly unlikely that Julius is a frog. Chances are about even that Lily is yellow. It is improbable that Fred left the football. Chances are slight that if 'Lily is yellow' or 'Fred left the football' or both then Bernhard is green. It is probably the case that if either 'Fred left the football' or 'Lily is yellow' but not both then Bill went to the bedroom. It is unlikely that if either 'Lily is yellow' or 'Fred left the football' but not both then Brian is white.",
        "invalid"
    ],
    [
        0.35681183139483136,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '783'}",
        "Write an excellent summary of the given text.\n\nTitle: I live with two roommates who fuck each other. They have 4 dogs and a cat between them. I have a separate bathroom, but the cat shits in my shower and the dogs piss all over the bathroom floor. What do I do?\n\nText: To be fair, we are all good friends. This isn't the typical \"I fucking hate my roommates\" cry for help. Although, laziness is definitely a factor. In the past, its taken over a week for one of them to take care of similar messes. I can deal with the living room and the kitchen cuz I'm barely ever here, but my bedroom and bathroom are not negotiable. I previously had a problem with the dogs in my room, but that ended when I threatened to piss on the corner of their bed if it happens to mine again. \n\nMine is the hallway bathroom, so it gets used by everyone. This also means that the bathroom door gets left open. As I said before, we DO in fact all get along, so doing something like putting a lock on my bathroom door wouldn't do much except maybe make me piss my pants one day when I can't find the key. \n\nThe female roommate says she will cut my dick off in my sleep if I take a shit in their shower, which in translation means it will probably spawn an argument or two. The male roommate (who's mom owns the house) could give a shit if it sat there as if it were just how the tile is supposed to look.\n\nI'm lost Reddit.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35679514706134796,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '205'}",
        "\"During a recent appearance on The Daily Show, guest host John Oliver and Sen. Rand Paul, R-Ky., engaged in a lively exchange on health insurance and why people buy it or not. Paul, an eye surgeon, is strongly opposed to President Barack Obama’s health care law. During the interview, Oliver pressed him on how to get more Americans signed up for insurance. Paul indicated that the biggest issue is affordability, particularly for young, healthy and relatively affluent people. According to the most recent statistics, he said, \"\"85 percent of people had insurance, so 15 percent didn't. So what you need to do is look at who are the 15 percent, and why don't they have insurance? Of the 15 percent who didn't have insurance, half of them made more than $50,000 a year. Why didn't they buy insurance? Because of the expense. They were young healthy people.\"\" In this fact-check, we’ll check his claim that half of the uninsured made more than $50,000 a year. In a separate report, we’ll look at whether the cost of insurance is the biggest barrier to uninsured Americans. We’ll start by noting that Paul is very close to the mark when he says 15 percent of Americans don’t have insurance. The most recent Census Bureau statistics for 2011 show that 15.7 percent of Americans are uninsured. What about the income breakdown for that 15 percent? There are a few different ways to slice the data, but none produces a number for $50,000-plus earners that reaches the 50 percent level Paul offered on The Daily Show. In a September 2012 paper, the Employee Benefits Research Institute looked at 2011 census data on health coverage. It found that 28 percent of the uninsured earned at least $50,000. That’s quite a bit lower than what Paul had indicated. The highest plausible percentage cited by our experts -- who included both liberals and conservatives -- used census data for households rather than for individuals. Using this method, 37.5 percent of the uninsured live in a household with an income above $50,000. Why the variation between household and individual data? Uninsured young adults who are roommates might live in a household where all roommates collectively make more than $50,000, even if each roommate individually earns much less. This type of living arrangement tends to boost the count of uninsured adults who \"\"earn\"\" more than $50,000, even if they really don’t make that much individually. This difference in counting methods matters in this sort of statistical comparison because people without health insurance \"\"are more likely to be living in less-common housing arrangements -- more in multi-generation families, more living with people who aren't related to them,\"\" said Hanns Kuttner, a senior fellow at the Hudson Institute. When we showed our calculations to Paul’s office, communications director Moira Bagley said there’s significant uncertainty in the Census data due to \"\"inexact data collection\"\" that \"\"under-reports the numbers of people who actually have health insurance.\"\" This refers to an argument made by some critics of Obamacare that the Census Bureau undercounts Medicaid recipients compared to the total cited by the Centers for Medicare and Medicaid Services. Subtracting these uncounted Medicaid recipients leaves the pool of uninsured Americans relatively better off. However, each of the seven ideologically diverse health policy experts we talked to for this story used the census numbers when we asked them to evaluate Paul's claim, and none expressed concerns about the ability of the census data to fairly evaluate the question. Our ruling Paul said that of the roughly 15 percent of Americans who don’t have health insurance, \"\"half of them made more than $50,000 a year.\"\" In reality, if you measure what individuals make, Census data shows that 28 percent of uninsured Americans earn $50,000. By another measure, using household income, almost 38 percent of uninsured Americans earn at least $50,000. Both of these figures are pretty far from the 50 percent Paul cited in the interview.\"",
        "false"
    ],
    [
        0.3567847857872645,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '700'}",
        "There is little chance that Winona is a cat. It is impossible that Mary took the football. It is highly unlikely that Greg is green. There is almost no chance that if 'Mary took the football' or 'Greg is green' or both then Lily is a rhino. It is probable that if either 'Winona is a cat' or 'Greg is green' but not both then Bernhard is a frog. It is certain that if 'Mary took the football and Winona is a cat' then Julius is white.",
        "invalid"
    ],
    [
        0.35676181813081104,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '220'}",
        "Во всех взглядах можно прочитать одну мысль ― думу о земле, которая в такую горячую вешнюю пору сиротеет где-нибудь за тысячу верст",
        "correct"
    ],
    [
        0.35675552984078723,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '23'}",
        "неизбежности",
        "correct"
    ],
    [
        0.35675552984078723,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '309'}",
        "неизбежности",
        "correct"
    ],
    [
        0.35675278802712757,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'danetqa', 'row_id': '464'}",
        "− Когда говорят, что в угоду директору станции или главному инженеру Дятлов мог проигнорировать принципы безопасности, дать указания отключить защиты реактора или нарушить инструкции, я этому никогда не поверю. Он мог понять ошибки, допущенные персоналом, если они аргументированы, но он абсолютно не мог принять разгильдяйства, некомпетентности и халатного отношения к своим обязанностям. А. С., как правило, отличали прямота, четкость и краткость изложения своей позиции, а это не всегда шло ему на пользу. Характерной чертой его характера было патологическое непринятие всякой неправды и лжи. В мини-сериале HBO «Чернобыль»  роль Дятлова сыграл Пол Риттер, а в фильме BBC 2006 года «Пережить катастрофу: Чернобыльская ядерная катастрофа»  — Роджер Алборо.",
        "False"
    ],
    [
        0.35674921174844104,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '287'}",
        "The lead author of the study is quoted as saying “The lamp we’re using at the moment costs less than $1,000, and you can imagine that if it were put into general circulation, the price would drop dramatically … we don’t see cost as being a limited factor here.” The first part of the quote gives a frame of reference, though “less than $1,000” is somewhat ambiguous. The second part also is speculative, so this is a barely passing satisfactory. We’re told: “… aerosolized particles of the H1N1 seasonal flu virus were released into a test chamber and exposed to very low doses of far-UVC light. The light inactivated the viruses with about the same efficiency as conventional germicidal UV light, while a control group of bacteria, not exposed to light, remained active.” We’re also told previous studies by the same authors have shown that far-UVC light “can kill MRSA bacteria, a common cause of infections after surgery.” However, it would be helpful to have data to support these claims, but that’s not provided. No harms of far-UVC light are mentioned; in fact, in the opening sentence we read:  “researchers have developed an ultraviolet (UV) lamp that kills influenza virus but isn’t harmful to human skin or eyes….” But, again, we’re given no data regarding safety. We are not told if the previous skin or eye studies (which we’re told prove the safety of this approach) were done in the laboratory or on real humans. The limitations of this in vitro study are not discussed. We’re not told what percent of the viruses were killed. Nor do we get any sense of whether findings from a test chamber can be applied to large public spaces as the story headline implies. In the published study the lead author cautions that the results need to be “confirmed in other scenarios.” It would have helped readers to include this. No disease mongering. The lead author of the story is the only source cited, and we’re not told if he has any conflicts of interest. The HealthDay story we reviewed rated better on this criteria. No mention is made that there is no cure for any of the strains of influenza virus and, therefore, most interventions focus solely on prevention and symptom management. This is important information to include when both your opening and closing paragraphs imply the far-UVC light studied might prevent the spread of the flu in public places. This is a just passing satisfactory–it’s implied that the product is not available yet, because the story mentioned the lead author “is working with a company to develop a commercially available version of the lamp.” It is made clear the authors have studied this type of light in killing methicillin-resistant staph. aureus (MRSA), but it’s not clear if the current study is the first to apply far-UVC light to an influenza virus (in the published study the authors claim this is the first time far-UVC light has been assessed for inactivating aerosolized viruses). While the story didn’t offer much more than what was stated in the news release, it does appear to contain original quotes.",
        "false"
    ],
    [
        0.3567417959372203,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '918'}",
        "\"\"\"Never\"\" is a strong word, yet Lavelle claimed he is a not a conspiracy theorist and has \"\"never allowed a conspiracy theorist on his show.\"\" We’ll agree there is a somewhat subjective definition of what constitutes a conspiracy theory. But we think of the four we quickly found -- Ukraine downed MH 17 to drum up sympathy, AIDS drugs are what are killings AIDS patients, 9/11 was an inside job, and an assistant secretary of state devised a plan to break-up Ukraine -- at least one would fit most people’s definition of a conspiracy theory. Lavelle’s hypothesis about MH 17, we should note, was uttered in the breaths after saying he doesn’t allow conspiracy theories on his show.\"",
        "false"
    ],
    [
        0.35669360558191937,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train23_test2to10', 'row_id': '721'}",
        "[Ellis] called his brother [Anthony] on Friday because it was his birthday. [James] was proud of his son, [Lee]. [Ellis] and [Lee] are brothers who look nothing alike.",
        "son"
    ],
    [
        0.3566887030998866,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '506'}",
        "It is certain that Emily is a cat. We believe that Julius is a rhino. It is highly unlikely that John discarded the apple. It is probably not the case that if 'Julius is a rhino and Emily is a cat' then Sumit is hungry. It is improbable that if either 'Emily is a cat' or 'Julius is a rhino' but not both then Greg is a frog. It is certain that if 'Julius is a rhino and Emily is a cat' then Gertrude is a mouse.",
        "invalid"
    ],
    [
        0.3566616624593735,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '44'}",
        "There is a better than even chance that Fred left the football. It is almost certain that Brian is green. It is highly likely that Lily is a swan. It is highly likely that if either 'Brian is green' or 'Lily is a swan' but not both then Gertrude is a cat. It is impossible that if either 'Fred left the football' or 'Lily is a swan' but not both then Mary went to the office. It is probably not the case that if either 'Fred left the football' or 'Brian is green' but not both then Daniel took the apple.",
        "invalid"
    ],
    [
        0.35666143397490185,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '979'}",
        "It is likely that Lily is white. We believe that Brian is a swan. There is almost no chance that Sandra left the football. Chances are slight that if either 'Sandra left the football' or 'Lily is white' but not both then Gertrude is a mouse. It is probably not the case that if 'Brian is a swan' or 'Sandra left the football' or both then Sumit is thirsty. It is almost certain that if either 'Brian is a swan' or 'Sandra left the football' but not both then John moved to the garden.",
        "invalid"
    ],
    [
        0.35665244857470196,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '542'}",
        "['Лайнер', 'рейс']",
        "correct"
    ],
    [
        0.356642946600914,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '339'}",
        "It is probably not the case that 'Brian is a rhino' or 'Bernhard is white' or both.",
        "invalid"
    ],
    [
        0.3566008359193802,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '118'}",
        "'Brian is a rhino' or 'Julius is a swan' or both.",
        "invalid"
    ],
    [
        0.3565687984228134,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '628'}",
        "It is probably not the case that Jessica is a cat. There is a very good chance that Julius is gray. Chances are slight that Bernhard is a swan. It is almost certain that if either 'Jessica is a cat' or 'Bernhard is a swan' but not both then Daniel took the apple. There is a better than even chance that if 'Julius is gray and Bernhard is a swan' then Lily is a lion. There is a very good chance that if either 'Julius is gray' or 'Jessica is a cat' but not both then John went to the hallway.",
        "invalid"
    ],
    [
        0.3565417528152466,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '80'}",
        "['Most genes affect many traits.', 'This phenomenon, known as pleiotropy, is a major constraint on evolution because adaptive change in one trait may be prevented because it would compromise other traits affected by the same genes.', 'Here we show that pleiotropy can have an unexpected effect and benefit one of the most enigmatic of adaptations—cooperation.', 'A spectacular act of cooperation occurs in the social amoeba Dictyostelium discoideum, in which some cells die to form a stalk that holds the other cells aloft as reproductive spores.', 'We have identified a gene, dimA, in D. discoideum that has two contrasting effects.', 'It is required to receive the signalling molecule DIF-1 that causes differentiation into prestalk cells.', 'Ignoring DIF-1 and not becoming prestalk should allow cells to cheat by avoiding the stalk.', 'However, we find that in aggregations containing the wild-type cells, lack of the dimA gene results in exclusion from spores.', 'This pleiotropic linkage of stalk and spore formation limits the potential for cheating in D. discoideum because defecting on prestalk cell production results in an even greater reduction in spores.', 'We propose that the evolution of pleiotropic links between cheating and personal costs can stabilize cooperative adaptations.']",
        "False"
    ],
    [
        0.35654038687547046,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '235'}",
        "И спрашивал государь Сегестета о артилерии, которой объявил, что их дацкая артилерия готова, толко пока не будет саксонская артилерия, то он дацкой без указу короля своего отдать не смеет",
        "correct"
    ],
    [
        0.3565218696991603,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '837'}",
        "It is unlikely that Winona is a sheep. It is highly likely that Sandra put down the milk. We doubt that Lily is green. Chances are slight that if 'Lily is green and Sandra put down the milk' then Brian is a swan. It is probably not the case that if either 'Winona is a sheep' or 'Lily is green' but not both then Gertrude is a sheep. There is a better than even chance that if 'Lily is green and Winona is a sheep' then Mary left the apple.",
        "invalid"
    ],
    [
        0.3564974144101143,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '72'}",
        "«вертолет, по предварительным данным, наняла семья из москвы, которая летела в нижний новгород», — рассказали представители правоохранительных органах региона",
        "correct"
    ],
    [
        0.3564832458893458,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '226'}",
        "It is impossible that either 'Greg is a swan' or 'Winona is a mouse' but not both.",
        "invalid"
    ],
    [
        0.35645415385564166,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '182'}",
        "Write an excellent summary of the given text.\n\nTitle: Me [23F] with [24M] for half a year and some, how can we be more in sync?\n\nText: We've (myself, 23F and him 24M) been dating for about half a year now, and dated for a year and a half a year ago. We currently have a solid relationship. But it seems like we have trouble being in sync and understanding each other at times (that wasn't a problem at the beginning of the second relationship).\n\nI feel like a lot of the time, if I approach my boyfriend in a gushy/loving way and he doesn't react or shows no interest, I will take time to myself in order to not feel rejected and just do my thing. If he does approach me on his own later on, I will typically have tried to detach myself from the situation and will come off as mad and have trouble genuinely reacting to his affection. Which leads to confusion on both parts. I feel like we do not show this kind of behavior at the same time and as such one of us always feels rejected or unloved, which is absolutely not the case. I love him dearly and I know he loves me too. \n\nDoes anyone have tips on how we can resolve this? I am aware I probably have a lot of work to do on myself so I won't clam up when he is available and showing me affection, but I can't help but feel like it's unfair for me to be rejected yet have to be in a great mood when he does decide to approach me. But at the same time I just want us to be happier together so I am willing to work on it. I'm expecting for commenters to say it's my problem to deal with.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35641156136989594,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '945'}",
        "There is little chance that Brian is gray. Chances are about even that Jason is tired. There is a better than even chance that Julius is a frog. It is highly likely that if either 'Julius is a frog' or 'Jason is tired' but not both then Greg is white. It is probably not the case that if 'Julius is a frog and Brian is gray' then Daniel put down the milk. There is a better than even chance that if 'Jason is tired and Julius is a frog' then Bill went to the garden.",
        "invalid"
    ],
    [
        0.3563993026812871,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '298'}",
        "Широкая дискуссия, о необходимости которой так упорно говорил г-н Титов, показалась однопартийцам ненужной, а быть может, и опасной",
        "correct"
    ],
    [
        0.35639876623948413,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '56'}",
        "It is likely that Greg is a swan. Chances are about even that Mary grabbed the milk. There is almost no chance that Bernhard is a frog. It is unlikely that if 'Bernhard is a frog and Mary grabbed the milk' then John went to the office. It is certain that if 'Mary grabbed the milk' or 'Bernhard is a frog' or both then Jessica is a cat. It is impossible that if either 'Mary grabbed the milk' or 'Bernhard is a frog' but not both then Lily is a lion.",
        "invalid"
    ],
    [
        0.35632627209027606,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '936'}",
        "It is probably not the case that Greg is a lion. We doubt that Bernhard is yellow. There is little chance that Jason is thirsty. It is likely that if either 'Bernhard is yellow' or 'Jason is thirsty' but not both then John picked up the milk. It is unlikely that if 'Jason is thirsty and Greg is a lion' then Mary moved to the garden. We doubt that if either 'Bernhard is yellow' or 'Greg is a lion' but not both then Brian is yellow.",
        "invalid"
    ],
    [
        0.35632456342379254,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '633'}",
        "Chances are slight that either 'Bernhard is a rhino' or 'Greg is a lion' but not both.",
        "invalid"
    ],
    [
        0.35631509125232697,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '113'}",
        "It is almost certain that Mary picked up the apple. It is likely that Julius is a swan. We doubt that Greg is yellow. It is improbable that if either 'Julius is a swan' or 'Mary picked up the apple' but not both then Sumit is thirsty. It is impossible that if either 'Julius is a swan' or 'Mary picked up the apple' but not both then Bernhard is a frog. Chances are slight that if either 'Greg is yellow' or 'Julius is a swan' but not both then Sandra left the milk.",
        "invalid"
    ],
    [
        0.3563007066647212,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '580'}",
        "It is highly unlikely that either 'Lily is a lion' or 'Jeff left the apple' but not both.",
        "invalid"
    ],
    [
        0.35628657042980194,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '25'}",
        "It is probably the case that 'Brian is white' or 'Bernhard is a lion' or both.",
        "invalid"
    ],
    [
        0.35625427464644116,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '833'}",
        "We believe that Greg is a swan. It is unlikely that Sandra took the apple. It is certain that Brian is a frog. There is a very good chance that if either 'Greg is a swan' or 'Sandra took the apple' but not both then Bernhard is green. It is highly unlikely that if 'Brian is a frog' or 'Greg is a swan' or both then Jeff discarded the milk. There is little chance that if 'Greg is a swan and Brian is a frog' then Mary dropped the milk.",
        "invalid"
    ],
    [
        0.3561934729417165,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '794'}",
        "It is probable that Mary picked up the milk. We doubt that John dropped the apple. It is impossible that Julius is a frog. Chances are slight that if 'Mary picked up the milk' or 'John dropped the apple' or both then Greg is a lion. It is improbable that if 'Mary picked up the milk' or 'John dropped the apple' or both then Daniel took the football. It is impossible that if 'Julius is a frog and Mary picked up the milk' then Lily is yellow.",
        "invalid"
    ],
    [
        0.35616926848888397,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '686'}",
        "['времена', 'браки', 'родители']",
        "correct"
    ],
    [
        0.3561662286520004,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '964'}",
        "It is almost certain that Bernhard is a swan. It is probable that Gertrude is a sheep. We believe that John moved to the garden. It is certain that if either 'John moved to the garden' or 'Gertrude is a sheep' but not both then Brian is white. It is unlikely that if either 'Gertrude is a sheep' or 'Bernhard is a swan' but not both then Winona is a wolf. It is impossible that if 'Bernhard is a swan and Gertrude is a sheep' then Lily is a rhino.",
        "invalid"
    ],
    [
        0.3561660796403885,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '933'}",
        "Write an excellent summary of the given text.\n\nTitle: My BF (25m) and I (23f) are having bed issues - at a stalemate.\n\nText: BF=bob\nSo this is a ridiculous question but we can't seem to come up with a solution. \n\nI spend weekends at bob's apartment, during the week I live at home with my parents to save money because my city is outrageously expensive. \n\nLast october, bob's bed broke. It was old and the frame collapsed and the middle was all sunken anyways. His parent's got him a new bed for his birthday. It isn't the bed he had suggested. His dad went out and bought the firmest mattress at costco. We were laying on it that first night and at 3am he finally rolled over and said we were going to walmart to get an air mattress because the bed was so fucking painful to sleep on. We told his parents. They got us two toppers for it. \n\nFor him, it's better. For me I always wake up with an incredibly sore back. We tried a third topper on top of the other two. Not great and expensive. He suggested he buy a new mattress but this one was a gift from his parents and brand new. It is too late to exchange it. My idea was to maybe buy a cheap but comfortable twin mattress and push it up against his, but that also sounds ridiculous. My back hurts and it's getting irritating but since I'm only there on the weekends, I don't feel I have any right to tell him what to do with his bed. What do?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3561432907978694,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '340'}",
        "We believe that Greg is a swan. It is probably not the case that Daniel dropped the apple. It is almost certain that Bernhard is a swan. It is almost certain that if 'Greg is a swan and Daniel dropped the apple' then Julius is yellow. We doubt that if 'Greg is a swan' or 'Daniel dropped the apple' or both then Lily is a rhino. It is highly unlikely that if 'Greg is a swan and Bernhard is a swan' then Mary went to the garden.",
        "invalid"
    ],
    [
        0.35610027114550274,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '6'}",
        "اگه نوشیدنی مالته باید تلخ باشه نه اینکه شیرین از خریدم کاملا پشیمونم و ب هیچ کسم پیشنهاد نمیکنم ک بخره چون پشیمون میشید تو عمرم با همچین نوشیدنی بر نخورده بودم",
        "نوشابه"
    ],
    [
        0.35609575112660724,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '617'}",
        "The title pretty much says it all (and I apologize profusely if this isn't the right forum in which to ask about this), but: I'm pretty interested in this guy, and I want our coffee date to go well, and then, you know, whatever happens after that. I feel bad, though, because I was tipsy when I called him. Should I admit that to him when I meet him for our date? I've not told him yet whether I drink or not, so he presumably has no preconceived notions of my habits. I feel bad withholding that information considering he may have some stance against drinking, but I also don't want to ruin anything pleasant before it begins.",
        "Accuracy"
    ],
    [
        0.3560602317253749,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '936'}",
        "Montresor lures Fortunato into a private wine - tasting excursion by telling him he has obtained a pipe ( about 130 gallons , 492 litres ) of what he believes to be a rare vintage of Amontillado . He proposes obtaining confirmation of the pipe 's contents by inviting a fellow wine aficionado , Luchesi , for a private tasting . Montresor knows Fortunato will not be able to resist demonstrating his discerning palate for wine and will insist that he taste the amontillado rather than Luchesi who , as he claims , `` can not tell Amontillado from Sherry '' . Fortunato goes with Montresor to the wine cellars of the latter 's palazzo , where they wander in the catacombs . Montresor offers wine ( first Medoc , then De Grave ) to Fortunato in order to keep him inebriated . Montresor warns Fortunato , who has a bad cough , of the dampness , and suggests they go back , but Fortunato insists on continuing , claiming that `` ( he ) shall not die of a cough '' . During their walk , Montresor mentions his family coat of arms : a golden foot in a blue background crushing a snake whose fangs are embedded in the foot 's heel , with the motto Nemo me impune lacessit ( `` No one attacks me with impunity '' ) .",
        ""
    ],
    [
        0.3560597747564316,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '918'}",
        "It is highly unlikely that Emily is a sheep. There is a better than even chance that Greg is a rhino. It is highly likely that Sumit is thirsty. It is likely that if 'Sumit is thirsty and Greg is a rhino' then Julius is yellow. There is almost no chance that if either 'Greg is a rhino' or 'Emily is a sheep' but not both then Daniel left the milk. It is highly unlikely that if 'Emily is a sheep' or 'Greg is a rhino' or both then Lily is a rhino.",
        "invalid"
    ],
    [
        0.35601908961931866,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '388'}",
        "متاسفانه اصلا مزه مناسبی نداشت. و خیلی هم مزه لیمو نعنا نمیداد. انگار همش اسانس و طعم دهنده مصنوعی داشت",
        "نوشابه"
    ],
    [
        0.355964000026385,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '820'}",
        "There is almost no chance that Winona is a mouse. We doubt that Julius is gray. It is probably the case that John dropped the milk. There is a better than even chance that if 'Julius is gray and Winona is a mouse' then Bill went to the kitchen. There is a very good chance that if 'John dropped the milk and Julius is gray' then Greg is a swan. It is almost certain that if 'John dropped the milk and Winona is a mouse' then Brian is yellow.",
        "invalid"
    ],
    [
        0.35588620603084564,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '830'}",
        "It is improbable that either 'Lily is a rhino' or 'Brian is green' but not both.",
        "invalid"
    ],
    [
        0.35588538149992627,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '858'}",
        "The summary is inaccurate; no one at the school knows about it.",
        "Accuracy"
    ],
    [
        0.3558744291464488,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '39'}",
        "Та единственная, амино-нуклеиново-кислотная форма жизни, которую мы знаем, без воды существовать не может",
        "correct"
    ],
    [
        0.3558744291464488,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '485'}",
        "Та единственная, амино-нуклеиново-кислотная форма жизни, которую мы знаем, без воды существовать не может",
        "correct"
    ],
    [
        0.35585571080446243,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '140'}",
        "مزه جالبی نداشت با این قیمت بالا خریدش اصلا به صرفه نیست ظاهرا پول بسته بندی جالبش را میدهید که آنهم خیلی گران حساب شده",
        "طعم"
    ],
    [
        0.35580839216709137,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '723'}",
        "There is little chance that Jason is bored. It is almost certain that Winona is a wolf. It is impossible that John moved to the garden. It is highly likely that if 'John moved to the garden and Jason is bored' then Fred put down the apple. It is highly likely that if either 'Jason is bored' or 'Winona is a wolf' but not both then Lily is a lion. It is unlikely that if 'Winona is a wolf' or 'Jason is bored' or both then Greg is white.",
        "invalid"
    ],
    [
        0.3557678610086441,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '555'}",
        "It is probably not the case that either 'Greg is a frog' or 'Bernhard is a rhino' but not both.",
        "invalid"
    ],
    [
        0.3557179719209671,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '535'}",
        "['философия', 'математики']",
        "correct"
    ],
    [
        0.3557061751683553,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '459'}",
        "ar van is, juist 1 zooals de wet den slavenhouder zei dat hij den' 𝙨𝙡𝙖𝙖𝙛 in eigendom had.\"• : Het zal niet moeilijk zijn de dwaasheid dezer",
        "𝙨𝙡𝙖𝙖𝙛"
    ],
    [
        0.35566893219947815,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '30'}",
        "['There is strong evidence for a genetic contribution to epilepsy, but it is commonly assumed that this genetic contribution is limited to ‘generalized’ epilepsies, and that most forms of ‘partial’ epilepsy are nongenetic.', 'In a linkage analysis of a single family containing 11 affected individuals, we obtained strong evidence for localization of a gene for partial epilepsy.', 'This susceptibility gene maps to chromosome 10q, with a maximum two–point lod score for D10S192 of 3.99 at θ=0.0.', 'All affected individuals share a single haplotype for seven tightly linked contiguous markers; the maximum lod score for this haplotype is 4.83 at θ=0.0.', 'Key recombinants place the susceptibility locus within a 10 centimorgan interval.']",
        "False"
    ],
    [
        0.3556643674770991,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '386'}",
        "It is probable that Greg is yellow. It is impossible that Brian is a rhino. Chances are slight that Jeff went to the hallway. There is almost no chance that if either 'Greg is yellow' or 'Brian is a rhino' but not both then Lily is yellow. It is certain that if 'Jeff went to the hallway' or 'Greg is yellow' or both then Bernhard is gray. It is almost certain that if 'Jeff went to the hallway' or 'Brian is a rhino' or both then Emily is a sheep.",
        "invalid"
    ],
    [
        0.355641429622968,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '792'}",
        "We believe that Emily is a wolf. Chances are about even that Bernhard is a lion. There is a better than even chance that Daniel put down the milk. We doubt that if 'Emily is a wolf and Daniel put down the milk' then Brian is a frog. It is certain that if either 'Emily is a wolf' or 'Daniel put down the milk' but not both then Julius is white. It is likely that if 'Emily is a wolf and Bernhard is a lion' then John took the football.",
        "invalid"
    ],
    [
        0.35560689369837445,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '525'}",
        "\"Was sich dem Zuschauer hingegen hier bietet, reicht bei chronischem Denkorgan-Standby zwar noch für die Kategorie \\\\\"\"Durchschnitt\\\\\"\" - kommt aber nicht ohne den bedauernden Vermerk aus, dass in vielerlei Hinsicht einiges mehr drin gewesen wäre.\"",
        "counterfactual"
    ],
    [
        0.35560689369837445,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '525'}",
        "\"Was sich dem Zuschauer hingegen hier bietet, reicht bei chronischem Denkorgan-Standby zwar noch für die Kategorie \\\\\"\"Durchschnitt\\\\\"\" - kommt aber nicht ohne den bedauernden Vermerk aus, dass in vielerlei Hinsicht einiges mehr drin gewesen wäre.\"",
        "counterfactual"
    ],
    [
        0.3555961896975835,
        "{'dataset_id': 'blended_skill_talk', 'config_id': 'default', 'row_id': '900'}",
        "['You should use soap, a loofah, shampoo, and some conditioner.', 'I think it also helps prevent dermatitis as well', 'Thats good cause some people are bald and wish they had hair.', 'Yeah, But its genetics so what are you going to do :/', \"I'm sure that is better than having complete baldness or hair loss.\", \"I do, but I'm not sure if I would want an unending existence.\"]",
        ""
    ],
    [
        0.35556285579999286,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '326'}",
        "It is probably not the case that either 'Jeff discarded the milk' or 'Brian is a swan' but not both.",
        "invalid"
    ],
    [
        0.355539138118426,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '42'}",
        "The summary says that the couple is struggling but in the post it’s just the user that seems to be struggling with the idea of Skype flirting being considered cheating or not.",
        "Accuracy"
    ],
    [
        0.355529248714447,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '424'}",
        "\"Ray Winstone ist nicht schlecht, aber recht generisch und seine Rolle hätte auch jeder andere Hollywood \\\\\"\"Antiheld\\\\\"\" übernehmen können.\"",
        "counterfactual"
    ],
    [
        0.355529248714447,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '424'}",
        "\"Ray Winstone ist nicht schlecht, aber recht generisch und seine Rolle hätte auch jeder andere Hollywood \\\\\"\"Antiheld\\\\\"\" übernehmen können.\"",
        "counterfactual"
    ],
    [
        0.35549935698509216,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '384'}",
        "Chances are slight that Greg is a swan. There is almost no chance that John got the milk. It is highly unlikely that Winona is a mouse. There is a better than even chance that if 'Greg is a swan and John got the milk' then Bill moved to the office. It is probably not the case that if 'John got the milk and Greg is a swan' then Julius is gray. It is highly likely that if 'John got the milk and Winona is a mouse' then Gertrude is a sheep.",
        "invalid"
    ],
    [
        0.35547901690006256,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '715'}",
        "There is little chance that Fred left the football. It is highly unlikely that Julius is white. It is highly likely that Daniel grabbed the milk. It is improbable that if 'Julius is white' or 'Fred left the football' or both then Emily is a cat. It is probably the case that if either 'Fred left the football' or 'Julius is white' but not both then Lily is a lion. Chances are about even that if 'Julius is white and Fred left the football' then Brian is yellow.",
        "invalid"
    ],
    [
        0.355433647831281,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '786'}",
        "It is certain that Mary left the football. It is highly unlikely that John moved to the office. There is almost no chance that Julius is a lion. It is impossible that if 'Julius is a lion' or 'John moved to the office' or both then Yann is thirsty. It is highly likely that if 'Mary left the football' or 'Julius is a lion' or both then Greg is a swan. It is probably not the case that if 'Julius is a lion' or 'John moved to the office' or both then Daniel put down the milk.",
        "invalid"
    ],
    [
        0.3554188907146454,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '752'}",
        "The histories of a number of popular consumer items have been rumored to have at least tenuous connections with certain unsavory elements. Contemporary lore is rife with product rumors that assert ties to the Ku Klux Klan (e.g., Marlboro cigarettes, Snapple fruit drinks, KFC, Troop clothing, Tropical Fantasy fruit drink) and the Nazis (e.g., Coors beer), groups mainstream American society views as evil. Such rumors are wholly without substance. Of all the product rumors of this class, only those associating the soft drink Fanta with Nazi Germany have anything to them, and even then, the truth of the matter is far more innocuous than the whispers. We’ve seen the Fanta/Nazi rumor rendered a number of ways, including: It is the last that is closest to the truth; the other three are naught but canard. Prior to the outbreak of the second world war, Coca-Cola’s only unqualified success on the international scene was its bottling operations in Nazi Germany. Sales records were being set year after year in that venue, and by 1939 Coca-Cola had 43 bottling plants and more than 600 local distributors in that country. However, the war was about to change that. As the inevitable clash loomed ever closer, obtaining the key ingredients necessary for the production of Coca-Cola syrup became increasingly difficult in Germany, grinding production towards a standstill. In 1938, the man in charge of Coca-Cola’s operations in Germany, American-born Ray Powers, died of injuries received in an automobile accident. His right-hand man, German-born Max Keith, took over: Meanwhile, the German government placed Max Keith in charge of Coca-Cola’s properties in the occupied countries, and he sent word through Coca-Cola’s bottler in neutral Switzerland that he would try to keep the enterprises alive. But with no means of getting ingredients, Keith stopped making Coca-Cola and began marketing an entirely new soft drink he called Fanta, a light-colored beverage that resembled ginger ale. [Allen, 1994] Fanta came by its name thanks to Keith’s instructions to employees during the contest to christen the beverage — he told them to let their Fantasie [Geman for fantasy] run wild. Upon hearing that, veteran salesman Joe Knipp immediately blurted out Fanta. This new soda was often made from the leavings of other food industries. (Remember, Germany did have a bit of an import problem at that time.) Whey (a cheese by-product) and apple fiber from cider presses found their way into the drink. As for which fruits were used in the formulation, it all depended on what was available at the time. In its earliest incarnations, the drink was sweetened with saccharin, but by 1941 its concocters were permitted to use 3.5 percent beet sugar. Fanta sold well enough to keep the plants operating and Coca-Cola people employed. In 1943, 3 million cases of Fanta were vended, but not all were imbibed — some were used to flavor soups and stews. (Sugar rationing inspired many a housewife to look to unusual sources for that which could no longer be bought outright in large enough quantities to satisfy.) Until the end of the war, Coca-Cola executives in Atlanta did not know if Keith was working for the company or for the Nazis, because communication with him was impossible. Their misgivings aside, Keith was safeguarding Coca-Cola interests and people during that period of no contact. It was thanks largely to his efforts that Coca-Cola was able to re-establish production in Germany virtually immediately after World War II. According to a report prepared by an investigator commissioned by Coca-Cola to examine Max Keith’s actions during that unsupervised period, Keith had never been a Nazi, even though he’d been repeatedly pressured to become one and indeed had endured hardships because of his refusal. He also could have made a fortune for himself by bottling and selling Fanta under his own name. Instead, in the face of having to work for the German government, he kept the Coca-Cola plants in Germany running and various Coca-Cola men alive throughout the war. At the end of the conflict, he welcomed the Coca-Cola company back to its German operations and handed over both the profits from the war years and the new soft drink. So where does all this leave the question of who or what invented Fanta and why? The truth is simple, even if it doesn’t run trippingly off the tongue: Fanta was the creation of a German-born Coca-Cola man who was acting without direction from Atlanta. This man wasn’t a Nazi, nor did he invent the drink at the direction of the Third Reich. Rather, in an effort to preserve Coca-Cola company assets and protect its people by way of keeping local plants operating, he formulated a new soft drink when it became impossible to produce the company’s flagship product.",
        "false"
    ],
    [
        0.35539859036604565,
        "{'dataset_id': 'grail_qa', 'config_id': 'default', 'row_id': '797'}",
        "['royalty.noble_person', 'people.sibling_relationship', 'royalty.noble_person']",
        ""
    ],
    [
        0.35531951983769733,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '786'}",
        "Write an excellent summary of the given text.\n\nTitle: DAE think that some \"unions\" are in conspiractory cahoots with the very corporations and/or agencies of which its workers is represented by?\n\nText: I just thought of this all of a sudden, dunno why. To clarify what I meant, I've noticed union dues have been skyrocketing in relative to the service they offer. This could just be due to incompetance. The inquisitive nature in me can't help but ask are some of these unions working with large corporations or factory owners in a shady, theatrical way to screw with workers who were abused by their employers? The dues collected by the union would make up for any losses or damages done to 'da buawss' while the unions themselves receive kickbacks, windfalls, or other dividends. Who knows, the unions themselves could be run by 'volunteer' beneficiaries of the companies. It might be a far-fetched idea, but hoping someone with similar thinking could weigh in on this with their thoughts. Oh and I'll be checking in periodically for responses. G'day.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35530799130598706,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '933'}",
        "من با سکانس پایان فیلم مشکل دارم  آخرین سکانس چی داشت می گفت  دختره تو هواپیما بود یا نه؟(خیانت کرده بود یا نه؟)  به نظرم این پایان باز نیست ، فیلم بدون پایانه",
        "صدا"
    ],
    [
        0.35530176758766174,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '210'}",
        "نظر شما در مورد عطر، بو، و طعم این عسل چیست؟",
        "طعم"
    ],
    [
        0.35530176758766174,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '238'}",
        "نظر شما در مورد عطر، بو، و طعم این عسل چیست؟",
        "طعم"
    ],
    [
        0.35530176758766174,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '266'}",
        "نظر شما در مورد عطر، بو، و طعم این عسل چیست؟",
        "طعم"
    ],
    [
        0.35529281198978424,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '213'}",
        "It is impossible that Emily is a mouse. It is improbable that Brian is yellow. It is likely that John dropped the apple. We believe that if either 'John dropped the apple' or 'Brian is yellow' but not both then Mary went to the garden. We believe that if 'Emily is a mouse' or 'Brian is yellow' or both then Bernhard is a swan. We believe that if either 'Brian is yellow' or 'John dropped the apple' but not both then Julius is a rhino.",
        "invalid"
    ],
    [
        0.3552878201007843,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '965'}",
        "It is unlikely that 'Brian is a rhino and Julius is a lion'.",
        "invalid"
    ],
    [
        0.3552788446346919,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '99'}",
        "Хозяйкой этой   интернациональной   квартиры была женщина из белоруссии, которая кляла свою тяжелую работу за 8000 рублей, но признавалась при этом, что на родине ей не удавалось заработать больше 100 долларов",
        "correct"
    ],
    [
        0.355275164047877,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '757'}",
        "Write an excellent summary of the given text.\n\nTitle: When was the last time someone used the 'it's because I'm <insert ethnic background>, isn't it?' at work? How, why and what Happened?\n\nText: Happened to me tonight - during the  last bit of my shift, an Israeli girl (a regular) stumbles up with her BF and I tell her politely 'hi, there, you've had a bit too much to drink tonight, come back another night'. She immediately gets hostile and starts into me about how she hasn't had anything to drink. I tell her 'hey, it's just policy, if I deem you're not in full control of your faculties, you're not getting served and therefore, you're not coming in. Come back another night'. \nThis is when she loses her shit, flipping out and telling me to go fuck myself, that she's coming in to the club and that I'm a lowly loser piece of shit. As per my judgement, I keep my cool and tell her 'Okay, I was being nice but now you're being belligerent. There is no way you're coming in'.\nThen out of nowhere she starts ripping on my appearance and then ends it with 'oh, it's because I'm black isn't it? You racist fuck, it's because I'm black, so what?! Fuck you!'\nMeanwhile, her bf is just milling about so I turn to him and address him directly 'take your girl home'. He makes a half hearted attempt while she's still screaming this on top of her lungs about how I'm being a racist piece of shit while waving her hands in my face. Then as I start walking away, she grabs me, i take her wrist and calmly tell her 'go home before the cops show up and you sit in a cell until Monday'. \nMeanwhile my manager has long since noticed and comes out and tells me to swap places and that he'll handle it. I go in and less than 15 seconds, he starts dialing Vegas' finest. Subsequently, she absconds in seconds. \nDuring all of this, a few dark skinned guys who aren't drunk and hostile come up, get carded an proceed to enter. She didn't notice, being wrapped up in telling me what a racist piece of shit I was.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3552375336488088,
        "{'dataset_id': 'quac', 'config_id': 'plain_text', 'row_id': '863'}",
        "['When did he win the triple crown?', 'What races did he win for the crown?', 'Which horses did he beat when he won the crown?', 'how much money did he win when he won the crown', 'were the races exciting?', 'did he win any of the races by a lot?', 'Was there anything else interesting about him winning the crown?', 'Who was Affirmed jockey?']",
        "Affirmed"
    ],
    [
        0.3552354425191879,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '439'}",
        "It is impossible that 'Julius is yellow' or 'Lily is a rhino' or both.",
        "invalid"
    ],
    [
        0.3552166720231374,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '400'}",
        "['часть', 'семьи', 'коробку']",
        "correct"
    ],
    [
        0.35519883533318836,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '696'}",
        "This summary is inaccurate because the girl mentioned in the post is not in love with someone else, she is mentally unstable. Also, it misses many key details.",
        "Accuracy"
    ],
    [
        0.35518976549307507,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '489'}",
        "It is certain that either 'Brian is a swan' or 'Bernhard is a frog' but not both.",
        "invalid"
    ],
    [
        0.35518159965674084,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '955'}",
        "It is probably the case that Gertrude is a wolf. It is probably the case that Greg is gray. It is highly unlikely that Brian is a frog. It is probable that if either 'Gertrude is a wolf' or 'Brian is a frog' but not both then John went to the garden. We believe that if 'Greg is gray' or 'Brian is a frog' or both then Bernhard is green. Chances are slight that if either 'Gertrude is a wolf' or 'Brian is a frog' but not both then Julius is white.",
        "invalid"
    ],
    [
        0.3551638474067052,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '817'}",
        "It is probably not the case that either 'Julius is a swan' or 'Brian is yellow' but not both.",
        "invalid"
    ],
    [
        0.3551379293203354,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '686'}",
        "نخودش خوبه یه مقداری توش کج و کوله هم داشت ، درجه یک یک نبود ولی مجموعا خوب بود",
        "طعم"
    ],
    [
        0.3550368398427963,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '193'}",
        "It is highly unlikely that 'Brian is a frog' or 'Emily is a mouse' or both.",
        "invalid"
    ],
    [
        0.35502087076505023,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '719'}",
        "Write an excellent summary of the given text.\n\nTitle: What do you think of this relationship blunder?\n\nText: Hey guys, I have a friend that has been going out with this girl for 4 years and note, that he is 21 and this is his first partner ever. Now for the past year this girl has showed signs that she was bored of him and always made arguments out of nothing, and was pissed pretty much 90% of time I hung out with with them. Until one day she was drunkish and made it clear to me that, indeed she wanted to move on.\n\nI tried telling me friend, but he will just deny it and told me to F off. Not too long ago my friend found her in bed with a co worker of hers and pretty much ended it, even though he still missed her.\n\nNow after all the signs telling him that this girl does not want him, he still mourns for her and blames everything on himself.  Just a couple of days ago I found out she took him back [I think because he just begged so much]\n\nMan....I tried helping him but this guy just lives in his own world and I just think I should stop trying to open his eyes, even though he always runs to me for advice.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3550110012292862,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '316'}",
        "Кто такие представители «обыкновенного» («низшего») большинства, согласно \"теории\" Родиона?",
        "False"
    ],
    [
        0.35499219844738644,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '483'}",
        "В противном случае ему пришлось бы добавлять, что «материя - это то, из чего состоят все физические тела», что «отрицательный электрический заряд» возникает на шелке, который потрут о стекло, в то время как положительный заряд появится на стекле», что «электричество - это форма энергии, которая может быть использована для получения тепла, света, механической силы и химических изменений», что «энергия - это способность производить работу», а работа, в свою очередь - и так далее, практически до бесконечности",
        "correct"
    ],
    [
        0.3549889276425044,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '46'}",
        "It is impossible that Julius is gray. It is probable that Lily is green. It is highly unlikely that John put down the milk. Chances are slight that if 'Lily is green and Julius is gray' then Sumit is thirsty. It is almost certain that if 'Lily is green and Julius is gray' then Bernhard is a rhino. There is a very good chance that if either 'Lily is green' or 'John put down the milk' but not both then Jason is tired.",
        "invalid"
    ],
    [
        0.354956512649854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '871'}",
        "It is highly likely that Greg is a rhino. It is probably the case that Sandra dropped the milk. There is little chance that Winona is a sheep. We doubt that if either 'Greg is a rhino' or 'Sandra dropped the milk' but not both then Mary went to the garden. It is highly unlikely that if either 'Winona is a sheep' or 'Greg is a rhino' but not both then Brian is white. Chances are slight that if 'Greg is a rhino and Sandra dropped the milk' then John picked up the milk.",
        "invalid"
    ],
    [
        0.3549201190471649,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '102'}",
        "It is probable that Jessica is a wolf. It is almost certain that Brian is a rhino. There is a very good chance that Julius is gray. It is probably the case that if 'Brian is a rhino and Jessica is a wolf' then Bernhard is green. There is a very good chance that if 'Brian is a rhino and Julius is gray' then Greg is a frog. It is impossible that if 'Julius is gray and Brian is a rhino' then John went to the kitchen.",
        "invalid"
    ],
    [
        0.35489197075366974,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '462'}",
        "توقع این بود وقتی در توضیحات زده نارگیلی ،کل محصول یک دست باشه و دیگه محصولی با مغز چیز دیگه از توش درنیاد که باز هم مثل گذشته فقط بسته های طلایی مغزش نارگیلیه ولی در پیشنهاد ویژه قیمتش خوب بود",
        "طعم"
    ],
    [
        0.35488881667455036,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '837'}",
        "Kim Horton is a spokeswoman for the Henderson County Department of Public Health. She tells the Citizen Times one person has died from the airborne disease. The N.C. Department of Health and Human Services said in a news release earlier this week that it is working with the health departments in Buncombe and Henderson counties to investigate multiple cases of Legionnaires’ reported in individuals who attended a fair in Fletcher earlier in the month. State Epidemiologist Dr. Zack Moore said in the news release that officials don’t know whether people were exposed to Legionella bacteria at the fair. Legionnaires’ is a form of bacterial pneumonia. It’s a serious illness but can be treated effectively with antibiotics.",
        "true"
    ],
    [
        0.3548777848482132,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '636'}",
        "['родители', 'детей']",
        "correct"
    ],
    [
        0.35483913620313007,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '992'}",
        "There is almost no chance that Brian is a rhino. We believe that Jessica is a mouse. Chances are slight that Julius is a lion.",
        "invalid"
    ],
    [
        0.35482336829106015,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '47'}",
        "связь",
        "correct"
    ],
    [
        0.35482291877269745,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '42'}",
        "There is a very good chance that Jessica is a cat. We doubt that Lily is a lion. It is likely that Brian is green. Chances are slight that if 'Jessica is a cat' or 'Lily is a lion' or both then Mary moved to the garden. It is likely that if 'Lily is a lion and Jessica is a cat' then John left the milk. Chances are about even that if either 'Brian is green' or 'Jessica is a cat' but not both then Fred dropped the apple.",
        "invalid"
    ],
    [
        0.35480740666389465,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '610'}",
        "['The debate around the frequency and importance of genetic exchange in parasitic protozoa is now several decades old.', 'Recently, fresh assertions have been made that predominant clonal evolution explains the population structures of several key protozoan pathogens.', 'Here, we present an alternative perspective.', 'On the assumption that much apparent clonality may be an artefact of inadequate sampling and study design, we review current research to define why sex might be so difficult to detect in protozoan parasite populations.', 'In doing so, we contrast laboratory models of genetic exchange in parasitic protozoa with natural patterns of genetic diversity and consider the fitness advantage of sex at different evolutionary scales.', 'We discuss approaches to improve the accuracy of efforts to characterize genetic exchange in the field.', 'We also examine the implications of the first population genomic studies for the debate around sex and clonality in parasitic protozoa and discuss caveats for the future.']",
        "False"
    ],
    [
        0.3547549198071162,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '864'}",
        "Write an excellent summary of the given text.\n\nTitle: TIFU by feeling sorry for my dog and leaving him inside while I went out\n\nText: So I have this dog called Dudley. He's a cute little dog, about 2 years old maybe 1 and a half, he's a good boy and never does anything wrong except dig holes in the backyard. So we were out of bread and my parents were out and my little brother was at the movies, and it was raining hard, and I really wanted some French toast, so I was like fuck it, bread shops 2 mins away I'll go get some bread. Now it's really raining and I'm about to leave and then my dog starts whimpering. I'm thinking hey he's a good dog I'll leave him inside so he'll stay warm and not get wet, that's a good idea (queue fuck up) I go out leave Dudley inside and go get the bread. I'm gone for less than 5 mins, 7 at most. I come home to find my 60$ bean bad ripped to pieces, all of those little fucking beanbag beans everywhere. And he pissed on the carpet. And there's the little fucker laying there chewing his bone all innocently. Now when I say the beans were everywhere, I mean everywhere and the worst part was my floor boards are those wood ones with the massive a lines missing inbetween each floor board so all the beans were in them. Parents come home to find house full of dead beanbag and dog piss, they weren't happy.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35474321742852527,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '84'}",
        "نظر شما در مورد عطر، بو، و طعم این ماکارونی، پاستا و رشته چیست؟",
        "طعم"
    ],
    [
        0.35474321742852527,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '658'}",
        "نظر شما در مورد عطر، بو، و طعم این ماکارونی، پاستا و رشته چیست؟",
        "طعم"
    ],
    [
        0.35474321742852527,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '805'}",
        "نظر شما در مورد عطر، بو، و طعم این ماکارونی، پاستا و رشته چیست؟",
        "طعم"
    ],
    [
        0.35473790268103284,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '84'}",
        "It is certain that John got the milk. It is probably the case that Brian is green. It is probable that Lily is a swan. Chances are slight that if 'John got the milk and Lily is a swan' then Fred went to the garden. It is improbable that if 'John got the milk and Lily is a swan' then Greg is yellow. It is likely that if either 'Brian is green' or 'John got the milk' but not both then Mary left the football.",
        "invalid"
    ],
    [
        0.3547307054201762,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '708'}",
        "This is innacurate because Walmart wasn't even mentioned. The author never implied it was worth it to have the warranty.",
        "Accuracy"
    ],
    [
        0.3546888381242752,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '647'}",
        "\"Leider halt ohne Morrison, aber - wie gesagt - durchaus musikalisch interessant - zumal Manzarek ein superber Musiker ist, ohne dessen Mitwirkung gar kein \\\\\"\"Doors-Sound\\\\\"\" hätte aufkommen können.\"",
        "counterfactual"
    ],
    [
        0.3546888381242752,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '647'}",
        "\"Leider halt ohne Morrison, aber - wie gesagt - durchaus musikalisch interessant - zumal Manzarek ein superber Musiker ist, ohne dessen Mitwirkung gar kein \\\\\"\"Doors-Sound\\\\\"\" hätte aufkommen können.\"",
        "counterfactual"
    ],
    [
        0.35468082626660663,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '998'}",
        "There is a very good chance that John discarded the milk. It is impossible that Lily is a swan. It is probably not the case that Jeff dropped the apple. We doubt that if 'Jeff dropped the apple and Lily is a swan' then Mary moved to the office. There is almost no chance that if 'Lily is a swan and Jeff dropped the apple' then Brian is yellow. It is certain that if either 'Lily is a swan' or 'John discarded the milk' but not both then Julius is white.",
        "invalid"
    ],
    [
        0.35467226306597394,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '503'}",
        "It is probable that Bernhard is gray. We doubt that Mary moved to the garden. It is almost certain that Julius is a swan. It is impossible that if 'Julius is a swan' or 'Mary moved to the garden' or both then Jason is tired. There is little chance that if 'Julius is a swan' or 'Mary moved to the garden' or both then Winona is a cat. It is highly likely that if either 'Julius is a swan' or 'Mary moved to the garden' but not both then Lily is a frog.",
        "invalid"
    ],
    [
        0.35466743012269336,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '870'}",
        "نظر شما در مورد شخصیت پردازی، بازیگردانی و بازی بازیگران فیلم  بارکد چیست؟",
        " بارکد"
    ],
    [
        0.35466283063093823,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '87'}",
        "It is probably not the case that 'Julius is a frog' or 'Winona is a cat' or both.",
        "invalid"
    ],
    [
        0.3546564777692159,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '64'}",
        "The summary mislabels the people involved. The author is also female and is dating a female who suffers from social anxiety. Some of this anxiety stems from the author's family not initially accepting their relationship which her girlfriend uses as a reason for not being there during her hospitalizations.",
        "Accuracy"
    ],
    [
        0.3545881857474645,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '492'}",
        "It is certain that Gertrude is a sheep. It is probably the case that Mary dropped the apple. There is almost no chance that Lily is a lion. It is unlikely that if 'Gertrude is a sheep and Mary dropped the apple' then Bernhard is a frog. It is probable that if either 'Lily is a lion' or 'Mary dropped the apple' but not both then Brian is yellow. There is a very good chance that if either 'Lily is a lion' or 'Mary dropped the apple' but not both then John went to the hallway.",
        "invalid"
    ],
    [
        0.35458208123842877,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '689'}",
        "I think the mother new about the attempted robbery as suggested in the post, but the son didn’t tell the father so there needs to be some clarity on that in the summary.",
        "Accuracy"
    ],
    [
        0.3545103222131729,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '128'}",
        "I've been in a relatively low maintenance with an older co-worker since late December. We bonded over having no family nearby, etc. You know how that goes. In the last month or so I have noticed her slightly adjusting things, picture frames, furniture, buying things, candles, a his & hers laundry hamper, a wine rack, (I don't drink wine,) etc.\n\nI'm a guy, I'll be the first to admit that I am sometimes messy. However, I keep a tight ship. I dust, sweep, and mop every Saturday. Every time I ask her what she's doing, why she's doing it, or to please not she verbally swats at me like I'm a child. She came over unannounced the other night, and brought a painting that she 'left for me to hang up.'\n\nThere are alot of things I adore about this woman. The way she uses her body to express her soul, and not just sexually. Her personality radiates, it fills the room. I can't get enough of her waking me up after she gets out of my shower... that now has 4x the amount of hygiene products it used to... with her wet hair on my chest. The way she proclaims herself Pasta Queen, because she can only cook pasta dishes. I think the thing I like most about her is the intimacy we've arranged, she'll wiggle herself around me like a cat if I'm relaxing, or doing something. I don't know what to do though, I have a concern that she is trying to take control how I live. It feels like the only thing left is for to judge my friends & family, and tell me who I can't see. She won't address my concerns, and I'm not sure about the relationship we have lasting... no matter how much I ... like her.",
        "Accuracy"
    ],
    [
        0.35449714461962384,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '764'}",
        "Любили люди вместо кофе ― сою… И муравьи любили кондоминиумы. Поэт собой соединил несое- …динимое",
        "correct"
    ],
    [
        0.3544805645942688,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '257'}",
        "\"Das ganze kommt in einem recht großen transparenten Plastikbehälter (s. letztes Produktfoto), der ebenfalls wasserdicht ist und, wenn man ihn extra kaufen wollte, wahrscheinlich schon alleine ungefähr den gleichen Preis hätte wie dieses \\\\\"\"Set\\\\\"\".\"",
        "counterfactual"
    ],
    [
        0.3544805645942688,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '257'}",
        "\"Das ganze kommt in einem recht großen transparenten Plastikbehälter (s. letztes Produktfoto), der ebenfalls wasserdicht ist und, wenn man ihn extra kaufen wollte, wahrscheinlich schon alleine ungefähr den gleichen Preis hätte wie dieses \\\\\"\"Set\\\\\"\".\"",
        "counterfactual"
    ],
    [
        0.354466254512469,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '290'}",
        "\"This story is an interesting twist to the usual health news article reviewed on this site. It comes from a regular column, \"\"The Unreal World,\"\" in the LA Times that reviews health issues in prime time TV shows. The story provides an overview of a recent episode of a popular TV show – Boston Legal (ABC, Dec 1) and then addresses the clinical content of the show in a point-by-point manner. The episode continues a story line about a lead character Denny Crane, played by William Shatner, who has been diagnosed with mild to moderate Alzheimer’s disease. Crane/Shatner’s memory loss is progressing so he takes legal action (all the way to the supreme court) to gain access to an experimental drug which has not been approved by the Food and Drug Administration (FDA). The aspects of this dramatization related to Alzheimer’s disease symptoms and stages, PET scans of the brain, the experimental drug Dimebon, and the FDA approval drug approval process are accurate. The article is well organized, raising and summarizing the relevant clinical issues, addressing the medical questions in depth and evaluating their portrayal in the TV show. The column omits some basic information we wish it had included such as quantifying the benefits seen with Dimebon, something on the harms seen with it, and a reminder that available medications for Alzheimer’s can help a small number of people but only for a limited amount of time.\"",
        "true"
    ],
    [
        0.35443951189517975,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '709'}",
        "The summary is slightly inaccurate; the poster is not 100% sure that the name is of a woman, although they believe it is likely.",
        "Accuracy"
    ],
    [
        0.3544196238120397,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '770'}",
        "There is a better than even chance that Greg is a swan. There is little chance that Mary went to the hallway. It is probably the case that John put down the milk. We believe that if either 'Greg is a swan' or 'John put down the milk' but not both then Bernhard is yellow. We doubt that if either 'Mary went to the hallway' or 'Greg is a swan' but not both then Brian is a lion. Chances are slight that if 'John put down the milk and Mary went to the hallway' then Daniel dropped the apple.",
        "invalid"
    ],
    [
        0.3544069876273473,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '578'}",
        "['Луч', 'источник']",
        "correct"
    ],
    [
        0.35440511504809064,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '535'}",
        "It is probably not the case that either 'Greg is yellow' or 'Lily is white' but not both.",
        "invalid"
    ],
    [
        0.35438185930252075,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '676'}",
        "Dubbed “Operation Double Helix,” the crackdown targeted telemedicine companies, doctors and labs, in a joint effort by the Justice Department , the FBI, U.S. attorneys’ offices, and the Health and Human Services inspector general. Thirty-five people were charged around the country. The alleged fraud flourished at a time when many people are getting DNA tests to trace back their family heritage. Fraudsters preyed on people’s fears of harboring genetic markers for cancer. However, genetic testing is not routinely used to screen for cancer. “A decade ago, it would have given Medicare beneficiaries pause if someone wanted to get a swab from their cheek of their saliva,” said Shimon Richmond, who heads the inspector general’s investigative division . “Today people know and recognize what (genetic testing) is, and they think ‘I can get that done, and I can get it done for free and find out if I have health issues that I need to address.’” It’s a bad decision, said Richmond. Not only does it put the patient’s Medicare ID in the hands of fraudsters who can then keep reselling it for illicit purposes, but it can potentially compromise unique details of an individual’s make-up. Another downside: Medicare might deny future coverage for genetic testing when it’s really needed, since the patient’s record would show such an analysis was already done. Patients should only have genetic testing if their own doctor orders it, officials said. The alleged scheme worked like this: Officials said a telemarketing or in-person “recruiter” would convince a Medicare enrollee to take a genetic test, assuring them that the program would pay the full cost. The patient would provide their Medicare information. A doctor in league with the fraudsters would approve the test, and collect a kickback from the recruiter company. A lab participating in the scheme would run the test, bill Medicare, and share payments collected from the government with the recruiter. Bills to Medicare connected with the scam typically ranged from $7,000 to $12,000, Richmond said, with some much higher. In many cases the patient never got a report back, or the results provided were incomprehensible. Medicare paid out hundreds of millions of dollars before authorities detected the fraud and moved in. There was no single organization behind the fraud. Friday’s operation targeted defendants in Florida, Georgia, Louisiana, and Texas, the Justice Department said. Nine doctors were among those charged. Others included owners of telemedicine companies and testing labs. Medicare enrollee Linda Morris of Parker City, Indiana, said she was roped in at a conference on aging well. The retired high school math and journalism teacher got her cheek swabbed by one of the many health vendors at the event. “Their ploy was, ‘Get a mouth swab and we can analyze how well your system synthesizes the drugs you are taking,’” she said. “It never crossed my mind there was anything wrong with this.” Then her Medicare statements started coming in, showing charges as high as $33,000. The program paid almost $10,000. Morris said she was never billed, and was never sent results. When she looked up the address for the test vendor it was “a house on a back road.” “I feel stupid, and in the meantime, I’m furious,” Morris said. Health fairs, church events, and senior centers are like magnets for the fraudsters, officials said. Dennie Krivokapich of Farmington, New Mexico, said he almost sent in his cheek swab following a telemarketing pitch. The retired accountant is a three-time cancer survivor and concerned about his future risk. The company sent him a kit, but the paperwork that came with it made him suspicious. “The physician who requested it was not my physician,” said Krivokapich. The marketing company kept calling him, until he blocked the number. Government-backed anti-fraud organizations known as the Senior Medicare Patrol have been trying to spread the word about genetic testing scams. Retired federal investigator Jennifer Trussell, a consultant to the groups, said fear of cancer is the scam artists’ most effective tool. “These are bad actors trying to take advantage of good medicine,” she said. Fraud against government health care programs is a pervasive problem that costs taxpayers tens of billions of dollars a year. The true extent is unknown. Experts say part of the problem is that Medicare is required to pay medical bills promptly, which means money often goes out before potential frauds get flagged. Investigators call that “pay and chase.” In recent years, Medicare has tried to adapt techniques used by credit card companies to head off fraud. Law enforcement coordination has grown, with strike forces of federal prosecutors and agents, along with state counterparts, specializing in health care investigations.",
        "true"
    ],
    [
        0.35436565180619556,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '180'}",
        "It is unlikely that 'Antoine is thirsty' or 'Lily is white' or both.",
        "invalid"
    ],
    [
        0.3543441991011302,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '986'}",
        "It is impossible that Mary picked up the milk. There is a better than even chance that Lily is gray. There is a very good chance that Brian is a swan.",
        "invalid"
    ],
    [
        0.35433878004550934,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '960'}",
        "It is improbable that 'Brian is yellow' or 'Lily is gray' or both.",
        "invalid"
    ],
    [
        0.3543289254109065,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '553'}",
        "It is unlikely that Lily is a rhino. It is improbable that Greg is a frog. It is likely that Julius is gray.",
        "invalid"
    ],
    [
        0.3543175409237544,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '71'}",
        "It is improbable that either 'Lily is yellow' or 'Julius is white' but not both.",
        "invalid"
    ],
    [
        0.3543108254671097,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '453'}",
        "There is a very good chance that Jeff moved to the garden. It is probably not the case that Mary went to the hallway. It is impossible that Lily is a lion. It is unlikely that if 'Jeff moved to the garden' or 'Lily is a lion' or both then Greg is a swan. It is probable that if 'Lily is a lion' or 'Jeff moved to the garden' or both then Fred dropped the apple. It is likely that if 'Lily is a lion and Jeff moved to the garden' then Sandra got the football.",
        "invalid"
    ],
    [
        0.3542784700791041,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '464'}",
        "There is a better than even chance that Winona is a wolf. There is a very good chance that Jessica is a cat. It is probable that Brian is green. It is improbable that if either 'Jessica is a cat' or 'Brian is green' but not both then Lily is gray. It is probably not the case that if 'Winona is a wolf and Jessica is a cat' then Mary left the football. There is little chance that if 'Jessica is a cat' or 'Winona is a wolf' or both then Julius is a lion.",
        "invalid"
    ],
    [
        0.3542464921871821,
        "{'dataset_id': 'grail_qa', 'config_id': 'default', 'row_id': '541'}",
        "['Neil Coles', 'Pete Oakley', 'Andrew Weaver', 'Henry Ransom', 'Mark McCumber', 'Bruce Devlin', 'Forrest Fezler', 'Bob Shearer', 'Mike Morley', 'Dan Halldorson', 'Shelley Mayfield', 'Gary Koch', 'Glen Day']",
        ""
    ],
    [
        0.3542131955424945,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '496'}",
        "Ведь он хорошо знал и, конечно, помнит папу, у него дочка Светлана, моя ровесница, фотографии которой на руках у Иосифа Виссарионовича показывал мне отец",
        "correct"
    ],
    [
        0.3541849801937739,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '840'}",
        "\"There wasn’t any discussion of costs of these treatments. The point of the story was tell readers that these treatments couldn’t be recommended on the basis of medical evidence. Even in an overview of available treatments, some cost information is important for readers, especially given the fact that regular acupuncture treatments are going to cost a lot more than vitamin B-6. How much money are people wasting on these treatments? A mixed bag here, but ultimately unsatisfactory in our view. The story does note that there \"\"wasn’t much hard data\"\" on psychological, social or economic outcomes — all of which are important to look at considering the lost work time, anxiety, and reduced quality of life that women may experience because of morning sickness. But then the story goes on to state that there was \"\"some evidence\"\" that ginger, vitamin B-6 and anti-vomiting drugs relieved nausea. Well, how much evidence was there and what exactly did it show? While the story states that the evidence for these treatments \"\"isn’t strong enough to make a recommendation,\"\" we feel the story should have tried to quantify this benefit in a way that would be meaningful for readers, whether as episodes of nausea/vomiting or some other \"\"real world\"\" outcome. The story noted that most of the studies included in the review didn’t include enough information about potential harms — \"\"something everyone would certainly want to know.\"\" We’ll call this satisfactory, but we wish it had included at least some information about the harms that were mentioned, such as heartburn in patients taking ginger and drowsiness in patients taking anti-nausea medications. The Cochrane systematic review discussed in this article is actually a \"\"study of studies.\"\" In this case, the story told us how many clinical trials were included in the review (27) and how many women participated in those studies (about 4,000). The story told us why the included studies, which at first glance might seem like an impressive volume of research, couldn’t provide reliable answers about the effectiveness of morning sickness treatments. The story noted that many of studies used different methods and had different ways of measuring outcomes, so the results couldn’t be pooled together to increase the statistical power of the analysis. The lead overstates the case a bit by saying that the review concluded that there was \"\"no reliable treatment to relieve vomiting and feelings of nausea in early-term pregnant women.\"\" But, in the third paragraph, the story says, \"\"Dublin City University’s Anne Matthews, the review’s lead researcher, says it was disappointing not to find more studies that were consistent in testing the same approaches. Without enough data that could be pooled together, it wasn’t possible for the Cochrane folks to figure out if anything really works reliably and safely.\"\" It would have been nice to see Cochrane’s methods evaluated as closely as those of any other type of research experiment. But it didn’t provide key information about how the researchers selected which studies to include in the review. We don’t know, for example, whether the included studies were randomized controlled trials or if uncontrolled trials were allowed. We also don’t know if the studies had to be of a certain size or quality to be included. This information is vital to understanding the strength of the review’s conclusions. This story didn’t exaggerate the effects of morning sickness. The only source quoted in the article was an author of the study being covered. As we discussed in our review of the competing LA Times piece, one could argue that this criterion should be ruled not applicable in this case since the Cochrane group authors are, by definition, an independent group of evaluators. Since other experts do sometimes dispute the way in which Cochrane authors analyze the evidence, however, we feel it would have added value to include the voice of another expert who wasn’t affiliated with the study. The story discusses many different treatments for morning sickness and reports that they all lack good-quality evidence to support their use. The whole point of the story was to discuss the most commonly used treatments for morning sickness: acupuncture, acupressure, ginger, vitamin B-6 and conventional anti-vomiting drugs. The novelty of the treatments analyzed in the review isn’t really in question, so we’ll call this not applicable. The story includes an interview with one of the authors of the study and doesn’t include any direct duplication of text from this press release. So we feel pretty confident that it didn’t rely exclusively on a release for its content.\"",
        "true"
    ],
    [
        0.35417122145493823,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '753'}",
        "There is a better than even chance that Brian is a rhino. Chances are about even that John took the football. It is impossible that Winona is a sheep.",
        "invalid"
    ],
    [
        0.35415781537691754,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '129'}",
        "Studying the DNA of two distant bat species, the scientists discovered how genes dealing with the bats’ immune system had undergone the most rapid change. This may explain why they are relatively free of disease and live exceptionally long lives compared with other mammals of similar size, such as the rat, said Professor Lin-Fa Wang, an infectious disease expert at the Duke-NUS Graduate Medical School in Singapore who led the multi-centre study. “We are not saying bats never get sick or never get infections. What we are saying is they handle infections a lot better,” Wang said in a telephone interview. What was missing from both species of bats was a gene segment known to trigger extreme, and potentially fatal, immune reactions to infections, called the cytokine storm. Cytokine storms end up killing not only offending viruses in the body, but the host’s own cells and tissues too. “Viruses rarely kill the host. The killing comes from the host’s immune response. So it looks like what bats are doing is depress the inflammation (cytokine storm). If we can learn that, we can design drugs to minimize the inflammation damage and control viral infection,” Wang said. The study, which saw the participation of researchers from China, Denmark, Australia and the United States, was published on Friday in the journal Science. Compared with other mammals of similar size, bats live a long time, with lifespans of between 20 and 40 years. Rats live between 2 and 3 years, on average. Interestingly, Wang and his colleagues found that the highly evolved genes that give bats their superior immune system also enable them to fly. Out of more than 5,000 types of mammals on the planet, bats are the only one capable of sustained flight and some species can fly more than 1,000 km in a single night. Such intense physical exertion is known to produce toxic “free radicals” that cause tissue damage and it is these same genes that give the bat the ability to repair itself, Wang said. “What we found was the genes that evolved fastest were genes involved in repairing DNA damage. That makes sense ... because when you fly, metabolism goes up and it generates free radicals that are toxic to cells,” Wang said. “Because bats fly, they (would have had) to evolve and adapt ... to get genes that can repair DNA damage.”  Wang said we have much to learn from the bat, which has evolved to avoid disease and live exceptionally long lives. “Cancer, ageing and infectious disease, these are the three major areas of concern for people,” he said. “We have studied rats for 150 years to understand how to do better in these three areas. Now we have a system, the bat, that has done very well in evolution. We can learn from the bat. With modern techniques, we can design new drugs to slow down the ageing process, treat cancer, fight infections.”",
        "true"
    ],
    [
        0.3541339387496312,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '666'}",
        "There is almost no chance that Greg is a rhino. We doubt that Mary got the football. It is probably the case that Fred dropped the apple. It is impossible that if either 'Mary got the football' or 'Fred dropped the apple' but not both then Lily is yellow. There is little chance that if either 'Mary got the football' or 'Fred dropped the apple' but not both then John went to the hallway. We believe that if either 'Fred dropped the apple' or 'Mary got the football' but not both then Winona is a mouse.",
        "invalid"
    ],
    [
        0.3541211634874344,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '473'}",
        "It is highly unlikely that either 'Mary got the football' or 'Lily is a frog' but not both.",
        "invalid"
    ],
    [
        0.35410839319229126,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '748'}",
        "Write an excellent summary of the given text.\n\nTitle: Reddit, What is Your Most It's Not What It Looks Like Situation? I'll Start...(Possibly NSFW)\n\nText: So, basically, I have this friend whom of which I'm not too close with but I still kept in touch because of other mutual friends. So what happens is one day, he sends me this link and me, being innocent just decides to open it. At the time, I was starting to be loaded into this game I play so I click the link, then Alt+Tab into my game. Well, I start playing this game for about maybe 30-40 minutes and after it's over my brother walks in and says he wants to check on something, keeping in mind that I still have my link open on a different window. (I think you see where this is going.) So, I'm just like sure and I change tabs to look at this link, only to find that it freaking some kind of porn site. I  was just shocked and my brother looks up and sees it and misunderstands that I was doing something with it. I'm like too shocked to even explain to him the situation so I just close the tab and continue on to start berating at my friend whom of which sent me the link. He just walks out of room and I'm basically sitting there, just thinking man, now I get the term \"It's not what it looks like.\" Anyway, that's my story and I'm somewhat youngish. I also didn't try to explain the situation because I thought it would kinda sound like I  was trying to cover the whole thing up. Geez. Enlighten me.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35408049325148266,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '81'}",
        "Теперь англичане решили убрать слова «отец» и «мать» из анкеты, которую заполняют для получения паспорта",
        "correct"
    ],
    [
        0.35399741927782696,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '874'}",
        "It is unlikely that Lily is a swan. We doubt that John left the milk. It is probably the case that Brian is a rhino.",
        "invalid"
    ],
    [
        0.3539868692557017,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '254'}",
        "There is a very good chance that Greg is green. It is almost certain that Brian is a frog. It is probable that Mary took the milk. Chances are slight that if either 'Mary took the milk' or 'Brian is a frog' but not both then Julius is gray. It is almost certain that if 'Greg is green' or 'Brian is a frog' or both then Bernhard is gray. It is probable that if 'Greg is green' or 'Mary took the milk' or both then Lily is a swan.",
        "invalid"
    ],
    [
        0.35396529734134674,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '691'}",
        "It is probable that Julius is white. It is probably not the case that Daniel left the apple. Chances are slight that John went to the office. Chances are slight that if 'John went to the office and Daniel left the apple' then Brian is yellow. It is impossible that if either 'Julius is white' or 'Daniel left the apple' but not both then Greg is white. It is likely that if 'Julius is white and John went to the office' then Bernhard is a swan.",
        "invalid"
    ],
    [
        0.3539578666289647,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '414'}",
        "There is little chance that Julius is a frog. It is probably the case that Gertrude is a sheep. It is improbable that Lily is a lion.",
        "invalid"
    ],
    [
        0.3539406284689903,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '619'}",
        "\"― Вы согласны с утверждением, что наш кинематограф потерпел крах?\"",
        "correct"
    ],
    [
        0.3539195656776428,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '66'}",
        "(1) Вилли в ресторане ждет потенциальных жен, а Марианна приходит на встречу заранее. (2) Молодые люди обращают друг на друга внимание, но не открывают истинных причин, почему пришли сюда. (3) Марианна представляет своего миллионера эксцентричным стариком, и, разумеется, даже не предполагает, что симпатичный мужчина у барной стойки он и есть. (4) Девушка думает, что Вилли - бедный парень, как она сама, поэтому с неохотой отвечает на ухаживания. (5) Все ее мысли сейчас о том, что с помощью вознаграждения от миллионера можно нанять отличного адвоката для отца. (6) Тем не менее, Вилли удается уговорить Марианну встретиться на следующий день. (7) Вилли переполняет восторг. (8) Чтобы завоевать любовь Марианны он готов практически на все. (9) Более того, согласен отказаться от наследства, если понадобится. (10) Сама же Марианна в растерянности. (11) Ей нравится Вилли, но что делать с долгом перед отцом? (12) Если она не поможет ему выйти из тюрьмы, никто не поможет, и, в конце концов, Марианна говорит новому поклоннику, что обручена с другим. (13) А жизнь, между тем, продолжается. (14) Наталия (мачеха Марианны) и Роза додумались шантажировать Валентино, настоящего отца Рикардо.",
        "False"
    ],
    [
        0.3539195656776428,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '67'}",
        "(1) Вилли в ресторане ждет потенциальных жен, а Марианна приходит на встречу заранее. (2) Молодые люди обращают друг на друга внимание, но не открывают истинных причин, почему пришли сюда. (3) Марианна представляет своего миллионера эксцентричным стариком, и, разумеется, даже не предполагает, что симпатичный мужчина у барной стойки он и есть. (4) Девушка думает, что Вилли - бедный парень, как она сама, поэтому с неохотой отвечает на ухаживания. (5) Все ее мысли сейчас о том, что с помощью вознаграждения от миллионера можно нанять отличного адвоката для отца. (6) Тем не менее, Вилли удается уговорить Марианну встретиться на следующий день. (7) Вилли переполняет восторг. (8) Чтобы завоевать любовь Марианны он готов практически на все. (9) Более того, согласен отказаться от наследства, если понадобится. (10) Сама же Марианна в растерянности. (11) Ей нравится Вилли, но что делать с долгом перед отцом? (12) Если она не поможет ему выйти из тюрьмы, никто не поможет, и, в конце концов, Марианна говорит новому поклоннику, что обручена с другим. (13) А жизнь, между тем, продолжается. (14) Наталия (мачеха Марианны) и Роза додумались шантажировать Валентино, настоящего отца Рикардо.",
        "False"
    ],
    [
        0.3539195656776428,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '68'}",
        "(1) Вилли в ресторане ждет потенциальных жен, а Марианна приходит на встречу заранее. (2) Молодые люди обращают друг на друга внимание, но не открывают истинных причин, почему пришли сюда. (3) Марианна представляет своего миллионера эксцентричным стариком, и, разумеется, даже не предполагает, что симпатичный мужчина у барной стойки он и есть. (4) Девушка думает, что Вилли - бедный парень, как она сама, поэтому с неохотой отвечает на ухаживания. (5) Все ее мысли сейчас о том, что с помощью вознаграждения от миллионера можно нанять отличного адвоката для отца. (6) Тем не менее, Вилли удается уговорить Марианну встретиться на следующий день. (7) Вилли переполняет восторг. (8) Чтобы завоевать любовь Марианны он готов практически на все. (9) Более того, согласен отказаться от наследства, если понадобится. (10) Сама же Марианна в растерянности. (11) Ей нравится Вилли, но что делать с долгом перед отцом? (12) Если она не поможет ему выйти из тюрьмы, никто не поможет, и, в конце концов, Марианна говорит новому поклоннику, что обручена с другим. (13) А жизнь, между тем, продолжается. (14) Наталия (мачеха Марианны) и Роза додумались шантажировать Валентино, настоящего отца Рикардо.",
        "False"
    ],
    [
        0.35391952594121295,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '65'}",
        "(1) Вилли в ресторане ждет потенциальных жен, а Марианна приходит на встречу заранее. (2) Молодые люди обращают друг на друга внимание, но не открывают истинных причин, почему пришли сюда. (3) Марианна представляет своего миллионера эксцентричным стариком, и, разумеется, даже не предполагает, что симпатичный мужчина у барной стойки он и есть. (4) Девушка думает, что Вилли - бедный парень, как она сама, поэтому с неохотой отвечает на ухаживания. (5) Все ее мысли сейчас о том, что с помощью вознаграждения от миллионера можно нанять отличного адвоката для отца. (6) Тем не менее, Вилли удается уговорить Марианну встретиться на следующий день. (7) Вилли переполняет восторг. (8) Чтобы завоевать любовь Марианны он готов практически на все. (9) Более того, согласен отказаться от наследства, если понадобится. (10) Сама же Марианна в растерянности. (11) Ей нравится Вилли, но что делать с долгом перед отцом? (12) Если она не поможет ему выйти из тюрьмы, никто не поможет, и, в конце концов, Марианна говорит новому поклоннику, что обручена с другим. (13) А жизнь, между тем, продолжается. (14) Наталия (мачеха Марианны) и Роза додумались шантажировать Валентино, настоящего отца Рикардо.",
        "False"
    ],
    [
        0.35391952594121295,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '70'}",
        "(1) Вилли в ресторане ждет потенциальных жен, а Марианна приходит на встречу заранее. (2) Молодые люди обращают друг на друга внимание, но не открывают истинных причин, почему пришли сюда. (3) Марианна представляет своего миллионера эксцентричным стариком, и, разумеется, даже не предполагает, что симпатичный мужчина у барной стойки он и есть. (4) Девушка думает, что Вилли - бедный парень, как она сама, поэтому с неохотой отвечает на ухаживания. (5) Все ее мысли сейчас о том, что с помощью вознаграждения от миллионера можно нанять отличного адвоката для отца. (6) Тем не менее, Вилли удается уговорить Марианну встретиться на следующий день. (7) Вилли переполняет восторг. (8) Чтобы завоевать любовь Марианны он готов практически на все. (9) Более того, согласен отказаться от наследства, если понадобится. (10) Сама же Марианна в растерянности. (11) Ей нравится Вилли, но что делать с долгом перед отцом? (12) Если она не поможет ему выйти из тюрьмы, никто не поможет, и, в конце концов, Марианна говорит новому поклоннику, что обручена с другим. (13) А жизнь, между тем, продолжается. (14) Наталия (мачеха Марианны) и Роза додумались шантажировать Валентино, настоящего отца Рикардо.",
        "False"
    ],
    [
        0.3538489490747452,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '834'}",
        "It is highly unlikely that Bernhard is a rhino. Chances are about even that Winona is a wolf. We doubt that John left the football. Chances are about even that if 'John left the football and Winona is a wolf' then Greg is a frog. It is probably not the case that if either 'Winona is a wolf' or 'John left the football' but not both then Emily is a mouse. It is almost certain that if 'John left the football and Winona is a wolf' then Jeff went to the garden.",
        "invalid"
    ],
    [
        0.3538394744197528,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '588'}",
        "با ماندن در یخچال تغییر کیفیت نمی دهد. این یه محصول خوب با کیفیت مناسب است",
        "طعم"
    ],
    [
        0.353815034031868,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '667'}",
        "It is certain that Lily is a rhino. It is likely that Jeff left the apple. It is improbable that Greg is gray. There is a better than even chance that if either 'Greg is gray' or 'Jeff left the apple' but not both then Jessica is a cat. It is likely that if 'Greg is gray' or 'Jeff left the apple' or both then Bill went to the office. We doubt that if 'Greg is gray and Lily is a rhino' then Bernhard is a swan.",
        "invalid"
    ],
    [
        0.35380681852499646,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '13'}",
        "It is likely that Julius is green. There is almost no chance that Greg is a lion. It is improbable that Brian is gray. There is little chance that if either 'Julius is green' or 'Greg is a lion' but not both then Mary is in the bathroom. It is highly likely that if 'Greg is a lion and Julius is green' then Jeff moved to the garden. It is certain that if either 'Greg is a lion' or 'Julius is green' but not both then Bernhard is yellow.",
        "invalid"
    ],
    [
        0.3537917335828145,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '969'}",
        "So i'm a pretty known student at my school. For the most part my first two years I was pretty shy and only talked to my girlfriend at the time, but now since then I've really opened up a lot. My dilemma here is that my gay friend John(fake name) wants to take me to prom for a fun day out. He knows im straight and understands there is nothing romantic from the talk we had since i was curious as to whether he wants to be anything more than friends. \n\nThe issue here isn't between my friend and me, but between my parents and my friend. They believe that regardless of whether or not others know i'm straight, someone will think i'm gay and that these assumptions will affect my \"reputation as a man\". This prom is his since he a senior and im just a junior because i joined school late. I understand that i'm young and don't know much so I guess i'd like a second opinion on whether you guys think my parents are completely right on their belief of this affecting my masculinity or if not that, whats wrong with either opinion here. \n\nAnother thing I need too add is that the reason why my parents are already sort of off with me having a gay friend is because they are firm in their belief in Christianity and that homosexuality is wrong. While they are religious i'm not, but just thought I needed to put that out there.",
        "Accuracy"
    ],
    [
        0.35378389557202655,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '556'}",
        "It is probably the case that either 'Greg is a lion' or 'Mary took the milk' but not both.",
        "invalid"
    ],
    [
        0.35377493997414905,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '383'}",
        "It is probably not the case that 'Bernhard is a frog' or 'Brian is white' or both.",
        "invalid"
    ],
    [
        0.35375850399335224,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '631'}",
        "There is almost no chance that either 'Julius is white' or 'Lily is yellow' but not both.",
        "invalid"
    ],
    [
        0.35375257829825085,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '285'}",
        "['Dynein is a microtubule motor that powers motility of cilia and flagella.', 'There is evidence that the relative sliding of the doublet microtubules is due to a conformational change in the motor domain that moves a microtubule bound to the end of an extension known as the stalk.', 'A predominant model for the movement involves a rotation of the head domain, with its stalk, toward the microtubule plus end.', 'However, stalks bound to microtubules have been difficult to observe.', 'Here, we present the clearest views so far of stalks in action, by observing sea urchin, outer arm dynein molecules bound to microtubules, with a new method, \"cryo-positive stain\" electron microscopy.', 'The dynein molecules in the complex were shown to be active in in vitro motility assays.', 'Analysis of the electron micrographs shows that the stalk angles relative to microtubules do not change significantly between the ADP.vanadate and no-nucleotide states, but the heads, together with their stalks, shift with respect to their A-tubule attachments.', 'Our results disagree with models in which the stalk acts as a lever arm to amplify structural changes.', 'The observed movement of the head and stalk relative to the tail indicates a new plausible mechanism, in which dynein uses its stalk as a grappling hook, catching a tubulin subunit 8 nm ahead and pulling on it by retracting a part of the tail (linker).']",
        "False"
    ],
    [
        0.353697270154953,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '141'}",
        "It is highly unlikely that 'Lily is a rhino' or 'John left the milk' or both.",
        "invalid"
    ],
    [
        0.35368487735589343,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '764'}",
        "We believe that Lily is a rhino. It is probably not the case that John put down the apple. It is certain that Greg is a frog.",
        "invalid"
    ],
    [
        0.35368242859840393,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '698'}",
        "It is impossible that 'Bernhard is a swan and Lily is a frog'.",
        "invalid"
    ],
    [
        0.353681743144989,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '300'}",
        "This summary implies the author is questioning their current relationship because of the breakup, which isn't true. The author is happy about their current relationship.",
        "Accuracy"
    ],
    [
        0.35361231366793316,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '148'}",
        "It is probably not the case that Mary went to the garden. It is highly unlikely that Lily is a frog. There is almost no chance that Daniel left the football. It is improbable that if 'Daniel left the football and Lily is a frog' then Jeff discarded the milk. There is a better than even chance that if 'Daniel left the football and Lily is a frog' then Fred put down the apple. Chances are slight that if 'Mary went to the garden' or 'Lily is a frog' or both then Emily is a mouse.",
        "invalid"
    ],
    [
        0.35360947748025257,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '694'}",
        "It is probably not the case that Lily is a swan. It is highly unlikely that Bernhard is yellow. There is a very good chance that John went to the garden. It is highly unlikely that if 'Lily is a swan and Bernhard is yellow' then Jason is bored. There is a very good chance that if either 'Bernhard is yellow' or 'Lily is a swan' but not both then Brian is a frog. Chances are slight that if 'Bernhard is yellow and John went to the garden' then Julius is a lion.",
        "invalid"
    ],
    [
        0.3535917401313782,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'danetqa', 'row_id': '35'}",
        "При кратком именовании родового имени ру опускается и называется только ел. При полном именовании ру называется первым, например Кара Қыпшақ, Сары Үйсін или Шекты Алимулы. В связи с тем, что родовые имена официально не считались фамилиями, то ещё в царские времена при зачислении казахов в учебные заведения им давались фамилии, как правило, производные от имени отца, деда или прадеда. Так, Чокан, являющийся прямым потомком Чингизхана, получил фамилию не Торе и не Чингиз, а Уалиханов, по имени деда Уали-Хана. А отчество по имени отца Чингиза Валиханова.",
        "False"
    ],
    [
        0.35359025994936627,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '970'}",
        "It is impossible that Bernhard is gray. It is probably not the case that Winona is a mouse. It is probably the case that Brian is a frog.",
        "invalid"
    ],
    [
        0.35357971489429474,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '350'}",
        "Chances are slight that either 'Greg is a frog' or 'Daniel left the milk' but not both.",
        "invalid"
    ],
    [
        0.35349086423714954,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '366'}",
        "Hey reddit. I made this throw away account because I'm in serious need of some advice.\n\nI'm a 20-year-old female who is going to school and living with my mom and grandma. I have an incredible bond with my family. I live in a glorious part of my state. I love it here not only for my friends, but there's also awesome things to do here.\n\nMy grandma owns the house I currently live in. Recently, she put it on the market (taxes are way too high here, the only negative aspect) and would like to move an hour and a half away. My mom is moving along with her. I'm simply refusing to move. I mean, where they're moving to is a nice area. Close to the shore and everything. But chances are, if I move with them, I'll constantly be making that drive to where my friends are. I'm on the hunt for some cheap places (I found a few actually) and I'd love to snatch one up). I'm currently looking for a job, and I have one that I applied for and will most likely get. I also have about $8k saved up in the bank so if I have money issues, I have a little bit to fall back on. It's not the best plan, but hey. I know a few people who have been in my position and they're doing well on their own.\n\nThe problem here: My mom will blow her top when I tell her I don't want to move with them. Is there a safe way to approach this? I'm absolutely terrified to tell her. I'm freaking out. I have 2 months to get everything together, which in my opinion is plenty of time. Obviously, I would help my family pack and get everything together. I'm not a shitty daughter. It's the least I can do for them. I just don't want to move away from the area.",
        "Accuracy"
    ],
    [
        0.3534601926803589,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '7'}",
        "نظر شما در مورد عطر، بو، و طعم این شکلات، تافی و آبنبات چیست؟",
        "طعم"
    ],
    [
        0.3534601926803589,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '175'}",
        "نظر شما در مورد عطر، بو، و طعم این شکلات، تافی و آبنبات چیست؟",
        "طعم"
    ],
    [
        0.3534601926803589,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '609'}",
        "نظر شما در مورد عطر، بو، و طعم این شکلات، تافی و آبنبات چیست؟",
        "طعم"
    ],
    [
        0.35344167798757553,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '15'}",
        "распространенности",
        "correct"
    ],
    [
        0.35344167798757553,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '162'}",
        "распространенности",
        "correct"
    ],
    [
        0.35342033207416534,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '408'}",
        "There is a very good chance that Winona is a sheep. It is probable that Brian is gray. There is a very good chance that Mary put down the apple. Chances are slight that if either 'Winona is a sheep' or 'Mary put down the apple' but not both then Gertrude is a cat. It is probably not the case that if either 'Brian is gray' or 'Mary put down the apple' but not both then John went to the office. There is little chance that if 'Winona is a sheep and Brian is gray' then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.3534187028805415,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '542'}",
        "It is almost certain that Lily is yellow. It is almost certain that Bill moved to the office. There is almost no chance that John went to the garden. It is highly unlikely that if 'John went to the garden and Lily is yellow' then Brian is a frog. Chances are slight that if 'John went to the garden' or 'Lily is yellow' or both then Jeff discarded the milk. It is probable that if either 'Lily is yellow' or 'John went to the garden' but not both then Julius is a rhino.",
        "invalid"
    ],
    [
        0.3534049168229103,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '518'}",
        "کار را بندازه برا مهمونی. و در کل هرچی از این محصولات دارای طعم دهنده و مواد نگه دارنده دار کمتر استفاده بشه بهتره. ممنون از دیجی بابت قیمت مناسبش",
        "طعم"
    ],
    [
        0.3533822000026703,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '333'}",
        "Write an excellent summary of the given text.\n\nTitle: Me [33F] with my bf[44M] over 3 years, I found out that he has been tracking my location through \"find my iphone\" app.\n\nText: We are in a LDR, he's about a 7 hour drive away.  We spend a ton of time together and text/email/facetime constantly,  he's been waiting 2.5 yrs for a job transfer so he can move to my city.  There have been some relationship issues in the past (mainly with him behaving inappropriately with other woman) but we worked through them and for the most part we're good.  Sex is great, we have fun together, and my 13 yo daughter adores him.\n\nI have **never** given him a reason to not trust me, so when I discovered that he had tracked my location over 90 times in 2 weeks...I felt violated and sick to my stomach. \n\n \nI love this guy but seriously, this is messed up.  When I confronted him about it he said that it has nothing to do with not trusting me and that he found comfort in seeing where I was and blamed it on the whole long distance thing. I don't really buy that as he would often text me \"what you doing?\" a minute after he tracked my location.  He says he's sorry but I can't help but feel that he's just sorry he got caught. After all he did make the conscious choice to guess my Apple ID password in order to track me.....\n\nI can't help but wonder what else he's keeping from me.\n\nHow do I handle this?  I can't just say \"since it was done out of love, I forgive you\" and move on.  Every time I think about it my stomach hurts. Looking for an outsiders perspective....\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.353375385204951,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '686'}",
        "There is a better than even chance that Greg is white. There is almost no chance that Lily is a swan. It is impossible that John discarded the milk.",
        "invalid"
    ],
    [
        0.35337407886981964,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '802'}",
        "There is almost no chance that either 'Greg is a frog' or 'Brian is yellow' but not both.",
        "invalid"
    ],
    [
        0.3533665289481481,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '689'}",
        "There is almost no chance that Lily is a swan. Chances are about even that Emily is a cat. Chances are slight that Mary dropped the apple. It is probably the case that if either 'Lily is a swan' or 'Emily is a cat' but not both then Gertrude is a wolf. There is a very good chance that if either 'Emily is a cat' or 'Mary dropped the apple' but not both then John went to the garden. Chances are slight that if 'Mary dropped the apple' or 'Lily is a swan' or both then Julius is yellow.",
        "invalid"
    ],
    [
        0.3533564656972885,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '118'}",
        "It is certain that Jason is bored. It is almost certain that Emily is a mouse. We doubt that Julius is a swan. It is highly likely that if 'Jason is bored' or 'Julius is a swan' or both then Lily is a frog. Chances are slight that if 'Emily is a mouse' or 'Jason is bored' or both then Winona is a wolf. It is impossible that if 'Emily is a mouse' or 'Jason is bored' or both then Greg is gray.",
        "invalid"
    ],
    [
        0.35335103670756024,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '683'}",
        "Write an excellent summary of the given text.\n\nTitle: She said she \"isn't really interested in a relationship right now\" but then invited herself over for dinner and drinks.\n\nText: We're coworkers and we've known each other for a couple of months now. We both got strung along by our respective others, so when we were at work we'd talk about it and we would both tell each other that they needed to end their relationship, but it always seemed that one of us was in it while the other wasn't and if just flipped around like that every couple of weeks for the past few months.\n\nThe other day I told her that my relationship was completely 110% done, and told her how great everything in my life was going with internships and such and she said she was excited for me. She said along the same lines as I did, but she said she's \"not really looking for a relationship right now\" and I didn't really think anything of it because at the time I wasn't either and hadn't even hinted at it so I didn't really think anything of it. \n\nI ended up telling her that I had food that I was going to cook for my ex one last time (I wanted to go out on a good note) but she, instead, said horrendous things to me. So I said \"I've got all this food with nobody to eat it with\" and my coworker got all excited and invited herself over my place (we have never hung out outside of work) and said she'd bring drinks too. It was so fast and I didn't even really think about what was happening but I said yeah.\n\nSo now she is supposed to be coming over tomorrow night and I don't actually really know what is going on. I think she likes me because she always laughs at my stupid jokes and tells me I always make her smile. We also have a work trip planned together that is two weekends and it's going to be a 4 hour car ride one way, so she's clearly comfortable spending extended time with me. But then I'm confused because I'm somewhat oblivious and I probably think too much about things that don't matter.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35333121567964554,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '96'}",
        "К примеру, тушенка из говядины, которая упоминалась в статье, весной этого года проходила очередное исследование, результаты которого подтвердили, что не зря ее любят потребители",
        "correct"
    ],
    [
        0.35332247118155163,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '688'}",
        "Между прочим, в некоторых гетто немцы создавали оркестры, они играли популярные мелодии Колнидре, Письмо матери, а в Вильнюсском или Минском гетто, не помню точно, заставляли известного певца Горелика петь еврейские песни",
        "correct"
    ],
    [
        0.35329940418402356,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '783'}",
        "It is almost certain that Fred put down the apple. There is almost no chance that Jessica is a sheep. It is highly likely that John went to the kitchen. There is almost no chance that if either 'Fred put down the apple' or 'Jessica is a sheep' but not both then Winona is a sheep. It is unlikely that if 'Jessica is a sheep and Fred put down the apple' then Greg is a lion. It is impossible that if 'John went to the kitchen' or 'Fred put down the apple' or both then Bernhard is a frog.",
        "invalid"
    ],
    [
        0.35322671631971997,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '227'}",
        "It is highly unlikely that Jessica is a cat. There is a very good chance that Julius is a swan. It is impossible that Bernhard is gray. We believe that if 'Julius is a swan and Bernhard is gray' then Jeff left the apple. It is highly likely that if either 'Julius is a swan' or 'Jessica is a cat' but not both then Winona is a mouse. It is likely that if 'Bernhard is gray' or 'Julius is a swan' or both then John dropped the apple.",
        "invalid"
    ],
    [
        0.3532256285349528,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '500'}",
        "The summary is completely accurate; the poster's boyfriend of 2 months broke up with her after she asked him to make a decision on whether he wanted to be in the relationship seriously or not.",
        "Accuracy"
    ],
    [
        0.35320185124874115,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '561'}",
        "It is probably the case that Bernhard is white. It is probable that Sumit is thirsty. It is highly unlikely that Daniel left the milk. We doubt that if 'Bernhard is white and Sumit is thirsty' then Julius is a lion. Chances are slight that if 'Sumit is thirsty' or 'Bernhard is white' or both then Brian is a rhino. Chances are slight that if either 'Sumit is thirsty' or 'Daniel left the milk' but not both then Greg is a frog.",
        "invalid"
    ],
    [
        0.35319862763086957,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '779'}",
        "\"A reader recently sent us a chain email we hadn’t seen before. The lengthy missive, purportedly written by a \"\"senior gentleman in Mesa, Arizona,\"\" details a visit to a hospital made contentious by Medicare payment rules. The anonymous author claims to have experienced \"\"a medical situation that made it very clear that the ‘Affordable Care Act’ is neither affordable, nor do they care.\"\" The full email, which is lengthy, is accessible in its entirety here. But briefly, the author relates what happened after he sought treatment for a suspected urinary-tract infection. After collapsing in a local urgent-care clinic, he was taken to a hospital. There, the medical staff feared he could be experiencing sepsis, a potentially serious inflammation caused by an infection, so they ordered a battery of tests, including one that could take a day or two to complete. As a result, they told him that he would need to stay in the hospital \"\"for observation\"\" rather than going home. Here’s what happened next: \"\"I said, ‘Doctor, correct me if I'm wrong, but if you admit me for observation, my Medicare will not pay anything. This is due to the Affordable Care Act.’ He said, ‘That's right, it won't.’ I then grabbed for my bag of clothing and said, ‘Then I'm going home.’ He said you're really too sick to be going home, but I understand your position. This health program is going to hit seniors especially hard.\"\" Then another doctor came into the room. \"\"I said, ‘Doc, you and I both know that under the Affordable Care Act anyone on Medicare who is admitted to a hospital for observation will be responsible for the bill. Medicare won't pay a cent.’ At which point he nodded in affirmation. I said, ‘You will either admit me for a specific treatment or you won't admit me.’ Realizing he wasn't going to win this one, he said he would prepare my release papers.\"\" We zeroed in on the core claim of this story, that \"\"under the Affordable Care Act, anyone on Medicare who is admitted to a hospital for observation will be responsible for the bill. Medicare won't pay a cent.\"\" When we looked into it, we found that Medicare does indeed have different reimbursement policies for patients who had been admitted to hospitals for observation as opposed to being admitted to treat a specific diagnosis. However, the email’s author (and, if his recounting is accurate, each of the medical professionals he spoke to) were sorely misinformed about how Medicare rules operate. The different reimbursement rates have to do with follow-up in-home care, not the original hospital stay. And crucially, the controversy over reimbursement for patients under \"\"observation care\"\" has nothing whatsoever to do with President Barack Obama’s health care law, the Affordable Care Act. What is ‘observation care’? According to Kaiser Health News, \"\"hospitals provide observation care for patients who are not well enough to go home but not sick enough to be admitted. This care requires a doctor’s order and is considered an outpatient service, even though patients may stay as long as several days. The hospitalization can include short-term treatment and tests to help doctors decide whether the patient should be admitted.\"\" Because observation care is considered outpatient treatment, Medicare generally covers such visits, minus things like copayments and the cost of routine drugs. Where Medicare reimbursement significantly falls short is once an observation patient leaves the hospital. \"\"Observation patients cannot receive Medicare coverage for follow-up care in a nursing home, even though their doctors recommend it,\"\" according to Kaiser. \"\"To be eligible for nursing home coverage, seniors must have first spent at least three consecutive days (or through three midnights) as an admitted patient, not counting the day of discharge.\"\" In other words, assuming the email author’s story actually happened, he shouldn’t have had to worry about Medicare paying for his time in the hospital while under observation. Medicare would have paid, minus copayments and the like; there was no need for him to go home while in a fragile state just to avoid being responsible for the full cost of his care. Is this related to the Affordable Care Act? Tying this policy to Obama’s law is flat-out wrong. \"\"The Affordable Care Act has nothing to do with observation status,\"\" said Mary T. (Terry) Berthelot, a senior attorney with the Center for Medicare Advocacy. Several other health-policy experts confirmed that. The policy was established by the Center for Medicare and Medicaid Services, a division of the Department of Health and Human Services. While we’re at it, we’ll take a moment to debunk an additional Affordable Care Act-related claim included in the email. The author writes that during a visit to his family practitioner, \"\"I told him that I had heard that the Affordable Care Act would no longer pay for cancer treatment for those 76 and older, is that true? His understanding is that it is true.\"\" In reality, there are no such age limits. In October 2014, we rated  a chain email that claimed that under the Affordable Care Act, \"\"at age 76 when you most need it most, you are not eligible for cancer treatment. …  Cancer hospital will ration care according to the patient's age.\"\" Our ruling The chain email said that \"\"under the Affordable Care Act, anyone on Medicare who is admitted to a hospital for observation will be responsible for the bill. Medicare won't pay a cent.\"\" That’s wrong. Medicare will cover the hospital stay, minus standard copayments and the like. Patients kept in the hospital under observation will not be able to receive Medicare reimbursements for follow-up care such as nursing-home stays, however. Even more inaccurate is the charge that this policy stemmed from the Affordable Care Act. In reality, this stems from a separate policy decision and had nothing to do with Obama’s law. The claim is not only ridiculous but also dangerous, by urging ailing patients to leave the hospital for no good reason. This claim rates .\"",
        "false"
    ],
    [
        0.35318177938461304,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '559'}",
        "Write an excellent summary of the given text.\n\nTitle: I want to tell my old best friend that I don't want to stay in contact anymore. I don't know what to write.\n\nText: This girl was my best friend for 5 years (ages 15-20). She doesn't live in the same state, but for years and years we talked for hours on the phone and Skype. It was one of the most significant relationships in my life, and in hers too she tells me. \n\nAnyway, we've both changed a lot. For the past year and a half we really haven't been talking about anything. Our conversations are dead and neither of us seems to want to be there, talking to the other. The only thing we talk about lately is how much our relationship needs work. \n\nI want to send her a message telling her that I don't want to stay in touch anymore and why. I don't want to call her because we're not good at these conversations, she's out of the country for a while, and I don't want to hear her cold \"I don't give a fuck\" voice. Hearing it makes me say stuff I don't mean. \n\nWe both value honesty a lot, so I wrote stuff like \"I'm no longer happy when you call, I dread it\" in an effort to explain the need for us to cut off contact. But I don't know what to say really, nor what to avoid. \n\nAnyone have any advice for what to say in this kind of message? I want to make it clear that I'm tired of expending energy trying to save a relationship that's over. I don't want to try anymore. I still think she's an awesome person, but we're not able to talk anymore about the things that matter to either of us... so the relationship is over. How do I make it final without being dramatic or fake?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3531426688035329,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '30'}",
        "It is probably not the case that John put down the apple. It is unlikely that Emily is a wolf. There is little chance that Lily is a frog. It is likely that if either 'Emily is a wolf' or 'John put down the apple' but not both then Antoine is thirsty. It is unlikely that if 'John put down the apple' or 'Lily is a frog' or both then Greg is green. Chances are about even that if 'Emily is a wolf' or 'Lily is a frog' or both then Mary went to the kitchen.",
        "invalid"
    ],
    [
        0.3531273752450943,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '321'}",
        "It is impossible that 'Julius is gray' or 'Brian is yellow' or both.",
        "invalid"
    ],
    [
        0.353104367852211,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '773'}",
        "\"With friends like Oliver Stone, it's no surprise Alan Grayson is blitzing Central Florida airwaves with glitzy, Hollywood-style campaign ads. Grayson, a Democrat considered vulnerable in his re-election campaign against former Florida House Speaker Dan Webster, is airing a series of ads called \"\"When They Lie.\"\" The couple of ads we've seen are slightly different, but all follow a simple pattern. The screen flashes black and white images of conservative figures like Bill O'Reilly, Rush Limbaugh and Anne Coulter. Then, MSNBC's Ed Schultz, looks directly into the camera and shouts, \"\"This guy is what it's all about.\"\" Next the movie action music ramps up along with images from around the world, mixing in messages in black and white, like \"\"Vote Truth,\"\" \"\"Vote Grayson,\"\" or \"\"When They Lie,\"\" \"\"Vote Grayson.\"\" The ads certainly are different, but we wanted to check the one real line included, the quote from liberal commentator Ed Schultz. Viewers have been tricked before by splicing together snippets of television, and in this case, the rest of the images in the ad have almost nothing directly to do with Grayson. So we wondered if the impression the ad leaves -- that Schultz is talking specifically about Grayson -- matches reality. Grayson, whom Democrats love because he's so blunt and Republicans hate because he's so blunt, took to the House floor Sept. 29, 2009, to detail what he called the Republicans' plan for health care. \"\"The Republicans' health care plan for America ... don't get sick,\"\" Grayson said, with a simple white poster board proclaiming the same message. \"\"That's what the Republicans have in mind for you, America.\"\" But, Grayson added, Republicans recognize that plan isn't foolproof and said the GOP had a backup plan. \"\"If you get sick, America, the Republican health care plan is die quickly,\"\" Grayson added. \"\"The Republicans want you to die quickly if you get sick.\"\" Conservative Republicans demanded an apology for the \"\"die quickly\"\" comment while liberal Democrats praised Grayson. Among the chorus of praise: Schultz, one the country's more prominent liberal pundits. On his Oct. 1, 2009, MSNBC show, Schultz interviewed Grayson about his comments and referred to Grayson as the \"\"new lefty hero on the block.\"\" Here's one exchange between the two, according to an transcript:  Schultz: Congressman, do you take anything back? I mean, are we going to see more of this? Grayson: Absolutely not. The people who should be apologizing are the Republicans. They're the ones who should apologize for dragging us all through the mud here while we're just trying to improve health care in America. That's all we're trying to do. Schultz: Now, the thing I liked about it is that you had charts. I mean, this was planned out. You must have known that this was going to kick up a lot of dust. Did you fire and fire for effect? Grayson: Listen, Ed, we've got to get past this point where everything is stalled, where the Republicans are winning just through inertia. We have a majority. We have to use it. We have to change America. That's the promise that President Obama made. We have to keep it. After nearly an eight-minute interview, Schultz wraps the segment up with his own take on Grayson, and the political impact of his comments. \"\"For all of the hooey and the prognostication that's going on out there about the midterms -- 'Oh, Grayson's doing this, he might hurt the Democrats in the midterms' -- the hell with that,\"\" Schultz said (about 7:55 in). \"\"This guy is what it's all about.\"\" The end of the full quote is the line in the Grayson ad -- Schultz is specifically talking about Grayson. For the record, Grayson did apologize for his comments. Sarcastically. Here was part of that apology. (Video here.) \"\"Well, I would like to apologize. I would like to apologize to the dead, and here's why. According to this study, 'Health Insurance and Mortality in U.S. Adults,' which was published two weeks ago, 44,789 Americans die every year because they have no health insurance. So I call upon the Democratic members of the House. I call upon the Republican members of the House. I call upon all of us to do our jobs for the sake of America, for the sake of those dying people and their families. I apologize to the dead and their families that we haven't voted sooner to end this holocaust in America.\"\" In his new Hollywood-style ad, Grayson uses a quote from a charged-up Schultz that suggests Grayson is \"\"what it's all about.\"\" Grayson clips the full quote -- and omits the suggestion that some think Grayson's antics could hurt Democrats in the 2010 elections -- but Schultz is indeed talking about Grayson, according to transcript and video.\"",
        "true"
    ],
    [
        0.353100061416626,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'ja', 'row_id': '523'}",
        "ちゃんとしたタグや・・プラスチックのフックが正規品と同様に付属していたことから精巧そのもので、普通の人は真贋を見極めることは難しいと思います。",
        "not-counterfactual"
    ],
    [
        0.353100061416626,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'ja', 'row_id': '523'}",
        "ちゃんとしたタグや・・プラスチックのフックが正規品と同様に付属していたことから精巧そのもので、普通の人は真贋を見極めることは難しいと思います。",
        "not-counterfactual"
    ],
    [
        0.353009099761645,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '61'}",
        "There is little chance that either 'Greg is a frog' or 'Lily is gray' but not both.",
        "invalid"
    ],
    [
        0.35298559566338855,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '357'}",
        "گوشت استیک نباید رگ و ریشه داشته باشد و فقط دو تکه رو استیکیه زیری ها ابعاد کوچک و نامناسب برای استیکه",
        "طعم"
    ],
    [
        0.35297831892967224,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '729'}",
        "Это то, на что люди покупают продукты, одежду, книги",
        "correct"
    ],
    [
        0.35297814508279163,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '914'}",
        "I think that the “end the relationship” line should have more clarity because it reads like he wants to end his own relationship but is probably referring to the new potential one his girlfriend has with another guy.",
        "Accuracy"
    ],
    [
        0.35297303398450214,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '436'}",
        "Например, теперь в самом Ханое турист может увидеть деревню Ко Лоа, которой на своём веку дважды приходилось выполнять столичные функции",
        "correct"
    ],
    [
        0.35294075806935626,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '215'}",
        "Write an excellent summary of the given text.\n\nTitle: He [23/M] and I [23/F] are in a monogamous, committed, long-term non-relationship.\n\nText: Met a guy in junior high, fell in love with him in high school. We dated for three years and we've been not-dating for four. He broke up with me because he's emotionally unstable (bipolar) and he doesn't think he's fit to be in a relationship. He's probably right. \n\nNeither of us have dated or been with other people. We spend a lot of our time together and we have a lot of the same friends. We tell people we're best friends, but we're sleeping together and we both say \"I love you\" whenever we hang up a call. He was away on my birthday but he Skyped to tell me how much he appreciates me; made me cry. \n\nBut we're not together. He asks about guy friends sometimes and whether or not I could see myself with them like we're best girl friends. I think he's jealous but I think he would be relieved if I began seeing somebody because then he could stop feeling guilty about holding me back. He says I'm too good for him and sometime it'll occur to me that I've been fooling myself into thinking he's a good person worth caring about. He says if he was going to be with anyone, it would be me, but it's never going to happen, so I should be thinking about my future with other guys. Then other times he kisses my nose and tells me I'm pretty. I couldn't accuse him of sending me mixed signals because he'd never mean to be cruel. It makes it hard to kill the hope. \n\nIt's hard to communicate how I feel about this situation and I can't talk to any of my (our) friends about it so I guess I'm just dumping this here to vent a little. I'm tired and frustrated of loving a man who loves me back, and having to acknowledge every single day that that just isn't enough all the time. Feels like it should be. Thanks a lot for reading.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3529193749030431,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '636'}",
        "It is probably not the case that Emily is a sheep. It is probably the case that Julius is gray. It is unlikely that John dropped the milk. It is highly likely that if 'Julius is gray' or 'John dropped the milk' or both then Antoine is hungry. It is impossible that if either 'Emily is a sheep' or 'John dropped the milk' but not both then Bernhard is green. There is a very good chance that if either 'John dropped the milk' or 'Emily is a sheep' but not both then Greg is a frog.",
        "invalid"
    ],
    [
        0.3528479312856992,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '386'}",
        "Однако монотонность в «Новых анаформах» - прозрачный поток, на дне которого лежат разноцветные камешки, галька, которую можно разглядывать до бесконечности",
        "correct"
    ],
    [
        0.3528377066055934,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '81'}",
        "We doubt that Brian is yellow. It is improbable that Julius is gray. It is unlikely that Jeff went to the bedroom. It is probable that if either 'Brian is yellow' or 'Julius is gray' but not both then Yann is hungry. It is unlikely that if either 'Jeff went to the bedroom' or 'Brian is yellow' but not both then John got the milk. There is almost no chance that if either 'Brian is yellow' or 'Julius is gray' but not both then Bernhard is a swan.",
        "invalid"
    ],
    [
        0.352833757797877,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '587'}",
        "It is highly unlikely that 'Julius is a frog' or 'Brian is yellow' or both.",
        "invalid"
    ],
    [
        0.3528006573518117,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '126'}",
        "It is unlikely that Sandra took the milk. It is likely that John went to the kitchen. It is highly likely that Brian is a swan. There is little chance that if either 'Brian is a swan' or 'John went to the kitchen' but not both then Mary left the football. There is a very good chance that if either 'Brian is a swan' or 'John went to the kitchen' but not both then Emily is a mouse. Chances are about even that if 'John went to the kitchen' or 'Brian is a swan' or both then Julius is gray.",
        "invalid"
    ],
    [
        0.352769876519839,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '754'}",
        "It is probably not the case that 'Greg is yellow' or 'Julius is a lion' or both.",
        "invalid"
    ],
    [
        0.3527674625317256,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '45'}",
        "There is almost no chance that Bernhard is a swan. It is highly unlikely that Sandra left the milk. It is certain that Brian is gray. It is probably not the case that if 'Brian is gray and Bernhard is a swan' then Winona is a wolf. There is a very good chance that if 'Brian is gray and Bernhard is a swan' then Greg is a rhino. There is little chance that if either 'Bernhard is a swan' or 'Sandra left the milk' but not both then Julius is yellow.",
        "invalid"
    ],
    [
        0.35275086760520935,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '485'}",
        "It is probably not the case that 'Julius is a swan and Lily is a rhino'.",
        "invalid"
    ],
    [
        0.3527410179376602,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '77'}",
        "نظر شما در مورد عطر، بو، و طعم این چای چیست؟",
        "طعم"
    ],
    [
        0.3527410179376602,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '399'}",
        "نظر شما در مورد عطر، بو، و طعم این چای چیست؟",
        "طعم"
    ],
    [
        0.3527410179376602,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '700'}",
        "نظر شما در مورد عطر، بو، و طعم این چای چیست؟",
        "طعم"
    ],
    [
        0.3527410179376602,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '728'}",
        "نظر شما در مورد عطر، بو، و طعم این چای چیست؟",
        "طعم"
    ],
    [
        0.35273564358552295,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '955'}",
        "Roland Deschain , son of Steven Deschain , was born in the Barony of Gilead , in In - World . Roland is the last surviving gunslinger , a man whose goal is finding and climbing to the top of the Dark Tower , purported to be the very center of existence , so that he may right the wrongs in his land . This quest is his obsession , monomania and geas to Roland : In the beginning the success of the quest is more important than the lives of his family and friends . He is a man who lacks imagination , and this is one of the stated reasons for his survival against all odds : he can not imagine anything other than surviving to find the Tower .",
        ""
    ],
    [
        0.3527297079563141,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '728'}",
        "It is probably the case that Lily is a rhino. It is almost certain that Julius is a swan. There is almost no chance that John went to the kitchen.",
        "invalid"
    ],
    [
        0.3527248402436574,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '790'}",
        "Chances are slight that either 'Bernhard is white' or 'Brian is a frog' but not both.",
        "invalid"
    ],
    [
        0.3527226547400157,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '2'}",
        "It is probably not the case that Brian is white. It is probably the case that Winona is a wolf. We doubt that Bernhard is green. Chances are about even that if 'Bernhard is green and Winona is a wolf' then John discarded the apple. We doubt that if 'Winona is a wolf and Brian is white' then Mary went to the office. It is improbable that if 'Bernhard is green' or 'Winona is a wolf' or both then Lily is yellow.",
        "invalid"
    ],
    [
        0.3527223964532216,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '590'}",
        "It is probably not the case that either 'Brian is yellow' or 'Mary discarded the milk' but not both.",
        "invalid"
    ],
    [
        0.35266515364249545,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '447'}",
        "У Эда в сумке оказалась бутылка воды, которую он, также не оплатив, упер из супермаркета",
        "correct"
    ],
    [
        0.3525843173265457,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '333'}",
        "It is impossible that Bernhard is a swan. There is a very good chance that Brian is white. We doubt that Jeff went to the hallway. Chances are slight that if either 'Jeff went to the hallway' or 'Brian is white' but not both then John is in the garden. It is probable that if 'Bernhard is a swan' or 'Brian is white' or both then Daniel grabbed the apple. It is likely that if 'Brian is white and Bernhard is a swan' then Mary dropped the milk.",
        "invalid"
    ],
    [
        0.3525620972116788,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '554'}",
        "['Совфед', 'закон']",
        "correct"
    ],
    [
        0.3525569885969162,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '447'}",
        "It is improbable that 'Lily is yellow' or 'Daniel got the milk' or both.",
        "invalid"
    ],
    [
        0.35252391546964645,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '347'}",
        "\"Первому нужна Украина без войны, которая будет  закупать продукцию немецкого автопрома.\"",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '1'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '3'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '6'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '7'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '8'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '9'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '10'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '11'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '14'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '21'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '26'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '27'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '31'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '33'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '34'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '36'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '38'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '42'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '43'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '44'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '45'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '46'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '47'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '48'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '49'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '50'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '52'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '53'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '54'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '55'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '56'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.episodes', 'row_id': '58'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '0'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '3'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '4'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '5'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '9'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '12'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '14'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '16'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '22'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '24'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '26'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '28'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '35'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '36'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '40'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '41'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '43'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '44'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '45'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '46'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '49'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '50'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '51'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '53'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '54'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '55'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '56'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '57'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '60'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '61'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '62'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '67'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '68'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '69'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '70'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '77'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '78'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '79'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '80'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '83'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '84'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '85'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '87'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '88'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '91'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '92'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '93'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '97'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '98'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '101'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '103'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '104'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '106'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '109'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '118'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '121'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '122'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '126'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '128'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '131'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '136'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '137'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '140'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '144'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '145'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '146'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '147'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '150'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '154'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '158'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '163'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '165'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '166'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '168'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '172'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '176'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '177'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '179'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '180'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '186'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '191'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '194'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '195'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '197'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '207'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '208'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '209'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '211'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '217'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '218'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '219'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '221'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '227'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '229'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '231'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '234'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '237'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '238'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '239'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '240'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '241'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '242'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '244'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '245'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '249'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '254'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '256'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '257'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '261'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '263'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '264'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '267'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '270'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '272'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '278'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '280'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '283'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '284'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '285'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '286'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '288'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '291'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '295'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '300'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '302'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '304'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '305'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '307'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '314'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '316'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '318'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '319'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '321'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '322'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '325'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '328'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '332'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '335'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '336'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '337'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '338'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '340'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '342'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '344'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '345'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '348'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '351'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '352'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '358'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '360'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '364'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '367'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '369'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '370'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '372'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '373'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '377'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '378'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '379'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '384'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '387'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '388'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '392'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '393'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '395'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '397'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '402'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '404'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '406'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '408'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '409'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '413'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '415'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '417'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '418'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '419'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '423'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '427'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '428'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '429'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '435'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '438'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '439'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '445'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '452'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '458'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '459'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '460'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '469'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '475'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '476'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '480'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '488'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '492'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '493'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '497'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '499'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '501'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '504'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '509'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '511'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '513'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '514'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '518'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '519'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '526'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '528'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '532'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '534'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '536'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '537'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '538'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '539'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '540'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '543'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '544'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '545'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '546'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '548'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '549'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '550'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '551'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '552'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '553'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '555'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '556'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '557'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '558'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '559'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '560'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '561'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '562'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '563'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '564'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '565'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '566'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '567'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '568'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '569'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '570'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '571'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '572'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '573'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '574'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '575'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '576'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '577'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '579'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '580'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '581'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '582'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '583'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '584'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '585'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '586'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '587'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '588'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '590'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '591'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '592'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '593'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '594'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '595'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '596'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '597'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '598'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '599'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '600'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '601'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '602'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '603'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '604'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '605'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '606'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '607'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '608'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '609'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '610'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '611'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '612'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '613'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '614'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '615'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '616'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '617'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '618'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '620'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '621'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '622'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '623'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '624'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '625'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '626'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '627'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '628'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '629'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '630'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '631'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '632'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '633'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '634'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '641'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '642'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '645'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '648'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '649'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '650'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '654'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '655'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '657'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '658'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '659'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '661'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '664'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '666'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '667'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '669'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '670'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '676'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '677'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '678'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '680'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '681'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '683'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '685'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '689'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '691'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '692'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '693'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '695'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '696'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '697'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '698'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '699'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '700'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '701'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '704'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '705'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '708'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '709'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '711'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '712'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '713'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '715'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '716'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '718'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '722'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '723'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '725'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '726'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '731'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '732'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '734'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '736'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '738'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '740'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '742'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '743'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '744'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '747'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '749'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '750'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '751'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '752'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '756'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '758'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '759'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '760'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '761'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '763'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '770'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '771'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '772'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '780'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '782'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '784'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '786'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '787'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '789'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '790'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '791'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '792'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '794'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '796'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '798'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '799'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '800'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '801'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '802'}",
        "correct",
        "correct"
    ],
    [
        0.3524496431152026,
        "{'dataset_id': 'RussianNLP/tape', 'config_id': 'winograd.raw', 'row_id': '803'}",
        "correct",
        "correct"
    ],
    [
        0.3524347245693207,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '29'}",
        "Preface: I'm the most insecure girl in the world. You know that \"gut feeling\" everyone says they have when they are asked, \"How did you know she/he was cheating on you?\" Well I have that feeling all the time. Whether it be a missed call from an unknown number, to the passenger seat in his car not being positioned exactly as I remembered it.\n\nI conjure a lot of shit up in my head. I know a lot of it is in my head. He's never cheated, but I can't shake that \"gut feeling\" whenever something seems off.\n\nWhenever something 'abnormal' occurs, my instinct tells me he's cheating on me.\n\nAll my insecurities and accusations have pushed him away. It's taken several months for us to get back to normal and rebuild our relationship. When my insecurities are gone, our relationship is amazing; he is responsive, loving, caring, and open again. But the second I start bringing up the past, accusing him of things, he pulls back and I can tell he loses hope in us.\n\nPlease help. How do I push these thoughts out of my head. I know tonight is just one of those nights when my insecurities are trying to take over me. This isn't a situation where I have loads of proof of him cheating. It's just an instance, but I need help calming my brain and making that \"gut feeling\" shut up before I say something stupid.\nI don't want to rock the boat over something so stupid. I'm so mad at myself for thinking this way.\n\nHarsh advice wanted. Anything to make my head shut up.",
        "Accuracy"
    ],
    [
        0.35242006182670593,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '268'}",
        "It is probably not the case that 'Mary left the milk' or 'Greg is a lion' or both.",
        "invalid"
    ],
    [
        0.352377121647199,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '495'}",
        "It is likely that Lily is a swan. It is almost certain that Sandra took the milk. It is likely that Jeff moved to the garden. We doubt that if 'Sandra took the milk' or 'Jeff moved to the garden' or both then Mary is in the bathroom. It is improbable that if 'Jeff moved to the garden' or 'Lily is a swan' or both then Greg is white. It is highly unlikely that if either 'Sandra took the milk' or 'Lily is a swan' but not both then Gertrude is a mouse.",
        "invalid"
    ],
    [
        0.3523661245902379,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '264'}",
        "We believe that Fred went to the garden. It is probably the case that Julius is white. It is unlikely that Gertrude is a sheep. It is probably the case that if 'Fred went to the garden' or 'Gertrude is a sheep' or both then Brian is a frog. It is certain that if either 'Julius is white' or 'Fred went to the garden' but not both then Daniel dropped the apple. It is improbable that if 'Julius is white and Fred went to the garden' then Greg is a lion.",
        "invalid"
    ],
    [
        0.3523626873890559,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '759'}",
        "Age-related macular degeneration, or AMD, is the leading cause of vision loss among seniors, gradually eroding crucial central vision. There are different forms but more than 5 million people worldwide, and a million in the U.S., have an advanced type of so-called “dry” macular degeneration that has no treatment. First patients may notice blurriness when they look straight ahead. Eventually many develop blank spots, becoming legally blind. “These are seniors who are entering their golden years and now they’ve lost the ability to read, watch television, see their loved ones,” said Dr. Rahul Khurana, a retina specialist and spokesman for the American Academy of Ophthalmology. The experimental drug, lampalizumab, aims to slow the destruction of light-sensing cells in the retina, creeping lesions that characterize the stage of dry AMD called “geographic atrophy.” When those cells die, they can’t grow back — the vision loss is irreversible. WHAT THE RESEARCH FOUND In an 18-month study of 129 patients, monthly eye injections of the drug modestly slowed worsening of the disease when compared with patients given dummy shots. What’s exciting for scientists came next, when researchers from drugmaker Genentech Inc. took a closer look at exactly who was being helped. It turns out that nearly 6 in 10 of the study’s participants carry a gene variation that makes part of the immune system go awry — a genetic flaw already known to increase the risk of getting macular degeneration in the first place. Those are the only patients who appeared to benefit from the drug; they had 44 percent less eye damage than the untreated patients, the Genentech team reported Wednesday in the journal Science Translational Medicine. While the study is too small to prove if lampalizumab really helps maintain vision, that’s a bigger difference than the overall results suggested. WHY WOULD AN IMMUNE-RELATED GENE AFFECT AGING EYES? One arm of the immune system, the complement pathway, helps fight infections by attracting immune cells to attack bacteria. Normally, there’s a barrier that keeps such cells away from the retina. But that barrier can break down with age, opening sensitive eye cells to harm from the spillover, explained Genentech immunologist Menno van Lookeren Campagne. Now for the gene connection: Previous studies have linked macular degeneration to gene variations that remove some of that pathway’s natural brakes, so it can become too active. The hypothesis: Genentech’s drug, lampalizumab, essentially offers a backup method for tamping down the immune reaction. An antibody, it works by inhibiting a particular enzyme named factor D that helps power the immune pathway. “We try to reinsert the braking ability,” said study lead author Brian Yaspan, a Genentech senior scientist. WHAT’S NEXT Wednesday’s study detected no safety concerns, clearing the way for Genentech and its parent company Roche to open two large-scale studies that aim to prove if the drug works. Results are expected later this year. The current research sheds light on how that long-suspected immune culprit might be working, and is “the first suggestion that there may be a treatment for geographic atrophy coming up in the future,” said National Eye Institute retina specialist Dr. Wai Wong, who wasn’t involved in the study. “It’s a very, very exciting study,” said Khurana, the ophthalmologist association’s spokesman, who also wasn’t part of the research. “From the basic science perspective, it makes a lot of sense.” HEALTH ADVICE FOR NOW Macular degeneration tends to occur after age 60, but it sometimes strikes earlier. According to the National Eye Institute, it’s less common in people who exercise regularly, avoid smoking, and eat a diet high in green leafy vegetables and fish. Symptoms often aren’t noticeable early on. But several eye tests can detect signs of macular degeneration, including a dilated eye exam and a tool called an Amsler grid with straight lines that may look wavy if the macula, the center of the retina, is harmed. Macular degeneration patients often are advised to take certain vitamin combinations that may help stave off advanced disease. And it’s important for patients to know what type they have. While there’s no treatment for the advanced dry form, the “wet” form occurs when leaky blood vessels grow under the retina — and there are several therapies that can help those patients preserve vision. ___ This Associated Press series was produced in partnership with the Howard Hughes Medical Institute’s Department of Science Education. The AP is solely responsible for all content.",
        "true"
    ],
    [
        0.3522963921229045,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '882'}",
        "\"There was no discussion of costs but we acknowledge that costs would be difficult to discuss in this story. They might have discussed the comparative costs of general vs. spinal vs. regional anesthesia or the potential downstream costs of anesthesia adverse effects. The benefits associated with the use of anesthesia were not presented other than the introduction explaining that anesthesia allows a patient to 'wake……as if from a deep slumber' having made it possible for surgery to take place. However there was no quantification of benefit from anesthesia in terms of how surgical risks are decreased in an anesthetized as opposed to unanesthetized patient. The story could also have addressed the comparative benefits between different forms of anesthesia. Possible harms associated with anesthesia were discussed in the article, though there was no information about how often these harms occur or how severe the effects might be. There were clear attempts to balance the information. The story stated, \"\"Many clinical anesthesiologists question the relevance of the animal studies.\"\" One source said, \"\"Human babies are not large rat pups.\"\" Although one of the anesthesiologists interviewed for this story talked about 'increasing evidence', the story itself did not contain evidence or even traceable references to evidence on the topic. Instead, it quoted a number of experts about their 'suggestions', 'fears', and 'hopes' when it comes to the effects that anesthesia had on function. While the story did mention rats taking longer to run a maze as adults when subjected to prolonged anesthesia when young, there was no quantitative estimate for the size of the effect anesthesia had been demonstrated to play. Even when data were given (1998 Lancet study showing 10% of elderly surgery patients have worse scores on cognition tests post surgery) we get no information on the magnitude of the effect (is it clinically important?) or on the research design (and therefore, the likely validity of any findings). The story was somewhat alarmist, citing 'suggestions' that anesthesia might weaken the body's ability to kill tumor cells  thereby making cancer recurrence more likely or that it might trigger an inflammatory response leading to atherosclerosis and other serious conditions. Mostly animal studies are cited to raise alarm about anesthesia. There are relevant human studies and they should have cited those and the rates of adverse effects. However, we'll give the story the benefit of the doubt because there were clear attempts to inject balance, with lines such as, \"\"Most anesthesiologists and surgeons, citing the millions of people the world over who live long, healthy lives after surgery, say there is no call for worry.\"\" Several professors were interviewed for this story including at least one who was not associated with a department of anesthesia. Although outlining reasons why anesthesia might present some increased risk of bodily harm, the story did not provide any guidance for determining whether a patient has any options in regards to anesthesia type, dose, and duration or anything about categories of procedures where options were more likely. Various anesthesia options were mentioned (regional/spinal/local) as was the fact that studies are underway to test hypotheses about particular advantages. However, the story didn't discuss any of the known advantages/disadvantages of these alternatives. The use of anesthesia is widely utilized in the surgical management of medical conditions, which is clear in the story. The story was clear that anesthesia is not new but explained that what is a more recent wrinkle is a focused examination of the long term impact of exposure to anesthesia Does not appear to rely on a press release.\"",
        "true"
    ],
    [
        0.352287158370018,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '474'}",
        "We believe that Jessica is a wolf. It is impossible that Winona is a sheep. There is a better than even chance that Brian is green. It is likely that if 'Jessica is a wolf and Brian is green' then Daniel left the apple. It is almost certain that if 'Winona is a sheep and Jessica is a wolf' then John went to the garden. It is certain that if 'Jessica is a wolf and Brian is green' then Mary put down the milk.",
        "invalid"
    ],
    [
        0.352258359392484,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '37'}",
        "Doctors were just guessing a decade ago when they gave Alison Cairnes’ husband a new drug they hoped would shrink his lung tumors. Now she takes it, but the choice was no guesswork. Sophisticated gene tests suggested it would fight her gastric cancer, and they were right.",
        "true"
    ],
    [
        0.3522546887397766,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'en', 'row_id': '983'}",
        "\"been buying these for years, like nylon cause it doesn't \\cling \\\"\" to leggings, makes for a smoother line; very difficult to find my size in local stores, very happy to be able to buy these easily--they're my favorite\"\"\"",
        "not-counterfactual"
    ],
    [
        0.3522546887397766,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'en', 'row_id': '983'}",
        "\"been buying these for years, like nylon cause it doesn't \\cling \\\"\" to leggings, makes for a smoother line; very difficult to find my size in local stores, very happy to be able to buy these easily--they're my favorite\"\"\"",
        "not-counterfactual"
    ],
    [
        0.3521956255038579,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '59'}",
        "There is a better than even chance that Brian is gray. It is improbable that Yann is tired. It is unlikely that Bernhard is white. It is probable that if 'Bernhard is white' or 'Brian is gray' or both then Greg is a lion. It is probably the case that if 'Bernhard is white' or 'Yann is tired' or both then Mary picked up the milk. It is highly likely that if 'Bernhard is white and Yann is tired' then John went to the kitchen.",
        "invalid"
    ],
    [
        0.3521904746691386,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '580'}",
        "[{('Francisco', 'son', 'Leonard'): [('Francisco', 'daughter', 'Anna'), ('Anna', 'brother', 'Leonard')]}, {('Anna', 'brother', 'Leonard'): [('Anna', 'sister', 'Wilhelmina'), ('Wilhelmina', 'brother', 'Leonard')]}]",
        "son"
    ],
    [
        0.3521677056948344,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '802'}",
        "Write an excellent summary of the given text.\n\nTitle: Parents of Reddit:  What is the best way you have communicated to your child?\n\nText: I am currently 21 years old, but I have been thinking about this question for quite a while now.  I have known people who enjoy the idea of a child, but once they have a child they have no idea on how to raise it.  And when they become older and more conscious of their own opinions towards certain topics the question is \"How was a parent really get through to a child?\"  I have seen so many kids who end up going down a bad path, despite what their parents warn them about or try to help them with, they just won't listen. Even when I was younger I often found myself fighting with my parents about things I thought was right from my point of view, however ended up being very wrong after I experienced it myself.  \n\nOne day I found myself spending a really long time contemplating the idea on how to best approach my children in the future, if I end up having any. So I created a set of videos of myself explaining certain topics directed to my children.  Each topic is roughly centered around different adolescent benchmarks, for example in some videos I discuss what to expect when you first enter High School and what my preconceived notions of High School were, another video discusses bullying, things I wish I would have done in high school, personal mistakes I have made (financially, in relationships, and so on).  The idea behind this was mainly driven by the idea that if I could approach my kids from a younger perspective, that it would have a greater impact on them instead of the old cliche \"When I was your age...\" line.  \n\nNow the question I'm interested in is how do other parents effectively reach their kids and prevent them from making costly mistakes?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35216565430164337,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '335'}",
        "It is probably not the case that either 'Winona is a cat' or 'Julius is white' but not both.",
        "invalid"
    ],
    [
        0.3521617700656255,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '803'}",
        "We doubt that Bernhard is white. It is almost certain that Brian is green. There is a better than even chance that Julius is a frog. It is unlikely that if 'Bernhard is white' or 'Brian is green' or both then Fred went to the garden. It is highly likely that if 'Brian is green' or 'Julius is a frog' or both then Jessica is a cat. It is impossible that if 'Brian is green' or 'Julius is a frog' or both then John dropped the apple.",
        "invalid"
    ],
    [
        0.3521517763535182,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '656'}",
        "Chances are slight that Brian is a swan. It is almost certain that Emily is a wolf. It is probably the case that John moved to the garden. It is almost certain that if either 'John moved to the garden' or 'Brian is a swan' but not both then Greg is green. It is improbable that if either 'Brian is a swan' or 'John moved to the garden' but not both then Mary left the football. There is a better than even chance that if 'Emily is a wolf and John moved to the garden' then Sandra got the football.",
        "invalid"
    ],
    [
        0.35213711857795715,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '560'}",
        "It is probably the case that either 'Bernhard is a frog' or 'Lily is gray' but not both.",
        "invalid"
    ],
    [
        0.35210544367631275,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '564'}",
        "There is little chance that Julius is white. Chances are about even that Emily is a sheep. It is probably the case that John moved to the office. It is certain that if 'Julius is white and Emily is a sheep' then Mary took the football. Chances are about even that if 'Julius is white and Emily is a sheep' then Greg is a lion. We doubt that if 'Emily is a sheep' or 'John moved to the office' or both then Lily is yellow.",
        "invalid"
    ],
    [
        0.3520965278148651,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '8'}",
        "It is probably not the case that either 'Lily is yellow' or 'Greg is gray' but not both.",
        "invalid"
    ],
    [
        0.3520910193522771,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '154'}",
        "We believe that Bernhard is white. We doubt that Bill went to the garden. There is a very good chance that Greg is a swan. We believe that if 'Bernhard is white and Greg is a swan' then Lily is a rhino. There is a very good chance that if either 'Bernhard is white' or 'Greg is a swan' but not both then Daniel left the apple. We believe that if 'Greg is a swan and Bernhard is white' then Mary dropped the apple.",
        "invalid"
    ],
    [
        0.35202539960543316,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '168'}",
        "In dieser Box gibt es übrigens so gut wie nichts, was nicht von hörenswert bis atemberaubend wäre'  dann Wyn Morris (Philips, z.Z.",
        "counterfactual"
    ],
    [
        0.35202539960543316,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '168'}",
        "In dieser Box gibt es übrigens so gut wie nichts, was nicht von hörenswert bis atemberaubend wäre'  dann Wyn Morris (Philips, z.Z.",
        "counterfactual"
    ],
    [
        0.35201071202754974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '650'}",
        "We believe that Mary went to the office. There is a better than even chance that Brian is a rhino. There is little chance that Julius is yellow. It is highly unlikely that if 'Julius is yellow' or 'Mary went to the office' or both then Lily is a lion. We believe that if either 'Brian is a rhino' or 'Julius is yellow' but not both then John grabbed the apple. It is highly unlikely that if either 'Brian is a rhino' or 'Julius is yellow' but not both then Bernhard is green.",
        "invalid"
    ],
    [
        0.3519724706808726,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '920'}",
        "(1) Гесиона пригласила к себе Элли, её отца и Менгена, чтобы расстроить её брак, ибо она не хочет, чтобы девушка выходила замуж за нелюбимого человека из-за денег и благодарности, которую она испытывает к нему за то, что когда-то Менген помог её отцу избежать полнейшего разорения. (2) В разговоре с Элли Гесиона выясняет, что девушка влюблена в некоего Марка Дарили, с которым познакомилась недавно и который рассказывал ей о своих необычайных приключениях, чем и покорил её. (3) Во время их разговора в комнату заходит Гектор, муж Гесионы, красивый, хорошо сохранившийся пятидесятилетний мужчина. (4) Элли внезапно умолкает, бледнеет и пошатывается. (5) Это и есть тот, кто представился ей как Марк Дарнли. (6) Гесиона выгоняет мужа из комнаты, чтобы привести Элли в чувство. (7) Придя в себя, Элли ощущает, что в один миг лопнули все её девичьи иллюзии, а вместе с ними разбилось и сердце. (8) По просьбе Гесионы Элли рассказывает ей все о Менгене, о том, как он в своё время дал её отцу крупную сумму, чтобы не допустить банкротства его предприятия. (9) Когда предприятие все же обанкротилось, Менген помог её отцу выпутаться из столь сложной ситуации, купив все производство и дав ему место управляющего. (10) Входят капитан Шатовер и Менген. (11) Капитану с первого же взгляда становится понятен характер отношений Элли и Менгена. (12) Он отговаривает последнего жениться из-за большой разницы в возрасте и добавляет, что его дочь во что бы то ни стало решила расстроить их свадьбу.",
        "False"
    ],
    [
        0.3519724706808726,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '921'}",
        "(1) Гесиона пригласила к себе Элли, её отца и Менгена, чтобы расстроить её брак, ибо она не хочет, чтобы девушка выходила замуж за нелюбимого человека из-за денег и благодарности, которую она испытывает к нему за то, что когда-то Менген помог её отцу избежать полнейшего разорения. (2) В разговоре с Элли Гесиона выясняет, что девушка влюблена в некоего Марка Дарили, с которым познакомилась недавно и который рассказывал ей о своих необычайных приключениях, чем и покорил её. (3) Во время их разговора в комнату заходит Гектор, муж Гесионы, красивый, хорошо сохранившийся пятидесятилетний мужчина. (4) Элли внезапно умолкает, бледнеет и пошатывается. (5) Это и есть тот, кто представился ей как Марк Дарнли. (6) Гесиона выгоняет мужа из комнаты, чтобы привести Элли в чувство. (7) Придя в себя, Элли ощущает, что в один миг лопнули все её девичьи иллюзии, а вместе с ними разбилось и сердце. (8) По просьбе Гесионы Элли рассказывает ей все о Менгене, о том, как он в своё время дал её отцу крупную сумму, чтобы не допустить банкротства его предприятия. (9) Когда предприятие все же обанкротилось, Менген помог её отцу выпутаться из столь сложной ситуации, купив все производство и дав ему место управляющего. (10) Входят капитан Шатовер и Менген. (11) Капитану с первого же взгляда становится понятен характер отношений Элли и Менгена. (12) Он отговаривает последнего жениться из-за большой разницы в возрасте и добавляет, что его дочь во что бы то ни стало решила расстроить их свадьбу.",
        "False"
    ],
    [
        0.3519541372855504,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '355'}",
        "It is probably the case that John took the football. It is highly unlikely that Emily is a sheep. It is probable that Greg is yellow. It is likely that if 'Greg is yellow and Emily is a sheep' then Lily is a rhino. It is probable that if 'Emily is a sheep' or 'John took the football' or both then Jeff left the football. It is probable that if either 'John took the football' or 'Greg is yellow' but not both then Brian is a swan.",
        "invalid"
    ],
    [
        0.3519451270500819,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '959'}",
        "It is almost certain that either 'Julius is a lion' or 'Mary took the milk' but not both.",
        "invalid"
    ],
    [
        0.35193876922130585,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '446'}",
        "Chances are slight that John went to the garden. It is certain that Winona is a mouse. There is almost no chance that Lily is a rhino. It is improbable that if 'John went to the garden and Winona is a mouse' then Bernhard is yellow. It is unlikely that if 'John went to the garden' or 'Winona is a mouse' or both then Julius is gray. We believe that if either 'Winona is a mouse' or 'John went to the garden' but not both then Daniel dropped the apple.",
        "invalid"
    ],
    [
        0.35190898676713306,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '882'}",
        "It is impossible that 'Greg is gray' or 'Julius is a swan' or both.",
        "invalid"
    ],
    [
        0.3519035329421361,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '443'}",
        "So I work part-time once or twice a week at a retail store and during my lunch breaks, I've been frequenting the same coffee store within the shopping centre I work at. \n\nLately when I get my coffee, I've been getting served by this cute barista guy at the coffee shop (I honestly can't tell whether he's younger than me or not because work uniforms, and I always see him on weekends) in which I'm having a little crush on.\n\nWe both kind of acknowledge and recognise each other when I got my coffee and exchange knowing smiles when I order. I'm already on friendly terms with the managers who work there, with them remembering my name and order whenever they serve me, as well as engaging in polite conversation. \n\nBut with the barista guy, I haven't really had the chance for a casual small conversation due too being too shy and the timing (lunch rush) but I would really like to, not necessarily in terms of going on a date with this guy, but just to get to know him a bit better first if that makes sense?  \n\nSo reddit! Any tips or advice as to how I should go about in talking to this cute barista in a friendly manner?",
        "Accuracy"
    ],
    [
        0.35189854602018994,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '977'}",
        "The Consumer Goods Forum (CGF), an industry network of some 400 retailers, manufacturers and other players from 70 countries with combined sales of 2.5 trillion euros ($3.4 trillion), agreed the commitments at its annual summit in Paris. “It is not business as usual anymore. Pressure is mounting from all sides and angles,” Paul Bulcke, chief executive of Nestle, the world’s biggest food and drink firm behind brands such as Kit-Kat and Nescafe, told the meeting. “We need to show them we are a responsive and responsible industry, now more than ever.”  Food manufacturers and retailers have come under mounting pressure in recent years over their role in a range of issues from the global obesity epidemic, to climate change and deforestation due to the growth of palm oil production. The steps announced on Wednesday included a commitment to     stop targeting advertising to children under 12 years by 2018 of products that fail to meet certain nutrition criteria and to introduce industry-wide labeling by 2018 to help consumers make healthier food choices. Bulcke said the CGF board also agreed that members would make company policies on nutrition and product formulation public by 2016. The CGF promised its members would aim for zero net deforestation by 2020 through the more sustainable sourcing of key commodities and begin phasing out hydro fluorocarbons, blamed for contributing to global warming, in new refrigeration units by 2015. In 2011, top U.S. food and drink makers including Coca-Cola and Kellogg Co agreed to industry-created voluntary nutrition guidelines for products marketed towards children under the age of 12. But the food, beverage and restaurant industries as a whole have successfully fought most government oversight on food advertising to children. In October 2013, U.S. legislation was proposed that would require uniform front-of-package food labels in a move to streamline labels and clarify certain claims on nutrition. In Europe, regulations that go into effect in December 2014 change existing legislation on food labeling that would require nutrition information on processed foods, origin labeling of unprocessed meat, the highlighting of allergens such as peanuts and better legibility. ($1 = 0.7383 euro)",
        "true"
    ],
    [
        0.3518546422322591,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '311'}",
        "[{'follow_up_question': 'Are you a family farmer or fisherman?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Does it involve a municipality?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.35182637472947437,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '997'}",
        "It is highly unlikely that Greg is a swan. It is probable that Emily is a sheep. Chances are about even that John discarded the milk. It is impossible that if 'Greg is a swan and Emily is a sheep' then Bernhard is green. It is probably the case that if 'John discarded the milk and Emily is a sheep' then Brian is yellow. It is improbable that if either 'Emily is a sheep' or 'John discarded the milk' but not both then Mary left the football.",
        "invalid"
    ],
    [
        0.35177595416704815,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '661'}",
        "It is impossible that Mary left the football. There is almost no chance that Greg is a rhino. We believe that Lily is a swan.",
        "invalid"
    ],
    [
        0.3517559965451558,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '830'}",
        "Write an excellent summary of the given text.\n\nTitle: TV calibration for dummies, anyone?\n\nText: I recently \"inherited\" an LG LCD-TV (32LG2000) from my parents after they gifted themselves a new one for christmas. To go with this recent windfall I purchased a\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35175428291161853,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '641'}",
        "It is impossible that 'Brian is a rhino and Daniel took the milk'.",
        "invalid"
    ],
    [
        0.3517434298992157,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '59'}",
        "Credit: UC Davis Comparative Oncology ProgramThis short news release describes a gene therapy experiment in four dogs that might turn out to help human patients with a rare blood disorder known as Factor VII deficiency. The release does a good job of making clear that this is just a proof-of-concept and needs human trials. Great specific language is used to make that clear. But it does not give any context for the problems of developing gene therapies for rare diseases. Companies may balk at developing a treatment than can’t be sold very widely, which contributes to high costs. Gene therapies are emotional minefields for patients and families, especially since so much has been promised and actual successes have been few. One gene therapy offered in Europe has a price tag of $1 million. This release would serve readers better if it gave some of that daunting context. A Washington Post story explains some of the challenges: “No [gene] therapy is approved yet in the United States, so discussions about price — as well as crucial questions about how much patients will pay directly — are hypothetical. But industry leaders are already talking about ways to get ahead of potentially massive one-time price tags that could make insurers and patients balk.”",
        "true"
    ],
    [
        0.35171832144260406,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '114'}",
        "It is highly unlikely that either 'Brian is white' or 'Jessica is a cat' but not both.",
        "invalid"
    ],
    [
        0.3517141838868459,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '293'}",
        "There is a very good chance that Julius is a frog. It is probably not the case that Antoine is hungry. It is highly likely that Mary got the football. There is little chance that if 'Antoine is hungry' or 'Mary got the football' or both then Winona is a mouse. There is almost no chance that if 'Antoine is hungry and Mary got the football' then John went to the hallway. There is almost no chance that if 'Mary got the football and Julius is a frog' then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.35170172651608783,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '984'}",
        "Write an excellent summary of the given text.\n\nTitle: Me [18 M] / my girlfriend [18 F] of 6 months, is talking to multiple other \"guy friends\" should I be concerned, what should I do?\n\nText: okay, I'll be short and to the point. My girlfriend has always had other guy friends, which I'm okay with, I've met them, or I already knew them, since me and her share a group of friends, and I trust them. \n\nBut, recently she's been talking to another guy she met at work, a lot. She's texted him in front of me repeatedly, and one time I saw him make a sexual \"joke\" to her, and I talked to her about it and she said she'd talk to him, about it but I don't know if she ever actually did anything.\n\nAnd she's been talking to another guy who she knows from school that added her on snapchat, and she told me that he was only talking to her for sex, and that it insulted her. But apparently he asked for her number, and she gave it to them, and I don't know how much she talks to him. \n\nWhat should I do, how should I take this? Should I be worried?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35169513523578644,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '526'}",
        "\"Although this is a very preliminary study, some mention of costs should have been included, even if simply to note that the cost of potential treatments is unknown at the present time. The published study itself does not quantify benefits clearly , perhaps understandable given that it is a laboratory study, not a clinical one. But we give the story a satisfactory rating for doing a reasonable job of putting the study results into context. The brevity of the response and the inconsistent findings across individuals were noted appropriately in the story. While harms are not quantified in the published study itself, this story does well to emphaszie the importance — and current lack — of safety data for an alluded-to use of oxytocin in children with autism. We do know a good deal about the toxicity of oxytocin when given to women to induce labor and for a few hours. In addititon to possible severe allergic reactions, water intoxication is an important side effect. We give the story kudos for noting several limitations in this research, including the wide variations in individual responses and a lack of evidence that the strategy \"\"would be effective at all\"\" in children or young adults. The author also notes a lack of long-term safety data, and she describes  challenges in translating the delivery method to a real-world application. We would have liked to have seen a bit more characterization of the preliminary nature of this laboratory study and its very small sample. The story does not resort to disease-mongering. The story cites several independent sources and provides several quotes for balance. The study authors themselves identified no conflicts of interest. The story does discuss the treatment of autism and that no drug therapies are currently available for the social dysfunction observed in people with Asperger syndrome and other forms of autism. The story is clear that the strategy used in this laboratory study is uNPRoven in the real world, particularly in children and young adults. They even note the issues in translating the delivery method to clinical practice. The article notes that there have been prior studies that also demonstrated an effect of oxytocin in people with autism. The story does not appear to rely on a news release.\"",
        "true"
    ],
    [
        0.3516929050286611,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '140'}",
        "We believe that Jessica is a cat. It is probable that Brian is yellow. It is almost certain that John dropped the milk. There is a better than even chance that if 'Brian is yellow and Jessica is a cat' then Sandra took the football. It is almost certain that if either 'Jessica is a cat' or 'John dropped the milk' but not both then Lily is a lion. Chances are about even that if 'Jessica is a cat' or 'John dropped the milk' or both then Emily is a wolf.",
        "invalid"
    ],
    [
        0.3516390224297841,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '598'}",
        "['RecQ helicases are highly conserved from bacteria to man.', 'Germline mutations in three of the five known family members in humans give rise to debilitating disorders that are characterized by, amongst other things, a predisposition to the development of cancer.', \"One of these disorders — Bloom's syndrome — is uniquely associated with a predisposition to cancers of all types.\", 'So how do RecQ helicases protect against cancer?', 'They seem to maintain genomic stability by functioning at the interface between DNA replication and DNA repair.']",
        "False"
    ],
    [
        0.3516332805156708,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '756'}",
        "It is impossible that 'Brian is a swan' or 'Bill moved to the office' or both.",
        "invalid"
    ],
    [
        0.35157326360543567,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '864'}",
        "It is probably not the case that either 'Lily is a rhino' or 'Sandra left the milk' but not both.",
        "invalid"
    ],
    [
        0.35156209766864777,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '924'}",
        "The summary is slightly inaccurate as he does not state that he questions their future together but questions her intentions for incessantly commenting on other men's attractiveness to him.",
        "Accuracy"
    ],
    [
        0.3515551785628001,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '403'}",
        "It is impossible that either 'Greg is a frog' or 'Jeff put down the milk' but not both.",
        "invalid"
    ],
    [
        0.3515479813019435,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '583'}",
        "It is probably not the case that 'Lily is a frog' or 'Fred is in the cinema' or both.",
        "invalid"
    ],
    [
        0.3514950176080068,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '923'}",
        "فیلمی پر کشش و دوست داشتنی   اما تلخ و آموزنده...   بازی آقای معادی اصلا در اندازه فیلم نبود و خانم جاوهریان هم گاهی به انچه باید می بود، نمی رسید.   بهترین بازیگر این فیلم، همان کودک جانسپرده بود که کاملا همراه بودو به خوبی خوابید...",
        "صحنه"
    ],
    [
        0.3514693925778071,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '943'}",
        "Chances are slight that 'Daniel dropped the apple' or 'Brian is a frog' or both.",
        "invalid"
    ],
    [
        0.35146217544873554,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'russe', 'row_id': '501'}",
        "Да и этот Кошенов тот еще жук. Нет, конечно, на прямой обман он никогда не пойдет, о каком-нибудь там сговоре с этим пацаном и речь идти не может, однако «доверяй, но проверяй»",
        "False"
    ],
    [
        0.3514547298351924,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '55'}",
        "It is unlikely that 'Greg is a rhino and Brian is a frog'.",
        "invalid"
    ],
    [
        0.3514476219813029,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '947'}",
        "زیاد توضیحی راجع به فیلم نمیدم  فقط به این جمله بسنده میکنم که خوب بود ولی عالی نبود",
        "صحنه"
    ],
    [
        0.3514465590318044,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '398'}",
        "It is probably the case that Winona is a cat. It is almost certain that Daniel grabbed the milk. It is likely that Sandra left the milk. There is almost no chance that if 'Daniel grabbed the milk' or 'Sandra left the milk' or both then Antoine is hungry. It is highly unlikely that if either 'Winona is a cat' or 'Sandra left the milk' but not both then Jessica is a mouse. There is almost no chance that if 'Winona is a cat' or 'Sandra left the milk' or both then John moved to the office.",
        "invalid"
    ],
    [
        0.35144249101479846,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '46'}",
        "[{'id': 'unknown_1a', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1b', 'response': 'Not contentious'}, {'id': 'unknown_1d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1e', 'response': 'Illegible OCR'}, {'id': 'unknown_1f', 'response': \"I don't know\"}, {'id': 'unknown_1g', 'response': 'Illegible OCR'}]",
        "𝙢𝙚𝙩𝙞𝙨"
    ],
    [
        0.35143551727135974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '63'}",
        "It is highly likely that Emily is a mouse. It is certain that Bernhard is yellow. It is unlikely that Lily is a swan. Chances are about even that if 'Bernhard is yellow and Lily is a swan' then Julius is a swan. There is little chance that if 'Emily is a mouse' or 'Lily is a swan' or both then Mary went to the bedroom. It is unlikely that if 'Lily is a swan' or 'Emily is a mouse' or both then John discarded the apple.",
        "invalid"
    ],
    [
        0.35141201814015705,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '244'}",
        "[{'follow_up_question': 'Is the person 18 years of age or older?', 'follow_up_answer': 'Yes'}, {'follow_up_question': \"Is the person a child who you paid or get child support for, even if they've turned 18?\", 'follow_up_answer': 'No'}, {'follow_up_question': 'Is the person the other parent in your child support case?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.35140950481096905,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '98'}",
        "نظر شما در مورد عطر، بو، و طعم این شربت و آبمیوه چیست؟",
        "طعم"
    ],
    [
        0.35140950481096905,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '168'}",
        "نظر شما در مورد عطر، بو، و طعم این شربت و آبمیوه چیست؟",
        "طعم"
    ],
    [
        0.35140950481096905,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '350'}",
        "نظر شما در مورد عطر، بو، و طعم این شربت و آبمیوه چیست؟",
        "طعم"
    ],
    [
        0.35140950481096905,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '469'}",
        "نظر شما در مورد عطر، بو، و طعم این شربت و آبمیوه چیست؟",
        "طعم"
    ],
    [
        0.35140950481096905,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '595'}",
        "نظر شما در مورد عطر، بو، و طعم این شربت و آبمیوه چیست؟",
        "طعم"
    ],
    [
        0.35139715174833935,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '193'}",
        "It is almost certain that Jason is tired. Chances are slight that Mary went to the kitchen. Chances are slight that Bernhard is a swan. It is impossible that if 'Jason is tired and Bernhard is a swan' then Brian is yellow. It is likely that if either 'Bernhard is a swan' or 'Jason is tired' but not both then Julius is a lion. We believe that if either 'Bernhard is a swan' or 'Mary went to the kitchen' but not both then Greg is a swan.",
        "invalid"
    ],
    [
        0.35135123630364734,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '535'}",
        "It is almost certain that Emily is a sheep. It is certain that Brian is green. There is almost no chance that Julius is a rhino. There is a better than even chance that if 'Emily is a sheep' or 'Brian is green' or both then Bernhard is a frog. It is almost certain that if either 'Emily is a sheep' or 'Julius is a rhino' but not both then Yann is bored. It is likely that if 'Julius is a rhino' or 'Emily is a sheep' or both then John went to the office.",
        "invalid"
    ],
    [
        0.3513462742169698,
        "{'dataset_id': 'boolq', 'config_id': 'default', 'row_id': '22'}",
        "The de facto official language of the United Kingdom is English, which is spoken by approximately 59.8 million residents, or 98% of the population, over the age of three. An estimated 700,000 people speak Welsh in the UK, an official language in Wales and the only de jure official language in any part of the UK. Approximately 1.5 million people in the UK speak Scots--although there is debate as to whether this is a distinct language, or a variety of English.",
        "False"
    ],
    [
        0.3513009299834569,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '946'}",
        "It is highly unlikely that Bernhard is a swan. It is impossible that John got the apple. There is a better than even chance that Daniel left the football. There is a better than even chance that if either 'Daniel left the football' or 'John got the apple' but not both then Greg is green. It is certain that if either 'Bernhard is a swan' or 'John got the apple' but not both then Brian is white. Chances are slight that if 'John got the apple and Bernhard is a swan' then Fred went to the garden.",
        "invalid"
    ],
    [
        0.35127655665079754,
        "{'dataset_id': 'WorkInTheDark/FairytaleQA', 'config_id': 'plain_text', 'row_id': '626'}",
        "\" thy inheritance , \" answered the king , \" be it great or small , and whether it lies in ireland or beyond ireland ; and for securities i give you my son art and gaul mac morna and the chief of the fians . \" gaul and the captains of the fianna consented to that arrangement , though reluctantly , for their minds misgave them as to who the great youth might be . after that all arose and armed themselves and ringed tara round with horse and foot , and thrice conn the hundred - fighter raised his awful regal voice , enjoining vigilance upon his people , and thrice gaul mac morna did the same , addressing the fians , and after that they filled their ears with wax and wool , and kept a stern and fierce watch , and many of them thrust the points of their swords into their flesh . now finn was alone in the banqueting chamber after the rest had gone out , and he washed his face and his hands in pure water , and he took from the bag that was at his girdle the instruments of divination and magic , which had been his father 's , and what use he made of them is not known ; but ere long a man stood before him , holding a spear in one hand and a blue mantle in the other . there were twenty nails of gold of arabia in the spear .",
        ""
    ],
    [
        0.35127655665079754,
        "{'dataset_id': 'WorkInTheDark/FairytaleQA', 'config_id': 'plain_text', 'row_id': '630'}",
        "\" thy inheritance , \" answered the king , \" be it great or small , and whether it lies in ireland or beyond ireland ; and for securities i give you my son art and gaul mac morna and the chief of the fians . \" gaul and the captains of the fianna consented to that arrangement , though reluctantly , for their minds misgave them as to who the great youth might be . after that all arose and armed themselves and ringed tara round with horse and foot , and thrice conn the hundred - fighter raised his awful regal voice , enjoining vigilance upon his people , and thrice gaul mac morna did the same , addressing the fians , and after that they filled their ears with wax and wool , and kept a stern and fierce watch , and many of them thrust the points of their swords into their flesh . now finn was alone in the banqueting chamber after the rest had gone out , and he washed his face and his hands in pure water , and he took from the bag that was at his girdle the instruments of divination and magic , which had been his father 's , and what use he made of them is not known ; but ere long a man stood before him , holding a spear in one hand and a blue mantle in the other . there were twenty nails of gold of arabia in the spear .",
        ""
    ],
    [
        0.3512377242247264,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '20'}",
        "It is impossible that Julius is gray. There is little chance that John went to the garden. It is probable that Jeff left the football. There is little chance that if either 'John went to the garden' or 'Jeff left the football' but not both then Gertrude is a sheep. Chances are about even that if either 'John went to the garden' or 'Julius is gray' but not both then Fred put down the apple. Chances are slight that if either 'Jeff left the football' or 'Julius is gray' but not both then Lily is a frog.",
        "invalid"
    ],
    [
        0.35122353086868924,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '630'}",
        "حجم خیلی زیادی داره و ممکنه اسراف بشه اصلا بو نداشت و طعم خوبی هم داشت",
        "طعم"
    ],
    [
        0.3512212385733922,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '696'}",
        "It is probably the case that John moved to the office. It is highly unlikely that Brian is a frog. There is little chance that Mary went to the garden. It is unlikely that if 'Brian is a frog' or 'John moved to the office' or both then Gertrude is a cat. Chances are about even that if 'Mary went to the garden' or 'John moved to the office' or both then Daniel left the football. It is impossible that if either 'Mary went to the garden' or 'Brian is a frog' but not both then Greg is yellow.",
        "invalid"
    ],
    [
        0.3512125611305237,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '31'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙤𝙣𝙩𝙙𝙚𝙠𝙠𝙚𝙣"
    ],
    [
        0.3512125611305237,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '34'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙩𝙧𝙖𝙙𝙞𝙩𝙞𝙤𝙣𝙚𝙡𝙚"
    ],
    [
        0.3512125611305237,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '37'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙧𝙤𝙤𝙩𝙨"
    ],
    [
        0.3512125611305237,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '44'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Weet ik niet'}]",
        "𝙬𝙚𝙧𝙚𝙡𝙙𝙝𝙞𝙨𝙩𝙤𝙧𝙞𝙨𝙘𝙝𝙚"
    ],
    [
        0.3512125611305237,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '45'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Weet ik niet'}]",
        "𝙍𝙊𝙈𝘼"
    ],
    [
        0.3512125611305237,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '68'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙖𝙘𝙝𝙩𝙚𝙧𝙜𝙧𝙤𝙣𝙙"
    ],
    [
        0.3512125611305237,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '74'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙕𝙞𝙢𝙗𝙖𝙗𝙬𝙚"
    ],
    [
        0.3511670380830765,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '630'}",
        "The summary is not exactly accurate; the poster's boyfriend is not yet a long-distance one.",
        "Accuracy"
    ],
    [
        0.3511319011449814,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '978'}",
        "There is a better than even chance that Brian is yellow. It is probably not the case that Mary dropped the milk. It is certain that Julius is gray. It is probably the case that if either 'Julius is gray' or 'Brian is yellow' but not both then Fred went to the office. It is probable that if 'Brian is yellow' or 'Julius is gray' or both then Jason is tired. It is probable that if 'Mary dropped the milk' or 'Julius is gray' or both then John moved to the garden.",
        "invalid"
    ],
    [
        0.3511151323715846,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '287'}",
        "خیلی خوب است و اصلا دور ریز ندارد و خوشپخت",
        "طعم"
    ],
    [
        0.35110210875670117,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '395'}",
        "It is probably not the case that either 'Julius is a swan' or 'Emily is a mouse' but not both.",
        "invalid"
    ],
    [
        0.3510737170775731,
        "{'dataset_id': 'boolq', 'config_id': 'default', 'row_id': '381'}",
        "Henry Daniel Mills is a fictional character in ABC's television series Once Upon a Time. Henry is the boy Emma Swan gave up to adoption; Regina Mills adopted him. Henry was originally portrayed as a child by Jared S. Gilmore, who won the Young Artist Award for Best Performance in a TV Series -- Leading Young Actor in 2012. For the show's seventh and final season, Andrew J. West later took over the role of Henry as an adult and father to a eight-year-old girl named Lucy, with Gilmore also making three appearances as Henry during the season.",
        "False"
    ],
    [
        0.35107343395551044,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '29'}",
        "It is impossible that 'John discarded the milk' or 'Julius is a rhino' or both.",
        "invalid"
    ],
    [
        0.35105369488398236,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '949'}",
        "girl has been dating guy for 4 months, he won't label it but mutual friend says he's said he's not good enough for a relationship due to commitment issues from previous relationship. girl wants to talk to guy about it.",
        "Accuracy"
    ],
    [
        0.3510527362426122,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '443'}",
        "The FDA evaluates drugs without considering costs, which is why they are not discussed in this news release. We hope the FDA will also begin commenting on the projected cost of a drug and its cost-effectiveness. In this case, costs are very steep. An NBC.com story on the approval which we also reviewed, predicts the drug will cost $37,000 annually. It’s unknown if Dupixent will be covered by health insurance. In terms of benefits, the release offers the following: “Overall, participants who received Dupixent achieved greater response, defined as clear or almost clear skin, and experienced a reduction in itch after 16 weeks of treatment.” But readers are left to interpret on their own what “greater response” and “a reduction in itch” mean. The release would have been better if it had told readers how the improvement was measured and how many patients experienced improvement rather than using the term “overall.” The release gets an acceptable rating in this category since it mentions that the drug can cause serious allergic reactions and eye problems including conjunctivitis (pinkeye) and keratitis (inflammation of the cornea). It also cautions that people with asthma shouldn’t use the drug since it hasn’t been tested for safety in these patients. The release should also have noted that regulators don’t know if there are any long-term harms associated with Dupixent use. None of the trials exceeded 16 weeks. The release describes who was studied and for how long, and offers a bare-bones description of the types of studies: “The safety and efficacy of Dupixent were established in three placebo-controlled clinical trials with a total of 2,119 adult participants with moderate-to-severe atopic dermatitis not adequately controlled by topical medication(s).” The FDA doesn’t provide a link to the studies or their titles and where they were published. The release would be more complete had that information been included. It would help journalists and people with eczema and would be a significant improvement to FDA releases. The release does not engage in disease-mongering. Instead it offers a clear description of what eczema is and what causes the condition. There is no mention of who funded the research leading to the FDA approval, although many readers will assume it was supported by the manufacturer Regeneron. The release gets a borderline satisfactory for mentioning topical corticosteroids as an alternative treatment for eczema but neglects to mention that other pharmaceuticals are also now available for treating it. Whether or not this medication will be covered by insurance is a huge concern. Its high cost will affect how many people can access this new drug. Its availability should have been addressed in the release. It’s newsworthy whenever the FDA approves a new drug. This appears to be the first biologic, injectable treatment for eczema. The release does not use any unjustifiable language.",
        "true"
    ],
    [
        0.3510514249404271,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '463'}",
        "I have a pretty good relationship with my mother in law. Or have had, for that matter. The thing is about a month ago my husband totaled our car. We're super tight on money so my in laws offered to loan us about the amount of our income tax returns so we could purchase a nice new car. My father is completely absent and my mother is virtually homeless with mental illness- so it wasn't like I could turn to them for help here. We could have purchased a pretty cruddy car with what we had but thought the deal seemed innocent enough to accept. My in laws are well off and travel the world every winter. They usually buy us great gifts for Christmas but I don't by any means completely expect them to. Since my husbands car was totaled, my MIL has been really weird about talking to me. We recently found out that she's techicully a narcissist so that might be part of what her dysfunction is. So we head over to their place today with presents for everyone. Everyone gets a turn opening and it finally comes to me. My gift says \"for photoshell and her husband\" I open it up and it's a frying pan. A cheap ugly frying pan. My husband got his own gift- as did everyone else. My husband even got one with his name. It was weird but I shrugged it off. Shortly there after we drove to my sisters house. I jokingly mentioned what had happened and everyones jaw dropped slightly. It dawned on me what a crappy gift I was given. I honestly just want to donate the damned frying pan because it upsets me just looking at it. We did not need a frying pan or any type of kitchen gear. It was completely random. Sorry this post isn't entirely juicy with drauma - I just want to know if I'm being unreasonable by feeling offeneded.",
        "Accuracy"
    ],
    [
        0.3510400007168452,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '915'}",
        "It is probably not the case that either 'John went to the office' or 'Lily is a frog' but not both.",
        "invalid"
    ],
    [
        0.3510178824265798,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '719'}",
        "There is little chance that 'Brian is green' or 'Lily is a rhino' or both.",
        "invalid"
    ],
    [
        0.3510020722945531,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '595'}",
        "It is probably not the case that Sumit is tired. It is likely that Brian is white. It is highly unlikely that Daniel dropped the apple. Chances are about even that if 'Sumit is tired' or 'Brian is white' or both then Emily is a cat. It is improbable that if either 'Brian is white' or 'Sumit is tired' but not both then Lily is yellow. Chances are about even that if 'Sumit is tired' or 'Brian is white' or both then John went to the bedroom.",
        "invalid"
    ],
    [
        0.3510013073682785,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '468'}",
        "It is impossible that either 'Julius is white' or 'Emily is a mouse' but not both.",
        "invalid"
    ],
    [
        0.3509906679391861,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '304'}",
        "It is unlikely that Lily is a lion. There is a better than even chance that Mary got the apple. It is highly unlikely that Antoine is thirsty.",
        "invalid"
    ],
    [
        0.35098183155059814,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '842'}",
        "(1) Спустя какое-то время везение прекращается. (2) Редакции наперебой стараются обжулить Мартина. (3) Добыть у них деньги за публикации оказывается нелёгким делом. (4) Руфь настаивает на том, чтобы Мартин устроился на работу к её отцу, она не верит в то, что он станет писателем. (5) Случайно у Морзов Мартин знакомится с Рэссом Бриссенденом и близко сходится с ним. (6) Бриссенден болен чахоткой, он не боится смерти, но страстно любит жизнь во всех её проявлениях. (7) Бриссенден знакомит Мартина с «настоящими людьми», одержимыми литературой и философией. (8) Со своим новым товарищем Мартин посещает митинг социалистов, где спорит с оратором, но благодаря расторопному и нещепетильному репортёру попадает на страницы газет в качестве социалиста и ниспровергателя существующего строя. (9) Газетная публикация приводит к печальным последствиям — Руфь присылает Мартину письмо, извещающее о разрыве помолвки. (10) Мартин продолжает жить по инерции, и его даже не радуют поступающие от журналов чеки — почти все, написанное Мартином, теперь публикуется. (11) Бриссенден кончает жизнь самоубийством, а его поэма «Эфемерида», которую опубликовал Мартин, вызывает бурю пошлейшей критики и заставляет Мартина радоваться, что его друг не видит этого.",
        "False"
    ],
    [
        0.35098183155059814,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '844'}",
        "(1) Спустя какое-то время везение прекращается. (2) Редакции наперебой стараются обжулить Мартина. (3) Добыть у них деньги за публикации оказывается нелёгким делом. (4) Руфь настаивает на том, чтобы Мартин устроился на работу к её отцу, она не верит в то, что он станет писателем. (5) Случайно у Морзов Мартин знакомится с Рэссом Бриссенденом и близко сходится с ним. (6) Бриссенден болен чахоткой, он не боится смерти, но страстно любит жизнь во всех её проявлениях. (7) Бриссенден знакомит Мартина с «настоящими людьми», одержимыми литературой и философией. (8) Со своим новым товарищем Мартин посещает митинг социалистов, где спорит с оратором, но благодаря расторопному и нещепетильному репортёру попадает на страницы газет в качестве социалиста и ниспровергателя существующего строя. (9) Газетная публикация приводит к печальным последствиям — Руфь присылает Мартину письмо, извещающее о разрыве помолвки. (10) Мартин продолжает жить по инерции, и его даже не радуют поступающие от журналов чеки — почти все, написанное Мартином, теперь публикуется. (11) Бриссенден кончает жизнь самоубийством, а его поэма «Эфемерида», которую опубликовал Мартин, вызывает бурю пошлейшей критики и заставляет Мартина радоваться, что его друг не видит этого.",
        "False"
    ],
    [
        0.35097816586494446,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '273'}",
        "\"The story does not mention the costs of zinc products. The story does a good job of describing how many studies showed no effect of the zinc products. In the one study showing a benefit of zinc nasal gel, the story provides quantification of benefits in natural frequencies (days of duration of the cold) rather than in terms of relative reduction. The story discusses unpleasant taste, upset stomatch, stinging sensation and, potentially, loss of smell as harms or side effects of zinc products. The story does a great job of describing the design of the current study, which is a special kind of literature review. The story does not exaggerate the seriousness or prevalence of colds. In fact the writer could have emphasized that colds are expensive, resulting in lost productivity and sick days due to illness in workers and their children. The story quotes an independent expert as well as the lead author on the current study and the representative of the manufacturer. The story mentions over-the-counter antihistamines, decongestants, and pain releivers as alternatives, appropriately pointing out that there is no \"\"cure\"\" for the common cold. The story clearly states that zinc products are available over the counter in drugstores. The story clearly states that zinc products are not a new idea. Because the story quotes multiple experts, the reader can assume that the story does not rely on a press release as the sole source of information.\"",
        "true"
    ],
    [
        0.35094672938187915,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '396'}",
        "It is impossible that either 'John took the apple' or 'Julius is a swan' but not both.",
        "invalid"
    ],
    [
        0.35092537105083466,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '870'}",
        "It is highly unlikely that 'Greg is white' or 'Daniel took the milk' or both.",
        "invalid"
    ],
    [
        0.35092416902383167,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '993'}",
        "We believe that Julius is a swan. It is almost certain that John grabbed the apple. We believe that Brian is green. We doubt that if either 'Julius is a swan' or 'John grabbed the apple' but not both then Bernhard is white. It is certain that if either 'Julius is a swan' or 'Brian is green' but not both then Mary went to the bedroom. It is almost certain that if 'Julius is a swan' or 'Brian is green' or both then Greg is a frog.",
        "invalid"
    ],
    [
        0.35090073198080063,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '119'}",
        "نظر شما در مورد عطر، بو، و طعم این قهوه چیست؟",
        "طعم"
    ],
    [
        0.35090073198080063,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '301'}",
        "نظر شما در مورد عطر، بو، و طعم این قهوه چیست؟",
        "طعم"
    ],
    [
        0.35090073198080063,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '490'}",
        "نظر شما در مورد عطر، بو، و طعم این قهوه چیست؟",
        "طعم"
    ],
    [
        0.35090073198080063,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '539'}",
        "نظر شما در مورد عطر، بو، و طعم این قهوه چیست؟",
        "طعم"
    ],
    [
        0.35090073198080063,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '560'}",
        "نظر شما در مورد عطر، بو، و طعم این قهوه چیست؟",
        "طعم"
    ],
    [
        0.3508795201778412,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '726'}",
        "It is impossible that Lily is yellow. It is almost certain that Jason is tired. There is almost no chance that Mary went to the office. It is likely that if 'Mary went to the office' or 'Lily is yellow' or both then Greg is green. Chances are about even that if 'Jason is tired' or 'Mary went to the office' or both then John left the milk. It is certain that if either 'Lily is yellow' or 'Jason is tired' but not both then Julius is white.",
        "invalid"
    ],
    [
        0.35087643563747406,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '696'}",
        "It is unlikely that 'Bernhard is a swan' or 'Brian is a rhino' or both.",
        "invalid"
    ],
    [
        0.3508703609307607,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '111'}",
        "It is unlikely that either 'Brian is a frog' or 'John went to the hallway' but not both.",
        "invalid"
    ],
    [
        0.35086604207754135,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '112'}",
        "خوشم نیومد بین بقیه ادامس ها گزینه اخر میتونه باشه",
        "طعم"
    ],
    [
        0.3508576850096385,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '301'}",
        "It is highly unlikely that 'Brian is white and Julius is a frog'.",
        "invalid"
    ],
    [
        0.3508315732081731,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '947'}",
        "It is impossible that 'Lily is yellow' or 'Jeff put down the milk' or both.",
        "invalid"
    ],
    [
        0.35080718994140625,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '490'}",
        "Write an excellent summary of the given text.\n\nTitle: Is living together a bad idea?\n\nText: Some back story: My boyfriend (22M) and I (21F) have been together for over a year. We were close friends for 2.5 years before we got together. We're in a bit of a situation. The girl who was supposed to live with me starting in May had to push it back until August because the girl who was supposed to sublease her current apartment over the summer backed out. She can't afford to pay two rents and can't find another person to take the apartment, so she's going to have to stay where she is. My boyfriend had plans to live with one of his good friends, but his friend recently decided he would rather live in a house with his band mates, leaving my boyfriend without a roommate/apartment.  \n\nI've already signed the lease to my future apartment, so I'm pretty stuck there with no roommate until August. This is going to cost me an extra $500/month, which is difficult for me to afford right now. My boyfriend suggested that he could stay with me during those months and pay that half of the rent, which would help me financially and give him more time to find another place to stay. It definitely makes logical sense, but I'm worried that we're not in a place to live together yet. \n\nWe're still so young and we've only been together for about a year. Even if we'd only be living together for a few months, I'm scared it might negatively impact our relationship. I love spending time with him and we are going strong. Although we stay at each others places multiple nights a week and have been on trips together, I know that actually living together is a completely different situation. \n\nWhat do you think, reddit? Do you think it's a bad idea? Or do you think it might be okay since it is only a few months?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35080506404240924,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '837'}",
        "Write an excellent summary of the given text.\n\nTitle: Asking for a raise or if I even should\n\nText: Some background information:\n\nI'm a 20 year old, college student taking 6 classes this current semester, but I still live at home with my parents so bills are minimal.\n\nNow the pressing issue:\n\nI've worked a few different jobs before finally landing this one. It is great to me. I'm working for a friend of a friend who owns a small business. My title is \"office manager\", but really I work out of the office room in his house and there are no employees below me. I was hired in February of this year.\nWhile I am at work, in his house, his wife is there as well. The three of us get along well and our relationship is just slightly more than professional. We know about each others personal lives and we share hobbies, yet we wouldn't meet outside of work.\nMy responsibilities were simple. Manage Quickbooks billing, pay bills such as insurance, handle any client issues, and some other insignificant tasks. I get paid $15 an hour for this, which I am grateful for because all of my prior jobs were minimum wage.\nIn the last couple of weeks, however, they have near doubled my responsibilities by giving me all of the functions that their accountant would typically handle and also throwing me a few more insignificant tasks to manage daily.\nThis new work has not been easy. I've needed help from the old accountant multiple times and I still find myself getting stuck occasionally.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35077884296576184,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '937'}",
        "It is probably the case that Brian is green. There is little chance that Lily is a swan. There is a very good chance that Mary grabbed the milk. It is unlikely that if 'Mary grabbed the milk and Lily is a swan' then Gertrude is a cat. There is a better than even chance that if 'Brian is green and Lily is a swan' then Daniel dropped the apple. We doubt that if either 'Lily is a swan' or 'Brian is green' but not both then Jason is bored.",
        "invalid"
    ],
    [
        0.3507729520400365,
        "{'dataset_id': 'cjvt/cosimlex', 'config_id': 'sl', 'row_id': '63'}",
        "Avtor Michael Crichton je predlagal, da bi DNK dinozavrov <strong>dobili</strong> iz komarjev, ujetih v jantarju. Ta metoda je s stališča današnje znanosti za zdaj še nemogoča, saj DNK s časom razpade zaradi stika z zrakom, vodo ali zaradi sevanja. V filmu je zagrešena tudi napaka, saj so DNK <strong>pridobili</strong> iz jantarja iz Dominikanske republike, ki je star samo 30 milijonov let in je tako nastal davno po izumrtju dinozavrov.",
        "pridobilo"
    ],
    [
        0.3507442424694697,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '289'}",
        "What's true: Dr. William Waddell was tried twice, but never convicted following a failed abortion during which the fetus initially survived. What's false: Waddell was found to have strangled the infant; the incident was recent in 2016. What's undetermined: The reasons for which the abortion was unsuccessful; what caused the premature infant's death.",
        " "
    ],
    [
        0.3507406587402026,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '362'}",
        "سلام ، برای اونایکه مشکلی با خوردن ئوشابه ندارن ،دیابت ندارن، قیمتش عالیه ، و به صرفه است",
        "نوشابه"
    ],
    [
        0.3507174650828044,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '294'}",
        "مزه اش بد نیست خرید از دیجی کالا به صرفه است",
        "طعم"
    ],
    [
        0.3506978054841359,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '395'}",
        "Write an excellent summary of the given text.\n\nTitle: I [20M] am unsure how to go to the next step in relationship with best friend [20F]\n\nText: I'll try to make this as short as possible. This girl and I have been friends since way back at the beginning of middle school. We stayed close friends all the way through high school and after graduation, even when I moved to a different school a half hour away. \n\nWe've both dated multiple different people during this time and were each other's rebounds for a bit when had separate break ups around the same time. We both know we are physically attracted to one another. Why we aren't in some sort of romantic relationship escapes me, but I have a feeling we both may be afraid to lose our close friendship. \n\nWe talk to each other almost every day, all day, and try to hang out with each other as much as possible. In fact, we are going to an amusement park this weekend together for their \"Halloween themed fright nights\". I've thought about just laying it all out on the table to her around then, but that fear is still in the back of my mind. I'm sure everything will probably be fine between us if she doesn't want to go much farther than friends seeing how close we are. Still though, this situation is not one I'm familiar with. I definitely don't want to do this through texting or on the phone, where we usually talk.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.35068494578202564,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '206'}",
        "It is probable that Bernhard is gray. It is certain that Jessica is a sheep. It is unlikely that Winona is a mouse. There is almost no chance that if 'Bernhard is gray' or 'Jessica is a sheep' or both then John discarded the milk. Chances are about even that if either 'Bernhard is gray' or 'Jessica is a sheep' but not both then Brian is yellow. It is improbable that if 'Jessica is a sheep and Bernhard is gray' then Greg is a lion.",
        "invalid"
    ],
    [
        0.3506828049818675,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '776'}",
        "\"There was no discussion about direct costs for this test. The story always qualified any potential benefit as possibility by qualifying every claim with the term ‘may’. It would have improved this piece to include an explicit statement that there is currently no way to quantify what the benefit of early detection might be. The story did not mention that 13% of the individuals in the study were unable to complete the test due to claustrophobia and that for 17% of the individuals tested, there were technical difficulties which made their test results unusable. Although it was good that the story qualified every claim made for this new method of assessment with the term \"\"may\"\" ( as in ‘may prove useful’), it did not mention that the study merely assessed a group of individuals at a single time point and found that this test correlated with some verbal tests of memory. Because it is not possible to determine whether what appears to be age-related differences may relate to other ways in which the tested individuals differ, it is premature to conclude that this test will be found to successfully distinguish between those who will and will not develop Alzheimer’s Disease. In fact, since individuals with cognitive impairment were from excluded from the study, the study did not provide any evidence that the test could actually distinguish between people with and without Alzheimer’s Disease, let alone those who will develop the disease. The story did not engage in overt disease-mongering. The story did include a quote from a neurologist who did not appear to be directly connected with the study. That said, his comments were general in nature and were not explicitly about the research reported on. The story mentioned that the testing procedure reported on ‘shows evidence of being more sensitive’ than other tests, while acknowledging that ‘a good clinical evaluation is still the best tool’. The story provided no insight about whether hospitals have the facilities needed for this test. While the story reported on a most recent study using DTI technology for assessment of Alzheimer’s disease, there is medical literature on this dating back several years, a context the story didn’t provide. We can’t be sure of the extent to which the story was primarily driven by a news release. The story acknowledges that the quote from the lead author of the research came from a news release.\"",
        "false"
    ],
    [
        0.3506542195876439,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '853'}",
        "It is highly unlikely that Greg is a rhino. It is improbable that John left the apple. It is highly likely that Lily is a frog.",
        "invalid"
    ],
    [
        0.3506446381409963,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '817'}",
        "Chances are about even that Greg is gray. There is a very good chance that Winona is a wolf. It is probably the case that John went to the kitchen. It is almost certain that if 'Winona is a wolf and John went to the kitchen' then Gertrude is a mouse. It is improbable that if 'Greg is gray' or 'John went to the kitchen' or both then Lily is a swan. There is little chance that if 'John went to the kitchen' or 'Greg is gray' or both then Mary dropped the apple.",
        "invalid"
    ],
    [
        0.35063351690769196,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '88'}",
        "(1) В любви король Людовик начал со своего кучера, потом почувствовал «склонность к псарю», но особой страстью пылал он к де Люиню. (2) Кардинал опасался, как бы короля не прозвали Людовиком-Заикой, и он «пришёл в восторг, когда подвернулся случай назвать его Людовиком Справедливым». (3) Людовик иногда рассуждал довольно умно и даже «одерживал верх» над кардиналом. (4) Но скорей всего, тот просто доставлял ему это маленькое удовольствие. (5) Некоторое время король был влюблён в фрейлину королевы госпожу д’Отфор, что, впрочем, не помешало ему воспользоваться каминными щипцами, чтобы достать записку из-за корсажа этой дамы, так как он боялся дотронуться рукой до её груди. (6) Любовные увлечения короля вообще «были престранными», ибо из всех чувств ему более всего была присуща ревность. (7) Он страшно ревновал госпожу д’Отфор к д’Эгийон-Вассе, хотя та и уверяла его, что он её родственник. (8) И только когда знаток генеалогии д’Озье, зная в чем дело, подтвердил слова придворной красавицы, король поверил ей. (9) С госпожой д’Отфор Людовик часто беседовал «о лошадях, собаках, птицах и других подобных предметах». (10) А надо сказать, что король очень любил охоту. (11) Помимо же охоты он «умел делать кожаные штанины, силки, сети, аркебузы, чеканить монету», выращивал ранний зелёный горошек, изготовлял оконные рамы, отлично брил, а также был неплохим кондитером и садовником.",
        "False"
    ],
    [
        0.35063351690769196,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '89'}",
        "(1) В любви король Людовик начал со своего кучера, потом почувствовал «склонность к псарю», но особой страстью пылал он к де Люиню. (2) Кардинал опасался, как бы короля не прозвали Людовиком-Заикой, и он «пришёл в восторг, когда подвернулся случай назвать его Людовиком Справедливым». (3) Людовик иногда рассуждал довольно умно и даже «одерживал верх» над кардиналом. (4) Но скорей всего, тот просто доставлял ему это маленькое удовольствие. (5) Некоторое время король был влюблён в фрейлину королевы госпожу д’Отфор, что, впрочем, не помешало ему воспользоваться каминными щипцами, чтобы достать записку из-за корсажа этой дамы, так как он боялся дотронуться рукой до её груди. (6) Любовные увлечения короля вообще «были престранными», ибо из всех чувств ему более всего была присуща ревность. (7) Он страшно ревновал госпожу д’Отфор к д’Эгийон-Вассе, хотя та и уверяла его, что он её родственник. (8) И только когда знаток генеалогии д’Озье, зная в чем дело, подтвердил слова придворной красавицы, король поверил ей. (9) С госпожой д’Отфор Людовик часто беседовал «о лошадях, собаках, птицах и других подобных предметах». (10) А надо сказать, что король очень любил охоту. (11) Помимо же охоты он «умел делать кожаные штанины, силки, сети, аркебузы, чеканить монету», выращивал ранний зелёный горошек, изготовлял оконные рамы, отлично брил, а также был неплохим кондитером и садовником.",
        "False"
    ],
    [
        0.35063309967517853,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '384'}",
        "It is probably not the case that John put down the apple. It is probably the case that Brian is a lion. It is likely that Lily is gray.",
        "invalid"
    ],
    [
        0.3505948732296626,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '711'}",
        "There is almost no chance that Brian is green. It is unlikely that Greg is a frog. It is probable that Julius is a rhino. It is probable that if 'Julius is a rhino and Brian is green' then Jessica is a mouse. It is probably not the case that if 'Brian is green and Julius is a rhino' then Sandra dropped the apple. It is probably the case that if 'Brian is green' or 'Greg is a frog' or both then Mary moved to the office.",
        "invalid"
    ],
    [
        0.3505755513906479,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '298'}",
        "It is impossible that either 'Greg is a swan' or 'John discarded the milk' but not both.",
        "invalid"
    ],
    [
        0.35057108600934345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '893'}",
        "It is almost certain that Mary went to the garden. It is impossible that Julius is a swan. There is a better than even chance that Lily is a rhino.",
        "invalid"
    ],
    [
        0.35057022670904797,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '556'}",
        "It is impossible that John discarded the apple. It is almost certain that Jessica is a mouse. There is a very good chance that Bernhard is white. It is probably the case that if either 'Bernhard is white' or 'John discarded the apple' but not both then Julius is gray. We doubt that if either 'Jessica is a mouse' or 'John discarded the apple' but not both then Sandra dropped the milk. There is almost no chance that if 'Bernhard is white' or 'Jessica is a mouse' or both then Brian is a rhino.",
        "invalid"
    ],
    [
        0.35056331753730774,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '209'}",
        "There is a better than even chance that Mary dropped the apple. It is probably the case that Lily is a lion. There is a very good chance that Brian is green. It is improbable that if 'Lily is a lion' or 'Brian is green' or both then Antoine is bored. We doubt that if either 'Mary dropped the apple' or 'Brian is green' but not both then Bernhard is yellow. Chances are about even that if either 'Lily is a lion' or 'Mary dropped the apple' but not both then Bill went to the garden.",
        "invalid"
    ],
    [
        0.35055863360563916,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '561'}",
        "بسیار خوشطعم . دارای گواهی نامه ارگانیک و امکان پس دادن محصول در صورت راضی نبودن! این یعنی احترام به اعتماد مشتری",
        "کلی"
    ],
    [
        0.35055121779441833,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '327'}",
        "There is a very good chance that Mary went to the bedroom. There is a better than even chance that Greg is yellow. It is almost certain that Lily is a rhino. It is probably the case that if either 'Mary went to the bedroom' or 'Lily is a rhino' but not both then Brian is a swan. There is a very good chance that if 'Lily is a rhino and Greg is yellow' then Jeff put down the milk. There is little chance that if either 'Lily is a rhino' or 'Mary went to the bedroom' but not both then John discarded the apple.",
        "invalid"
    ],
    [
        0.35053281982739765,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '592'}",
        "We believe that John got the apple. It is certain that Yann is thirsty. It is highly likely that Julius is a frog. There is a very good chance that if 'Julius is a frog and Yann is thirsty' then Mary dropped the milk. It is probably not the case that if either 'John got the apple' or 'Yann is thirsty' but not both then Greg is a swan. It is unlikely that if 'Yann is thirsty and Julius is a frog' then Lily is green.",
        "invalid"
    ],
    [
        0.35050703088442486,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '543'}",
        "It is highly unlikely that Greg is a frog. There is little chance that John dropped the milk. It is impossible that Julius is a rhino.",
        "invalid"
    ],
    [
        0.35050588846206665,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '373'}",
        "Cost is not discussed, which is a significant oversight. At least some idea of what the out-of-pocket costs are for this kind of therapy is important. While we wouldn’t expect the story to necessarily address all the following issues, these are the kinds of questions people have when considering what kind of therapy to receive. First, the treadmill systems: It is difficult for consumers to find a cost for underwater treadmills, as most of the companies that sell them tell potential customers to contact the company for a quote. However, the treadmill company mentioned by name in the article quotes $65,000 in the example on how its leasing program works. And a 2013 story in USA Today says that underwater treadmill systems range in price from $33,000 to $270,000. A 2014 story in Runner’s World says that insurance may cover the use of such a treadmill system at a physical therapist’s office, if the system is being used for injury recovery. The CBS story doesn’t even give us that much information. Second, this story also mentions pools that have a “water flow system you can work against.” Again, it’s not clear what the costs of such a system would be, but one such company notes that its least expensive therapy pool options start at $7,400 (yet, the same company notes that its standard system “starts at $22,900”). Third, the story also refers to simply exercising in a pool with a foam vest or foam handbells. This is, of course, far more affordable for most people. But it’s not clear, at all, how comparable the benefits of this sort of activity are to the use of the high-end systems discussed in the rest of the article. Lastly, for a story like this, it would be great to know how water-based physical therapy compares in cost to standard PT. It may not be covered by a patient’s insurance and result in higher out of pocket costs, for example. The story focuses on multiple benefits, none of which are quantified. For example, the story discusses the ways in which being underwater can reduce joint pain during exercise. How much does it reduce pain? What are the benefits in terms of health outcomes? Unclear. There also was no attempt to quantify speed of recovery and final recovery state compared to other treatments such as standard physical therapy. It also cites a study showing cardiovascular benefits for stroke patients, but it doesn’t even appear that this study directly compared outcomes of water-based PT vs. standard PT in patients following a stroke. Rather, it sounds like the study compared physiologic measures in stroke patients comparing two forms of exercise testing, which isn’t proof that one method resulted in better recovery outcomes for patients. The story doesn’t discuss harms. There don’t appear to be any particular health risks associated with the use of underwater treadmills that wouldn’t apply to beginning any exercise or rehabilitation regime — but that’s actually a point worth making. However, exercising in a pool poses risks of its own — particularly for patients who may be recovering from surgery or stroke. As a result, it would be wise to explain that these patients (or any patient who is not confident in the water) should have supervision. And, this therapy may induce anxiety among people who can’t swim or are anxious around water. The story refers only to a single study, and doesn’t give readers much information on how to find the study it does refer to. It does tell readers where the study was published (though not when), that the study compared on-land treadmill use and underwater treadmill use among stroke survivors, and that the study involved 21 patients. (If you’re curious, we found the relevant study. It’s here.) There was no evidence provided to support the claims of any benefits other than cardiovascular benefits for stroke survivors. No disease mongering here. Though, the story implies that this form of therapy can be used for just about any condition where treadmill or bike treatment is indicated. So not disease mongering, but possibly treatment mongering. The story quotes four experts, making this a strong point. It would have been helpful for one of these experts to point out that there is very little evidence supporting water-based PT compared to standard PT. The alternative to using a treadmill underwater would be to engage in cardiovascular exercise on dry land. The story addresses this, noting both the treadmill comparison study (mentioned above) and the fact that exercising in water reduces stress on joints. So, we’ll give it a Satisfactory rating. However, the story intimates that exercising in a pool and exercising on an underwater treadmill are comparable. It’s not clear that this is the case, and the 2014 story from Runner’s World indicates that they are actually quite different. What’s more, there is no discussion of another form of aquatic exercise: swimming. Is swimming a viable option for cardiovascular recovery? It’s not clear from the story how widely available underwater treadmills are for the general public. Underwater treadmills are not particularly new (the research literature on them goes back to at least 1989). Frankly, it’s not clear why this story was written now, or what is novel about underwater treadmill exercise (given how the story indicates that it is comparable to walking in a pool with a foam vest). The story does not appear to be based on a news release.",
        "false"
    ],
    [
        0.3505002558231354,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '636'}",
        "\"This story is about a study in which the strongest finding is that treatment with antipsychotics lowers mortality. The differences between drugs is less convincing and the opening statement that \"\"thousands of lives could have been saved\"\" if patients had been prescribed clozapine is simply not explained or justified adequately. There are cardiac and other long-term risks associated with most anti-psychotic medications (including clozapine) and schizophrenics generally have a higher rate of suicide than the general population, so we cannot say how many lives would have been saved with clozapine. The story focuses on clozapine as a viable drug treatment for schizophrenia when other anti-psychotic medication does not work. Use of the drug as a \"\"last resort\"\" may be reconsidered based on new evidence that there is lower long-term mortality risks with this drug compared to other commonly prescribed anti-psychotic medications. However, the story does not mention more common side effects of this drug which may limit tolerability. The story also does not mention that patients taking clozapine are typically monitored frequently (weekly to monthly) for white blood cell counts (loss of white blood cells led to the death of patients taking the drug in the 1970s). This would increase cost, which is also not mentioned. One strength of the story is that it used two independent sources who provide good clinical perspective on the results of this 10-year retrospective study.\"",
        "false"
    ],
    [
        0.3504941165447235,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '334'}",
        "\"At times, it hasn’t been 100 percent clear to vendors and shoppers what’s covered under Philadelphia’s sugary drinks tax. Look no further than that time ShopRite taxed hot sauce in January. But a high-ranking PepsiCo employee should probably understand, right? Well that’s not what it sounded like in a tweet earlier this week from the anti-tax coalition Ax The Bev Tax. The tweet replayed a conversation on WURD 900-AM between host Solomon Jones and Amy Chen, founder of PepsiCo’s Food for Good initiative. In the short clip, as presented in the tweet, Chen says, \"\"We offer a tremendous amount of low calorie, no calorie options, like waters, unsweetened products, low calorie diet items. All of which unfortunately are taxed by this tax.\"\" Unsweetened products and water, taxed? Um, what happened? First of all, unsweetened beverages and water are not taxed. According to the Mayor’s Office, the soda tax covers all non-alcoholic beverages with any amount of natural or artificial sweetener. Any unsweetened beverage and regular water would not be taxed. And even in the realm of sweetened beverages there are some exceptions. Drinks that are at least 50 percent milk, baby formula, 100 percent juice, at least 50 percent \"\"fresh\"\" fruit or vegetable  are not taxed. Chen’s conversation with Jones lasted for several minutes, based on the audio file from WURD’s website. So Ax The Bev Tax edited it down for purposes of the tweet. And not only did they shorten Chen’s conversation, the alteration of the clip adjusted what she said. In her original conversation with Jones, Chen said, \"\"We offer a tremendous amount of low calorie, no calorie options, like waters, unsweetened products, low calorie diet items. All of which unfortunately -- or most of which -- are taxed by this tax.\"\" Ax the Bev Tax’s clip removed \"\"or most of which,\"\" the portion of her statement where she realized her error of saying all those drinks would be taxed and corrected herself. Speaking for PepsiCo and Ax The Bev Tax, Anthony Campisi said it was an editing error committed by someone \"\"still getting oriented with the nuances of the tax\"\" and that the anti-soda tax coalition had consistently claimed from the beginning the tax only applies to sweetened beverages. He called it an honest mistake and said, \"\"this just seems like in the grand scheme of things about the beverage tax to be really small stuff.\"\" Our ruling The Ax The Bev Tax Twitter account played a clip of Pepsi employee Amy Chen saying \"\"We offer a tremendous amount of low calorie, no calorie options, like waters, unsweetened products, low calorie diet items. All of which unfortunately are taxed by this tax.\"\" Water, as long as it has no sweeteners added, and unsweetened beverages are not taxed. Chen actually said on the radio show that \"\"most\"\" of those types of beverages were taxed, but Ax The Bev Tax’s clip was altered. Ax The Bev Tax has acknowledged the clip is inaccurate, with spokesperson Anthony Campisi chalking it up to an editing error by someone still getting familiar with the nuances of the tax. But the error was still made. A true statement by Chen was turned into a false statement by Ax The Bev Tax. PolitiFact regularly challenges politicians who make claims and then later admitted they made a mistake or misspoke or walk their original statement back. This is similar.\"",
        "false"
    ],
    [
        0.3504684219757716,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '420'}",
        "It is highly likely that Brian is a rhino. It is improbable that Sumit is hungry. It is almost certain that Lily is green. It is likely that if either 'Sumit is hungry' or 'Brian is a rhino' but not both then Mary left the football. It is unlikely that if 'Brian is a rhino and Lily is green' then Julius is a swan. It is likely that if either 'Sumit is hungry' or 'Lily is green' but not both then Sandra took the football.",
        "invalid"
    ],
    [
        0.3504623919725418,
        "{'dataset_id': 'boolq', 'config_id': 'default', 'row_id': '274'}",
        "Just like other affines, or ``in-laws'', siblings-in-law are related by a type of kinship called affinity. Just like the children of one's siblings, the children of one's siblings-in-law are called simply nieces and nephews -- if necessary, specified whether ``by marriage'', as opposed to ``by blood'' or ``by adoption''.",
        "True"
    ],
    [
        0.3504500836133957,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '981'}",
        "It is probably not the case that Lily is yellow. It is improbable that Bernhard is a frog. It is likely that Brian is a rhino.",
        "invalid"
    ],
    [
        0.3504398812850316,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '819'}",
        "It is probably not the case that Sumit is thirsty. There is little chance that John got the apple. There is a very good chance that Brian is a lion. It is probably the case that if 'John got the apple and Sumit is thirsty' then Sandra took the football. It is almost certain that if 'Brian is a lion' or 'Sumit is thirsty' or both then Bernhard is gray. It is unlikely that if 'John got the apple' or 'Brian is a lion' or both then Bill moved to the office.",
        "invalid"
    ],
    [
        0.35043713450431824,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '123'}",
        "It is improbable that 'Brian is yellow' or 'Julius is a rhino' or both.",
        "invalid"
    ],
    [
        0.35041578114032745,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '206'}",
        "It is likely that Lily is a lion. There is a better than even chance that Bernhard is a rhino. It is impossible that John grabbed the apple.",
        "invalid"
    ],
    [
        0.3503563503424327,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '45'}",
        "It is unlikely that Brian is white. It is almost certain that Bernhard is a lion. It is probably not the case that Jeff left the football.",
        "invalid"
    ],
    [
        0.3503275662660599,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '35'}",
        "نظر شما در مورد عطر، بو، و طعم این ماهی، میگو و خاویار چیست؟",
        "طعم"
    ],
    [
        0.3503275662660599,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '672'}",
        "نظر شما در مورد عطر، بو، و طعم این ماهی، میگو و خاویار چیست؟",
        "طعم"
    ],
    [
        0.3503275662660599,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '742'}",
        "نظر شما در مورد عطر، بو، و طعم این ماهی، میگو و خاویار چیست؟",
        "طعم"
    ],
    [
        0.3503275662660599,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '763'}",
        "نظر شما در مورد عطر، بو، و طعم این ماهی، میگو و خاویار چیست؟",
        "طعم"
    ],
    [
        0.3503274967273076,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '516'}",
        "It is likely that Emily is a sheep. It is almost certain that Mary picked up the apple. It is unlikely that Greg is a frog. There is a very good chance that if either 'Greg is a frog' or 'Emily is a sheep' but not both then Bernhard is a rhino. There is little chance that if 'Greg is a frog and Mary picked up the apple' then Julius is green. It is unlikely that if 'Emily is a sheep' or 'Greg is a frog' or both then John left the football.",
        "invalid"
    ],
    [
        0.35032670696576435,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '369'}",
        "It is probably not the case that 'Daniel dropped the milk' or 'Winona is a wolf' or both.",
        "invalid"
    ],
    [
        0.3503219981988271,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '525'}",
        "It is improbable that Mary left the football. It is highly unlikely that Lily is green. It is improbable that Greg is a frog. There is little chance that if either 'Mary left the football' or 'Lily is green' but not both then Emily is a sheep. We doubt that if 'Mary left the football and Lily is green' then John picked up the milk. It is highly likely that if either 'Lily is green' or 'Greg is a frog' but not both then Brian is white.",
        "invalid"
    ],
    [
        0.35030826429526013,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '746'}",
        "It is highly unlikely that either 'Mary picked up the apple' or 'Brian is a frog' but not both.",
        "invalid"
    ],
    [
        0.3502924193938573,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '795'}",
        "Den festen Sitz, den hier andere Nutzer berichten, kann ich definitiv nicht bestätigen - und es gibt definitiv auch keinen mysteriösen Trick oder einen besonderen Kniff, mit dem man ihn herbeiführen könnte.",
        "counterfactual"
    ],
    [
        0.3502924193938573,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '795'}",
        "Den festen Sitz, den hier andere Nutzer berichten, kann ich definitiv nicht bestätigen - und es gibt definitiv auch keinen mysteriösen Trick oder einen besonderen Kniff, mit dem man ihn herbeiführen könnte.",
        "counterfactual"
    ],
    [
        0.3502797931432724,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '978'}",
        "This is a very good easy to read summary that encompasses the idea of the post",
        "Accuracy"
    ],
    [
        0.35027869045734406,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '196'}",
        "نظر شما در مورد عطر، بو، و طعم این حبوبات و سویا چیست؟",
        "طعم"
    ],
    [
        0.35027869045734406,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '329'}",
        "نظر شما در مورد عطر، بو، و طعم این حبوبات و سویا چیست؟",
        "طعم"
    ],
    [
        0.35027869045734406,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '406'}",
        "نظر شما در مورد عطر، بو، و طعم این حبوبات و سویا چیست؟",
        "طعم"
    ],
    [
        0.35027014712492627,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '147'}",
        "The summary states that she wonders if she’s actually gay despite being interested in women which does not make sense. She has always been interested in both genders.",
        "Accuracy"
    ],
    [
        0.35024330019950867,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '254'}",
        "(1) Джим не может не видеть страшной закомплексованности девушки. (2) Он пытается помочь, убеждает, что её хромота совсем не бросается в глаза, — никто в школе даже не замечал, что она носит специальную обувь. (3) Люди совсем не злые, пытается он втолковать Лауре, особенно когда узнаешь их поближе. (4) Практически у всех что-нибудь да не ладится — не годится считать себя хуже всех. (5) По его мнению, главная проблема Лауры заключается в том, что она вбила себе в голову: только у неё все плохо... (6) Лаура спрашивает про девушку, с которой Джим встречался в школе, — говорили, что они обручились. (7) Узнав, что никакой свадьбы не было и Джим давно уже ee не видел, Лаура вся расцветает. (8) Чувствуется, что в душе ee зародилась робкая надежда. (9) Она показывает Джиму свою коллекцию стеклянных фигурок — высший знак доверия. (10) Среди зверюшек выделяется единорог — вымершее животное, ни на кого не похожее. (11) Джим сразу обращает на него внимание. (12) Тому, наверное, скучно стоять на одной полке с заурядными животными вроде стеклянных лошадок?",
        "True"
    ],
    [
        0.35024330019950867,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '255'}",
        "(1) Джим не может не видеть страшной закомплексованности девушки. (2) Он пытается помочь, убеждает, что её хромота совсем не бросается в глаза, — никто в школе даже не замечал, что она носит специальную обувь. (3) Люди совсем не злые, пытается он втолковать Лауре, особенно когда узнаешь их поближе. (4) Практически у всех что-нибудь да не ладится — не годится считать себя хуже всех. (5) По его мнению, главная проблема Лауры заключается в том, что она вбила себе в голову: только у неё все плохо... (6) Лаура спрашивает про девушку, с которой Джим встречался в школе, — говорили, что они обручились. (7) Узнав, что никакой свадьбы не было и Джим давно уже ee не видел, Лаура вся расцветает. (8) Чувствуется, что в душе ee зародилась робкая надежда. (9) Она показывает Джиму свою коллекцию стеклянных фигурок — высший знак доверия. (10) Среди зверюшек выделяется единорог — вымершее животное, ни на кого не похожее. (11) Джим сразу обращает на него внимание. (12) Тому, наверное, скучно стоять на одной полке с заурядными животными вроде стеклянных лошадок?",
        "True"
    ],
    [
        0.35024330019950867,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '257'}",
        "(1) Джим не может не видеть страшной закомплексованности девушки. (2) Он пытается помочь, убеждает, что её хромота совсем не бросается в глаза, — никто в школе даже не замечал, что она носит специальную обувь. (3) Люди совсем не злые, пытается он втолковать Лауре, особенно когда узнаешь их поближе. (4) Практически у всех что-нибудь да не ладится — не годится считать себя хуже всех. (5) По его мнению, главная проблема Лауры заключается в том, что она вбила себе в голову: только у неё все плохо... (6) Лаура спрашивает про девушку, с которой Джим встречался в школе, — говорили, что они обручились. (7) Узнав, что никакой свадьбы не было и Джим давно уже ee не видел, Лаура вся расцветает. (8) Чувствуется, что в душе ee зародилась робкая надежда. (9) Она показывает Джиму свою коллекцию стеклянных фигурок — высший знак доверия. (10) Среди зверюшек выделяется единорог — вымершее животное, ни на кого не похожее. (11) Джим сразу обращает на него внимание. (12) Тому, наверное, скучно стоять на одной полке с заурядными животными вроде стеклянных лошадок?",
        "True"
    ],
    [
        0.35024330019950867,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '258'}",
        "(1) Джим не может не видеть страшной закомплексованности девушки. (2) Он пытается помочь, убеждает, что её хромота совсем не бросается в глаза, — никто в школе даже не замечал, что она носит специальную обувь. (3) Люди совсем не злые, пытается он втолковать Лауре, особенно когда узнаешь их поближе. (4) Практически у всех что-нибудь да не ладится — не годится считать себя хуже всех. (5) По его мнению, главная проблема Лауры заключается в том, что она вбила себе в голову: только у неё все плохо... (6) Лаура спрашивает про девушку, с которой Джим встречался в школе, — говорили, что они обручились. (7) Узнав, что никакой свадьбы не было и Джим давно уже ee не видел, Лаура вся расцветает. (8) Чувствуется, что в душе ee зародилась робкая надежда. (9) Она показывает Джиму свою коллекцию стеклянных фигурок — высший знак доверия. (10) Среди зверюшек выделяется единорог — вымершее животное, ни на кого не похожее. (11) Джим сразу обращает на него внимание. (12) Тому, наверное, скучно стоять на одной полке с заурядными животными вроде стеклянных лошадок?",
        "True"
    ],
    [
        0.3502352386713028,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '656'}",
        "We doubt that Winona is a sheep. It is likely that Julius is a frog. Chances are about even that Greg is white.",
        "invalid"
    ],
    [
        0.3501789520184199,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '668'}",
        "It is improbable that either 'Lily is a swan' or 'Julius is green' but not both.",
        "invalid"
    ],
    [
        0.35015519460042316,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '261'}",
        "I'm not sure how to format this, so I'm going to try to get to the point as fast as possible.\n\nI have very, very few friends and a long-distance relationship with a really lovely guy. I've been having trouble with my divorced parents, my dad is unemployed and my mom is abusive. My boyfriend really hates seeing me upset and about a month ago in a bit of an argument, he told me that if I don't do anything about my mom hitting me he's going to cut contact. Despite how mean that seems, he's really a good guy and I depend on him quite a lot.\n\nIn the past month, my mother's only gotten worse and earlier tonight I told him about it. He's giving me until tomorrow to call the police or do something about it or he's going to cut contact. I can't call the police because I don't have any good relatives except my father, who cannot support my sister and I. If I call the police, we're going to be taken into custody or something and I really can't choose between keeping him and not leaving everyone else.\n\nMy current plan is to wait until my dad finds a job so I can be put into his custody, but my boyfriend wants me to act now. I'm just not sure what to do to stop him from leaving.",
        "Accuracy"
    ],
    [
        0.3501538385947545,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'danetqa', 'row_id': '545'}",
        "Николай Гоголь никогда не был женат и предпочитал вести замкнутый образ жизни. О его личной жизни сохранилось мало данных, что стало причиной возникновения ряда гипотез о его гомосексуальности. Известно, что в 1829 году Гоголь внезапно уехал из Петербурга в Любек. В письме матери он объяснил свой поступок следующим образом: Кто бы мог ожидать от меня подобной слабости. Но я видел её… нет, не назову её… она слишком высока для всякого, не только для меня.",
        "False"
    ],
    [
        0.35010917484760284,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '761'}",
        "There is almost no chance that either 'Brian is a swan' or 'Sandra left the milk' but not both.",
        "invalid"
    ],
    [
        0.35009945432345074,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '282'}",
        "It is probably not the case that either 'Lily is green' or 'Julius is gray' but not both.",
        "invalid"
    ],
    [
        0.35008539259433746,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '991'}",
        "It is probable that Julius is a lion. There is little chance that Greg is gray. There is a very good chance that Mary dropped the apple. It is certain that if 'Mary dropped the apple and Julius is a lion' then Bernhard is a rhino. It is highly likely that if 'Julius is a lion and Greg is gray' then John went to the kitchen. It is unlikely that if 'Julius is a lion and Greg is gray' then Jessica is a cat.",
        "invalid"
    ],
    [
        0.35006289680798847,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '167'}",
        "It is probably not the case that Gertrude is a sheep. It is certain that Sandra left the milk. It is impossible that Lily is green. It is unlikely that if 'Lily is green and Sandra left the milk' then John picked up the apple. It is probable that if 'Lily is green and Sandra left the milk' then Greg is white. It is probable that if 'Lily is green' or 'Sandra left the milk' or both then Julius is yellow.",
        "invalid"
    ],
    [
        0.3500174631675084,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '569'}",
        "There is a very good chance that Julius is a swan. It is probable that John moved to the garden. It is unlikely that Emily is a sheep. It is impossible that if 'Emily is a sheep' or 'Julius is a swan' or both then Winona is a mouse. Chances are slight that if 'Emily is a sheep and Julius is a swan' then Bernhard is green. It is probable that if 'Emily is a sheep and Julius is a swan' then Brian is yellow.",
        "invalid"
    ],
    [
        0.35001395642757416,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '781'}",
        "There is a better than even chance that Gertrude is a cat. It is highly likely that Bernhard is white. It is probably not the case that Emily is a sheep. It is probably the case that if 'Emily is a sheep' or 'Bernhard is white' or both then Brian is a rhino. It is probably not the case that if either 'Emily is a sheep' or 'Bernhard is white' but not both then Julius is a frog. It is probable that if either 'Emily is a sheep' or 'Gertrude is a cat' but not both then John picked up the apple.",
        "invalid"
    ],
    [
        0.3499974310398102,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '694'}",
        "This news release describes the discovery of propentofylline, a drug that researchers claim could help patients with brain tumors. But there’s no justification for calling this test of a drug on brain tumor cells in a lab dish “a significant breakthrough.” Because of the murky wording of the release, and the many mentions of potential benefits to patients, as well as references to clinical trials (without being clear that those trials involved patients with Alzheimer’s and other diseases, not brain tumors), readers may not realize that the number of patients in this trial was exactly zero. The release also miscasts the threat posed by glioblastoma multiforme. It calls the disease the most common primary tumor of the brain and central nervous system and warns that “it affects people of all ages,” without noting that the disease is diagnosed in only about 2 or 3 people per 100,000 population each year, or only about 1 percent of all cancer cases. Glioblastoma multiforme is a devastating disease with little in the way of effective treatments. It is for this very reason that reports of potential new approaches should be measured and free of hyperbole and false hope. Most people are unaware just how few experimental drugs that show encouraging results in laboratory tests eventually show they can help real patients. While the results of this cell culture test may be worth investigating further, it is far too early to crow about potential benefits to patients.",
        "false"
    ],
    [
        0.3499877254168193,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'en', 'row_id': '553'}",
        "\"It was easier to believe in \\The General's Daughter\\\"\" because he wasn't in a hostile country where no one would miss him.\"\"\"",
        "not-counterfactual"
    ],
    [
        0.3499877254168193,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'en-ext', 'row_id': '670'}",
        "\"It was easier to believe in \\The General's Daughter\\\"\" because he wasn't in a hostile country where no one would miss him.\"\"\"",
        "not-counterfactual"
    ],
    [
        0.3499877254168193,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'en', 'row_id': '553'}",
        "\"It was easier to believe in \\The General's Daughter\\\"\" because he wasn't in a hostile country where no one would miss him.\"\"\"",
        "not-counterfactual"
    ],
    [
        0.3499877254168193,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'en-ext', 'row_id': '670'}",
        "\"It was easier to believe in \\The General's Daughter\\\"\" because he wasn't in a hostile country where no one would miss him.\"\"\"",
        "not-counterfactual"
    ],
    [
        0.349960799018542,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '156'}",
        "Chances are slight that Emily is a wolf. It is unlikely that Julius is a lion. There is almost no chance that Mary got the football. Chances are about even that if 'Mary got the football and Julius is a lion' then Brian is yellow. There is a very good chance that if either 'Emily is a wolf' or 'Julius is a lion' but not both then Gertrude is a cat. There is a very good chance that if 'Emily is a wolf' or 'Mary got the football' or both then Bernhard is green.",
        "invalid"
    ],
    [
        0.34993931154410046,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '400'}",
        "There is little chance that 'John dropped the apple' or 'Brian is a lion' or both.",
        "invalid"
    ],
    [
        0.3499252398808797,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '40'}",
        "[{'follow_up_question': 'Are you a veteran who wears or uses a prosthetic or orthopedic appliance which tends to wear or tear clothing?', 'follow_up_answer': 'No'}, {'follow_up_question': \"Are you a veteran who uses medication, which a physician has prescribed for a skin condition that is due to a service-connected disability and causes irreparable damage to the Veteran's outer garments?\", 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.34992222984631854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '681'}",
        "It is unlikely that 'Lily is a frog' or 'Sandra got the milk' or both.",
        "invalid"
    ],
    [
        0.3499003102382024,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '436'}",
        "Write an excellent summary of the given text.\n\nTitle: I (22F) have been dating for 3 months (25M), friends say I should still be seeing other people cause he has been pretty busy lately and we haven't been hanging out as much\n\nText: I (22F) have been dating this guy (25M) for little over 3 months now. We met online and I am starting to really like him a lot. Mt problem is that when I start having these feeling I tend to get needy as most people put it. Now I have friends that I hang out with a ton and I also have a lot of activities I like to do too. But that doesn't mean I don't want to hang out with him and have experiences with him too as much as I can. Especially at the beginning of a relationship or whatever it is. I don't think this makes me needy. \n\nWell, he has been really busy over the last few weeks with work and other hobbies of his. And the amount of time we have hang out has kinda gone down from when we first met. He hasn't been ignoring me in like text and stuff and he got me a christmas gift (something we never discussed and was totally unexpected) so I don't think he is trying to fade out on me. \n\nBut I still feel like uncertain with things I guess. All of my friends tell me I shouldn't put all my eggs in one basket and I should continue to like see other guys. But this makes me feel like wrong or something. For one I don't want to sleep with anyone else or do anything (kissing, dating, whatever) with anyone else, and two I would just feel like I'm leading everyone on who gets involved. I think they are telling me this cause they don't want to see me get hurt and they are just trying to help but it just kinda seems like a bad idea to me. Especially cause me and this guy have talked about being exclusive, but we haven't had the bf and gf talk, and I really don't want to see other people. So ya I feel like my issue is pretty silly but I wanted to see what other people had to say I guess.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3498801638682683,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '798'}",
        "-1",
        "طعم"
    ],
    [
        0.3498791456222534,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'rob_train_disc_23_test_all_23', 'row_id': '429'}",
        "[Mona] was very proud of her son, [Colin]. She did n't feel the same way about his brother, [Robert], she thought he was a disgrace. [Denise] likes going to the mall with her aunt [Lindsay].",
        "son"
    ],
    [
        0.3498726934194565,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '299'}",
        "It is unlikely that either 'Julius is a lion' or 'Mary dropped the apple' but not both.",
        "invalid"
    ],
    [
        0.3498534659544627,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '717'}",
        "Write an excellent summary of the given text.\n\nTitle: \"Did you just bang my mom, RasTr3nt?\";\"...yeah, i did.\" Most awkward conversation you've ever had?\n\nText: A bit of backstory: \n    The first time I had sex was with a woman nearly twice my age in a travel trailer with her daughter in the next room. I had just turned 19, was socially awkward, and had a tendency to hang with the \"wrong crowd\". Having driven one of the aformentioned douchepistols to a girl's ~~house~~ trailer (they lived behind her grandmother), I ended up talking to her mom for a good 2-3 hours. We had a lot in common, and somehow the subject of my virginity card came into the coversation.\n     Douchepistol laughs and says I'm a virgin. The mom looked me dead in the eye and told me she was willing to help with that. Fast forward an hour or so, the trailer is rocking. Literally. Friend is higher than I would care to describe in the next room, trying desperately to get laid (and failing). \n     As we're about to leave the daughter asks me point blank if I had boned her mother. I don't think I've ever been redder in my entire life, I told her yes and that I was coming over again next week.\n     BONUS: I called my dad on the drive home.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3498353759447734,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '814'}",
        "One of about two dozen methamphetamine users who received free bubble-ended pipes on a recent afternoon, Russell is a  participant in a pioneering but illegal program launched in March that aims to indirectly curb infectious diseases. “Dude’s got something to smoke but he doesn’t have a pipe, what’s he going to do?” Russell said later as he munched on a sandwich. “Panhandle, steal. Inject.”  The theory behind the handout program is that giving meth pipes to drug users may steer some away from needles, which are far riskier than smoking, especially if the user is sharing with another person infected with HIV or hepatitis C.  There is little scientific evidence to support that claim, but The People’s Harm Reduction Alliance, a privately funded needle-swap group run by drug users, said it has distributed more than 1,000 pipes in Seattle in a matter of weeks and could expand to other cities in Washington state and Oregon. Its program also draws addicts from society’s fringes into its compassionate fold, with links to treatment and housing services, Executive Director Shilo Murphy said. Even though needle exchanges have faced continued opposition in many parts of the United States since the first legal one opened in Tacoma, Washington in 1988, the programs have been credited with reducing HIV infections and saving lives. But opponents say giving away meth pipes discourages quitting while wasting resources on an untested scheme that will not solve a city-wide health problem. They note that among methamphetamine-using gay men, HIV is transmitted primarily through unprotected sex, not syringe- or pipe-sharing. There are no studies to show meth users will resort to injections if pipes are unavailable, or that handing out pipes prevents needle use, said Matthew Golden, a Seattle and King County Disease Control Officer and a University of Washington professor of medicine. It is also hard to quantify how much the campaign might prevent death or infection, if at all, even if it does give meth users safer options than a needle or smoking out of a jerry-rigged light bulb, Golden said. “It is plausible the intervention could be effective,” Golden said. “It’s simply an unstudied idea.”   But the Alliance, which says it is the nation’s largest needle-exchange program by syringes dispersed, has pushed legal boundaries for years with user-conceived experiments unacceptable to its taxpayer-funded counterparts, Murphy said. It faced public outcry five years ago with a similarly illegal campaign to hand out crack pipes with extension tubes to prevent the hot glass from blistering addicts’ lips, on the theory that disease could spread between pipe-sharers through open wounds, Murphy said. A similar program began in San Francisco last year. The Alliance launched its meth pipe program after learning from its own survey that 80 percent of area meth users would be less likely to inject drugs if given access to pipes. On a recent afternoon in an alley near the leafy University of Washington campus, dozens of drug users ambled up to a makeshift table to dump fistfuls of dirty syringes into biohazard bins and retrieve fresh boxes of needles, as well as meth pipes. Addicts, among them a transient man with a military-style backpack and two glassy-eyed college-age youths, also helped themselves to supplies like cookers, pushers and latex ties, as well as condoms and health pamphlets. “We don’t see this as controversial. We see this as what’s needed in our community,” Murphy said. Giving out meth or crack pipes is illegal under state law, but the Seattle Police Department said it has taken no action to actively monitor or shutter the program. Anti-drug groups say needle exchanges make hard drug use appear acceptable and bring crime to communities, among other concerns. Phillip Wilson, 56, said the pipe programs were harming the community, adding that he planned to re-sell the glassware he got on the street for about $10. “Come on man, giving that shit away to people who are trying to quit? I just can’t understand it,” he said.",
        "true"
    ],
    [
        0.3498242497444153,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '857'}",
        "On a hot 8 August in the late 1930s , eight people arrive on a small , isolated island off the Devon coast of England . Each has an invitation tailored to his or her personal circumstances , such as an offer of employment or an unexpected late summer holiday . They are met by Thomas and Ethel Rogers , the butler and cook - housekeeper , who state that their hosts , Mr Ulick Norman Owen and his wife Mrs Una Nancy Owen , whom they have not yet met in person , have not arrived , but left instructions , which strikes all the guests as odd .",
        ""
    ],
    [
        0.3498211205005646,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '697'}",
        "There is a very good chance that Julius is a lion. Chances are slight that Mary went to the bedroom. It is unlikely that Bill moved to the office. Chances are about even that if 'Julius is a lion and Mary went to the bedroom' then John discarded the apple. It is almost certain that if either 'Mary went to the bedroom' or 'Bill moved to the office' but not both then Bernhard is yellow. It is highly likely that if 'Mary went to the bedroom' or 'Julius is a lion' or both then Greg is a frog.",
        "invalid"
    ],
    [
        0.3498118420441945,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '3'}",
        "It is certain that Brian is white. We doubt that Bill went to the kitchen. It is unlikely that John moved to the office. We believe that if either 'Bill went to the kitchen' or 'John moved to the office' but not both then Sandra got the football. There is little chance that if either 'Bill went to the kitchen' or 'Brian is white' but not both then Bernhard is gray. It is likely that if 'Bill went to the kitchen' or 'John moved to the office' or both then Greg is a lion.",
        "invalid"
    ],
    [
        0.34981122612953186,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '360'}",
        "Write an excellent summary of the given text.\n\nTitle: I need advice regarding a situation that involves herpes, among other things...\n\nText: A- my boyfriend, 27\nB- boyfriend's brother, 21\nC- brother's on/off fwb, 20\n\nAnd I am 19 f. B and C have had a thing going on for a while. A and C are fairly close friends and she has been confiding in him lately. C is troubled to say the least; I won't go into detail, but it seems like all the bad things that could possibly happen have happened to her.\n\nSo A, B, C, and I all work at the same place. Last night C and I were talking in the breakroom and she told me that she has herpes. I asked if she'd told everyone she'd been with; she said she'd only been with one guy recently and that was a few months ago. I don't know if she was referring to B or not, because I didn't ask (stupid, I know). I don't think she even knows I know about her and B.\n\nC told me not to tell anyone. But I definitely feel like B has the right to know. I don't talk to him much so I feel like it might be better to have A tell him; the thing is, I feel like it would be a bit inappropriate to tell him that his brother may have been exposed to herpes via text message. I might see A this afternoon during shift change when he's leaving work and I'm about to come in. I don't really know if I'll have a chance to tell him in private. I'll see him tomorrow morning for work as well and then again when we hang out tomorrow night. \n\nSo should I text A, find a way to tell him at work, or wait until tomorrow when we'll have time alone? Or maybe I could just ask C if she's told B, but I'm afraid she'll be angry at A for telling me about their thing.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.349777619043986,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '27'}",
        "[{'id': 'unknown_1a', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙖𝙛𝙠𝙤𝙢𝙨𝙩"
    ],
    [
        0.3497655342022578,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '883'}",
        "Chances are about even that Emily is a sheep. It is highly likely that Jessica is a cat. There is a very good chance that Lily is green. It is improbable that if either 'Emily is a sheep' or 'Jessica is a cat' but not both then Greg is yellow. There is almost no chance that if 'Lily is green' or 'Jessica is a cat' or both then Sandra got the football. It is likely that if 'Jessica is a cat and Lily is green' then Brian is white.",
        "invalid"
    ],
    [
        0.34975893298784894,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '427'}",
        "نظر شما در مورد عطر، بو، و طعم این روغن چیست؟",
        "طعم"
    ],
    [
        0.34975893298784894,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '441'}",
        "نظر شما در مورد عطر، بو، و طعم این روغن چیست؟",
        "طعم"
    ],
    [
        0.34975893298784894,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '525'}",
        "نظر شما در مورد عطر، بو، و طعم این روغن چیست؟",
        "طعم"
    ],
    [
        0.34972648819287616,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '664'}",
        "It is improbable that Mary went to the kitchen. There is little chance that Winona is a wolf. We believe that Greg is gray. It is probable that if 'Mary went to the kitchen' or 'Winona is a wolf' or both then Yann is thirsty. There is almost no chance that if either 'Mary went to the kitchen' or 'Winona is a wolf' but not both then Fred left the football. We believe that if 'Greg is gray and Winona is a wolf' then Lily is a frog.",
        "invalid"
    ],
    [
        0.34967634081840515,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'danetqa', 'row_id': '457'}",
        "Рагна́р Лодбро́к  — легендарный датский конунг, представитель скандинавского рода Инглингов, отец Бьёрна Железнобокого, основателя династии Мунсё. Достоверных источников, подтверждающих существование Рагнара, нет. В основном подробности его жизни и деятельности известны из скандинавских саг, повествующих, как Рагнар промышлял набегами и морским разбоем. Предполагают, что исторический Рагнар  действовал в первой половине IX века и был одним из наиболее влиятельных военных вождей Дании. Вероятно, он был сыном Сигурда Кольцо.",
        "True"
    ],
    [
        0.3496192395687103,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '212'}",
        "Chances are about even that Sumit is thirsty. It is almost certain that Julius is a lion. It is almost certain that Brian is green. It is certain that if either 'Sumit is thirsty' or 'Julius is a lion' but not both then Bill left the milk. We believe that if 'Sumit is thirsty and Julius is a lion' then Greg is white. It is probably not the case that if 'Brian is green' or 'Sumit is thirsty' or both then John dropped the apple.",
        "invalid"
    ],
    [
        0.3496172974507014,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '33'}",
        "[{'id': 'unknown_1a', 'response': 'Weet ik niet'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Onleesbare OCR'}]",
        "𝙍𝙤𝙢𝙖"
    ],
    [
        0.3495895316203435,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '305'}",
        "It is impossible that either 'Mary discarded the milk' or 'Greg is a swan' but not both.",
        "invalid"
    ],
    [
        0.3495883693297704,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '414'}",
        "من مصرف آدامسم زیاده و همیشه تریدنت و فایو استفاده کردم،بخاطر تحریم ها متاسفانه ادامس های خارجی یا نیستن یا تاریخ گذشته ن،این آدامس از نظر کیفیت از بایودنت و اگزیت و وایت و اکشن و... بالاتره یعنی بعد از تریدنت من این آدامس رو میپسندم با قیمت بسیارررررر ارزان",
        "کلی"
    ],
    [
        0.34951000412305194,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '675'}",
        "There is a better than even chance that Bernhard is green. It is probably not the case that Mary got the apple. It is highly unlikely that Lily is a swan. We believe that if 'Mary got the apple and Bernhard is green' then Greg is a rhino. We believe that if 'Mary got the apple and Lily is a swan' then Jessica is a wolf. It is certain that if either 'Lily is a swan' or 'Mary got the apple' but not both then John left the milk.",
        "invalid"
    ],
    [
        0.3495003829399745,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '309'}",
        "['Although genetic association studies have been with us for many years, even for the simplest analyses there is little consensus on the most appropriate statistical procedures.', 'Here I give an overview of statistical approaches to population association studies, including preliminary analyses (Hardy–Weinberg equilibrium testing, inference of phase and missing data, and SNP tagging), and single-SNP and multipoint tests for association.', 'My goal is to outline the key methods with a brief discussion of problems (population structure and multiple testing), avenues for solutions and some ongoing developments.']",
        "False"
    ],
    [
        0.34946847955385846,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '841'}",
        "It is impossible that Brian is a frog. It is improbable that Sandra is in the kitchen. It is impossible that Bernhard is a rhino.",
        "invalid"
    ],
    [
        0.3494536181290944,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '329'}",
        "The summary is not an accurate summation of the post.",
        "Accuracy"
    ],
    [
        0.3494512736797333,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '830'}",
        "[{('Shantel', 'son', 'Robert'): [('Shantel', 'son', 'Louis'), ('Louis', 'brother', 'Robert')]}, {('Louis', 'brother', 'Robert'): [('Louis', 'son', 'Samuel'), ('Samuel', 'uncle', 'Robert')]}, {('Louis', 'son', 'Samuel'): [('Louis', 'son', 'Paul'), ('Paul', 'brother', 'Samuel')]}]",
        "son"
    ],
    [
        0.3494241585334142,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '824'}",
        "[{'follow_up_question': 'Was the property a gift (there are different rules if it was to your spouse, civil partner or a charity)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'did you inherit it?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.3494241187969844,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '951'}",
        "[{'follow_up_question': 'Was the property a gift (there are different rules if it was to your spouse, civil partner or a charity)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'did you inherit it?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.34941711525122326,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '606'}",
        "It is almost certain that Brian is a rhino. It is unlikely that Fred discarded the apple. It is unlikely that Bernhard is a swan. It is highly unlikely that if 'Brian is a rhino and Fred discarded the apple' then Jessica is a mouse. It is probable that if 'Brian is a rhino and Bernhard is a swan' then Sandra dropped the milk. There is a better than even chance that if 'Fred discarded the apple' or 'Bernhard is a swan' or both then John went to the bedroom.",
        "invalid"
    ],
    [
        0.3494150588909785,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '546'}",
        "نظر شما در مورد عطر، بو، و طعم این بیسکویت و ویفر چیست؟",
        "طعم"
    ],
    [
        0.3494150588909785,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '721'}",
        "نظر شما در مورد عطر، بو، و طعم این بیسکویت و ویفر چیست؟",
        "طعم"
    ],
    [
        0.3494100073973338,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '980'}",
        "It is highly likely that Bernhard is white. It is certain that John dropped the apple. It is certain that Julius is a lion. It is probably not the case that if 'Julius is a lion' or 'John dropped the apple' or both then Mary went to the office. Chances are slight that if 'Bernhard is white' or 'John dropped the apple' or both then Gertrude is a cat. It is almost certain that if 'John dropped the apple' or 'Julius is a lion' or both then Brian is a swan.",
        "invalid"
    ],
    [
        0.3493739018837611,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '7'}",
        "It is highly unlikely that either 'Greg is a lion' or 'Gertrude is a cat' but not both.",
        "invalid"
    ],
    [
        0.3493663817644119,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '385'}",
        "We believe that John dropped the apple. There is almost no chance that Bill went to the garden. We doubt that Brian is a swan. It is likely that if 'Bill went to the garden' or 'Brian is a swan' or both then Jessica is a mouse. It is almost certain that if either 'Brian is a swan' or 'John dropped the apple' but not both then Julius is a frog. There is a very good chance that if either 'John dropped the apple' or 'Bill went to the garden' but not both then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.34936265647411346,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '13'}",
        "Two female friends, one a representative and one not, have a disagreement about whether or not the non-representative should attend the weekly meeting.",
        "Accuracy"
    ],
    [
        0.349335715174675,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '778'}",
        "The original selection committees chose to recognize some entertainers ' contributions in multiple categories with multiple stars . Gene Autry is the only honoree with stars in all five categories . Bob Hope , Mickey Rooney , Roy Rogers , and Tony Martin each have stars in four categories -- Rooney has three of his own and a fourth with his eighth and final wife , Jan , while Rogers also has three of his own , and a fourth with his band , Sons of the Pioneers . Thirty - three people , including Bing Crosby , Frank Sinatra , Jo Stafford , Dean Martin , Dinah Shore , Gale Storm , Danny Kaye , Douglas Fairbanks Jr. , and Jack Benny , have stars in three categories .",
        ""
    ],
    [
        0.34933070838451385,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '851'}",
        "It is probably the case that John went to the kitchen. It is improbable that Julius is a lion. It is likely that Bernhard is yellow. We believe that if 'Bernhard is yellow' or 'John went to the kitchen' or both then Jeff left the football. Chances are slight that if either 'Bernhard is yellow' or 'John went to the kitchen' but not both then Jason is tired. It is impossible that if either 'John went to the kitchen' or 'Bernhard is yellow' but not both then Lily is white.",
        "invalid"
    ],
    [
        0.34931894143422443,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '440'}",
        "The story did not discuss cost. There are dozens of fish oil supplements on the market and their cost varies widely. The story could have given some sense of the financial impact that this regimen would have. This was a strong point of the story, giving us both absolute and relative risk figures up front in the second paragraph: Among children whose mothers took fish-oil capsules, 16.9 percent had asthma by age 3, compared with 23.7 percent whose mothers were given placebos. The difference, nearly 7 percentage points, translates to a risk reduction of about 31 percent. Too often, even when stories do provide absolute risk figures, they highlight relative risks high up in the story and bury the absolute risk information far down in the text where it’s less likely to be read. The story explains that no adverse events were associated with the intervention. However, the harms assessed by the researchers were things like maternal or infant death, emergency caesarean delivery, and preterm birth. They didn’t assess (and the story didn’t mention) less serious harms like fishy taste, nausea, belching, and heartburn that are commonly associated with fish oil capsules and which might make this regimen burdensome for pregnant women. Moreover, it would have been useful if the story had also noted that the reason researchers want to replicate the results in a larger group of women is to make sure these very high doses of fish oil are indeed safe. The story gives us details of the study–how many women were enrolled, that there was a placebo group, and that the children were followed for seven years. An independent source also explains that the study was “well designed and carefully performed.” The story does not disease monger–childhood asthma is a common and often exasperating condition that many parents grapple with. The story clearly explains who funded the study, and includes an independent source. But it doesn’t note the extensive conflicts of interest reported by the lead author who’s quoted in the piece: Dr. Bisgaard reports receiving consulting fees from Chiesi Pharmaceuticals and Boehringer Ingelheim, and Drs. Bisgaard and Bønnelykke report being named on a pending patent related to the prevention of childhood asthma through FADS genotyping and the assessment of blood levels of eicosapentaenoic acid and docosahexaenoic acid in pregnant mothers. The patent filing related to genetic testing is particularly relevant, given that the researcher advocates genetic testing and testing of fish oil levels in pregnant women to determine who might benefit most from supplementation. Aside from avoidance of maternal smoking, there are no known ways to reduce the risk of developing asthma in childhood. The story explains this is why doctors are testing this method, and excited by the findings. The story explains that the “capsules were an over-the-counter product called Incromega TG33/22, a fish extract made by the British chemical company Croda Health Care.” And in regard to whether women should start taking the supplement to lower asthma risk in their babies, the story lets us know researchers “are not ready to recommend that pregnant women routinely take fish oil” due to the very high dose used in this study. Further research is needed first to establish safety and confirm benefit. We learn that previous studies on this topic were inconclusive, and so the inference is that this is the first time more conclusive results were seen, especially regarding the benefit in women who had lower-than-normal levels of the fatty acids in their blood. This story did not rely on the news release.",
        "true"
    ],
    [
        0.34930870433648425,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '649'}",
        "an aU* maatsfihappelijke deugden.Het is bijna onmogelijk, d»t de 𝙝𝙖𝙡𝙛𝙗𝙡𝙤𝙚𝙙 dien traditioneel»0 eo ras-trots tooi_!-idie de zwarte vrouw ste",
        "𝙝𝙖𝙡𝙛𝙗𝙡𝙤𝙚𝙙"
    ],
    [
        0.34928057342767715,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '203'}",
        "نظر شما در مورد عطر، بو، و طعم این مربا چیست؟",
        "طعم"
    ],
    [
        0.34928057342767715,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '217'}",
        "نظر شما در مورد عطر، بو، و طعم این مربا چیست؟",
        "طعم"
    ],
    [
        0.34928057342767715,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '343'}",
        "نظر شما در مورد عطر، بو، و طعم این مربا چیست؟",
        "طعم"
    ],
    [
        0.34928057342767715,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '567'}",
        "نظر شما در مورد عطر، بو، و طعم این مربا چیست؟",
        "طعم"
    ],
    [
        0.34926027059555054,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '40'}",
        "[{'id': 'unknown_1a', 'response': 'Illegible OCR'}, {'id': 'unknown_1b', 'response': 'Not contentious'}, {'id': 'unknown_1d', 'response': \"I don't know\"}, {'id': 'unknown_1e', 'response': 'Illegible OCR'}, {'id': 'unknown_1f', 'response': 'Illegible OCR'}, {'id': 'unknown_1g', 'response': 'Illegible OCR'}]",
        "𝙜𝙖𝙮"
    ],
    [
        0.3492213835318883,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '606'}",
        "The post never specified the person was a woman, so this is inaccurate.",
        "Accuracy"
    ],
    [
        0.3492194761832555,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '142'}",
        "It is probably not the case that either 'John went to the bedroom' or 'Lily is white' but not both.",
        "invalid"
    ],
    [
        0.34920187294483185,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '861'}",
        "It is unlikely that 'Bernhard is gray' or 'Lily is a swan' or both.",
        "invalid"
    ],
    [
        0.3491974174976349,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '28'}",
        "Write an excellent summary of the given text.\n\nTitle: I [M20] don't feel attracted to my GF [F19] anymore but I feel trapped.\n\nText: Where to begin.. \n\nFor starters,  we started dating on bad terms,  she was my best friends ex,  I won't go into too much detail because there was a lot of confusion. \n\nBut here we are,  about 2 years after the fact and I'm in a bad area of my life.  I don't really have any friends,  and by that I mean I have 0 friends.  I'm over it,  I'm used to it. She is all I have and we live together.  We have good times and I enjoy her company..However,  I don't feel attracted to her,  sure she has a nice body but other than that..  idk.   I don't feel it.  I'm still not completely over my traumatizing break up with my ex that happened in 2012, and I'm trying to get my life together. \n\nWhen we go out in public I see other girls and feel I'm with the wrong by person; I want to end it,  but I feel if I do I couldn't handle being alone every day and night.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34919699529806775,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '977'}",
        "It is improbable that either 'Sandra got the football' or 'Greg is a lion' but not both.",
        "invalid"
    ],
    [
        0.3491821537415187,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '505'}",
        "There is almost no chance that Sandra left the apple. It is unlikely that Mary discarded the milk. It is almost certain that Lily is a rhino. It is almost certain that if 'Sandra left the apple' or 'Mary discarded the milk' or both then Bernhard is yellow. We doubt that if 'Lily is a rhino and Sandra left the apple' then Brian is white. There is almost no chance that if 'Sandra left the apple and Lily is a rhino' then John picked up the milk.",
        "invalid"
    ],
    [
        0.34918105105559033,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '41'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Onleesbare OCR'}]",
        "𝙜𝙚𝙢𝙚𝙣𝙜𝙙"
    ],
    [
        0.34917545815308887,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '880'}",
        "It is probably not the case that 'Bernhard is yellow' or 'Lily is a swan' or both.",
        "invalid"
    ],
    [
        0.3491627871990204,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '14'}",
        "It is impossible that Julius is a swan. It is almost certain that Mary dropped the milk. It is highly likely that Sandra left the apple. There is little chance that if 'Sandra left the apple' or 'Mary dropped the milk' or both then Greg is a rhino. We doubt that if 'Mary dropped the milk and Sandra left the apple' then Bernhard is white. It is almost certain that if 'Mary dropped the milk and Julius is a swan' then Jeff moved to the office.",
        "invalid"
    ],
    [
        0.34912994007269543,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '729'}",
        "It is probably not the case that 'Greg is a rhino' or 'Daniel grabbed the apple' or both.",
        "invalid"
    ],
    [
        0.34911466638247174,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '79'}",
        "\"Für weniger Geld wäre ich vielleicht nicht so sehr enttäuscht: die Remaster-CD/Doppel-CD von The Wall steht ausser Frage, dies ist ein Klassiker, das ist Kult und das ist \\\\\"\"unumschubsbar\\\\\"\" mehr als 5 Sterne Wert.\"",
        "counterfactual"
    ],
    [
        0.34911466638247174,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '79'}",
        "\"Für weniger Geld wäre ich vielleicht nicht so sehr enttäuscht: die Remaster-CD/Doppel-CD von The Wall steht ausser Frage, dies ist ein Klassiker, das ist Kult und das ist \\\\\"\"unumschubsbar\\\\\"\" mehr als 5 Sterne Wert.\"",
        "counterfactual"
    ],
    [
        0.34911443293094635,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '538'}",
        "This Wall Street Journal article describes results of an unpublished, non-peer-reviewed study of a gene-based test designed to help physicians prescribe antidepressants in people with moderate-to-severe depression who have failed on at least one of the drugs. The story, both in the narrative and in some quotes, adds some moderating context and healthy skepticism to the enthusiastic “landmark” claims from a company release. It also is clear about the cost ($1,500) of the test offered by Myriad Genetics. But it needed to examine more closely the fact that the test can’t really tell a psychiatrist or other physician which of the dozens of antidepressants may work best–only which are most likely to cause problems and should be avoided. If this is the case, what’s driving the (small) benefit? Is it because people whose treatment was guided by genetic testing experienced fewer side effects and therefore were more likely to adhere to treatment? We’re not told. Federally-funded surveys of mental health in the U.S. consistently estimate that around 15 to 20 million adult Americans have moderate-to-severe depression that warrants treatment. The good news is that there are dozens of antidepressant drugs approved by the FDA for use alone or with other, non-drug therapies. The bad news is that, as the WSJ article underscores, finding the right medicine for any given patient is largely a matter of highly subjective clinical judgment and trial and error, sometimes for years. Moreover, the drugs are often not cheap and may cause side effects. Thus, the application of gene-based “precision medicine” testing — in this case to test for a dozen or so genes that may help predict how classes of drugs are metabolized and used by the body and brain — is potentially big news.",
        "true"
    ],
    [
        0.3491114526987076,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '127'}",
        "It is unlikely that 'Greg is yellow' or 'Lily is a rhino' or both.",
        "invalid"
    ],
    [
        0.3490982900063197,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '634'}",
        "There is a very good chance that 'Brian is white' or 'John picked up the milk' or both.",
        "invalid"
    ],
    [
        0.349062904715538,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '813'}",
        "It is unlikely that Jeff moved to the office. We doubt that Bernhard is a swan. There is little chance that Lily is a frog. It is impossible that if 'Bernhard is a swan and Jeff moved to the office' then Mary went to the garden. Chances are about even that if 'Jeff moved to the office' or 'Lily is a frog' or both then Julius is white. Chances are slight that if 'Lily is a frog and Bernhard is a swan' then Brian is yellow.",
        "invalid"
    ],
    [
        0.3490140239397685,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '454'}",
        "Write an excellent summary of the given text.\n\nTitle: In your opinion, how long into dating should the feelings/expectations talk happen? Me [22F] with a guy I've been seeing for about a month [23M].\n\nText: I've been sort of seeing this guy for about a month, and I'm just feeling really confused about where I stand with him. Twice now I've been convinced that things were headed in a friendship-like direction but then he did some kind of affectionate gesture that made me think otherwise. It's really driving me up the wall not knowing what he's thinking about me. I keep thinking I need to try to dial my feelings back and maybe date other people, but in all honesty I don't want to. I want him. In my interactions with him I've tried to really play it cool and not come off as clingy or overly interested, but now I'm thinking maybe I've been playing it too cool. I need to tell him how I feel, there's no doubt in my mind about that. But, I've only known him for about a month and I feel like it might be too soon to bring it up. So I'm curious what /r/relationships thinks. How long do you usually wait to tell someone how you feel about them?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34900334974129993,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '263'}",
        "It is improbable that Greg is gray. Chances are about even that Winona is a sheep. It is probably the case that Bernhard is a lion.",
        "invalid"
    ],
    [
        0.3489980250597,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '60'}",
        "The summary is inaccurate.",
        "Accuracy"
    ],
    [
        0.3489970068136851,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '827'}",
        "\"Alles wirkt kalt und unnahbar, halt wie in der \\\\\"\"Matrix\\\\\"\" und ich stimme dem Charakter Fischer (Cillian Murphy) zu, wenn er sagt, dass man anstatt in eine Eiswüste ruhig an einen karibischen Strand hätte gehen können.\"",
        "counterfactual"
    ],
    [
        0.3489970068136851,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '827'}",
        "\"Alles wirkt kalt und unnahbar, halt wie in der \\\\\"\"Matrix\\\\\"\" und ich stimme dem Charakter Fischer (Cillian Murphy) zu, wenn er sagt, dass man anstatt in eine Eiswüste ruhig an einen karibischen Strand hätte gehen können.\"",
        "counterfactual"
    ],
    [
        0.3489961226781209,
        "{'dataset_id': 'WorkInTheDark/FairytaleQA', 'config_id': 'plain_text', 'row_id': '625'}",
        "\" o illustrious prince , though it is not right for a guest to even seem to observe aught that may be awry , or not as it should be , in the hall of his entertainer , yet the sorrow of a kindly host is a sorrow , too , to his guest , and sometimes unawares the man of the house finds succour and help in the stranger . there is sorrow in this chamber of festivity . if anyone who is dear to thee and thy people happens to be dead , i can do nothing . but i say it , and it is not a vain boast , that even if a person is at the point of death , i can restore him to life and health , for there are marvellous powers of life - giving in my two hands . \" conn the hundred - fighter answered , \" our grief is not such as you suppose ; and why should i not tell a cause of shame , which is known far and wide ? this , then , is the reason of our being together , and the gloom which is over us . there is a mighty enchanter whose dwelling is in the haunted mountains of slieve gullion in the north . his name is allen , son of midna , and his enmity to me is as great as his power . once every year , at this season , it is his pleasure to burn tara . descending out of his wizard haunts , he standeth over against the city and shoots balls of fire out of his mouth against it , till it is consumed . then he goes away mocking and triumphant . this annual building of tara , only to be annually consumed , is a shame to me , and till this enchanter declared war against me , i have lived without reproach . \"",
        ""
    ],
    [
        0.3489888211091359,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '35'}",
        "[{'id': 'unknown_1a', 'response': \"I don't know\"}, {'id': 'unknown_1b', 'response': 'Not contentious'}, {'id': 'unknown_1d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1e', 'response': 'Illegible OCR'}, {'id': 'unknown_1f', 'response': 'Not contentious'}, {'id': 'unknown_1g', 'response': 'Illegible OCR'}]",
        "𝙈𝙖𝙧𝙧𝙤𝙣"
    ],
    [
        0.34896549582481384,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '939'}",
        "It is improbable that Bernhard is green. We believe that Lily is yellow. It is improbable that Greg is a frog. It is probably not the case that if either 'Greg is a frog' or 'Bernhard is green' but not both then Sumit is thirsty. There is a better than even chance that if either 'Bernhard is green' or 'Lily is yellow' but not both then Mary went to the hallway. There is almost no chance that if 'Bernhard is green and Greg is a frog' then Julius is gray.",
        "invalid"
    ],
    [
        0.3489577919244766,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '823'}",
        "Write an excellent summary of the given text.\n\nTitle: art or programming?\n\nText: I'd like to apologize in advance for what I feel to be an ambiguous title and the lengthy post (I hope that there isn't too much back story but I feel that it's relevant). To just get down to the point, I am 24 years old and I am at a cross road in my life where I have need to do something that is very meaningful to me but feel that I am too late or lack the passion to be successful. (In regards to this dilemma I also have trouble defining what success means to me.)\n\nBackground:\n\nWhen I was little I loved to draw but it isn't something that I have done in I couldn't tell you how long. I was never really encouraged by anyone to continue doing it and things sort of fizzled with it. I don't know if that is because of a lack of love for it or no one supporting me. The reason that I am hesitant to start again is because I feel that I am so late into the game and being very competitive I feel that I this is both a driving force to start now a to just never try. \n\nProgramming on the other hand is something that I always felt interesting. I feel that I am logical to a fault and the type of thinking that is accompanied by programming is something that comes natural to me. I have taught myself the basics of several languages but that push that you need to give yourself to just man up and work through the hard parts is something that I couldn't bring myself to do. This is also a much more lucrative option.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3489534060160319,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '220'}",
        "[{'follow_up_question': 'Are you exporting a pure bred horse?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is your product caviar or a caviar substitute?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Is your product truffles or goods containing truffles?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.3489430199066798,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '99'}",
        "It is unlikely that 'Julius is gray' or 'Bernhard is a lion' or both.",
        "invalid"
    ],
    [
        0.3489006261030833,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '772'}",
        "It is unlikely that Bernhard is yellow. Chances are slight that Gertrude is a mouse. It is almost certain that Greg is a swan. Chances are slight that if 'Greg is a swan' or 'Gertrude is a mouse' or both then Winona is a sheep. It is certain that if 'Gertrude is a mouse' or 'Greg is a swan' or both then John moved to the garden. We believe that if either 'Greg is a swan' or 'Gertrude is a mouse' but not both then Lily is a frog.",
        "invalid"
    ],
    [
        0.3488900164763133,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '399'}",
        "The summary is somewhat inaccurate; the poster did not explicitly state that he is asking for advice in the post.",
        "Accuracy"
    ],
    [
        0.3488316312432289,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '164'}",
        "کیفیت نسبت به قبل واقعا اومده پایین و از پالپ فقط یه کلمه روی بطری مونده چند ساله اورنجینا میخرم ولی طی این یکی دو سال اخیر به شدت کیفیت رو به افول و فقط طعم کمی اسانس پرتقال و آب گازدار زیاد میده",
        "نوشابه"
    ],
    [
        0.3488233834505081,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '333'}",
        "There is little chance that Antoine is bored. It is improbable that Julius is white. There is almost no chance that Lily is a rhino.",
        "invalid"
    ],
    [
        0.3488115320603053,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '166'}",
        "There is almost no chance that Jeff moved to the office. It is improbable that Julius is a lion. There is a very good chance that John left the apple. There is almost no chance that if 'Jeff moved to the office' or 'Julius is a lion' or both then Greg is gray. It is highly unlikely that if either 'Jeff moved to the office' or 'Julius is a lion' but not both then Lily is white. There is a better than even chance that if 'Jeff moved to the office and Julius is a lion' then Yann is hungry.",
        "invalid"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '28'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '182'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '259'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '315'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '581'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '637'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '693'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '770'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.3488036592801412,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '826'}",
        "نظر شما در مورد عطر، بو، و طعم این آدامس و خوشبو کننده‌ی دهان چیست؟",
        "طعم"
    ],
    [
        0.348773255944252,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '951'}",
        "It is certain that Greg is yellow. Chances are slight that Jeff moved to the office. It is almost certain that Lily is a rhino. There is little chance that if either 'Lily is a rhino' or 'Jeff moved to the office' but not both then Julius is gray. There is a better than even chance that if either 'Jeff moved to the office' or 'Greg is yellow' but not both then Mary went to the bedroom. We believe that if 'Jeff moved to the office' or 'Greg is yellow' or both then John got the milk.",
        "invalid"
    ],
    [
        0.34873813887437183,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '662'}",
        "The guy never mentioned that they have been seeing each other for a few months though the summary included that.",
        "Accuracy"
    ],
    [
        0.34873032569885254,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '574'}",
        "نظر شما در مورد عطر، بو، و طعم این گوشت گاو و گوساله چیست؟",
        "طعم"
    ],
    [
        0.3487265855073929,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '364'}",
        "It is certain that Greg is a swan. There is a better than even chance that Yann is tired. There is a better than even chance that Daniel dropped the apple. It is probably not the case that if 'Daniel dropped the apple' or 'Greg is a swan' or both then Julius is gray. It is improbable that if 'Yann is tired' or 'Daniel dropped the apple' or both then Brian is green. It is likely that if 'Daniel dropped the apple and Greg is a swan' then Gertrude is a cat.",
        "invalid"
    ],
    [
        0.3487130751212438,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '238'}",
        "Chances are slight that Daniel left the football. It is probably the case that Mary moved to the office. We believe that Brian is yellow. It is almost certain that if either 'Daniel left the football' or 'Mary moved to the office' but not both then Julius is white. It is impossible that if 'Mary moved to the office' or 'Brian is yellow' or both then Jessica is a cat. There is a better than even chance that if either 'Brian is yellow' or 'Mary moved to the office' but not both then Bernhard is green.",
        "invalid"
    ],
    [
        0.3487034390370051,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '598'}",
        "This story opens readers’ eyes to a debate that flared up before attendees of a recent meeting of the American Society of Clinical Oncology – but a debate that most of us wouldn’t know about. The sidebar story, “Some Stealth Marketing by a ‘Hot Chemo’ Company,” was an important addition. This is an important piece of enterprise journalism. The “chemo bath” approach has been around for many years, but the use of heated solutions is relatively new and has limited data to support it use. Despite the limited evidence, the approach is gaining in acceptance. Anyone who’s heard about is smarter after reading this piece.",
        "true"
    ],
    [
        0.34869367629289627,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '434'}",
        "خیلی عالی بودند.کیم بال همه چیش خوبه.هیچ کدوم از گردن ها خونمرده گی یا تیرگی نداشت.ممنون",
        "طعم"
    ],
    [
        0.3486814747254054,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '157'}",
        "It is impossible that either 'Mary went to the kitchen' or 'Lily is a rhino' but not both.",
        "invalid"
    ],
    [
        0.3486669063568115,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '295'}",
        "Write an excellent summary of the given text.\n\nTitle: Me [21 M] with my best friend [21 M] of five years, what is the appropriate amount of friends ?\n\nText: So we've been friends since high school, he was sort of the shy quite type of person. I had just moved to this school and was looking to make new friends. one day we strike conversation etc etc become friends, start hanging out with my other friends.\n\nthrough those years I tried to push him out of shell. after a while he does. and he starts making a lot new friends. we I we start hanging out less, he is busy socializing with a lot of people. I figure that I back off a bit. after a while he keeps asking me why we don't hangout. \n\nI tell him that he is always busy, he asks me to hang with him with his friends ( which I did a couple of times ) , have them as friends and we could hangout more. I tell him that I prefer small circle with friends that I can keep up with ( 4 / 5 ). I mentioned an important event in which I told him and he forgot.  He says I'm overexaggerate.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3486566146214803,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '587'}",
        "Amy Nordness, director of speech-language pathology at the Munroe-Meyer Institute for Genetics and Rehabilitation at the University of Nebraska Medical Center, and Shannon Todd, a care services specialist with The ALS Association Mid-America Chapter, will lead the discussion. The title: “The Eyes Have It — How the Eyes Keep People with ALS Connected to the World.” The disease claimed famed New York Yankee Lou Gehrig. Its medical name: amyotrophic lateral sclerosis. It affects nerve cells in the brain and the spinal cord and is characterized by progressive muscle weakness. The event is scheduled to begin at 7 p.m. Aug. 14 at the Slowdown. Science Cafés involve face-to-face conversations with scientists about current science topics.",
        "true"
    ],
    [
        0.34863776961962384,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '968'}",
        "It is unlikely that either 'Brian is yellow' or 'Jessica is a wolf' but not both.",
        "invalid"
    ],
    [
        0.34859005113442737,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '812'}",
        "It is almost certain that Sandra left the football. There is almost no chance that Greg is a swan. It is probably not the case that John went to the kitchen. It is probable that if 'John went to the kitchen and Greg is a swan' then Bernhard is white. We doubt that if 'Sandra left the football and John went to the kitchen' then Julius is a lion. There is a very good chance that if 'Greg is a swan' or 'John went to the kitchen' or both then Lily is a frog.",
        "invalid"
    ],
    [
        0.34858939051628113,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '34'}",
        "It is certain that either 'Winona is a wolf' or 'Greg is white' but not both.",
        "invalid"
    ],
    [
        0.34857483208179474,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '872'}",
        "There is a very good chance that Brian is yellow. It is impossible that Bernhard is yellow. There is a very good chance that John dropped the apple. There is a better than even chance that if 'Bernhard is yellow' or 'Brian is yellow' or both then Julius is a rhino. There is a better than even chance that if 'Brian is yellow and Bernhard is yellow' then Lily is a frog. There is almost no chance that if 'Bernhard is yellow' or 'John dropped the apple' or both then Mary is in the hallway.",
        "invalid"
    ],
    [
        0.34857120116551715,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '296'}",
        "fneemt.Denkelijk óók wel niet!De Heer Lewis heet een lichtkleurige 𝙢𝙪𝙡𝙖𝙩 — waarschijnlijk ons koffiemerk „bruinachtig blank\" — die aan de H",
        "𝙢𝙪𝙡𝙖𝙩"
    ],
    [
        0.34856776396433514,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '816'}",
        "[{'follow_up_question': 'Are you a family farmer or fisherman?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Does it involve a municipality?', 'follow_up_answer': 'Yes'}]",
        "False"
    ],
    [
        0.34856776396433514,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '856'}",
        "[{'follow_up_question': 'Are you a family farmer or fisherman?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Does it involve a municipality?', 'follow_up_answer': 'Yes'}]",
        "False"
    ],
    [
        0.3485369185606639,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '502'}",
        "Write an excellent summary of the given text.\n\nTitle: My brother[40/m] and his wife[33/f] just had a baby[0/m], but he is planning to divorce her. Should I[36/f] get involved?\n\nText: My brother(40/m) is planning to divorce his wife(33/f) of 8 years. They are both at fault. They thought that a baby would fix their relationship, but it only made their problems worse. \n\nI have been happily married for 10 years, we have 2 kids. My parents have been married for 40 years, and I have learned a lot about relationships from them.  While it does not make me an expert in relationships, I feel like I have something to say. My biggest fear is that if they get a divorce, their son will be the one who suffers the most from this. \n\nSo I feel that I should go to visit them (they live in a different city, and we usually see each other once a year, so my visit would be highly unusual), and try to talk sense into both of them before it is too late.\n\nShould I go? I feel that their relationship is my business because he is my brother, and I love him and I want him to be happy, and because I love my nephew ( I have not seen him yet, but he is a part of my family). Would you ever listen to your younger sister or your sister in law?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3485356519619624,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '182'}",
        "Chances are about even that Julius is a lion. It is probably not the case that John picked up the apple. There is a better than even chance that Brian is yellow.",
        "invalid"
    ],
    [
        0.3485318919022878,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '136'}",
        "Immerhin hat der ehemalige Google-Chef Eric Schmidt ja einmal gesagt: „Wenn es etwas gibt, von dem Sie nicht wollen, dass es irgendjemand erfährt, sollten Sie es vielleicht ohnehin nicht tun.“.",
        "counterfactual"
    ],
    [
        0.3485318919022878,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '136'}",
        "Immerhin hat der ehemalige Google-Chef Eric Schmidt ja einmal gesagt: „Wenn es etwas gibt, von dem Sie nicht wollen, dass es irgendjemand erfährt, sollten Sie es vielleicht ohnehin nicht tun.“.",
        "counterfactual"
    ],
    [
        0.34853143990039825,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '988'}",
        "It is almost certain that Julius is a lion. It is highly likely that Greg is white. It is highly likely that Brian is green.",
        "invalid"
    ],
    [
        0.34852953751881915,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '18'}",
        "['Genetically identical cells sharing an environment can display markedly different phenotypes.', 'It is often unclear how much of this variation derives from chance, external signals, or attempts by individual cells to exert autonomous phenotypic programs.', 'By observing thousands of cells for hundreds of consecutive generations under constant conditions, we dissect the stochastic decision between a solitary, motile state and a chained, sessile state in Bacillus subtilis.', \"We show that the motile state is 'memoryless', exhibiting no autonomous control over the time spent in the state.\", 'In contrast, the time spent as connected chains of cells is tightly controlled, enforcing coordination among related cells in the multicellular state.', 'We show that the three-protein regulatory circuit governing the decision is modular, as initiation and maintenance of chaining are genetically separable functions.', 'As stimulation of the same initiating pathway triggers biofilm formation, we argue that autonomous timing allows a trial commitment to multicellularity that external signals could extend.']",
        "False"
    ],
    [
        0.34850846230983734,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '178'}",
        "['Age-related macular degeneration (AMD), a progressive condition that is untreatable in up to 90% of patients, is a leading cause of blindness in the elderly worldwide.', 'The two forms of AMD, wet and dry, are classified based on the presence or absence of blood vessels that have disruptively invaded the retina, respectively.', 'A detailed understanding of the molecular mechanisms underlying wet AMD has led to several robust FDA-approved therapies.', 'In contrast, there are no approved treatments for dry AMD.', 'In this review, we provide insight into the critical effector pathways mediating each form of the disease.', 'A recurring theme that spans most aspects of AMD pathogenesis is defective immune modulation in the classically immune-privileged ocular haven.', 'Interestingly, the latest advances in AMD research also highlight common molecular disease pathways with other neurodegenerative disorders.', 'Finally, the therapeutic potential of intervening at known mechanistic steps of AMD pathogenesis is discussed.']",
        "False"
    ],
    [
        0.3485080798467,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '32'}",
        "[{'follow_up_question': 'Do you have a recognition care to purchase immature plants, clones, or seeds from a licensed producer?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.3485019604365031,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '298'}",
        "Write an excellent summary of the given text.\n\nTitle: I [21m] am in a long distance relationship of 2.5 years with [23f] and am a Uni Senior. Had a really good night at a bar with another senior [22f].... confusing situation\n\nText: I have a long distance girlfriend of two and a half years. We have a pretty healthy relationship. I am actually her first boyfriend so she is just a little slow catching up in certain things.\n\nThe other night I went out to a club with some friends and ended up walking home with a girl I met. We had a lot in common and a bunch of mutual friends. I made it clear that I had a girlfriend, but I was interested in hanging out and talking because she was an interesting person and easy to talk to. Also it is my Senior year at Uni and I just wanted to cram in some more memories. We snuggled and talked for a couple hours and then she took me back to my house. Weird thing happened as I was getting out of the car. We kissed goodnight. It just felt like the natural thing to after having such a pleasant night. \n\nI have not made contact with that girl since except for becoming facebook friends. I don't feel like I had any romantic feelings behind the kiss and have talked to my girlfriend and we've chalked it up to drunken college behavior of no consequence.\n\nMy issue is I do want to hang with this other girl a couple more times before I graduate in May. I do not know if this would cause issues or what, but I genuinely enjoyed talking to this girl and she seems like somebody I could have been good friends with had I met her earlier in my Uni career.\n\nWhat do?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34849995871384937,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '816'}",
        "The highest paid player in Major League Baseball ( MLB ) from the 2013 season is New York Yankees ' third baseman Alex Rodriguez with an annual salary of $29,000,000 , $4 million higher than the second - highest paid player , Cliff Lee . MLB does not have a hard salary cap , instead employing a luxury tax which applies to teams whose total payroll exceeds certain set thresholds for a given season . Free agency did not exist in MLB prior to the end of the reserve clause in the 1970s , allowing owners before that time to wholly dictate the terms of player negotiations and resulting in significantly lower salaries . Babe Ruth , widely regarded as one of the greatest baseball players ever , earned an estimated $910,696 ( $14,654,832 inflation - adjusted from 1931 dollars ) over his entire playing career . When asked whether he thought he deserved to earn $80,000 a year ( $1,171,952 inflation - adjusted ) , while the president , Herbert Hoover , had a $75,000 salary , Ruth famously remarked , `` What the hell has Hoover got to do with it ? Besides , I had a better year than he did . ''",
        ""
    ],
    [
        0.34849074482917786,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '569'}",
        "Write an excellent summary of the given text.\n\nTitle: My [30 F] sister-in-law [33 F] is having brain surgery in a few days. Advice on how can I be helpful and caring?\n\nText: My SIL got the news about a week and a half ago that the cause of her headaches is a brain tumor. They are operating this week - hopefully to fully remove the tumor - and we won't know if it is cancerous until they can do a biopsy.\n\nThey live near both my parents and hers so they have a lot of hands on deck to help with things. I expect to be driving the two hours home on weekends to give my mom a hand with childcare and errands since it is harvest season. They have three young children - 5, 2, and 6 months. Emotional support isn't my strong suit but I will run all the errands and change all the diapers! Besides, we're not very close in the first place.\n\nWhat are some things I should or should not do in the upcoming weeks? I want to be helpful, not a burden. I'm not doing this to satisfy a desire for acknowledgment or appreciation.\n \nThank you in advance :)\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3484858026107152,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '420'}",
        "\"The cost of health care is a huge issue for everyone. If you have health insurance, the chances are excellent that you've seen your costs, along with co-payments and deductibles, go up significantly. If you don't have health insurance, the bill you get from your doctor or hospital is strikingly higher than what people with health insurance are charged. That's because insurance companies negotiate deep discounts that uninsured people never see. And because people who don't have insurance are seven times more likely to skip the care they need, according to the Centers for Disease Control and Prevention, that typically makes your care more expensive when you do seek it. If, on top of everything else, you can't pay for that care and a hospital provides it for free, as a hospital is obligated to do, those costs are passed on to everyone else. So it caught our attention when Marie Ghazal, chief executive officer of the Rhode Island Free Clinic, the Providence nonprofit organization that treats the uninsured, began an opinion column in The Providence Journal by asserting that \"\"Rhode Island has the highest percentage of uninsured adults of any state in New England.\"\" She stated that between 13.9 percent and 21.4 percent of residents are not insured, which translates to 139,000 to 214,000 Rhode Islanders. We wondered if our ranking was really that poor, and why the range was so large. When we contacted Ghazal, she said she got the information from a story in the Providence Business News. The article gives no specific numbers for Rhode Island or most other states. It was based on a map developed by the CDC that breaks the states into three categories: those having the highest proportion of people with health insurance, those having the lowest and those in between. Rhode Island -- like New York, New Jersey, Ohio, Virginia and most of the states in the Midwest -- is in the in-between category. Ghazal said our rate of uninsured adults was 13.9 percent to 21.4 percent because, as it turns out, that's how the CDC defined the in-between group. We asked if she had specific numbers. She said she didn't. So we went searching. When we contacted CDC, they directed us to state-by-state numbers, as collected by Behavioral Risk Factor Surveillance System, a telephone survey that counts how many people are without health insurance at the time of the call. According to the BRFSS statistics, which served as the basis for the map cited by Ghazal, the 2009 telephone survey of 4,318 Rhode Islands found that the percentage of uninsured adults in Rhode Island was 14.2 percent, below the national average of 16.9 percent. Thirty-two states had a lower rate of health insurance coverage than Rhode Island. The worst rate was in Texas, where 29.1 percent of the population was not covered. In 15 states, at least 20 percent of the adult population younger than 65 was without health insurance. But we found something else while digging into the numbers. The margin of error in the survey was plus or minus 1.9 percentage points. If you ignore the margin of error, it is true that Rhode Island had the highest rate of uninsured adults in New England. Maine, where 13.7 percent were uninsured, was closest to Rhode Island. But that's a difference of only 0.5 percentage points. Massachusetts, in contrast, had the lowest rate of uninsured -- 6.2 percent -- because the Bay State has mandatory health insurance. However, if you consider the margin of error in the poll, we could rank ahead of New Hampshire (where 13.1 were uninsured) and Maine. For additional context, we looked at the percentages going back to 1995 (excluding 2001 and 2002, two years when the survey results are not on the National Center for Chronic Disease Prevention & Health Promotion website). It turns out that in 2004, the level of uninsured in Rhode Island was a bit higher -- 14.4 percent; 15 years ago it was at about 13 percent. The rate did dip to 11.7 percent in the 1998 survey but, in general, the numbers have stayed consistent. By any measure, that's still a lot of people walking around without health insurance. Ultimately, if you ignore the margin of error, Ghazal is correct about our ranking compared with other New England states. But if you take that into account, its possible that her statement could be inaccurate. More importantly, she's making a selective comparison. When you compare us with the rest of the country, we're better than average. Because of those omissions.\"",
        "true"
    ],
    [
        0.3484450926383336,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '529'}",
        "It is probably not the case that 'John dropped the milk' or 'Julius is a frog' or both.",
        "invalid"
    ],
    [
        0.34843936562538147,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '32'}",
        "[{'id': 'unknown_1a', 'response': 'Niet omstreden'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Onleesbare OCR'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝘼𝙯𝙞𝙖𝙩𝙞𝙨𝙘𝙝"
    ],
    [
        0.3484392315149307,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '283'}",
        "It is unlikely that either 'Brian is gray' or 'Mary discarded the milk' but not both.",
        "invalid"
    ],
    [
        0.34843044479688007,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '128'}",
        "It is likely that Lily is white. It is certain that Gertrude is a sheep. It is highly likely that Mary went to the garden. There is a better than even chance that if either 'Mary went to the garden' or 'Gertrude is a sheep' but not both then John picked up the milk. It is highly likely that if 'Mary went to the garden and Gertrude is a sheep' then Sandra got the football. It is likely that if 'Lily is white' or 'Gertrude is a sheep' or both then Brian is yellow.",
        "invalid"
    ],
    [
        0.3484196936090787,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '322'}",
        "نظر شما در مورد عطر، بو، و طعم این حلوا شکری، ارده و کنجد چیست؟",
        "طعم"
    ],
    [
        0.3484196936090787,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '364'}",
        "نظر شما در مورد عطر، بو، و طعم این حلوا شکری، ارده و کنجد چیست؟",
        "طعم"
    ],
    [
        0.3484196936090787,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '553'}",
        "نظر شما در مورد عطر، بو، و طعم این حلوا شکری، ارده و کنجد چیست؟",
        "طعم"
    ],
    [
        0.3484196936090787,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '714'}",
        "نظر شما در مورد عطر، بو، و طعم این حلوا شکری، ارده و کنجد چیست؟",
        "طعم"
    ],
    [
        0.3484196936090787,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '749'}",
        "نظر شما در مورد عطر، بو، و طعم این حلوا شکری، ارده و کنجد چیست؟",
        "طعم"
    ],
    [
        0.3484114358822505,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '362'}",
        "Chances are slight that Mary went to the garden. It is likely that Gertrude is a cat. It is almost certain that Lily is a swan. There is little chance that if either 'Mary went to the garden' or 'Lily is a swan' but not both then Brian is green. It is highly unlikely that if 'Lily is a swan and Gertrude is a cat' then Julius is a lion. There is almost no chance that if either 'Gertrude is a cat' or 'Mary went to the garden' but not both then John took the football.",
        "invalid"
    ],
    [
        0.34838544329007465,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '836'}",
        "It is unlikely that either 'John went to the hallway' or 'Lily is a rhino' but not both.",
        "invalid"
    ],
    [
        0.3483835955460866,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '699'}",
        "It is certain that Mary went to the office. There is little chance that Bernhard is yellow. It is probably not the case that Daniel got the football. It is probably not the case that if either 'Daniel got the football' or 'Bernhard is yellow' but not both then Gertrude is a wolf. There is a better than even chance that if either 'Daniel got the football' or 'Mary went to the office' but not both then Brian is a frog. It is highly unlikely that if 'Bernhard is yellow and Daniel got the football' then Lily is a rhino.",
        "invalid"
    ],
    [
        0.34831487635771435,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '328'}",
        "It is probably not the case that 'John took the football' or 'Julius is a rhino' or both.",
        "invalid"
    ],
    [
        0.3482587933540344,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '330'}",
        "(1) Однажды Тэсс случайно подслушивает разговор своих товарок — Мэрион, Рэтти и Изз. (2) Девушки признаются друг Другу в любви к молодому мистеру Клэру, и жалуются, что он ни на кого из них даже смотреть не хочет, ибо глаз не спускает с Тэсс Дарбейфилд. (3) После этого Тэсс начинает мучиться вопросом — имеет ли она право на сердце Энджела Клэра? (4) Однако жизнь все решает сама: Клэр влюбляется в неё, а она — в него. (5) Энджел специально едет домой сообщить родителям о своём решении жениться на простой крестьянке, чтобы обрести в её лице не только верную жену, но и надёжную помощницу на избранном им жизненном поприще. (6) Отец молодого человека, суровый англиканский священник, не одобряет ни планов, ни выбора младшего сына, из которого он, как и из его старших братьев, хотел сделать священника. (7) Однако он не собирается и противиться ему, и Клэр возвращается на ферму с твёрдым намерением жениться на Тэсс. (8) Девушка долгое время не принимает его предложения, но потом соглашается. (9) При этом она все время порывается рассказать ему о своём прошлом, но влюблённый не хочет её слушать. (10) Мать же Тэсс, сообщая в письме о согласии семьи на её брак, замечает, что никто из женщин никогда не рассказывает женихам о бедах вроде той, что приключилась с ней.",
        "False"
    ],
    [
        0.3482552419106166,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '514'}",
        "It is improbable that Greg is a frog. It is likely that Sandra dropped the milk. There is a very good chance that Brian is gray. We doubt that if 'Greg is a frog and Sandra dropped the milk' then Gertrude is a sheep. There is almost no chance that if either 'Sandra dropped the milk' or 'Brian is gray' but not both then Mary went to the garden. There is almost no chance that if either 'Sandra dropped the milk' or 'Brian is gray' but not both then John left the football.",
        "invalid"
    ],
    [
        0.3482532600561778,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '178'}",
        "Costs are not discussed. However, the “treatment” at issue is not a drug or medical technology with clearly defined costs. Rather, the DASH diet focuses on an individual’s food choices. While there are cost constraints associated with any diet, and many people do not have easy access to the fruit and vegetables that are at the heart of the DASH diet, it would be challenging to address those issues in any meaningful way in the context of a news release like this one. That being the case, we’ll rate this as “not applicable.” The release states that “The odds of becoming depressed over time was 11 percent lower among the top group of DASH adherers versus the lowest group.”  Here the release is relying on relative risk reduction figures which are far less meaningful to patients than numbers that explain the absolute risk reduction. We also are left wondering how closely the “top group of DASH adherers” followed the DASH diet? To what extent did that differ from the “lowest group”? The release does not address potential harms. However, there are few (if any) harms associated with adopting a well-balanced diet that is high in fruits and vegetables. While it is always wise to consult a physician before making significant lifestyle changes, we feel that this is not necessarily something that a news release needs to state explicitly. With that in mind, we give this a satisfactory rating. One of the biggest problems with the release concerns lack of evidence concerning the DASH diet’s potential impact on depression. Does depression lead to a change in dietary patterns? Fatigue and lack of motivation — both hallmarks of depression — may lead people to cook less frequently. Research also suggests that sugary foods lower cortisol levels more than other foods and consequently people with depression may choose them preferentially over a DASH style diet since they provide them with some therapeutic relief. And further, these are older adults (average age of 81). If they were to develop conditions that affected their energy, mobility, chronic pain, etc. this would also influence their dietary choices and impact these results. The release includes a caution at the end stating the study doesn’t prove cause and effect. That’s good, but we think the causal claim in the headline — “may also reduce depression” — will overshadow that message. No disease mongering here. The release notes that the study was supported by the National Institute on Aging, which is good. However, conflicts of interest are not explicitly addressed. Given that only one of the researchers involved with the study was named, it is impossible for readers to determine if there are any conflicts of interest. For example, one can buy any number of DASH diet cookbooks online — are any study co-authors associated with those? Given the paucity of information in the release, it’s impossible to tell. (As noted above, we obtained a copy of the study abstract and didn’t see any obvious conflicts of interest — but the information isn’t readily available in the release.) One alternative raised in the release is the Mediterranean diet. But the release doesn’t describe the Mediterranean diet or quantify how adherence to that diet was associated with a decreased risk of depression symptoms. Other factors that can contribute to reduced risk of depression aren’t discussed. The release refers repeatedly to the DASH diet. However, while the DASH diet has been around for years, many readers will likely never have heard of it. The release appears to assume that the DASH diet is common knowledge. While the DASH diet isn’t a secret, it’s not something you can assume readers are familiar with either. This could have been addressed by simply noting that the DASH diet has, well, been around for years. It could even have referred readers to a description of the plan on an NIH website. This is far from the first study to assess relationships between diet and depression. For example, a 2013 paper in Annals of Neurology that looked at (among other things) nine different studies involving the Mediterranean diet and depression. How does this forthcoming conference paper fit into that expansive body of work? It’s not clear. Based on the release, readers may think this is the first study to consider a link between diet and depression. To be clear, this research may well address novel research questions, but the release doesn’t make clear what those are — particularly in the context of previous work in the field. This is a tricky one. The release does one thing that we don’t like — and it does that thing more than once. The headline says “Diet…may also reduce risk of depression” (emphasis added). The first sentence says “People…may have lower rates of depression…” (emphasis added). In either instance, the release could just as easily have said “may not.” It begs the question of why the news release was issued at this point. However, we want to applaud two things the release does do. First, the release explicitly states that “the study does not prove that the DASH diet leads to a reduced risk of depression; it only shows an association.” That is such an important point to make, and we think that is great. Second, the release also quotes one of the researchers as saying “Future studies are now needed to confirm these results and to determine the best nutritional components of the DASH diet to prevent depression later in life and to best help people keep their brains healthy.” Again, this is an important point and we are very glad to see it addressed. All in all, we give it a satisfactory rating here.",
        "false"
    ],
    [
        0.34822311500708264,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '955'}",
        "It is improbable that 'Mary got the apple' or 'Julius is a lion' or both.",
        "invalid"
    ],
    [
        0.3482168863217036,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '704'}",
        "It is unlikely that Greg is gray. It is likely that Yann is hungry. There is a very good chance that Antoine is bored. We doubt that if either 'Greg is gray' or 'Yann is hungry' but not both then John went to the garden. It is almost certain that if either 'Greg is gray' or 'Antoine is bored' but not both then Bernhard is a lion. We believe that if either 'Greg is gray' or 'Yann is hungry' but not both then Mary got the football.",
        "invalid"
    ],
    [
        0.34820040067036945,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '597'}",
        "Write an excellent summary of the given text.\n\nTitle: I think I'm in a toxic relationship\n\nText: I will preface this saying there have been other issues and fights but today was my tipping point.\n\nLately I've been working real hard trying to provide for my wife and I; got a new job with better pay, paid off all credit card debts, etc. Talking to my wife about the future and moving soon and starting a family has got us really excited.\n\nMy wife has MS and while she isn't on any medication she has found relief in marijuana. While I'm ok with the usage of marijuana recreationally or medically I don't think it should used as a crutch. Currently she smokes 24/7 and does absolutely nothing around the house. I work 9/5 come home have to clean, do the laundry and cook dinner every single night. I'm not saying thats her job or anything and I know she's sick but she should have to hold her share of this relationship. It feels like I'm living with a roommate.\n\nWhile the notion of starting a family has me excited at first, I mention to her that if we do decide to go through with having a family she would have to stop smoking weed. Initially she agrees and stops. Now after a few days she has become so unbearable to be around to the point I don't want to go home anymore. She's constantly yelling at me and the dogs, throwing things and threatining to hurt herself all because she's in pain.\n\nI've offered to take her to the hospital, or even the regular doctor to get some actual medical help but she refuses.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3482001970211665,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '605'}",
        "It is almost certain that Bernhard is a swan. It is impossible that Brian is white. It is almost certain that John picked up the milk.",
        "invalid"
    ],
    [
        0.348188857237498,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '78'}",
        " ; ¡de man met de burnoes doet zijn iutrede.Dr.Pierre Grenier, de 𝙈𝙪𝙯𝙚𝙡𝙢𝙖𝙣, is te Parijs gearriveerd.Aan de gare ile Lyon trok hij met zijn ",
        "𝙈𝙪𝙯𝙚𝙡𝙢𝙖𝙣"
    ],
    [
        0.3481847395499547,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '202'}",
        "It is improbable that 'Greg is a frog' or 'Bernhard is a swan' or both.",
        "invalid"
    ],
    [
        0.34816063940525055,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '941'}",
        "امتیاز:۶.۵  یک ایده مرکزی خوب که هرز می‌رود. نقش اول فیلم مشخص نیست، فضای فیلم نیز. نه قهرمانانه است، نه امیدوارانه و نه تراژدیک.  از نقش مثبت خانم ایزدیار هم داریم خسته می‌شویم. این سومین فیلم ایشان بود با همین تم.",
        "صدا"
    ],
    [
        0.34815255800882977,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '995'}",
        "(1) Священник Йорик, друг семьи, давно служивший в этой местности, посещает отца Шенди, который жалуется, что Тристраму трудно даётся исполнение религиозных обрядов. (2) Они обсуждают вопрос об основах отношений между отцом и сыном, по которым отец приобретает право и власть над ним, и проблему дальнейшего воспитания Тристрама. (3) Дядя Тоби рекомендует в гувернёры молодого Лефевра и рассказывает его историю. (4) Однажды вечером дядя Тоби сидел за ужином, как вдруг в комнату вошёл хозяин деревенской гостиницы. (5) Он попросил стакан-другой вина для одного бедного джентльмена, лейтенанта Лефевра, который занемог несколько дней назад. (6) С Лефевром был сын лет одиннадцати-двенадцати. (7) Дядя Тоби решил навестить джентльмена и узнал, что тот служил с ним в одном полку. (8) Когда Лефевр умер, дядя Тоби похоронил его с воинскими почестями и взял опеку над мальчиком. (9) Он отдал его в общественную школу, а затем, когда молодой Аефевр попросил позволения попытать счастья в войне с турками, вручил ему шпагу его отца и расстался с ним как с собственным сыном. (10) Но молодого человека стали преследовать неудачи, он потерял и здоровье, и службу — все, кроме шпаги, и вернулся к дяде Тоби. (11) Это случилось как раз тогда, когда Тристраму искали наставника.",
        "False"
    ],
    [
        0.3481451819340388,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '646'}",
        "There is a better than even chance that Julius is a swan. We believe that Gertrude is a wolf. We doubt that Emily is a mouse. It is likely that if 'Gertrude is a wolf' or 'Julius is a swan' or both then John grabbed the apple. It is unlikely that if 'Emily is a mouse' or 'Gertrude is a wolf' or both then Greg is gray. Chances are slight that if 'Emily is a mouse' or 'Julius is a swan' or both then Bernhard is yellow.",
        "invalid"
    ],
    [
        0.3481360971927643,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '320'}",
        "Write an excellent summary of the given text.\n\nTitle: I [23M] don't know if i should bring this up with [22F]\n\nText: Long story short, been together with SO for over 6 months now, relationship has been honest, trustworthy and mature. I have very strong feelings for this woman which is why I'm afraid of bringing up the subject about oral sex.\n\nShe's mentioned not liking giving oral, i understand that, i respect her decision and would never think of forcing her to do anything she wouldn't want to, but the thing is she's told mentioned to me when we first got together that she's performed oral in previous relationships which honestly makes me feel like maybe its not just her but maybe I'm the problem too.\n\nIve been holding this in for awhile and I'm afraid of bringing it up to her as to not push her in any way, I'm perfectly fine with never receiving oral but that thought of me being the problem is still in the back of my head bothering me.\n\nWould it be wrong to bring it up or should i just try to get past it and let if happen if it ever does.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34812337160110474,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'rob_train_sup_23_test_all_23', 'row_id': '714'}",
        "[Lori] was having a hard time with her math homework, so she went to her brother [Wayne] for help. [Wayne] did n't seem to know either, so [Lori] went to her father [William], as she was sure he could help. [Lou] and her sister [Lori] went out to eat with [Lou]'s father, [William]. [Wayne] needed his brother, [Kevin], to help with a problem",
        "son"
    ],
    [
        0.3481109340985616,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '5'}",
        "[{'id': 'unknown_1a', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Niet omstreden'}, {'id': 'unknown_1e', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙆𝙖𝙪𝙠𝙖𝙨𝙞𝙨𝙘𝙝"
    ],
    [
        0.3480883489052455,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '688'}",
        "It is unlikely that Julius is gray. It is probable that Greg is a swan. Chances are slight that Mary moved to the garden. It is likely that if either 'Julius is gray' or 'Mary moved to the garden' but not both then Gertrude is a mouse. There is almost no chance that if 'Mary moved to the garden and Greg is a swan' then John took the football. It is improbable that if 'Mary moved to the garden and Julius is gray' then Brian is yellow.",
        "invalid"
    ],
    [
        0.34808680911858875,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '287'}",
        "It is certain that Fred went to the garden. It is impossible that Emily is a wolf. It is probably not the case that John discarded the apple. We doubt that if 'Fred went to the garden and Emily is a wolf' then Brian is gray. It is probably the case that if either 'Emily is a wolf' or 'Fred went to the garden' but not both then Jessica is a mouse. It is unlikely that if either 'Fred went to the garden' or 'John discarded the apple' but not both then Bernhard is a frog.",
        "invalid"
    ],
    [
        0.34807227551937103,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '701'}",
        "It is impossible that 'Bernhard is white and Greg is a lion'.",
        "invalid"
    ],
    [
        0.34807104369004566,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '823'}",
        "We believe that Mary dropped the apple. There is little chance that John took the football. It is certain that Winona is a mouse. It is probably the case that if either 'Winona is a mouse' or 'Mary dropped the apple' but not both then Greg is a rhino. It is likely that if either 'Winona is a mouse' or 'Mary dropped the apple' but not both then Bernhard is a lion. It is probable that if 'John took the football' or 'Winona is a mouse' or both then Julius is yellow.",
        "invalid"
    ],
    [
        0.3480649342139562,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '671'}",
        "“Why should we refuse the charms of the soil to those at the end of their lives? Nothing justifies such an prohibition,” the Clermont-Ferrand University Hospital Center said in statement. The center’s head, Dr. Virginie Guastella, said terminally ill patients had the right to “enjoy themselves”. The bar will be the first in France to offer such a facility for patients and their families. Staff will be specially trained before it opens in the hospital’s palliative care center in September. “Medically supervised tastings will help brighten what is often a difficult daily life,” the hospital said. Although some researchers have long held that an antioxidant found in red wine is good for the heart, some recent research has determined that wine’s health benefits are exaggerated.",
        "true"
    ],
    [
        0.3480590532223384,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '859'}",
        "It is highly unlikely that Lily is a rhino. It is highly likely that Sandra grabbed the apple. We doubt that Bernhard is yellow. There is a better than even chance that if 'Sandra grabbed the apple and Bernhard is yellow' then Julius is a lion. There is almost no chance that if either 'Bernhard is yellow' or 'Lily is a rhino' but not both then Brian is green. There is a very good chance that if 'Sandra grabbed the apple' or 'Bernhard is yellow' or both then Mary left the milk.",
        "invalid"
    ],
    [
        0.34805547694365185,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '572'}",
        "(1)Многие считают понятие чести устарелым, несовременным, в том смысле, что оно нынче не применимо — не те условия. (2)Для одних это связано с такими действиями, как дуэль: мол, чем иначе можно защитить свою честь от оскорблений?(3)Другие считают: честь сегодня заменена более высоким понятием — принципиальность. (4)Вместо человека чести — человек принципов... (5)Как может устареть чувство чести, чувство собственного достоинства, сугубо личное нравственное чувство?(6)Как может устареть понятие чести, которая даётся человеку однажды, вместе с именем, и которую нельзя ни возместить, ни исправить, которую можно только беречь?(7)Мне вспоминается случай, связанный с именем А.П Чехова. (8) В 1902 году царское правительство аннулировало избрание Максима Горького в почётные академики. (9)В знак протеста Короленко и Чехов отказались от звания академиков. (10)Для Чехова это был акт не только общественный, но и личный. (11)Он писал в заявлении, что при избрании Горького он повидался с ним и первый поздравил его. (12)А теперь, когда Академия наук известила, что выборы недействительны, выходит, что он, Чехов, как академик, признаёт это. (13)«Я Поздравлял сердечно, и я же признаю выборы недействительными — такое противоречие не укладывается в моём сознании, примирить с ним свою совесть я не мог, — писал он в Академию наук.— И после долгого размышления я мог прийти только к одному решению... о сложении с меня звания почётного академика». (14)А ведь так сложились обстоятельства, вроде независимые от Чехова, и он мог бы найти для себя оправдание. (15)Убеждения, конечно, вещь необходимая. (16)Но есть такое более простое, конкретное понятие, как слово, данное человеком. (17)Оно не подтверждено никаким документом, справкой. (18)Просто слово. (По Д. Гранину)",
        "True"
    ],
    [
        0.3480512499809265,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '743'}",
        "خردید از دیجی کالا نسبت به خرید از فروشگاهها با توجه به صرف زمان کمتر و جستجوی راحت کالا با قیمت مناسب، ارجحیت دارد",
        "کلی"
    ],
    [
        0.3480411320924759,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '860'}",
        "\"This is a story about a commercial method for cooling patients who have suffered cardiac arrest in an attempt to prevent brain damage. The story did not clearly define whom the treatment might benefit or how often the treatment is successful at providing benefit. Yet it found time to quote the CEO of the company making the cooling device. The story reported on one patient who said she \"\"shouldn’t have made it\"\" and who related that doctors had told her that if she had not received the treatment she would have been \"\"dead or brain damaged\"\". However – the story provided no background information to help readers assess the veracity of these statements; nor did it provide any indication of how often the treatment resulted in the outcomes experienced by this patient. It provided little to help a reader learn more about when the treatment might be considered an appropriate option. Overall, this was a story of high human interest that was lacking in any meaningful discussion of evidence for benefits or harms, a lack of clarity about the population for whom this is intended, and too strong a focus on the product of one specific company. This is the third such story on cooling of cardiac arrest patients that we’ve reviewed so far this year. It appears to be something that local medical centers who use the approach like to promote. We hope that they – and the journalists who cover them – include more evidence in future promotions or news stories.\"",
        "false"
    ],
    [
        0.34801459809144336,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '839'}",
        "It is highly unlikely that 'Brian is white' or 'John dropped the apple' or both.",
        "invalid"
    ],
    [
        0.34798988699913025,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '908'}",
        "It is highly unlikely that John moved to the office. We believe that Winona is a sheep. It is likely that Daniel dropped the apple. It is highly likely that if either 'Winona is a sheep' or 'Daniel dropped the apple' but not both then Antoine is thirsty. It is unlikely that if 'Daniel dropped the apple and John moved to the office' then Greg is green. It is impossible that if either 'Winona is a sheep' or 'Daniel dropped the apple' but not both then Gertrude is a sheep.",
        "invalid"
    ],
    [
        0.3479885409275691,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '808'}",
        "There is a better than even chance that Julius is a lion. It is almost certain that Greg is green. It is almost certain that Brian is a swan.",
        "invalid"
    ],
    [
        0.3479805489381154,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '901'}",
        "There is almost no chance that 'Lily is a frog and Bernhard is a rhino'.",
        "invalid"
    ],
    [
        0.3479769577582677,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '338'}",
        "It is highly unlikely that Lily is yellow. It is highly likely that Greg is gray. It is likely that John went to the office. We doubt that if either 'Lily is yellow' or 'John went to the office' but not both then Jason is tired. We doubt that if either 'Lily is yellow' or 'Greg is gray' but not both then Julius is a frog. It is probable that if 'Lily is yellow and John went to the office' then Bernhard is a swan.",
        "invalid"
    ],
    [
        0.34794746339321136,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '927'}",
        "It is highly unlikely that either 'Fred is in the school' or 'Lily is yellow' but not both.",
        "invalid"
    ],
    [
        0.3479417860507965,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '481'}",
        "The author hooked up with a friend and now he wants to be more than friends. She isn't sure, because they share mutual friends and she doesn't want things to get weird. Should the author worry or just hope things work out?",
        "Accuracy"
    ],
    [
        0.34793295959631604,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '361'}",
        "It is unlikely that Greg is yellow. It is likely that Sandra put down the milk. There is almost no chance that John picked up the apple. It is probably the case that if 'Sandra put down the milk' or 'Greg is yellow' or both then Bernhard is a swan. It is probable that if either 'Greg is yellow' or 'Sandra put down the milk' but not both then Mary discarded the milk. We doubt that if either 'John picked up the apple' or 'Greg is yellow' but not both then Lily is a rhino.",
        "invalid"
    ],
    [
        0.3479078412055969,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '492'}",
        "The male friend is not in a relationship as the summary states but rather the girl who asked for porn is.",
        "Accuracy"
    ],
    [
        0.3478944847981135,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '619'}",
        "It is unlikely that 'Gertrude is a wolf' or 'Brian is a frog' or both.",
        "invalid"
    ],
    [
        0.34787388145923615,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '376'}",
        "There is almost no chance that either 'Greg is yellow' or 'Winona is a wolf' but not both.",
        "invalid"
    ],
    [
        0.34785494208335876,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '346'}",
        "The story speculates at length about potential benefits of this treatment, before ever establishing that this is preliminary research. Our guideline is “if it’s not too early to talk about benefits, then it’s not too early to talk about costs.” This story didn’t do so. The heading of the article is eye catching: blood-sucking parasitic worms! The health of millions improved! It’s not until about two-thirds of the way through the article that it becomes clear these claims are based on the findings of a laboratory study of asthmatic mice, and so there are no actual benefits to report on. The treatment hasn’t yet been tested in humans. The article does make an attempt to explain how similarities in mouse and human anatomy suggest that humans might benefit from the same treatment. It also notes that “their [the researchers’] next step is a phase one clinical trial, which would test the effectiveness of an AIP-2 pill.” Actually, phase I trials assess safety and appropriate dosage for new medications. Final effectiveness of new treatments is not assessed until much later, in phase III trials. Any possible benefits of this treatment to the public, therefore, are considerably farther down the road than the article implies. Furthermore, findings from other studies in the line of research are mixed. All in all, the statement that AIP-2 “may make millions of people healthier” is premature. As we’ve stated many times, mouse research is usually not newsworthy because of these challenges. The article provides some explanation of the potential harms of ingesting live hookworms for therapeutic purposes. It warns against readers “trying this at home,” especially in the cases of young children and pregnant women. No statement is made about the potential harms of treatments derived from hookworm spit or similar compounds, but at least most readers probably won’t leave this article with the impression that buying hookworms overseas and self-infecting is a great idea. Two studies from the same lab are mentioned in the article. The first involved 12 patients with celiac disease. The article reports that their tolerance for gluten “improved” after ingesting live hookworms, but it is very short on details. There is no explanation of how long they were treated, how much they improved, or even whether there was a control group. The story states that it is “difficult to scale” that kind of study because of the challenges in finding patients who are willing to be infected with live parasites. It does not mention that the small sample size would also make it impossible to generalize any findings to the larger population. More information is provided about the study that is the main focus of the article, a laboratory experiment in which mice were treated with a compound synthesized from hookworm spit. But the story provides no sense of how challenging it will be to translate these results to humans, a very important caveat that should have been discussed. The article does not engage in disease mongering. No independent sources are cited. Although the article talks about 235 million asthma sufferers across the world, it provides no description of the challenges they face or the limitations of current treatment options. It’s not clear, therefore, why or for what types of people an alternative treatment is needed and what this treatment might have to offer over the status quo. The story does’t address availability. As we explain in the quantified benefits criterion above, the most readers get is an erroneous statement about the next steps: “Navarro said their next step is a phase one clinical trial, which would test the effectiveness of an AIP-2 pill.” A phase one trial is actually to test safety–not effectiveness–and this error may have the effect of making this pill seem closer to reality than it is. Research about therapeutic use of hookworms and other parasitic worms (helminths) has been around since the 1990s, although it has entered into the public consciousness within the past five years at most. So in one sense, the material in this article is novel. The beginning of the story describes the genesis of this line of research in questions about the connection between the dramatic success of deworming programs around the world and the rise of immune system problems like asthma and celiac disease. However, the article makes no mention of multiple previous and ongoing studies investigating the effects of “worm therapy” on auto-immune diseases like Crohn’s disease, multiple sclerosis, and asthma. The idea that parasites may play a role in the development of the human immune system is still surprising for most of us, but not as novel as this report on the findings of a single research group would suggest–just a few months ago we reviewed an NPR story on worms for allergies. The article should have provided more context. The story appears to include novel quotes from the researchers that were not taken from the news release.",
        "false"
    ],
    [
        0.3478548526763916,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '969'}",
        "Like so many questionable bits of scientific misinformation, the claim that putting onions on your feet will do something unspecified that has to do with “toxins” is repeated with similar or identical language on many different web sites. One site that has given this concept undue attention is that of David ‘Avocado’ Wolfe, a prolific purveyor of misinterpreted science and blenders. He explains the basic rationale in a November 2016 post: The Chinese found that there are thousands of tiny nerve endings on the bottom of the feet. These nerve endings act as access points to the internal organs. They are also closely linked to the nervous system. Onions have strong anti-bacterial and anti-viral properties. When you cut an onion and place it on the bottom of the foot, it gets right to work removing toxins and healing your body. If that explanation isn’t doing it for you, Wolfe provides additional reasoning as well. But, like a desperate student called on in class after a heavy night of not studying, Wolfe lists numerous unrelated, disconnected, illogical, and wholly inaccurate claims about how an onions on your feet might impart a health benefit in the hopes that the sheer volume of answers will not betray his own lack of knowledge. Only three of these five explanations hold even a modicum of relevance to the onion sock theory: Onions detox the body – Onions are rich in sulphuric compounds. These compounds are responsible for their strong odor. Sulfer [sic] helps the body release unwanted toxins, especially in the liver. Onions purify your blood – While the onion is next to your foot, phosphoric acid is released. It enters your bloodstream and helps to purify the blood running through your veins. […] Onions support the immune system – Thanks to the anti-bacterial and anti-viral properties of onions, your immune system becomes better prepared to fight off infections and inflammation. […] With these claims in place, we can get a general picture of how Wolfe and others suggest this works: Borrowing from the Traditional Chinese Medicine concept of meridians, the feet are a gateway to multiple organ systems in your body which allow chemicals from the onion to enter your bloodstream like a portal, where they get to purifying, bacteria killing, and virus fighting. First off, the existence of meridians have not been demonstrated scientifically, and even if they had been, practitioners of Traditional Chinese Medicine describe their action as transporting energy or “qi”, not as transporting actual physical compounds, so Wolfe’s description of the mechanism by which beneficial onion compounds make it to your body is not off to a great start. Ignoring this problematic beginning, the next claim refers to an onion’s sulphuric compounds. They do indeed exist, and they have indeed been proposed as the primary chemicals responsible for an onion’s medicinal benefits. A 2002 review in the journal Phytotherapy describes these chemicals and lists their potential health effects: Onions are rich in two chemical groups that have perceived benefits to human health. These are the flavonoids and the alk(en)yl cysteine sulphoxides (ACSOs). […]. The ACSOs are the flavour precursors, which, when cleaved by the enzyme alliinase, generate the characteristic odour and taste of onion. The downstream products are a complex mixture of [sulfur-based compounds]. Compounds from onion have been reported to have a range of health benefits which include anticarcinogenic properties, antiplatelet activity, antithrombotic activity, antiasthmatic and antibiotic effects. Unfortunately for proponents of onion foot therapy, these potential benefits all necessitate the ingestion of these compounds, not passively leaving the entity responsible for their creation in close proximity to one’s foot. Ultimately, this kind of reasoning is a lazy distraction, equating the benefits of ingestion with other less plausible, and often undefined, pathways. While there have been some limited studies regarding some of these (ingested) benefits in laboratory settings, it needs to be noted that there has been little research definitively showing these effects on humans (though there is also a lack of research in general on the topic), per that same review: Clearly there are many claims on health benefits of Alliums [the genus that includes Onions], however, most, with the exception of garlic, have not received any rigorous (or even gentle) scientific investigation Further, the notion that these sulfur-based chemicals “release” toxins is vague oversimplification. The argument could be made that the antioxidant properties of some onion chemicals aid in the cleansing of “toxins” from your body,  but, again, you would need to be ingesting said chemicals. In the same vein as releasing toxins is the notion that the phosphoric acid found in onions cleanses your blood. The inclusion of this pro-phosphoric acid statement is odd for a David Wolfe page, given the fact that he rails against the chemical on his other pages. Though there are myriad problems with the idea that phosphoric acid cleanses your blood and with the notion that topical application of it on your foot would have any effect whatsoever, all of these issues are irrelevant as onions do not contain phosphoric acid to begin with. In fact, phosphoric acid is used in laboratory settings to liberate compounds from onions and garlic for analysis. Every so often, alarm bells are sounded on food blogs about the inclusion of phosphoric acid as a preservative in minced packages of (the closely related) garlic. Needless to say, the lack of phosphoric acid in onions is another serious blow to the proffered theories for why sock onions could have medicinal properties. In terms of the onion’s ability to boost your immune system through their antibacterial and antiviral compounds there are two ways to look at it: Yes, onions have been shown in laboratory settings to fight both viruses as well as bacteria and conceivably, these compounds could have a benefit to you — but, again, only when ingested. In this case, as well, the topical application of some chemicals in onions could kill bacteria externally. However, just as the ingestion of onions will not reduce external bacterial infections, neither will a topical application be effective at creating any change to the internal systems of one’s body, as claimed.",
        "false"
    ],
    [
        0.3478516439596812,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '454'}",
        "Chances are slight that Mary left the apple. It is certain that Bernhard is a swan. It is highly likely that John discarded the milk. We doubt that if 'Bernhard is a swan' or 'Mary left the apple' or both then Julius is gray. We doubt that if 'Bernhard is a swan' or 'John discarded the milk' or both then Brian is a frog. We believe that if either 'Bernhard is a swan' or 'John discarded the milk' but not both then Bill went to the garden.",
        "invalid"
    ],
    [
        0.3478338321050008,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '542'}",
        "Ins sich gesehen eine stimmige Geschichte mit einer guten Idee und eben auch einer Begründung warum ein Mensch sich auf die dunkle Seite begibt und was dahinter stehen könnte, plus nicht jeder böse Mensch ist nur böse.",
        "counterfactual"
    ],
    [
        0.3478338321050008,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '542'}",
        "Ins sich gesehen eine stimmige Geschichte mit einer guten Idee und eben auch einer Begründung warum ein Mensch sich auf die dunkle Seite begibt und was dahinter stehen könnte, plus nicht jeder böse Mensch ist nur böse.",
        "counterfactual"
    ],
    [
        0.3478288948535919,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '722'}",
        "Chances are about even that Brian is green. It is highly unlikely that Bill got the milk there. We doubt that Emily is a sheep. It is probable that if 'Brian is green' or 'Emily is a sheep' or both then Sandra dropped the milk. It is highly unlikely that if either 'Emily is a sheep' or 'Brian is green' but not both then Bernhard is yellow. Chances are about even that if 'Brian is green' or 'Emily is a sheep' or both then John grabbed the apple.",
        "invalid"
    ],
    [
        0.3478247324625651,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '267'}",
        "[{'follow_up_question': 'Was the property a gift (there are different rules if it was to your spouse, civil partner or a charity)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'did you inherit it?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Did you sell it for less than it was worth to help the buyer?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.3478142519791921,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '362'}",
        "A common stoner trope (and a well-worn excuse for those teenagers trying to hide their stoner status from their parents) is that of the secondhand high from marijuana smoke. It is not something taken lightly by scientists, either, especially in light of a wave of marijuana legalization across the United States; studies have investigated the effects of secondhand cannabis smoke on nonsmokers for decades. While this work comes with notable limitations, the consensus is that it is, in fact, possible to get high from secondhand cannabis smoke, at least under certain extremely unventilated and confined conditions. A relevant example of such conditions — and actually a model for researchers studying the effects of second hand cannabis smoke — would be “hotboxing,” which in cannabis culture is the process of smoking marijuana with a group of people in an unventilated car or room, potentially increasing the degree to which participants are exposed to cannabis smoke. Early research sought to recreate these conditions primarily to see if people not directly smoking would absorb the active components of cannabis to the point where they could be detected in urine or blood. Though small in sample size, numerous studies conducted in the 1980s have shown that under these extreme conditions passive participants could absorb enough THC and other cannabinoids so that they could be detected in blood or urine (and, as a result, potentially affect drug screening tests for a short period of time following exposure.) A 1986 study also reported that the subjective effects of being exposed indirectly to 16 “marijuana cigarettes” were similar to those produced by directly smoking a single joint, though it bears mentioning that this 1986 marijuana was up to 10 times weaker than modern high-potency medical or recreational marijuana. The question of a second-hand high was most recently investigated in a 2015 study performed at Johns Hopkins University. Researchers confined groups of six smokers (who were each provided with ten joints) and six non-smokers in a chamber under both ventilated and unventilated conditions, letting the smokers toke at their leisure for an hour in the company of the non-smokers. Using a battery of tests following these sessions, the scientists concluded that getting high indirectly (and mildly) is possible, though dependent on how ventilated a space is: Room ventilation has a pronounced effect on exposure to secondhand cannabis smoke. Under extreme, unventilated conditions, secondhand cannabis smoke exposure can produce detectable levels of THC in blood and urine, minor physiological and subjective drug effects, and minor impairment on a task requiring psychomotor ability and working memory. The authors of the study caution that it took specific and “extreme” conditions to produce effects from the second hand high, and that their study design may not accurately reflect the real world: The size of room, amount of cannabis consumed, duration of exposure, and frequency of such exposure are all variables that likely would influence outcomes in the real world. Their results do suggest, however, that secondhand highs are possible but that you would probably have to work pretty hard to get there. That means, if you’re in a position where you’re trying to brazen out a story about how you accidentally got a contact high after a long night, you might have to think up another excuse.",
        "true"
    ],
    [
        0.3478139489889145,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '543'}",
        "It is probably not the case that Jeff went to the garden. It is probably the case that Gertrude is a cat. There is little chance that Lily is yellow. It is highly unlikely that if either 'Lily is yellow' or 'Gertrude is a cat' but not both then Julius is white. It is highly unlikely that if 'Gertrude is a cat and Lily is yellow' then Fred dropped the milk. It is probably the case that if either 'Lily is yellow' or 'Gertrude is a cat' but not both then Brian is yellow.",
        "invalid"
    ],
    [
        0.3477894564469655,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '460'}",
        "['Highly active (i.e., \"hot\") long interspersed element-1 (LINE-1 or L1) sequences comprise the bulk of retrotransposition activity in the human genome; however, the abundance of hot L1s in the human population remains largely unexplored.', 'Here, we used a fosmid-based, paired-end DNA sequencing strategy to identify 68 full-length L1s that are differentially present among individuals but are absent from the human genome reference sequence.', 'The majority of these L1s were highly active in a cultured cell retrotransposition assay.', 'Genotyping 26 elements revealed that two L1s are only found in Africa and that two more are absent from the H952 subset of the Human Genome Diversity Panel.', 'Therefore, these results suggest that hot L1s are more abundant in the human population than previously appreciated, and that ongoing L1 retrotransposition continues to be a major source of interindividual genetic variation.']",
        "False"
    ],
    [
        0.3477845291296641,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '463'}",
        "['Ribosomal DNA is one of the most variable regions in the human genome with respect to copy number.', 'Despite the importance of rDNA for cellular function, we know virtually nothing about what governs its copy number, stability, and sequence in the mammalian genome due to challenges associated with mapping and analysis.', 'We applied computational and droplet digital PCR approaches to measure rDNA copy number in normal and cancer states in human and mouse genomes.', 'We find that copy number and sequence can change in cancer genomes.', 'Counterintuitively, human cancer genomes show a loss of copies, accompanied by global copy number co-variation.', 'The sequence can also be more variable in the cancer genome.', 'Cancer genomes with lower copies have mutational evidence of mTOR hyperactivity.', 'The PTEN phosphatase is a tumor suppressor that is critical for genome stability and a negative regulator of the mTOR kinase pathway.', 'Surprisingly, but consistent with the human cancer genomes, hematopoietic cancer stem cells from a Pten-/- mouse model for leukemia have lower rDNA copy number than normal tissue, despite increased proliferation, rRNA production, and protein synthesis.', 'Loss of copies occurs early and is associated with hypersensitivity to DNA damage.', 'Therefore, copy loss is a recurrent feature in cancers associated with mTOR activation.', 'Ribosomal DNA copy number may be a simple and useful indicator of whether a cancer will be sensitive to DNA damaging treatments.']",
        "False"
    ],
    [
        0.34773750106493634,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '664'}",
        "The poster is conflicted about relationships because he can't get over his ex. He recently broke up with a girl knowing he'd go back to his ex at the drop of a hat and wanted to be fair to the new girl. ",
        "Accuracy"
    ],
    [
        0.34772733350594837,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '722'}",
        "\"This is a classic story of the potential promise of a new technology for the health care sector. A nice anecdote sets the stage and then a number of preliminary findings are used as proxies for real evidence. It is implied that the technology will keep people healthier, happier and at less cost to our costly system. This is, unfortunately, often a fairy tale mainstay of health news journalism. It’s interesting that several leading journalists wrote to us with concerns about this story. One wrote, \"\"She didn’t interview a real skeptic. It is still quite possible that these devices will only yield minor results, since heart failure is, after all, an end stage disease, so it may just be rearranging the deck chairs on the Titanic.\"\"\"",
        "false"
    ],
    [
        0.34771506985028583,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '225'}",
        "It is probable that Emily is a wolf. It is unlikely that Lily is a lion. It is almost certain that Bernhard is a frog.",
        "invalid"
    ],
    [
        0.34770896037419635,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '99'}",
        "ju — voi» I & ï®°l dc: verklaringen?va i'.ains VVeils —d; ?fCr6sté 𝙣𝙚𝙜𝙚𝙧 jagers rij laten de negers niet hunne Vereenigiag\" toe 'als liden ",
        "𝙣𝙚𝙜𝙚𝙧"
    ],
    [
        0.34770092864831287,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '428'}",
        "این پودر قهوه رو اولین بار بود خریدم که از خرید پشمون شدم.من که همیشه قهوه فله میگیرم اصلا از طعم و بو و گیرایی این قهوه راضی نبودم.البته خب نسبت به پولی ک پرداخت کردم همینم بد نبود",
        "کلی"
    ],
    [
        0.3476829379796982,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '452'}",
        "It is certain that Lily is green. Chances are about even that Mary went to the office. It is probably the case that John dropped the milk. It is improbable that if 'Lily is green and John dropped the milk' then Daniel took the apple. It is improbable that if 'Mary went to the office' or 'John dropped the milk' or both then Brian is a swan. It is highly unlikely that if 'John dropped the milk' or 'Lily is green' or both then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.34757766127586365,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '366'}",
        "At this level of research, speaking to costs would seem to be unnecessary but since the drug used in the study is commercially available, the cost is relevant and should have been mentioned in the release. The drug is expensive — at $500 to $3,000 a month for asthma patients depending on insurance and co-pays — even though it’s impossible to know at this stage what  the costs or dosing would be if it is ever proven to be useful in patients with Alzheimer’s disease. Noting the cost could have been done in the context of the costs to care for someone with Alzheimer’s for years or decades. The release is light on data describing how much better at maze navigation the treated mice were compared to non-treated mice. “… significantly better on the tests…” and “…superior performance do not provide an adequate quantification of the test results. There is also a tacit and unfounded assumption that the reductions in leukotrienes and in tau are sustainable during prolonged treatment. Harms in a mouse model do not necessarily translate to humans but we do know what the side effects profile looks like. The harms include alteration of liver function, sleep and behavioral disorders — to name a few. It’s irresponsible to say that this research “could soon be translated to the clinic,” which is simply not true. There’s a tremendous gap between this research and proving clinical effectiveness. As we noted in the summary, the release should have specifically addressed the work still to do in understanding how the reversal of tau damage in designer mice translates to a potential treatment for restoring brain function in people. No mongering here. But nor does the release provide any context on the prevalence of Alzheimer’s. Funding sources are named. The release would have been improved if it had acknowledged the multiple failures over many decades of other once promising drugs for dementia tested in animals. The take-home message should be that these disorders, and brain chemistry in general, are complicated, and although research may bring hope, it has yet to bring effective treatments. The release makes the statement, albeit at the very end, that the research could “soon translate” into clinical use. That is at best misleading and provides a false hope for patients and their families, given that no timetable or process is given for what would be required to take the step to human use. A plus is that the drug already is approved for use in asthma, but it is likely that even if further animal studies confirm the current work, clinical use is still months or even years away. The release could have been improved if it noted that the current research is an extension of work done by these researchers. A 2013 publication in PLOS Medicine previously demonstrated cognitive improvements in mice treated with zileutin and alterations in levels of tau. The suggestion that this was a breakthrough seems a bit of a stretch given their previous work. Although parts of the release are cautious in describing what the drug can do, the use of words like “breakthrough” and “especially exciting” appear unwarranted.",
        "false"
    ],
    [
        0.3475607732931773,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '917'}",
        "[{('Shantel', 'son', 'Robert'): [('Shantel', 'son', 'Antonio'), ('Antonio', 'brother', 'Robert')]}, {('Antonio', 'brother', 'Robert'): [('Antonio', 'brother', 'Louis'), ('Louis', 'brother', 'Robert')]}, {('Antonio', 'brother', 'Louis'): [('Antonio', 'son', 'Aaron'), ('Aaron', 'uncle', 'Louis')]}]",
        "son"
    ],
    [
        0.34754660725593567,
        "{'dataset_id': 'WorkInTheDark/FairytaleQA', 'config_id': 'plain_text', 'row_id': '795'}",
        "\" why are you so enraged , my boy ? \" said the king , \" and why do you so maltreat my nobles ? \" \" because they have not treated me with the respect due to a stranger , \" replied the boy . \" who are you yourself ? \" said conchubar . \" i am setanta , the son of sualtim , and dectera , your own sister , is my mother ; and it is not before my uncle 's palace that i should be insulted and dishonoured . \" this was the debut and first martial exploit of the great cuculain , type of irish chivalry and courage , in the bardic firmament a bright and particular star of strength , daring , and glory , that will not set nor suffer aught but transient obscuration till the extinction of the irish race ; cuculain , bravest of the brave , whose glory affected even the temperate - minded tierna , so that his sober pen has inscribed , in the annals of ancient erin , this testimony : \" cuculain , filius sualtam fortissimus heros scotorum . \" after this setanta was regularly received into the military school , where , ere long , he became a favourite both with old and young . he placed himself under the tuition of fergus mac roy , who , each day , grew more and more proud of his pupil , for while still a boy his fame was extending over ulla .",
        ""
    ],
    [
        0.3475425988435745,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '801'}",
        "It is unlikely that Bill moved to the office. There is little chance that Daniel dropped the milk. It is highly likely that Yann is hungry. It is impossible that if either 'Daniel dropped the milk' or 'Bill moved to the office' but not both then Mary went to the garden. It is unlikely that if either 'Yann is hungry' or 'Bill moved to the office' but not both then Julius is a rhino. It is certain that if either 'Bill moved to the office' or 'Yann is hungry' but not both then John got the apple.",
        "invalid"
    ],
    [
        0.34754225611686707,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '335'}",
        "Write an excellent summary of the given text.\n\nTitle: I [15M] have no idea how to approach crush [15F] with many mutual friends.\n\nText: Sophomore year of high school, and I'm really having trouble talking to a girl that I've had a crush on since 9th grade. We've never talked to each other in 9th grade and I'm just so afraid to approach her. \n\nThis year she hangs out a lot with my friends and stuff. But still I haven't talked to her at all. One time she went over to my area with just one other friend but I just got super anxious and shy and I didn't say a thing. \n\nShe talks to my friends a lot, and I always catch myself staring at her. No one has a hint that I like her, and I'm afraid to tell people because my friends make it so obvious. I've never had any kind of relationship before, and I'm just so afraid. I think about her a lot but I have no idea how to approach her without looking to obvious that I like her and looking to creepy and emotionless. We have no classes together\nAny advice?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3475329478581746,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '741'}",
        "Rutina Wesley as Nova Bordelon , the eldest Bordelon child , a journalist , activist and herbal healer Dawn - Lyen Gardner as Charlotte `` Charley '' Bordelon West , the middle Bordelon child - half sibling to Nova and Ralph Angel , a sports manager , mother of Micah and ex-wife of Davis Kofi Siriboe as Ralph Angel Bordelon , the youngest Bordelon child , the face - forward brother of Bordelon sisters looking to better himself after recently being released from prison Tina Lifford as Violet Bordelon , Ernest 's younger sister , aunt to the Bordelon children , and Hollywood 's girlfriend Omar Dorsey as Hollingsworth `` Hollywood '' Desonier , Violet 's much younger oil rig worker boyfriend and friend of the Bordelon family Dondre Whitfield as Remy Newell , an irrigation specialist who was a friend and confidante to Ernest who soon becomes a helping hand to Ernest 's children and soon becomes Charley 's love interest Bianca Lawson as Darla , Ralph Angel 's ex-girlfriend and Blue 's mother , seeking to reconnect with them both as she is in recovery from a drug addiction Nicholas L. Ashe as Micah West , Charley 's and Davis 's teenage son Ethan Hutchison as Blue Bordelon , Ralph Angel and Darla 's 6 - year - old son Henry G. Sanders as Prosper Denton , a lifelong friend to Ernest and fellow farmer ( Season 3 ; Recurring Seasons 1 - 2 ) Timon Kyle Durrett as Davis West , Charley 's charismatic star basketball player ex-husband , client , and Micah 's father whose involvement in a sex scandal leads to the dissolution of their marriage ( Seasons 1 - 3 ) Greg Vaughan as Calvin , a married police officer and Nova 's longtime secret lover ( Season 1 ; Guest Season 2 ) Marycarmen Lopez as Reyna Velez , Blue 's elementary school teacher ( Season 1 )",
        ""
    ],
    [
        0.3475269873936971,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '626'}",
        "Write an excellent summary of the given text.\n\nTitle: Child's mother may be going to jail. Need help.\n\nText: My ex and I were never married, but together four years and we have a 6 year old daughter together. We have had joint custody and have not been together since she was 3 years old. We are not on good terms and the mother prefers for me not to be around.. But that's not what I'm here to talk about!\n\nMy family has told me that she has been sentenced to either 2 years jail-time or 5 years probation ((which she cannot afford)). More likely than not, she will end up in jail. Either taking the jail-time or not being able to afford probation fees.\n\nI wish to take my daughter and seek full custody as soon as I know she is in jail. (whenever that may be)\n\nI am wondering what I need to expect, and how long she has to make this decision. I am not sure how long ago they gave her this choice, but the incident was in the paper a couple months ago.\n\nThe story- For those interested, my ex is being sentenced to jail/probation for harboring a fugitive in TX, USA. The fugitive was her now-boyfriend/2nd baby's father. He was on the run for bail jumping, breaking and entering, possession of a firearm, and two counts of evading arrest. When they arrived at their home to arrest him, she stated that he did not live there. When they forced themselves into the home, they saw the boyfriend jumping out of the window and had to chase him down the street.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34752435982227325,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '631'}",
        "[{'id': '253', 'response': 'Illegible OCR'}, {'id': '254', 'response': \"I don't know\"}, {'id': '255', 'response': 'Contentious according to current standards'}, {'id': '256', 'response': \"I don't know\"}, {'id': '257', 'response': 'Illegible OCR'}, {'id': '258', 'response': 'Not contentious'}, {'id': '259', 'response': \"I don't know\"}]",
        "𝙢𝙪𝙡𝙖𝙩"
    ],
    [
        0.34751829504966736,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '843'}",
        "In Nebenrollen trifft man einige alte Bekannte aus frueheren Buechern, die in die Jahre gekommen sind (Logan ist nur fast 'lammfromm', Chivers, Costa und seine Soeldner, ..), aber der Schwerpunkt der Handlung liegt auf anderen (ein Rechtsanwalt als Anti-Held, sein Name 'Temple' kommt wohl auch daher, weil er immer 'oh god' seufzt, wenn es brenzlig wird).",
        "not-counterfactual"
    ],
    [
        0.34751829504966736,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '843'}",
        "In Nebenrollen trifft man einige alte Bekannte aus frueheren Buechern, die in die Jahre gekommen sind (Logan ist nur fast 'lammfromm', Chivers, Costa und seine Soeldner, ..), aber der Schwerpunkt der Handlung liegt auf anderen (ein Rechtsanwalt als Anti-Held, sein Name 'Temple' kommt wohl auch daher, weil er immer 'oh god' seufzt, wenn es brenzlig wird).",
        "not-counterfactual"
    ],
    [
        0.3474870026111603,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '782'}",
        "\"Was mir zum perfekten Rucksack fehlt ist eine durchgehende, wasserdichte \\\\\"\"Wanne\\\\\"\" wie beim Schwimmsport Rucksäcken.\"",
        "counterfactual"
    ],
    [
        0.3474870026111603,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '782'}",
        "\"Was mir zum perfekten Rucksack fehlt ist eine durchgehende, wasserdichte \\\\\"\"Wanne\\\\\"\" wie beim Schwimmsport Rucksäcken.\"",
        "counterfactual"
    ],
    [
        0.3474530677000682,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '195'}",
        "Co-owner Waylynn Lucas tops donuts with bacon at Fonuts bakery, which offers unfried, gluten-free and vegan donuts, in Los Angeles, California September 19, 2011. REUTERS/Lucy Nicholson Restaurants are printing notes like this in droves, and hosts are now googling phrases like “lacto-ovo” before dinner parties. Dietary restrictions seem to grow more numerous every year, whether it’s a rise of gluten intolerance or a new low-carb low-fat no-sugar raw food diet. Good manners says to eat what you’re served, and it also says to respect the beliefs of others, and especially when you’re a host, to graciously accommodate them. Contradictory? Not if a little tact and understanding are applied. For straight-up dislikes when among friends, it’s fine to refuse a dish you don’t care for with a polite “No, thank you.” At a dinner party where the host has gone to a great deal of trouble, it’s good manners to take at least a little of every dish being offered. Teach the concept of the “no thank you helping” to children, even for family meals-it makes it easier for them when the spotlight is on them as a guest. Allergies are another matter, and can’t be avoided; your health and safety is a priority. A conscientious host will ask first-time guests if they have any particular allergies or dietary restriction. If the host doesn’t ask, it’s especially important for the guest to inform him of allergies, medical conditions, or religious prohibitions. If the gathering is small, the dinner is in your honor, or you’re going to be an overnight houseguest, however, or if you’re severely allergic to certain foods (or pets), it’s a good idea to let your host know up front when you first respond to the invitation and give him or her a chance to adjust the menu if necessary. “I’d love to come, but I should tell you that I’m completely allergic to shellfish”; “I’d love to come to the barbeque, but I should tell you that I’m a vegetarian. Could I bring a tabouleh salad if that’s okay with you?”   Always give the host the option to accommodate you or not. In some cases it may not be possible, so don’t take offense if it doesn’t work out. For a small dinner party, offer to bring a dish to share. Say: “Thanks so much for the invitation. I should let you know that I’m a vegetarian. I’d love to bring a quiche if that’s okay with you.” This way, your host won’t waste time preparing the wrong food for you or have to trouble himself figuring out what type of dish would best suit your preferences. If you’re allergic to a particular food or on a restricted diet and your host urges you to help yourself to food you know you shouldn’t or can’t eat, gently decline, “Shellfish is off-limits for me, but I’m enjoying everything else.”   It’s not necessary to inform the host of a cocktail party, large dinner party, buffet, or reception that you’re a vegetarian, mildly allergic to milk, or diabetic, because there’s bound to be a variety of foods to choose from. At the party, it’s fine to ask about the ingredients in a particular dish. When your dietary restrictions are based on religious tenets, it may not be practical to accept some invitations. If the invitation is for a small gathering, you can explain to your hostess that you’d love to accept, but that you’ll have to bring a dish that you’ve prepared according to your dietary rules-provided that’s acceptable to her. As a large part of entertaining is about being social, many hosts will encourage you to attend and bring your special dish. If you don’t drink alcohol, ask for water or a non-alcoholic beverage (which are fine to toast with should there be toasts). You don’t have to give a reason for abstaining unless you wish to. Never feel you have to drink alcohol, even if pressed. The rudeness in that case is theirs, not yours. The goal as a host is not to call special attention to guests who don’t drink alcohol. Also, be attentive to the seating arrangements. A friend in recovery shouldn’t spend the evening next to a wine aficionado extolling the virtues of every wine served.",
        "true"
    ],
    [
        0.3474523176749547,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '452'}",
        "It is probably not the case that Lily is a lion. Chances are slight that Sandra left the milk. Chances are slight that Jessica is a mouse.",
        "invalid"
    ],
    [
        0.3474365621805191,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '997'}",
        "وای از پانته آ بهرام... عجب بازی ای ارائه می ده.   البته مهناز افشار هم خوب شاهر شده به نسبت همه کارهای قبلیش.   فیلمنامه اقتباسی خوب.کارگردانی و پلان های جذاب.   مرسی.دوست داشتم.",
        "صدا"
    ],
    [
        0.34741008281707764,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '235'}",
        "Write an excellent summary of the given text.\n\nTitle: My gf's [22 F] best friend is also her ex, should I be concerned?\n\nText: So I am fairly new to romantic relationships in general. The girl I am seeing goes to another college about 2 hours away. She has a lot of guy friends, including her best friend, which I am ok with. We'll call him J. What bothers me is two things. 1.) She used to date J for a brief period of time, until he started see other girls, she wanted something exclusive, so they broke up. They remained close friends 3 years since. 2.) She idolizes him. She talks about how he is the ideal romantic parter (save for the unfaithfulness). She told me this before we were in a relationship. \n\nShe called me up last night, the conversation lasted about a minute, and then she abruptly told me she had to leave. I found out later that J had shown up while she was talking to me and she decided it would be rude to have him wait while she was on the phone (I kind of get that, but some sort of explanation would have been nice). It made me feel pretty shitty. She called back a few hours later and talked about she hadn't had so much fun hanging out with him in a long time, how they made each other laugh the whole night. I felt shittier. \n\nHere is my dilemma. I don't think they are doing anything romantic together, per se, but I think that she is settling for me. I fear that she thinks he would be perfect if he were only more interested in a serious relationship. Should I ask her if this is true? How should I bring this up to her? I already let her know that I am not super comfortable with her hanging out with J, but I trust her, and will not dictate what friends she can have.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.347399577498436,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '888'}",
        "It is likely that Daniel put down the milk. It is probable that Greg is yellow. It is probably the case that Bernhard is a frog. It is certain that if 'Greg is yellow and Bernhard is a frog' then Jason is tired. We believe that if either 'Bernhard is a frog' or 'Greg is yellow' but not both then Julius is white. It is certain that if either 'Daniel put down the milk' or 'Bernhard is a frog' but not both then Bill moved to the office.",
        "invalid"
    ],
    [
        0.34739136199156445,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '815'}",
        "It is probably not the case that either 'Lily is yellow' or 'Sandra got the milk' but not both.",
        "invalid"
    ],
    [
        0.3473783830801646,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '267'}",
        "عسل شناس نیستم ولی به نظرم عسل خوبیه اقلا طعم نبات نمیده و طعم و بوی عسل داره",
        "کلی"
    ],
    [
        0.3473578890164693,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '966'}",
        "[Shantel] dotes on her son [Louis]. Because of this, [Louis] is pretty spoiled. [Harold] is taking his son [Antonio] out for coffee. [Laura] bought a gift for her father [Antonio] yesterday, and is going to get one for her grandmother [Shantel] tomorrow.",
        "son"
    ],
    [
        0.3473578641812007,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '807'}",
        "We believe that John got the apple. It is improbable that Mary went to the office. It is impossible that Bernhard is a swan. Chances are slight that if 'Mary went to the office' or 'John got the apple' or both then Lily is yellow. We believe that if 'Mary went to the office and John got the apple' then Greg is a lion. It is probably not the case that if either 'John got the apple' or 'Mary went to the office' but not both then Jeff left the football.",
        "invalid"
    ],
    [
        0.3473571141560872,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '82'}",
        "The summary is not accurate.",
        "Accuracy"
    ],
    [
        0.3473391681909561,
        "{'dataset_id': 'blended_skill_talk', 'config_id': 'default', 'row_id': '908'}",
        "['Do they usually get along with other people?', \"My parents will pretend to like someone they don't really like.  It's harder to figure out if they like someone.\", 'That sounds difficult.  My parents will refuse to give advice if I decide not to do something.', 'I would actually like more advice from my parents.  I usually ask my sister for advice.  Do you have any siblings?', 'I always thought it would be fun to have a lot of siblings.  I only have one.', \"It's like a classroom and your mom is the teacher haha\"]",
        ""
    ],
    [
        0.3473309228817622,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '805'}",
        "It is likely that Sandra got the milk. It is highly likely that John moved to the garden. It is probably not the case that Julius is a rhino. It is impossible that if 'John moved to the garden and Julius is a rhino' then Emily is a cat. There is almost no chance that if 'Sandra got the milk' or 'John moved to the garden' or both then Winona is a sheep. It is highly unlikely that if either 'John moved to the garden' or 'Julius is a rhino' but not both then Gertrude is a sheep.",
        "invalid"
    ],
    [
        0.34730909764766693,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '43'}",
        "It is probably not the case that John moved to the garden. It is likely that Yann is bored. There is little chance that Lily is a rhino. It is unlikely that if 'John moved to the garden and Lily is a rhino' then Mary grabbed the milk. It is almost certain that if 'Lily is a rhino and Yann is bored' then Julius is a lion. It is probable that if either 'John moved to the garden' or 'Yann is bored' but not both then Bernhard is gray.",
        "invalid"
    ],
    [
        0.3472817043463389,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '850'}",
        "[{'follow_up_question': 'Was the property a gift (there are different rules if it was to your spouse, civil partner or a charity)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'did you inherit it?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Did you sell it for less than it was worth to help the buyer?', 'follow_up_answer': 'No'}, {'follow_up_question': 'did you own it before April 1982', 'follow_up_answer': 'Yes'}]",
        "False"
    ],
    [
        0.3472613990306854,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '425'}",
        "There is little chance that John went to the hallway. It is likely that Bill left the football. There is little chance that Lily is yellow. It is unlikely that if either 'Bill left the football' or 'John went to the hallway' but not both then Brian is a rhino. Chances are slight that if 'Bill left the football' or 'Lily is yellow' or both then Bernhard is gray. It is likely that if either 'Lily is yellow' or 'John went to the hallway' but not both then Winona is a wolf.",
        "invalid"
    ],
    [
        0.34724703431129456,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '48'}",
        "We believe that John moved to the office. It is almost certain that Julius is green. There is almost no chance that Greg is a lion. We doubt that if either 'Julius is green' or 'Greg is a lion' but not both then Brian is a frog. We doubt that if 'John moved to the office' or 'Greg is a lion' or both then Mary went to the bedroom. It is probably not the case that if 'Julius is green' or 'John moved to the office' or both then Lily is yellow.",
        "invalid"
    ],
    [
        0.34722768763701123,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '350'}",
        "It is likely that Julius is yellow. There is little chance that Jessica is a cat. Chances are slight that Emily is a sheep. We believe that if 'Julius is yellow' or 'Emily is a sheep' or both then Bernhard is a lion. We doubt that if either 'Julius is yellow' or 'Emily is a sheep' but not both then Lily is gray. Chances are about even that if 'Julius is yellow and Jessica is a cat' then John left the apple.",
        "invalid"
    ],
    [
        0.34721696376800537,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '291'}",
        "[{'follow_up_question': 'Was the property a gift (there are different rules if it was to your spouse, civil partner or a charity)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'did you inherit it?', 'follow_up_answer': 'Yes'}]",
        "False"
    ],
    [
        0.34720448156197864,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '79'}",
        "“We kept on seeing new cases and we could not understand why,” said Antoine Ruplinger, an executive with the company that runs the home. Since then 36 residents at the home have died of coronavirus-related conditions, according to the local mayor’s office, which registers the deaths. There were 109 residents before the coronavirus crisis broke. Death rates from COVID-19 in old people’s homes around the world have been high, in part because the disease hits the elderly disproportionately and because testing at care homes has been patchy. What happened at La Riviera underlines the potential value of blanket testing at an early stage, some French officials said. “Maybe if we had been able to test from the beginning, everything would have been different,” said Florence Arnaiz-Maumé, an official with the National Union of Private Homes and Facilities for the Elderly (SYNERPA). The response by staff at La Riviera was centred around checking who was showing symptoms of infection and isolating them from the rest of the home. That was in line with national guidelines at the time, which were for only the first three suspected cases to be tested. But for over two weeks after the first case, residents in the home were not tested for COVID-19. That meant people who had the virus yet showed no symptoms were still part of the general population in the home and potentially transmitting infection. “No one had been tested, so we did not know who was infected and who wasn’t,” said Richard Galy, a medical doctor and mayor of the town of Mougins where the home is located. France last week changed its policy, so that all nursing home residents and staff are tested at those homes where a COVID-19 case has been detected, whether or not they are showing symptoms. Twenty days after the first case, systematic testing of residents for COVID-19 began at La Riviera on April 4. Thirty-three residents were found to be carrying the virus, as well as 14 staff, who were sent home. The testing allowed the home to put in place a new virus containment plan, guided by an infectious disease specialist from a nearby hospital. Those who tested positive have been put on the first and second floors of the complex. They are cared for by staff who do not mix with other patients, and who use their own dedicated elevator, changing rooms and break rooms. Engineers have visited to make sure there is negative pressure inside rooms with coronavirus patients, so when a door is opened, air does not stream out, spreading the infection. By the time it became clear that the virus was spreading after the first case of COVID-19 at the home was identified in mid-March, Galy had been in touch for days with staff at the home, public health officials, and regional officials. Galy said he knew about the deaths, and was urging immediate testing. But tests were not available. The company that usually does testing for the Riviera, laboratoire de L’Esperance, only had enough kits to do 80 tests per day and priority was given to hospitals, healthcare workers, and people with symptoms, said the head of the laboratory, Dr Françoise Duhalde-Guignard. “So at the time, we couldn’t test,” she told Reuters. The regional public health authority said it has launched an investigation into why so many people died at the home. The authority has said the home’s managers waited too long to seek help. The home’s operator, Korian SA, said its staff acted in line with official guidance, and sought help when it was necessary. The mayor and four families of La Riviera residents have joined a legal case brought by some of the families against unidentified individuals alleging involuntary homicide, endangerment of life, and failure to assist a person in danger. The mayor said he was joining because he wanted to understand better what happened and where the responsibility for what happened lay. Korian and the public health authority both declined to comment on the legal case. The first case at the home was identified on March 15, when a local hospital treating a resident informed the home that the person had tested positive for COVID-19. Ruplinger, the executive with the home’s operator, received a call about the case just before midnight. The next morning, he arrived at La Riviera. He ordered that staff were to wear protective gear at all times, cleaning was to be stepped up and residents were to be confined to their rooms. Residents suspected of having the virus were moved to an 11-bed unit on a separate floor. Within three days of opening, the segregation unit had run out of beds. Several residents had already died, according to Magali Lamoureux, who runs a local funeral home and was called by the home to collect some of the bodies. She said death certificates listed COVID-19 as the cause of death. By the time testing did happen, it was too late for patients like Odette Noyer, who arrived there around 18 months ago from the town of Romans-sur-Iseres, about 400 km (250 miles) north. On March 24, she marked her 94th birthday and her family, who lived nearby, spoke to her by telephone to congratulate her. Six days later, her grandson rang the home at 5 pm to ask after her, according to a legal complaint filed by the family of Noyer and several other residents, which was seen by Reuters. A member of staff said she was being administered oxygen, but was fine. At 10 pm the same night, she died.",
        "true"
    ],
    [
        0.3471761147181193,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '775'}",
        "Write an excellent summary of the given text.\n\nTitle: Boba Fett and the Predator both crash land on the same planet.  Both are aware of each other's presence, both are aware of where the other one crashed, and both want to kill the other.  Who wins?  Why?\n\nText: **The Arena:**\n\nBoth parties crashland in a jungle part of the planet.  Within five miles is an abandoned colony, with extra food, ammunition, medical supplies, weapons, a communications device, and one spaceship in which party(ies) can escape the planet.\n\nThe jungle itself is full of fauna that could conceivably kill either party if they were weakened enough.  However, this also leaves a food supply large enough so that either could survive indefinitely.\n\n**The Weapons:**\n\nPredator's working equipment include combi-stick, wristblades, cloaking device, self destruct, health syringes, explosive darts, mask with infrared vision, speargun, and shoulder cannon.\n\nBoba Fett's working equipment includes his helmet, an EE-3 Carbine Rifle, Tenloss DXR-6 Disruptor rifle, blaster pistol, concussion grenade launcher, wrist mounted flamethrower, short burst jetpack, and wrist mounted laser.   \n\n**NOTE:** Boba Fett's helmet includes infrared vision, motion sensor, sound sensor, a rangefinder, and an environmental filter system.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3471674422423045,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '867'}",
        "It is probably not the case that either 'Greg is a frog' or 'Sandra took the milk' but not both.",
        "invalid"
    ],
    [
        0.3471355189879735,
        "{'dataset_id': 'blimp', 'config_id': 'adjunct_island', 'row_id': '217'}",
        "Who can Danielle find without embarrassing Brian?",
        "False"
    ],
    [
        0.34712858498096466,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '16'}",
        "[{'id': 'unknown_1a', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1b', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1e', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1f', 'response': \"I don't know\"}, {'id': 'unknown_1g', 'response': 'Contentious according to current standards'}]",
        "𝙯𝙞𝙜𝙚𝙪𝙣𝙚𝙧"
    ],
    [
        0.3471236328283946,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '740'}",
        "The findings from the Los Angeles County Department of Public Health come as friction mounts between the beverage industry and health advocates over the best way to fight obesity and diabetes, tied by studies to over-consumption of soda, sweets and junk food. “There have been a lot of arguments against this sort of policy,” including claims it will cost the poor more to buy food, said Paul Simon, head of chronic disease prevention for the county and lead author of the study. But Simon said nearly two-thirds of those surveyed by the county in a broad 2011 assessment of public attitudes toward health issues, said they supported a soda tax, and three-quarters favored limiting junk food advertising. Public health advocates across the country have clamored for ways to reduce consumption of sugary drinks and junk food, but lawmakers and voters have generally opposed enacting taxes or other regulations. Lawmakers in Illinois rejected a measure in late May that would have taxed soda purchases at one cent per ounce, and a tax proposed for California failed in the state Legislature last year. On Wednesday, an attorney for New York City asked the state’s top court to revive the city’s ban on large sugary drinks, which was overturned by a lower court last year. In California, a measure to require warning labels on sodas passed the state Senate last week. The industry association CalBev downplayed the Los Angeles survey and other polls showing support for such restrictions. “A polling question asked in a vacuum without any context often gives the impression that voters support these types of taxes, but the reality is when you put it directly to the voters they always go down in defeat,” the association said Thursday. Simon and his colleagues analyzed data from a survey of about 1,000 Los Angeles County adults called randomly by telephone. They found support for such restrictions to be highest among low-income residents, whose obesity and diabetes rates are highest. “It’s described as regressive, that it would discriminate against poorer people because they have less money,” Simon said. “Nonetheless we found in our study that there is more support among those groups.”",
        "true"
    ],
    [
        0.34712066253026325,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '641'}",
        "[{'follow_up_question': 'Are you the tenant-operator or owner-operator of a family farm after loan closing?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.3471170663833618,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '30'}",
        "[{'id': 'unknown_1a', 'response': 'Weet ik niet'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Onleesbare OCR'}]",
        "𝙈𝙖𝙧𝙧𝙤𝙣"
    ],
    [
        0.34711440404256183,
        "{'dataset_id': 'blimp', 'config_id': 'adjunct_island', 'row_id': '543'}",
        "Who had Ellen respected without talking to Clyde?",
        "False"
    ],
    [
        0.3471025824546814,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '663'}",
        "This is not accurate because it implies the writer doesn't want to separate physically, but the post says this is impossible because of their schedules.",
        "Accuracy"
    ],
    [
        0.3470723976691564,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '29'}",
        "[{'id': 'unknown_1a', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1b', 'response': 'Not contentious'}, {'id': 'unknown_1d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1e', 'response': \"I don't know\"}, {'id': 'unknown_1f', 'response': 'Not contentious'}, {'id': 'unknown_1g', 'response': 'Contentious according to current standards'}]",
        "𝙋𝙮𝙜𝙢𝙚𝙚"
    ],
    [
        0.3470619171857834,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '122'}",
        "It is probably not the case that 'John moved to the office' or 'Lily is a swan' or both.",
        "invalid"
    ],
    [
        0.3470315585533778,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '418'}",
        "It is highly likely that Julius is gray. It is almost certain that Gertrude is a cat. It is improbable that Bernhard is a swan. It is improbable that if 'Julius is gray' or 'Gertrude is a cat' or both then Greg is a lion. It is unlikely that if either 'Gertrude is a cat' or 'Julius is gray' but not both then John picked up the apple. It is likely that if either 'Gertrude is a cat' or 'Julius is gray' but not both then Mary discarded the milk.",
        "invalid"
    ],
    [
        0.34701622525850934,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '35'}",
        "It is impossible that either 'Bernhard is green' or 'Brian is a rhino' but not both.",
        "invalid"
    ],
    [
        0.34696638584136963,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'ja', 'row_id': '162'}",
        "もっとすっきりしたのを買えばよかったと、ちょっと後悔してますが、まあ安かったので仕方ないです＾＾普通に使えますが、次は買わないね",
        "counterfactual"
    ],
    [
        0.34696638584136963,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'ja', 'row_id': '162'}",
        "もっとすっきりしたのを買えばよかったと、ちょっと後悔してますが、まあ安かったので仕方ないです＾＾普通に使えますが、次は買わないね",
        "counterfactual"
    ],
    [
        0.3469598740339279,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '819'}",
        "It is probably not the case that either 'Greg is a frog' or 'Bernhard is gray' but not both.",
        "invalid"
    ],
    [
        0.34695566693941754,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '846'}",
        "Write an excellent summary of the given text.\n\nTitle: Do I have to disclose ALL previous employment when applying for jobs/is my reason for doing so good enough?\n\nText: I'm thinking about taking time off from my education but if I'm going to do that I need to get a full time job fairly quickly. I'd like to get a job that will look good for when I eventually apply to grad school (for speech language pathology), so most likely in the education field and/or working with disabled children. My problem is that I quit a full-time job in education this summer because I couldn't stand the living conditions I was faced with (it was overseas). Do I have to put this job that I only worked a month at on my resume? My thought is that quitting that quickly looks really bad but maybe it'd be worse to leave it off, what do you think?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.346955547730128,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '462'}",
        "It is unlikely that 'Lily is a lion' or 'Jeff went to the bedroom' or both.",
        "invalid"
    ],
    [
        0.3469252785046895,
        "{'dataset_id': 'dart', 'config_id': 'default', 'row_id': '81'}",
        "[[\"You Can't Stop the Reign (Shaquille O'Neal and The Notorious B.I.G.)\", 'YEAR', '1996'], [\"You Can't Stop the Reign (Shaquille O'Neal and The Notorious B.I.G.)\", 'ALBUM', \"You Can't Stop the Reign\"], [\"You Can't Stop the Reign (Shaquille O'Neal and The Notorious B.I.G.)\", 'PEAK_CHART_POSITIONS_UK', '40']]",
        "False"
    ],
    [
        0.3469189802805583,
        "{'dataset_id': 'qed', 'config_id': 'qed', 'row_id': '879'}",
        "William Henry Harrison spent the shortest time in office , and Franklin D. Roosevelt spent the longest . He is the only president to have served more than two terms . Following ratification of the 22nd Amendment in 1951 , presidents -- beginning with Dwight D. Eisenhower -- have been ineligible for election to a third term or for election to a second full term after serving more than two years of a term to which some other person was elected president . The amendment contained a grandfather clause that explicitly exempted the incumbent president -- then Harry S. Truman -- from the new term limitations .",
        ""
    ],
    [
        0.34691084921360016,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '829'}",
        "It is certain that Julius is yellow. It is highly likely that Bernhard is gray. It is impossible that John took the football. It is likely that if 'Bernhard is gray' or 'John took the football' or both then Mary went to the kitchen. It is unlikely that if either 'John took the football' or 'Bernhard is gray' but not both then Brian is a rhino. It is almost certain that if 'Bernhard is gray' or 'Julius is yellow' or both then Lily is a rhino.",
        "invalid"
    ],
    [
        0.3469053655862808,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '390'}",
        "On Dec. 20, 2019, the livestock industry publication Tri-State Livestock News published a wide-ranging screed against the Impossible Whopper, the livestock-free substitute burger sold at Burger King. The author of the article, South Dakota veterinarian James Stangle, made a series of dubious assertions to arrive at the conclusion that four Impossible Whoppers per day contain “enough estrogen to grow boobs on a male.” For several reasons articulated below, this conclusion is flawed. Strictly speaking, Impossible Burgers, which use soy as their protein, have no estrogen in them whatsoever. Estrogen refers to a group of sex hormones created by an animal’s endocrine system that affect myriad reproductive and other bodily processes. These chemicals, the most significant of which is estradiol, are not found in any plant-based product, including the soy protein of Impossible Whoppers. When people express concern about “estrogen” in soy products, they are actually expressing concern about phytoestrogens — a class of compounds structurally similar to but nonetheless different from estrogens. In soy products, the most relevant chemicals meeting this description are known as isoflavones. Though Stangle devotes ample space to the lesson “not all proteins are created equal,” he frequently relies on the demonstrably false assumption that phytoestrogens and estrogens are equal in terms of their effect on hormonally mediated processes.",
        "false"
    ],
    [
        0.34689969817797345,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '115'}",
        "There is almost no chance that Sandra dropped the milk. Chances are slight that John took the apple. It is highly likely that Bernhard is white. Chances are about even that if either 'Bernhard is white' or 'John took the apple' but not both then Bill went to the garden. It is likely that if 'John took the apple' or 'Bernhard is white' or both then Greg is a lion. There is a very good chance that if either 'John took the apple' or 'Sandra dropped the milk' but not both then Julius is a frog.",
        "invalid"
    ],
    [
        0.34688039124011993,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '980'}",
        "But none of the leads we’ve followed converge on a single source, much less an authoritative one. There doesn’t seem to be a source. It’s just “that story about that time Hillary Clinton got schooled by Mother Teresa” people tell at pro-life events. It is told consistently, mind you — apart from small details — but such is the case with most anecdotes this pointed and this short, regardless of whether they’re true or false. Until we encounter a citation that names an eyewitness source — or, better yet, quotes one.",
        "unproven"
    ],
    [
        0.346872220436732,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '217'}",
        "cht kan laten wedervaren zonder onzakelijk te zijn, Juist omdat de 𝙠𝙤𝙚𝙡𝙞𝙚 zoon bijzondere werkman is, hij is ondanks zijn lompen innerlijk e",
        "𝙠𝙤𝙚𝙡𝙞𝙚"
    ],
    [
        0.3468564624587695,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '837'}",
        "ﺭﻓﺘﻢ ﺩﯾﺪﻡ ﺑﺎ ﺍﺣﺘﺮﺍﻡ ﺑﻪ ﻫﻤﻪ ﺍﻭﻧﺎﯾﯽ ﮐﻪ ﺩﻭﺳﺖ ﺩﺍﺷﺘﻦ ﻭﻟﯽ ﻣﻦ ﺩﻭﺳﺖ ﻧﺪﺍﺷﺘﻢ .",
        "صدا"
    ],
    [
        0.3468023091554642,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '940'}",
        "It is probably the case that John discarded the milk. Chances are slight that Greg is green. It is probably not the case that Emily is a wolf. There is a very good chance that if either 'Emily is a wolf' or 'Greg is green' but not both then Julius is white. There is almost no chance that if 'Emily is a wolf and John discarded the milk' then Bernhard is a swan. It is impossible that if 'John discarded the milk and Greg is green' then Mary got the football.",
        "invalid"
    ],
    [
        0.3467954297860463,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '508'}",
        "Chances are slight that Bernhard is gray. There is almost no chance that Greg is a swan. It is likely that John went to the bedroom. It is impossible that if 'Bernhard is gray and Greg is a swan' then Jeff moved to the office. It is unlikely that if 'Bernhard is gray' or 'John went to the bedroom' or both then Brian is yellow. It is likely that if either 'Bernhard is gray' or 'Greg is a swan' but not both then Lily is a swan.",
        "invalid"
    ],
    [
        0.34678980708122253,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '476'}",
        "نظر شما در مورد عطر، بو، و طعم این نوشابه چیست؟",
        "طعم"
    ],
    [
        0.34678980708122253,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '504'}",
        "نظر شما در مورد عطر، بو، و طعم این نوشابه چیست؟",
        "طعم"
    ],
    [
        0.34678320089975995,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'rob_train_clean_23_test_all_23', 'row_id': '79'}",
        "[Herman]'s son is [Guy]. [Guy] and his father always go fishing together on Sundays and have a great time together. [Danny] likes to watch boxing with his brother. His name is [Guy].",
        "son"
    ],
    [
        0.34677917261918384,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '353'}",
        "It is unlikely that either 'John went to the bedroom' or 'Brian is a frog' but not both.",
        "invalid"
    ],
    [
        0.3467765798171361,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '196'}",
        "It is almost certain that Daniel put down the milk. It is impossible that Greg is a frog. It is impossible that Mary went to the hallway.",
        "invalid"
    ],
    [
        0.34676572183767956,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'ja', 'row_id': '509'}",
        "ドンデンも人情話も加われば、バラヤー帝国に疎い人物への説明の形で歴史背景の解説も（そうだったのか）が盛りだくさん。",
        "not-counterfactual"
    ],
    [
        0.34676572183767956,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'ja', 'row_id': '509'}",
        "ドンデンも人情話も加われば、バラヤー帝国に疎い人物への説明の形で歴史背景の解説も（そうだったのか）が盛りだくさん。",
        "not-counterfactual"
    ],
    [
        0.3467651804288228,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '441'}",
        "The first sentence of the summary is not an accurate representation of the post.",
        "Accuracy"
    ],
    [
        0.3467487245798111,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '504'}",
        "It is impossible that 'Bernhard is gray' or 'Lily is yellow' or both.",
        "invalid"
    ],
    [
        0.3467237055301666,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '361'}",
        "Lexicon shares, which have lost about 15 percent of their value last year, fell as much as 7.5 percent to $1.85 on the Nasdaq in early trading on Monday. The company said Arthur Sands, CEO since 1995 and a co-founder, intends to develop a succession plan with the board. He will continue in his position until a successor is appointed. Analysts said Sands might have been perceived as more of a scientist who would not be able to lead the company into a commercial launch of the late-stage drugs. “I think Arthur Sands could have easily done the transition to commercial, but possibly the board felt they wanted someone with direct commercial experience”, Wedbush analyst Liana Moussatos said. Lexicon said it would cut 115 jobs, primarily positions in research and discovery, to reduce costs. The company said it would focus mainly on its drugs to treat diabetes and carcinoid syndrome, a condition which affects some people with a rare cancerous tumor. “Most of the value of the company is wrapped up in these late-stage drugs,” Morningstar analyst Karen Andersen said. “It makes sense to focus on what investors are really looking at.”  Lexicon said it expects to lower expenses by about $14 million, net of severance costs and some other charges, for the rest of 2014. It expects to save about $22 million annually. “This could give them an extra two to three quarters of cash,” Moussatos said. The company had $151.2 million in cash and investments as of September 30 last year. Andersen said Lexicon needed to conserve cash while it looked for a partner to fund the development of its diabetes drug. “In order to do a comprehensive diabetes program, it takes hundreds of millions of dollars, which is more than Lexicon can afford right now,” she said. The company is testing two other drugs in mid-stage trials to treat irritable bowel syndrome and rheumatoid arthritis. It also has a glaucoma drug in early-stage development. Moussatos said that Lexicon could license the development of the drugs to other pharmaceutical companies. Lexicon has drug discovery agreements with Bristol-Myers Squibb Co, Roche Holding AG’s unit Genentech and Takeda Pharmaceutical Co Ltd.  Lexicon shares, which once traded above $40, were down 4.5 percent at $1.91.",
        "true"
    ],
    [
        0.34672045210997265,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '952'}",
        "It is probably not the case that Jessica is a mouse. It is impossible that Greg is green. Chances are slight that John went to the garden. There is almost no chance that if 'John went to the garden' or 'Greg is green' or both then Brian is yellow. It is probably not the case that if either 'Greg is green' or 'Jessica is a mouse' but not both then Emily is a cat. It is probably the case that if 'Greg is green' or 'John went to the garden' or both then Mary got the milk.",
        "invalid"
    ],
    [
        0.3467193692922592,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '376'}",
        "It is probably not the case that 'Brian is a frog and Lily is green'.",
        "invalid"
    ],
    [
        0.34671856959660846,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '895'}",
        "[{'follow_up_question': 'Was the property a gift (there are different rules if it was to your spouse, civil partner or a charity)?', 'follow_up_answer': 'No'}, {'follow_up_question': 'did you inherit it?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Did you sell it for less than it was worth to help the buyer?', 'follow_up_answer': 'Yes'}]",
        "False"
    ],
    [
        0.346710537870725,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '377'}",
        "It is highly unlikely that Emily is a wolf. There is a very good chance that Sandra dropped the milk. We believe that Winona is a cat. It is highly unlikely that if 'Sandra dropped the milk' or 'Emily is a wolf' or both then Jeff went to the hallway. We believe that if 'Sandra dropped the milk' or 'Emily is a wolf' or both then Greg is a rhino. It is probably the case that if 'Winona is a cat and Emily is a wolf' then Bernhard is a frog.",
        "invalid"
    ],
    [
        0.3466987709204356,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '918'}",
        "سلام به همه  خدا رحمتت کنه صادق هدایت که نبودی و نیستی که پرپر کردن برگرفته از داستانت را ببینی واقعا بهتره به جای اشاره کردن به برگرفته از آثار ادیبان نام آشنا بزنند نگاهی عجیب به این داستانها...",
        " داش آکل"
    ],
    [
        0.3466941962639491,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '826'}",
        "There is almost no chance that Bernhard is yellow. Chances are slight that Winona is a cat. It is probable that John went to the garden. It is certain that if either 'Winona is a cat' or 'John went to the garden' but not both then Greg is a rhino. Chances are slight that if either 'John went to the garden' or 'Bernhard is yellow' but not both then Mary grabbed the milk. Chances are slight that if either 'Bernhard is yellow' or 'Winona is a cat' but not both then Brian is white.",
        "invalid"
    ],
    [
        0.3466786742210388,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '85'}",
        " woorden van den heer Effendi, van wien hij niet begreep, hoe een 𝙞𝙣𝙝𝙚𝙚𝙢𝙨 lid zo over de inheemse bevolking kon spreken als hij deed.De reg",
        "𝙞𝙣𝙝𝙚𝙚𝙢𝙨"
    ],
    [
        0.3466635197401047,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '176'}",
        "It is impossible that 'Mary went to the garden' or 'Lily is a lion' or both.",
        "invalid"
    ],
    [
        0.34665152430534363,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '441'}",
        "We believe that Fred put down the apple. It is improbable that Greg is a rhino. There is a better than even chance that John took the football. It is highly unlikely that if either 'Fred put down the apple' or 'Greg is a rhino' but not both then Mary went to the office. It is probable that if either 'John took the football' or 'Fred put down the apple' but not both then Brian is green. We believe that if either 'Fred put down the apple' or 'John took the football' but not both then Bernhard is a lion.",
        "invalid"
    ],
    [
        0.34662923216819763,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '57'}",
        "[{'id': 'unknown_1a', 'response': 'Weet ik niet'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1e', 'response': 'Niet omstreden'}, {'id': 'unknown_1f', 'response': 'Weet ik niet'}, {'id': 'unknown_1g', 'response': 'Weet ik niet'}]",
        "𝙈𝙚𝙩𝙞𝙨"
    ],
    [
        0.34661632279555005,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '404'}",
        "t zn bed belde, en als ik niet \" „Wie was die klant,\" sneed Vork af.𝙋𝙖𝙜𝙚 grinnikte.\"Dat raadt V nooit de gezant van Hileria!\"Vork keek echte",
        "𝙋𝙖𝙜𝙚"
    ],
    [
        0.3466148028771083,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '898'}",
        "Chances are about even that Mary got the football. We doubt that Bernhard is a rhino. There is little chance that Julius is a frog. It is highly unlikely that if 'Bernhard is a rhino and Julius is a frog' then Emily is a cat. There is a very good chance that if 'Bernhard is a rhino' or 'Julius is a frog' or both then Greg is a frog. There is little chance that if 'Julius is a frog and Bernhard is a rhino' then John went to the office.",
        "invalid"
    ],
    [
        0.34660038352012634,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '617'}",
        "There is almost no chance that John went to the garden. It is unlikely that Sandra grabbed the apple. It is almost certain that Greg is green. It is impossible that if either 'Sandra grabbed the apple' or 'John went to the garden' but not both then Daniel got the milk. It is impossible that if 'John went to the garden' or 'Greg is green' or both then Yann is hungry. It is unlikely that if either 'John went to the garden' or 'Greg is green' but not both then Lily is a lion.",
        "invalid"
    ],
    [
        0.3465966780980428,
        "{'dataset_id': 'blimp', 'config_id': 'adjunct_island', 'row_id': '399'}",
        "Who is Randolf confusing while approaching Galileo?",
        "False"
    ],
    [
        0.3465949247280757,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '765'}",
        "Write an excellent summary of the given text.\n\nTitle: Need help convincing my parents to go my first ever (real) party!\n\nText: I'm going to be graduating high school next friday (the 27th) and there is a party right after at somebody's house. Problem is, my mom set up something the same day with family even though we're going to have another family party the next day! She makes me feel guilty by telling me that the family is there for me and I won't be there... but I feel like i'll regret not going to the final shabang, you know? Also I'm 19 and I've never been to a party before. I'm not awkward, I just have trouble standing up to my mom. I'm wondering if anyone can give me advice on this? Thanks!\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3465912838776906,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '543'}",
        "This story barely meets the criterion. It discusses costs, and does a good job of emphasizing that most treatments that reduce the appearance of wrinkles have only temporary effects and need to be repeated indefinitely, often at great cost. However, it lacks specific figures about the cost of the new laser device. The story does emphasize that the effects of this device are much smaller than those of cosmetic treatments offered by dermatologists; but the magnitude of the difference is not defined. Also, this statement is made without reference to any evidence to support a conclusion about the relative effectiveness of the device compared to established procedures. The dermatologist quoted in the story says, “I think you’re looking at a device that’s going to only produce a single digit fraction of results as compared to what you can get in a dermatologist’s office.” The meaning of “a single digit fraction” is a mystery left unanswered in this story. The medical correspondent states the obvious by pointing out that a device used at home would be more convenient than going to a physician for treatment. Although the headline of this story is about a home laser device, there is almost no discussion of the device itself. A dermatologist warns against a tendency to “over-abuse and overuse,” but these terms are not defined. No evidence is discussed. Indeed, the manufacturer refused requests from other news organizations for details about the device, so there are no facts to report. What’s more, when discussing laser treatments done by a dermatologist, the correspondent relies on a single set of before-and-after photographs of a patient, without making reference to any controlled trials or other scientific evidence. The story repeatedly confuses wrinkles with aging. Wrinkles are not a disease. Treatments that reduce the appearance of wrinkles have no effect on the underlying process of aging… or of certain conditions that affect the appearance of the skin. A person who has wrinkles burned or scrubbed away or disguised by cosmetic treatments is no younger or healthier than someone who covers up the wrinkles with make-up. This story feeds misconceptions about health and aging. In an odd reversal of the usual pattern of stories that fail to meet this criterion, this report included only doctors who were independent of the company marketing this laser device. There was no interview or other information that came from anyone with first-hand knowledge of the device, how it was tested, or what results it has demonstrated in trials. Viewers were left to figure out on their own that the dermatologist interviewed for this story has a vested interest in persuading people to pay him or his colleagues for treatment, rather than trying an over-the-counter device. There were no quotes or statements from professional societies, public agencies, or others who could offer an independent overview of the pros and cons of the new device. Most of this report is about alternative procedures, so it would seem to meet this criterion. However, the lack of information about the new device makes any meaningful comparisons impossible. This one is a close call. The story does state that the device has received FDA approval, but is not yet available. However, the absence of any detail about device or the manufacturer leaves viewers in the dark. There are other devices available to consumers that use “light therapy” to affect the appearance of the skin. Since this story provided no information about the recently-approved device, it is impossible to tell whether or how it may be different from competing products. By looking at other sources, it does appear that this device is the first laser specifically approved for over-the-counter treatment of wrinkles; but this distinction is not clear from viewing the story. The story included an interview with a dermatologist and does not appear to rely only on a news release.",
        "false"
    ],
    [
        0.3465671141942342,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '39'}",
        "[{'id': 'unknown_1a', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Weet ik niet'}, {'id': 'unknown_1e', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Niet omstreden'}]",
        "𝙈𝙤𝙨𝙡𝙞𝙢𝙨𝙘𝙝𝙚"
    ],
    [
        0.3465646654367447,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'ja', 'row_id': '374'}",
        "not-counterfactual",
        "と思いました^^"
    ],
    [
        0.3465646654367447,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'ja', 'row_id': '374'}",
        "not-counterfactual",
        "と思いました^^"
    ],
    [
        0.3465602993965149,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '3'}",
        "\"No discussion of costs – a recurring and significant oversight. The claims of \"\"100% accuracy\"\" and that \"\"The investigators found that after just one laser treatment, misfiring ceased in 84 percent of the treated veins, and 90 percent remained inactive three months after treatment\"\" aren’t put into any meaningful context about what difference this made in patient outcomes. Of course, what can you possibly say about outcomes after just three months? Which is exactly the point of raising this issue at all. No discussion of harms. No discussion of the limitations of drawing conclusions from a study of just 27 people. No explanation of whether destroying misfiring cells with \"\"100% accuracy\"\" actually makes a difference in people’s lives and outcomes. No overt disease mongering. However, to say that \"\"about 2.2 million Americans currently live with an irregular heartbeat condition, known as atrial fibrillation\"\" in the same breath as describing a study of just 27 people may imply that this very small study has immediate ramifications for all 2.2 million. And it does not. Barely satisfactory. There’s actually no interview – only a rehash of what was published in a journal, restated from a news release. No independent source cited. Again, the comparison of the \"\"new approach\"\" with existing approaches is superficial and unhelpful. And there was no comparison of performance or outcomes data. Terribly incomplete on this point. It is never made clear whether the device and approach are still experimental or already in clinical use. The word \"\"new\"\" was used five times in the short story. Yet the real novelty of this approach is only scantily and insufficiently described – especially if the implication is that this has relevance for 2.2 million Americans. The story admits it’s based on an American Heart Association news release. There’s no sign of any independent reporting or vetting.\"",
        "false"
    ],
    [
        0.3465501268704732,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '779'}",
        "['Although many distinct mutations in a variety of genes are known to cause Amyotrophic Lateral Sclerosis (ALS), it remains poorly understood how they selectively impact motor neuron biology and whether they converge on common pathways to cause neuronal degeneration.', 'Here, we have combined reprogramming and stem cell differentiation approaches with genome engineering and RNA sequencing to define the transcriptional and functional changes that are induced in human motor neurons by mutant SOD1.', 'Mutant SOD1 protein induced a transcriptional signature indicative of increased oxidative stress, reduced mitochondrial function, altered subcellular transport, and activation of the ER stress and unfolded protein response pathways.', 'Functional studies demonstrated that these pathways were perturbed in a manner dependent on the SOD1 mutation.', 'Finally, interrogation of stem-cell-derived motor neurons produced from ALS patients harboring a repeat expansion in C9orf72 indicates that at least a subset of these changes are more broadly conserved in ALS.']",
        "False"
    ],
    [
        0.34654835363229114,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '43'}",
        "[{'id': 'unknown_1a', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1b', 'response': \"I don't know\"}, {'id': 'unknown_1d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1e', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1f', 'response': 'Not contentious'}, {'id': 'unknown_1g', 'response': 'Contentious according to current standards'}]",
        "𝙄𝙣𝙗𝙤𝙤𝙧𝙡𝙞𝙣𝙜"
    ],
    [
        0.3465439627567927,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '648'}",
        "It is highly unlikely that 'Brian is white' or 'John went to the office' or both.",
        "invalid"
    ],
    [
        0.346534584959348,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '367'}",
        "It is unlikely that Lily is green. It is certain that Jason is tired. We believe that Mary got the apple. Chances are about even that if either 'Jason is tired' or 'Lily is green' but not both then John went to the kitchen. Chances are slight that if 'Mary got the apple' or 'Lily is green' or both then Greg is a rhino. There is a better than even chance that if 'Lily is green' or 'Mary got the apple' or both then Bernhard is white.",
        "invalid"
    ],
    [
        0.3465241938829422,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '813'}",
        "Write an excellent summary of the given text.\n\nTitle: I feel bad. Did I do the wrong thing?\n\nText: For a university project I had to work together with someone I know fairly well. However the communication between us was bad. During the year I worked on it on my own, while he was busy with other tasks (other projects he also was enrolled in). Only on the day before the deadline did we really work together. It seems as if he wanted to put enough effort into it, but didn't have the time or the skills.\n\nI send an email to inform them that he didn't contributed that much. Today we had to present/defend our project and they asked some normal questions about the project to gauge the situation. He couldn't answer them correctly. They continued by asking detailed question on how the work was divided.. that was really annoying. And I felt bad when they asked him a specific question and he couldn't answer.\n\nAfter the presentation I could see he felt bad. And I didn't know what to say. Now I feel bad myself because I informed them about the problem. I feel I could have tried harder to get him to work, or talked about it in person first. I tried to pretend there wasn't a problem, still talked to him normally.. So what's bothering me now is that I did the wrong thing, and that I now think he basically hates me, or at least lost a lot of trust.\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34651904304822284,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '332'}",
        "\"The factual claims made in a Facebook video entitled \"\"Is your food fake or real? Find out with these 16 easy tests at home!\"\" are valid.\"",
        "false"
    ],
    [
        0.3465186655521393,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '936'}",
        "(1) Тургенев в одном письме раздраженно полемизирует с методом Толстого. (2) Он говорит: Толстой описывает, как блестели сапоги Наполеона, и читателю кажется, что Толстой все знает о Наполеоне. (3) На самом деле он ни черта о нем не знает. (4) Наполеон – мировоззренческий враг Толстого. (5) По Толстому, обновить человечество можно, только если человек, сам себя воспитывая, освободит себя изнутри. (6) Именно этим Толстой и занимался всю жизнь. (7) По Толстому, только так можно было и нужно было завоевывать человечество. (8) И Толстой, как новый Кутузов, изгоняет Наполеона из области духа. (9) Поэтому, по Толстому, Наполеон — это огромный солдафон и судить о нем незачем выше сапога. (10) Пускать в ход собственный могучий психологический аппарат даже для отрицательной характеристики Наполеона Толстой не намерен. (11) Он боится этим самым его перетончить. (12) По Толстому, сложность зла есть надуманная сложность. (13) В Наполеоне Толстого никакого обаяния. (14) Словно предчувствуя трагические события двадцатого века, он пытается удержать человека от увлечения сильной личностью, от еще более кровавых триумфаторов. (По Фазилю Искандеру)",
        "False"
    ],
    [
        0.34648177524407703,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '186'}",
        "It is impossible that either 'Bill moved to the office' or 'Greg is a rhino' but not both.",
        "invalid"
    ],
    [
        0.34647081792354584,
        "{'dataset_id': 'sagnikrayc/quasar', 'config_id': 'quasar-s', 'row_id': '798'}",
        "['Question : I am trying to fetch all MLS agents using phrets but everything I try returns nothing . The goal of this is to be able to get more info about a salesperson of an MLS listing . If that is not possible is there any way how I can figure out all available fields for that class Comment : If you are a vendor developer you most likely do not have access to the agents table in your data feed . I m a vendor for a MLS and we do not have access to that data as it is restricted . Comment : Hey I was able to get additional information by looking up each agent of a listing by e-mail address we do have access to their phone-number website e-mail address and full name - see the accepted answer and its comments . .. . Answer : You can enter in your RETS login information into RETS M.D . http : retsmd.com and it will return all metadata and fields for each class ResidentialProperty Agent etc . If you want to get the listing agent s information for a specific MLS listing and you have the MLS ID it would be something like this : .. . .. . If you wanted to run a search query to return all Agents from a RETS Server your DMQL might search for all agents with a status of Active . Comment : I will try that tomorrow thanks . But what exactly do you mean with login into RETS M.D . What is the RETS MD Comment : Forgot to put the link : retsmd.com http : retsmd.com . Comment : Thank you . I don t really have the agent s public ID but my listings contain the agent s e-mail address . With that I can search the agent . RETS MD seems to be a very handy tool', 'Question : I have partially developed a property website that fetch properties data from a RETS IDX . You may know that RETS server listened to port 6103 over http protocol . My website is deployed on a shared-hosting due to which I can not connect to 6103 port . I do have a dedicated-server which allows connect to port 6103 . I want to use this dedicated-server as a middle-tier between my website and the RETS IDX server . My problem is I want to develop that middle-tier script i.e HTTP Tunnel . My website will send all RETS request to this Tunnel that will meanwhile sent it to the RETS IDX server and its response will be sent back to the website at the same moment . RETS Server also requires to login so the session should be maintained properly . I want to have quick best solution to do the job . May be through .htaccess or streaming php script or may be some third party script can also cut some of my time . I would love to hear any thought or suggestion you have . P.S : I can not move my website to a dedicated-server because in near future I am going to have plenty of them and they would cost too much . .. . Answer : You can achieve this by using curl s PHP extension . An example code could be : .. . .. . Obviously you have to add protection perhaps add .htaccess .htpasswrd protection to it . A more complete code with cookie support and such can be found there : https : github.com cowboy php-simple-proxy Comment : It wont send the received headers to url . Also it does not have the ability to save session . I want the script to send every received information to url or forwarding url i.e . headers session-cookies http authentication everything with a single difference of the url and port-number .', 'Question : I get XML files for rets server by following this document http : www.mredllc.com 5Crets 5Cdocuments 5CRETS 20Developer 20Start 20Guide1.pdf . i can see the many xml files for my rets server over there . now i want to display all the property listing into my wordpress site . What is the processor i have to follow for it . thank you .. . Answer : Please try phRets library to deal with rets in php . phRets handles decode xml to array internally . phRets have very good documentation . phRets on github : https : github.com troydavisson PHRETS', 'Question : I have partially developed a property website that fetch properties data from a RETS IDX . You may know that RETS server listened to port 6103 over http protocol . My website is deployed on a shared-hosting due to which I can not connect to 6103 port . I do have a dedicated-server which allows connect to port 6103 . I want to use this dedicated-server as a middle-tier between my website and the RETS IDX server . My problem is I want to develop that middle-tier script i.e HTTP Tunnel . My website will send all RETS request to this Tunnel that will meanwhile sent it to the RETS IDX server and its response will be sent back to the website at the same moment . RETS Server also requires to login so the session should be maintained properly . I want to have quick best solution to do the job . May be through .htaccess or streaming php script or may be some third party script can also cut some of my time . I would love to hear any thought or suggestion you have . P.S : I can not move my website to a dedicated-server because in near future I am going to have plenty of them and they would cost too much . .. . Answer : I d personally go for the Reverse Proxy http : en.wikipedia.org wiki Reverse proxy approach . This will allow you to intelligently forward requests based on configurable criteria . Both Apache and nginx have reverse proxy capabilities in fact it was nginx s original purpose . For Apache you need to use mod-proxy while nginx has the functionality built-in unless you explicitly disable it before compiling . Of these two options I personally prefer nginx it is robust and lightweight and completely fit for purpose . I find Apache more cumbersome but if you already have Apache set up on your dedicated-server you may prefer to use that instead . The beauty of using web servers to proxy is that they understand the underlying protocol . They will preserve headers modify cookies preserve sessions and translate hostnames correctly . .. . .. . Apache Config .. . .. . In both cases configuration is very straightforward the Apache config looks something like the following : .. . .. . There s also options for tweaking cookies setting timeouts etc . All of which can be found in the mod-proxy documentation http : httpd.apache.org docs 2.2 mod mod proxy.html .. . .. . You should note that this cannot go in a .htaccess file . It must go in the main server config . .. . .. . nginx Config .. . .. . Equally as simple .. . .. . Again tons of options in the HttpProxyModule documentation http : wiki.nginx.org HttpProxyModule for caching rewriting urls adding headers etc . .. . .. . Please do consult the docs . I ve not tested either of these configurations and they may be a little off as they re from memory + a quick google . Make sure you test your app by proxying to an unreachable server and ensure it handles failures correctly since you are introducing another point of failure . I m working on the assumption you are able to configure your own dedicated-server . If this is not the case your hosts may be willing to help you out . If not leave me a comment and I ll try and come up with a more robust curl option . Comment : Perfect This is exactly what I was looking for . I have implemented it locally on my machine . It work good for the first couple of request signing in after that I get 404 error . May be we need to add some parameter to keep the connection alive or may be it is not passing the cookies session Comment : @FatalError : You ll have to hit the log files and find out exactly what the 404 was for . Was it a 404 on your proxying server because a redirect was returned and it didn t cater for it or was it a 404 on the RETS server and it just got forwarded back to you . Set logging to stun and be prepared to write a bunch of rules to cater for everything : Comment : Proxy is not working for multipart contents i.e . images . Can you look at serverfault.com questions 410730 http : serverfault.com questions 410730 apache-proxypass-rewriterule-with-p-flag-return-no-content-when-response-has-mu', 'Question : I am trying to fetch all MLS agents using phrets but everything I try returns nothing . The goal of this is to be able to get more info about a salesperson of an MLS listing . If that is not possible is there any way how I can figure out all available fields for that class Comment : If you are a vendor developer you most likely do not have access to the agents table in your data feed . I m a vendor for a MLS and we do not have access to that data as it is restricted . Comment : Hey I was able to get additional information by looking up each agent of a listing by e-mail address we do have access to their phone-number website e-mail address and full name - see the accepted answer and its comments . .. . Answer : To figure out all available fields of a class use', 'Question : I am trying to do get a response from NWMLS web service using PHP with XML query parsing as in below source code which returns as beneath the error . There are similar questions in SO but those solutions doesn t worked out for me . How to resolve this .. . .. . Source Code : .. . .. . Instead of listing I am facing the below issue .. . .. . ERROR : .. . .. . Could not find schema information for the element urn : evernet.nwmls.com evernetqueryservice evernetquery.asmx WSDL : for EverNetQuerySpecification Message Head UserId Password SchemaName Body Query MLS PropertyType BeginDate EndDate Status Filter Comment : Please post properly formatted code what you ve posted is totally unreadable . Use the tool to mark code not the quotation tool . .. . Answer : s.no Check lists 1 . extension php openssl.dll - Enabled 2 . default socket timeout - 60 3 . allow url fopen - On 4 . local cert try this .. . 5 . www in URL - Present 6 . WSDL - Enabled 7 . soap.wsdl cache enabled - 1 8 . The httpd.conf - time out - 600 very important .. . .. . These are the configuration combination I tried and resolved from localhost wamp not from live server . In addition to get a output value in included the below']",
        "rets"
    ],
    [
        0.34646639227867126,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '426'}",
        "There is almost no chance that either 'Brian is a swan' or 'John moved to the garden' but not both.",
        "invalid"
    ],
    [
        0.3464490920305252,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '476'}",
        "[{('Francisco', 'son', 'Leonard'): [('Francisco', 'son', 'Wayne'), ('Wayne', 'brother', 'Leonard')]}, {('Wayne', 'brother', 'Leonard'): [('Wayne', 'mother', 'Cindy'), ('Cindy', 'son', 'Leonard')]}]",
        "son"
    ],
    [
        0.3464490920305252,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '655'}",
        "[{('Francisco', 'son', 'Leonard'): [('Francisco', 'son', 'Wayne'), ('Wayne', 'brother', 'Leonard')]}, {('Wayne', 'brother', 'Leonard'): [('Wayne', 'mother', 'Cindy'), ('Cindy', 'son', 'Leonard')]}]",
        "son"
    ],
    [
        0.34642264743645984,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '365'}",
        "The decision by Cleveland County District Judge Thad Balkman in Norman, Oklahoma, came in the first case to go to trial out of 2,700 nationally by states, counties and cities seeking to hold drug companies responsible for the deadly epidemic. Balkman reduced the amount he had awarded in August by $107 million after agreeing with New Brunswick, New Jersey-based J&J that he had made a math error. J&J said it will appeal, and that the award and finding of liability were “neither supported by the facts nor the law.”  A spokesman for Oklahoma Attorney General Mike Hunter said that office is reviewing the decision and will formally respond within the next few days. Opioids were involved in almost 400,000 overdose deaths from 1999 to 2017, according to the U.S. Centers for Disease Control and Prevention. Following a non-jury trial, Balkman ruled in August that Oklahoma had proven that J&J engaged in misleading marketing about the benefits of painkillers, and that their addictive risks caused a public nuisance in the form of the opioid crisis. Hunter had sought to have J&J pay $17 billion to help fund addiction treatment and other services to repair damage from the opioid epidemic over the next 30 years. Balkman, however, awarded only enough money for one year of programs, saying Oklahoma failed to support its claims regarding the need to abate the epidemic in future years. Following the August ruling, Oklahoma asked Balkman for permission to return to his courtroom annually to prove those costs, but Balkman on Friday maintained his prior ruling. J&J, meanwhile, argued that it deserved a $355 million credit, reflecting pre-trial settlements by the drugmakers Purdue Pharma LP and Teva Pharmaceutical Industries Ltd.  Balkman concluded on Friday that state law did not allow such credits. Last month, J&J and four other companies proposed a $48 billion settlement framework to resolve all of the opioid cases they face, with J&J paying $4 billion. Lawyers for the local governments have opposed the proposal. If approved, the settlement would let J&J resolve some of the thousands of product liability lawsuits it faces. The company also faces litigation over whether its baby powder causes cancer, a claim it denies.",
        "true"
    ],
    [
        0.34641946852207184,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '285'}",
        "This article does an excellent job of putting a new finding about the benefits of echinacea in context of previous research. Too often an article will report the new findings and only much lower in the story mention that it contradicts earlier work. From the first paragraph the reporter lets us know we’re getting only the latest news about a messy, unresolved area of study. The reporter also does a first-rate job of gathering a range of sources to put the findings in context. This article goes well beyond the minimum researcher-plus-one-outside-source requirement, with great benefit to readers. But the story falls short in the area of helping readers make informed decisions based on the findings. The article doesn’t provide enough information on the magnitude of the benefits, the costs of the treatment, or the alternatives. This may leave a reader informed but not well prepared to make a decision about how these findings apply to their own lives.",
        "true"
    ],
    [
        0.34641748170057934,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '649'}",
        "\"Dan Fanelli, a retired airline captain and Republican running against U.S. Rep. Alan Grayson, who represents the Orlando, Fla., area, has a catchy video on his website related to the health care bill dubbed \"\"Obamacare. \"\"Set in a doctor's office with somber orchestral music as the backdrop, a sympathetic doctor rolls up his chair to talk to an elderly white-haired man in a patient's gown. \"\"I'm sorry. I've tried everything,\"\" the doctor says. \"\"But doctor, I've already waited over six months,'' says the patient. \"\"I can't bear this any longer. \"\"\"\"It's not that it's ...,\"\" the kind doctor hesitates, placing his hand on the patient's shoulder. \"\"They denied you because you passed the age limit for the treatment. \"\"The depressed old man's gaze averts downward -- perhaps a hint that he realizes he will die?Will the new health care bill approved by Congress translate to denying treatment to sweet old men like the one featured in the video? Will somber-faced doctors be telling grandpa that he is too old for treatment? We had to check this out. First we contacted Fanelli, who said he posted the video on his website in late March. We asked if he could point us to any documentation -- such as a section of the bill, a position paper from an organization -- to support his conclusion about age limits. The simple answer: no. \"\"You are asking for substantiation. I can't go to a page in the bill but what I can tell you is the country is over $13 trillion in debt. ... The medical program increases the number of recipients substantially. When you increase the number dramatically ... where is the money going to come from? It is obvious it's going to have to be only certain people are going to get certain coverages. ... The commercial is to show what is going on in other countries with socialized medicine. You can't add more services when you don't have enough money to pay the government bills currently, and that's what we've done. \"\"Fanelli said he has his own family experience to draw his conclusions. \"\"My aunt lives in France and had been denied for a procedure,\"\" to get a pacemaker, he said. \"\"The reason she was denied was because she was too old. Common sense tells me when you increase the number of people covered, and you don't have enough money to go around ... there's eventually going to come to point where we say what can we afford, what we can't afford.\"\" Ultimately his French aunt was able to get the procedure, according to Fanelli.Fanelli said the video \"\"is a metaphor for what is used in England where they use age to determine what services people are going to get. \"\"Our friends at FactCheck.org researched a question about age limits and health care in England in July 2009. The article quoted a nonprofit in England, Age Concern and Help the Aged, that ageism does occur -- for example a doctor refusing to refer an elderly patient to a consultant. But the nonprofit also stated that a national organization was created to improve health care for the elderly and one of its standards was \"\"rooting out age discrimination. \"\"Steve Ullmann, professor and director of Programs in Health Sector Management and Policy at the University of Miami, said \"\"there is some limitation in provisions of care of people based on age in England,\"\" for certain treatments though \"\"you can buy them out of pocket outside of the National Health Service. \"\"Back to health care in the United States. We asked specifically if Fanelli had found an age-limit in the health care bill. \"\"I have tried to look at that bill and it's a masterful mess,'' said the 54-year-old retired airline captain and Navy reserves retiree. When we asked about whether Fanelli had read about an age cutoff in news articles, he replied: \"\"I have been at lectures.\"\" He heard one from a brain surgeon. \"\"I don't remember the name. I wasn't anticipating getting a phone interview on this.\"\" We contacted him again the next day to clarify if he had read any news articles about an age limit and he said: \"\"There are various articles. I can't quote verse, page and date. ... We arrived at the claim because there is not enough money generated in tax revenue to pay for the current expenses for the U.S. government and this is going to be an additional expense. \"\"Among Fanelli's claimed sources is his wife's dermatologist, Dr. John Meisenheimer of Orlando. He said the doctor saved his wife's life when she had skin cancer. Meisenheimer also is the doctor starring in Fanelli's video. \"\"Meisenheimer has discussed they are going to be picking and choosing,\"\" Fanelli said. \"\"It is generally accepted by medical health professionals there will only be limited amount of money. Most people believe it will be younger people as opposed to older people. \"\"We called Meisenheimer, a board-certified dermatologist for more than 20 years, to get his explanation of the video. \"\"The ad is a metaphor for ageism,\"\" Meisenheimer said. \"\"This isn't about 'death panels.' Death panels do not exist. \"\"(PolitiFact agrees with Meisenheimer about death panels. That was a claim made by Sarah Palin in August 2009 that we rated . )But the health care bill makes cuts to Medicare, he said, and that will lead to less care for the elderly. \"\"It can be a very slippery slope. It's not going to happen like in the commercial,'' said Meisenheimer, whose office website states that he accepts Medicare patients. \"\"Doctors will have to make a decision: where is the best use of money? Do I use it for a 95-year-old who has skin cancer or for somebody younger? ... There is not enough money there in the can for everybody.\"\" The Kaiser Family Foundation states that the Medicare provisions are estimated to result in a net reduction of $428 billion between 2010 and 2019. It also states that the bill supports \"\"comparative effectiveness research\"\" to compare the clinical effectiveness of treatments, but that the findings \"\"may not be construed as mandates, guidelines, or recommendations for payment, coverage, or treatment or used to deny coverage.\"\" So that seems to say that even if research shows a certain treatment for the elderly isn't effective, that can't be used to create an age limit for that treatment.We also contacted the U.S. Department of Health and Human Services which oversees Medicare. Spokesman Peter Ashkenaz told us in an e-mail that there are no age limits for treatment under Medicare. \"\"There are no eligibility changes to Medicare in the new law,\"\" he wrote.Fanelli said his video hasn't aired on television, though it's on his campaign website and on YouTube. We sent links to Fanelli's video to experts on the health care bill: Ullmann at the University of Miami; Alwyn Cassil, director of public affairs for the Center for Studying Health System Change, a nonpartisan research organization; and Len Nichols, Director for the Center for Health Policy Research and Ethics at George Mason University. All three said there is nothing in the bill that would cut off treatment based on an age limit.The video \"\"has no basis in reality whatsoever,\"\" Cassil said. \"\"There is nothing in that bill that I am aware of, or certainly every reporter who has combed every inch of it that mentions anything about 'age limits.' '' So to recap, Fanelli's ad offers a dramatic scene that has no solid facts behind it. He claims it portrays \"\"Obamacare,\"\" but he cannot cite any provisions in the health care bill -- other than vague fear of a European system -- that could cause such a tragic scene. He referred us to his wife's dermatologist -- who also happens to be the star of the commercial -- but the dermatologist did not produce any conclusive evidence, either. So the ad has lots of melodrama but no facts. We find the claim .\"",
        "false"
    ],
    [
        0.3464166621367137,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '591'}",
        "There is little chance that John went to the office. It is certain that Julius is a frog. It is probably the case that Bernhard is a rhino. There is a better than even chance that if either 'Julius is a frog' or 'Bernhard is a rhino' but not both then Mary got the football. It is almost certain that if either 'Bernhard is a rhino' or 'Julius is a frog' but not both then Jeff left the apple. It is unlikely that if 'John went to the office and Bernhard is a rhino' then Gertrude is a cat.",
        "invalid"
    ],
    [
        0.3463853945334752,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '233'}",
        "There is little chance that 'Fred left the apple' or 'Greg is a lion' or both.",
        "invalid"
    ],
    [
        0.3463657299677531,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '815'}",
        "It’s true that Humphrey did say he viewed a woman as a “host” for a fetus once she has become pregnant, but he did not reduce the entire status of women in society to that of a host, even stipulating that beyond the context of pregnancy, “your body is your body.” It is a matter of subjective opinion whether or not one accepts his distinction as being sincere or meaningful, but the fact remains that Humphrey did express such a viewpoint.",
        "true"
    ],
    [
        0.3463586817185084,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '385'}",
        "تکه های شنسیل داخل بسته بزرگ و ضخیم بودن و بخاطر همین هم پختش یکم زمان میبره ولی تازه بود و یخ زده هم نبود. ادویه ی روش هم یه مقدار فلفلی هست",
        "طعم"
    ],
    [
        0.3463429758946101,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '235'}",
        "[{'id': '355', 'response': 'Illegible OCR'}, {'id': '356', 'response': 'Contentious according to current standards'}, {'id': '357', 'response': 'Illegible OCR'}, {'id': '358', 'response': \"I don't know\"}, {'id': '359', 'response': 'Not contentious'}]",
        "𝙈𝙖𝙧𝙧𝙤𝙣"
    ],
    [
        0.3463204602400462,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '578'}",
        "It is highly likely that Greg is yellow. It is improbable that Lily is a lion. It is probable that Julius is white.",
        "invalid"
    ],
    [
        0.34631675978501636,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '371'}",
        "['Using high-throughput sequencing, we devised a technique to determine the insertion sites of virtually all members of the human-specific L1 retrotransposon family in any human genome.', 'Using diagnostic nucleotides, we were able to locate the approximately 800 L1Hs copies corresponding specifically to the pre-Ta, Ta-0, and Ta-1 L1Hs subfamilies, with over 90% of sequenced reads corresponding to human-specific elements.', 'We find that any two individual genomes differ at an average of 285 sites with respect to L1 insertion presence or absence.', 'In total, we assayed 25 individuals, 15 of which are unrelated, at 1139 sites, including 772 shared with the reference genome and 367 nonreference L1 insertions.', 'We show that L1Hs profiles recapitulate genetic ancestry, and determine the chromosomal distribution of these elements.', 'Using these data, we estimate that the rate of L1 retrotransposition in humans is between 1/95 and 1/270 births, and the number of dimorphic L1 elements in the human population with gene frequencies greater than 0.05 is between 3000 and 10,000.']",
        "False"
    ],
    [
        0.34630265831947327,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '39'}",
        "Gone Girl lässt sich leicht lesen ist spannend und der Schluß ist irgendwie ernüchternd und nicht so wie mann es sich vielleicht wünschen würde ; ) Für einen Bestseller halte ich ihn nicht, aber für zwischendurch ganz ok.",
        "counterfactual"
    ],
    [
        0.34630265831947327,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '39'}",
        "Gone Girl lässt sich leicht lesen ist spannend und der Schluß ist irgendwie ernüchternd und nicht so wie mann es sich vielleicht wünschen würde ; ) Für einen Bestseller halte ich ihn nicht, aber für zwischendurch ganz ok.",
        "counterfactual"
    ],
    [
        0.3462959403793017,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '877'}",
        "فیلم، فیلم من نبود. یعنی من را همراه خود نمی‌کرد. درگیر نمی‌شدم. پنجره تازه‌ای به واقعیت یا خیال برایم باز نمی‌کرد. اما به لحاظ تکنیک و فرم و دغدغه، فیلم محترمی بود.",
        "صدا"
    ],
    [
        0.34629212816556293,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '147'}",
        "\"es kann doch nicht sein, dass bei mittlerweile 26 rezensionen \\\\\"\"Dirk Dorkowski\\\\\"\" der einizge ist, der etwas genauer hinh&ouml;rt und somit zurecht feststellt, dass die produktion dieser CD eigentlich nicht einmal einen einzigen stern verdient h&auml;tte.\"",
        "counterfactual"
    ],
    [
        0.34629212816556293,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '147'}",
        "\"es kann doch nicht sein, dass bei mittlerweile 26 rezensionen \\\\\"\"Dirk Dorkowski\\\\\"\" der einizge ist, der etwas genauer hinh&ouml;rt und somit zurecht feststellt, dass die produktion dieser CD eigentlich nicht einmal einen einzigen stern verdient h&auml;tte.\"",
        "counterfactual"
    ],
    [
        0.346269612510999,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '106'}",
        "عطر و طعمش فرق چندانی با قهوه فوری نداره و میشه گفت ضعیفتره بیشتر پول زلمزیمبوشو میدین تا کیفیت قهوه",
        "کلی"
    ],
    [
        0.34624337653319043,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '9'}",
        "Q: Did an FDA-approved form of “synthetic marijuana” lead to recent deaths in Illinois? A: No. The drugs that have killed four people in the last two months are unregulated and illegal. Four people have died after using drugs made to imitate the high of marijuana in Illinois over the last two months. That’s true.It’s not true that the drugs they used were approved by the Food and Drug Administration, as was claimed by a story circulating on Facebook under the headline: “Big Pharma Synthetic Marijuana Leaves 2 Dead, 89 Hospitalized In Illinois.”The number of those who died is wrong in the headline because the story was copied, for the most part, from a legitimate report that was published on April 6, when that number was accurate.The recent story that Facebook users flagged as potentially false comes from a site registered to an owner in Pakistan and differs in a couple of important ways from the original. It has a misleading headline (indicating that the drugs were made by regulated pharmaceutical manufacturers) and it starts out with a sentence that is wrong.It says at the top: “The users ingested an FDA-approved version of synthetic cannabis known as K2 or Spice.”That’s not true.The FDA has approved three drugs with synthetic versions of chemicals similar to or the same as those found in marijuana — Marinol, Syndros, and Cesamet can be used to help with nausea from cancer treatments and Marinol and and Syndros can also be used to treat weight loss in AIDS patients. The FDA is currently reviewing another drug related to marijuana that would treat epilepsy.Neither “K2” nor “Spice” has been approved by the FDA, administration spokesman Michael Felberbaum confirmed.Not only are they not approved by the FDA, those are two of the most common names under which imitation marijuana is sold. A Drug Enforcement Administration official, Susan Gibson, used them as an example when she testified in front of Congress earlier this year, saying, “Synthetic cannabinoids and their byproducts (sometimes sold under brand names such as K2 or Spice) continue to be a significant threat to public health and safety.”Synthetic cannabinoids are typically sprayed onto dried plant material and smoked or used in e-cigarettes to achieve a high similar to marijuana, but their effects can be unpredictable and dangerous, according to the National Institute on Drug Abuse. The drugs used in the recent spate of overdoses in Illinois and surrounding states included a chemical found in rat poison, according to the Illinois Department of Public Health and the Centers for Disease Control and Prevention.NIDA: These chemicals are called cannabinoids because they are similar to chemicals found in the marijuana plant. Because of this similarity, synthetic cannabinoids are sometimes misleadingly called “synthetic marijuana” (or “fake weed”), and they are often marketed as safe, legal alternatives to that drug. In fact, they are not safe and may affect the brain much more powerfully than marijuana; their actual effects can be unpredictable and, in some cases, more dangerous or even life-threatening.The chemical composition of imitation marijuana can vary, which makes legislating against it difficult, although all 50 states have banned some form of synthetic cannabinoids, according to the National Conference of State Legislatures. In Illinois, imitation marijuana is illegal under two laws — one that was passed specifically to address those drugs and under the state’s Controlled Substances Act, according to Eileen Boyce, spokeswoman for the Illinois attorney general.In April 2017 the DEA temporarily added chemical compounds often used in imitation marijuana to the list of schedule 1 controlled substances, citing overdoses on the increasingly popular drug as the reason. Those compounds are set to remain on the list until April 10, 2019.So, if you’ve read the story traveling around Facebook and gotten the impression that people are dying from legal, regulated medications related to marijuana — they’re not. The imitation marijuana that is killing people is unregulated and illegal.Editor’s note: FactCheck.org is one of several organizations working with Facebook to debunk false stories flagged by readers on the social media network.Illinois Department of Public Health. WARNING: Synthetic Cannabinoids Linked to Bleeding. Accessed 17 May 2018.“Big Pharma Synthetic Marijuana Leaves 2 Dead, 89 Hospitalized In Illinois.” Trendsadays.com. 15 May 2018.Tomoski, Miroslav. “89 hospitalized and 2 dead in Illinois after using synthetic marijuana.” Herb.co. 6 Apr 2018.Gibson, Susan. Statement for hearing entitled “COMBATING THE OPIOID CRISIS: HELPING COMMUNITIES BALANCE ENFORCEMENT AND PATIENT SAFETY.” 28 Feb 2018.Felberbaum, Michael. Spokesman, Food and Drug Administration. Interview with FactCheck.org. 17 May 2018.National Institute on Drug Abuse. Drug facts — Synthetic Cannabinoids (K2/Spice). Feb 2018.National Conference of State Legislatures. Emerging Drug Threats. 7 Jun 2017.Illinois Department of Public Health. “Fourth Death Related to Synthetic Cannabinoids.” 24 Apr 2018.Centers for Disease Control and Prevention. Outbreak Alert: Potential Life-Threatening Vitamin K-Dependent Antagonist Coagulopathy Associated With Synthetic Cannabinoids Use. 5 Apr 2018.Boyce, Eileen. Spokeswoman, Illinois Office of the Attorney General. Interview with FactCheck.org. 17 May 2018.Federal Register. Schedules of Controlled Substances: Temporary Placement of Six Synthetic Cannabinoids (5F-ADB, 5F-AMB, 5F-APINACA, ADB-FUBINACA, MDMB-CHMICA and MDMB-FUBINACA) into Schedule I. 10 Apr 2017.",
        "false"
    ],
    [
        0.34621161719163257,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '104'}",
        "It is improbable that Fred went to the garden. It is probably the case that Gertrude is a cat. It is likely that Brian is a rhino. It is probably the case that if 'Brian is a rhino' or 'Gertrude is a cat' or both then Emily is a wolf. It is likely that if either 'Fred went to the garden' or 'Brian is a rhino' but not both then Mary dropped the milk. It is impossible that if 'Brian is a rhino and Fred went to the garden' then John moved to the office.",
        "invalid"
    ],
    [
        0.3462110310792923,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '329'}",
        "We believe that Daniel dropped the apple. It is certain that Greg is a swan. Chances are about even that Jason is tired. There is a very good chance that if either 'Daniel dropped the apple' or 'Greg is a swan' but not both then Julius is white. It is almost certain that if 'Jason is tired and Daniel dropped the apple' then Jessica is a mouse. It is certain that if 'Greg is a swan and Daniel dropped the apple' then Brian is a rhino.",
        "invalid"
    ],
    [
        0.3461751441160838,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '428'}",
        "It is highly likely that Sandra took the milk. It is highly unlikely that Mary is in the school. There is little chance that Winona is a mouse. Chances are about even that if 'Winona is a mouse and Sandra took the milk' then Julius is white. It is probably the case that if 'Winona is a mouse' or 'Mary is in the school' or both then Bernhard is green. It is highly unlikely that if either 'Mary is in the school' or 'Winona is a mouse' but not both then John dropped the apple.",
        "invalid"
    ],
    [
        0.346155380209287,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'rob_train_disc_23_test_all_23', 'row_id': '420'}",
        "[Aurora] does n't like having to babysit her younger brother, [Timothy]. [Linda] and [Sean] are siblings and best friends. They do everything together. Sometimes [Linda] invites her mom, [Denise].",
        "son"
    ],
    [
        0.34615522623062134,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '267'}",
        "Write an excellent summary of the given text.\n\nTitle: A buddy of mine (20 or 21-ish/M) wants me (25/M) to smoke him out. Problem is, he's on probation.\n\nText: So here's my deal.\n\nI got a friend who I've known for about a year, who recently just got put on probation for possession and paraphernalia. This is his second offense, so he was put on a pretty heavy six month probation with mandatory drug tests every week. He tried to quit, but had a few incidents since he got on probation.\n\nMy weed, I smoke exclusively in my apartment. There's no chance of me getting caught. I live in a corner unit, and both of my neighbors (next door, and downstairs) smoke as well. I'm in a safe area. My weed, basically, is open to all my friends. I'm 24, and I work at a 420-friendly mom & pop donut shop (we have themed donuts), and most of the people who work there are living with their parents, or at least on the verge of moving out. So my apartment is open to any of my friends, and I make enough money to have a pretty good supply of weed at all times. I got a pretty sweet set up, with a 42 inch TV and a\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3461110492547353,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '47'}",
        "['Myriapods (e.g., centipedes and millipedes) display a simple homonomous body plan relative to other arthropods.', 'All members of the class are terrestrial, but they attained terrestriality independently of insects.', 'Myriapoda is the only arthropod class not represented by a sequenced genome.', 'We present an analysis of the genome of the centipede Strigamia maritima.', 'It retains a compact genome that has undergone less gene loss and shuffling than previously sequenced arthropods, and many orthologues of genes conserved from the bilaterian ancestor that have been lost in insects.', 'Our analysis locates many genes in conserved macro-synteny contexts, and many small-scale examples of gene clustering.', 'We describe several examples where S. maritima shows different solutions from insects to similar problems.', 'The insect olfactory receptor gene family is absent from S. maritima, and olfaction in air is likely effected by expansion of other receptor gene families.', 'For some genes S. maritima has evolved paralogues to generate coding sequence diversity, where insects use alternate splicing.', 'This is most striking for the Dscam gene, which in Drosophila generates more than 100,000 alternate splice forms, but in S. maritima is encoded by over 100 paralogues.', 'We see an intriguing linkage between the absence of any known photosensory proteins in a blind organism and the additional absence of canonical circadian clock genes.', 'The phylogenetic position of myriapods allows us to identify where in arthropod phylogeny several particular molecular mechanisms and traits emerged.', 'For example, we conclude that juvenile hormone signalling evolved with the emergence of the exoskeleton in the arthropods and that RR-1 containing cuticle proteins evolved in the lineage leading to Mandibulata.', 'We also identify when various gene expansions and losses occurred.', 'The genome of S. maritima offers us a unique glimpse into the ancestral arthropod genome, while also displaying many adaptations to its specific life history.']",
        "False"
    ],
    [
        0.34609488149483997,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '923'}",
        "\"Not applicable. Costs not discussed but we understand that at this point in the research. Nonetheless, we wish the story had used even one short line, as the Wall Street Journal did, to say the drugmaker said it was too soon to discuss pricing. Good job on this, especially putting results in context in calm, measured terms: Good job quantifying the harms found in the study, the severity of those harms, and including one – death (in 1.5% of patients on the experimental approach) –  that many news stories didn’t report. The story didn’t discuss a key point raised in some other stories, such as one by TheStreet.com that reported that the study \"\"lacked a comparison to a placebo or true control, which makes the results harder to interpret.\"\" No disease mongering in this story. The study author was interviewed along with a clinician who has used the drug. Drug company funding of the study was disclosed. Story explains that this is \"\"the first drug to improve advanced melanoma patients’ survival in a large, definitive trial.\"\" The story was clear about the experimental stage of the approach. The novelty – that is \"\"the first drug to improve advanced melanoma patients’ survival in a large, definitive trial\"\" – was explained. It’s clear the story didn’t rely on a news release.\"",
        "true"
    ],
    [
        0.3460913598537445,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '704'}",
        "There is little chance that either 'Lily is green' or 'Greg is white' but not both.",
        "invalid"
    ],
    [
        0.34608784317970276,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '253'}",
        "[{'id': '355', 'response': 'Illegible OCR'}, {'id': '356', 'response': 'Contentious according to current standards'}, {'id': '357', 'response': 'Contentious according to current standards'}, {'id': '358', 'response': 'Not contentious'}, {'id': '359', 'response': \"I don't know\"}]",
        "𝙙𝙬𝙚𝙧𝙜𝙚𝙪"
    ],
    [
        0.34607090055942535,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '448'}",
        "Write an excellent summary of the given text.\n\nTitle: Promised myself [21/M] I wouldn't get into a LDR again, but here I am!... with [21/F]. Need advice.\n\nText: At the end of May, I met a wonderful girl. We hit it off instantly and feelings were mutual; no games involved. We got really close, shared some of our deepest secrets, the words I love you came naturally, and basically I had never felt so strongly for someone so quickly.\n\nProblem is, she goes to school 11 driving hours away. Her parents house and my parents house are right by each other, but unfortunately we go to school miles and miles apart. It is our senior year, and at first we didn't think it would make sense to be serious about this relationship when we started school (which is now), and just hope that we would meet up again after the school year. But, obviously, the more time we spent together, the closer we got, the more attached we got, and now we find ourselves in a long distance relationship. \n\nI've done this once before, with only a 2 hour separation and it didn't work out for other reasons, so my view on LDR's isn't completely shot. But i didn't want to get into another one because I loved the freedom college provided and it is my senior year. However, this girl came along, and completely changed my mind. I am convinced that if we get through this LDR, I will marry her. She is everything I want and more.\n\nI came here to seek advice from you wonderful redditors, hopefully who have experienced similar circumstances. If it was the beginning of my sophomore year things would be different, because I dont think I could do ~3 years of LDR. But 1 year doesn't seem so bad. I know it will suck at times, and communication is key, but what are some tips, tricks, advice, words of encouragement that would help me get through this with her?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.3460685461759567,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '485'}",
        "['Genome-wide association studies (GWAS) have now identified at least 2,000 common variants that appear associated with common diseases or related traits (http://www.genome.gov/gwastudies), hundreds of which have been convincingly replicated.', 'It is generally thought that the associated markers reflect the effect of a nearby common (minor allele frequency >0.05) causal site, which is associated with the marker, leading to extensive resequencing efforts to find causal sites.', 'We propose as an alternative explanation that variants much less common than the associated one may create \"synthetic associations\" by occurring, stochastically, more often in association with one of the alleles at the common site versus the other allele.', 'Although synthetic associations are an obvious theoretical possibility, they have never been systematically explored as a possible explanation for GWAS findings.', 'Here, we use simple computer simulations to show the conditions under which such synthetic associations will arise and how they may be recognized.', 'We show that they are not only possible, but inevitable, and that under simple but reasonable genetic models, they are likely to account for or contribute to many of the recently identified signals reported in genome-wide association studies.', 'We also illustrate the behavior of synthetic associations in real datasets by showing that rare causal mutations responsible for both hearing loss and sickle cell anemia create genome-wide significant synthetic associations, in the latter case extending over a 2.5-Mb interval encompassing scores of \"blocks\" of associated variants.', 'In conclusion, uncommon or rare genetic variants can easily create synthetic associations that are credited to common variants, and this possibility requires careful consideration in the interpretation and follow up of GWAS signals.']",
        "False"
    ],
    [
        0.34604055682818097,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '75'}",
        "It is probably not the case that Lily is yellow. It is improbable that Julius is a frog. There is almost no chance that Sandra left the milk.",
        "invalid"
    ],
    [
        0.3460194766521454,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '524'}",
        "It is impossible that Greg is a frog. We doubt that Lily is green. It is likely that John went to the office. It is highly unlikely that if 'John went to the office and Greg is a frog' then Bernhard is a swan. It is highly unlikely that if 'Lily is green and John went to the office' then Sandra took the milk. There is little chance that if 'John went to the office and Lily is green' then Emily is a mouse.",
        "invalid"
    ],
    [
        0.34600335359573364,
        "{'dataset_id': 'boolq', 'config_id': 'default', 'row_id': '7'}",
        "The Waiter Rule refers to a common belief that one's true character can be gleaned from how one treats staff or service workers, such as a ``waiter''. The rule was one of William H Swanson's 33 Unwritten Rules of Management, copied from Dave Barry's version ``If someone is nice to you but rude to the waiter, they are not a nice person.''",
        "True"
    ],
    [
        0.345980167388916,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'rob_train_sup_23_test_all_23', 'row_id': '680'}",
        "[{('Nettie', 'son', 'Robert'): [('Nettie', 'son', 'William'), ('William', 'brother', 'Robert')]}, {('William', 'brother', 'Robert'): [('William', 'brother', 'Ryan'), ('Ryan', 'brother', 'Robert')]}]",
        "son"
    ],
    [
        0.3459656337896983,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '203'}",
        "It is likely that Jason is tired. It is probably the case that Greg is white. It is probably not the case that John took the apple. It is highly likely that if 'Greg is white and Jason is tired' then Mary is in the school. We doubt that if 'John took the apple' or 'Jason is tired' or both then Lily is yellow. There is a very good chance that if either 'Greg is white' or 'Jason is tired' but not both then Yann is thirsty.",
        "invalid"
    ],
    [
        0.3459611733754476,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '221'}",
        "[{'follow_up_question': 'Are you a carer or person with a disability?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.3459611733754476,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '828'}",
        "[{'follow_up_question': 'Are you a carer or person with a disability?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.34595495959122974,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '305'}",
        "It is almost certain that Julius is white. It is highly likely that Mary went to the bedroom. We believe that John moved to the garden. It is certain that if 'John moved to the garden and Mary went to the bedroom' then Bernhard is a rhino. It is unlikely that if 'John moved to the garden and Mary went to the bedroom' then Lily is green. There is little chance that if 'Mary went to the bedroom' or 'Julius is white' or both then Greg is a frog.",
        "invalid"
    ],
    [
        0.34594598909219104,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '238'}",
        "[{'id': '355', 'response': 'Illegible OCR'}, {'id': '356', 'response': 'Contentious according to current standards'}, {'id': '357', 'response': \"I don't know\"}, {'id': '358', 'response': \"I don't know\"}, {'id': '359', 'response': \"I don't know\"}]",
        "𝙢𝙚𝙩𝙞𝙨"
    ],
    [
        0.34594517946243286,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '28'}",
        "[{'id': 'unknown_1a', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1b', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1e', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1f', 'response': 'Not contentious'}, {'id': 'unknown_1g', 'response': 'Contentious according to current standards'}]",
        "𝙯𝙞𝙜𝙚𝙪𝙣𝙚𝙧"
    ],
    [
        0.34594517946243286,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '42'}",
        "[{'id': 'unknown_1a', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1b', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1e', 'response': 'Contentious according to current standards'}, {'id': 'unknown_1f', 'response': 'Not contentious'}, {'id': 'unknown_1g', 'response': \"I don't know\"}]",
        "𝙗𝙡𝙖𝙣𝙠"
    ],
    [
        0.34592414398988086,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '501'}",
        "There is little chance that Sandra left the football. It is highly unlikely that Jessica is a sheep. It is probably the case that Greg is a rhino. We believe that if 'Sandra left the football and Jessica is a sheep' then Bernhard is gray. It is probably not the case that if 'Greg is a rhino' or 'Sandra left the football' or both then John got the milk. It is impossible that if either 'Jessica is a sheep' or 'Greg is a rhino' but not both then Yann is hungry.",
        "invalid"
    ],
    [
        0.34589384496212006,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '455'}",
        "It is almost certain that either 'Bernhard is a lion' or 'John dropped the milk' but not both.",
        "invalid"
    ],
    [
        0.3458893646796544,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '252'}",
        ": Geen toovenaar; geen hond, Doodslager, of hoereerder, Leug'naar; 𝙖𝙛𝙜𝙤𝙙-vereerder, Die ooit DAAR woning vond! !\"— B.A.",
        "𝙖𝙛𝙜𝙤𝙙"
    ],
    [
        0.3458760281403859,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '614'}",
        "It is improbable that either 'Julius is a frog' or 'Mary took the football' but not both.",
        "invalid"
    ],
    [
        0.3458156536022822,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'rob_train_clean_23_test_all_23', 'row_id': '645'}",
        "[Matthew] and his brother [Rich] got into a fight over who was the better basketball player. [Helen] was having a hard time with her math homework, so she went to her brother [Rich] for help. [Rich] did n't seem to know either, so [Helen] went to her father [Scott], as she was sure he could help.",
        "son"
    ],
    [
        0.34580475588639575,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '892'}",
        "It is certain that Mary moved to the garden. It is probable that John got the milk. Chances are slight that Greg is white. It is highly likely that if either 'Mary moved to the garden' or 'John got the milk' but not both then Julius is a swan. It is highly unlikely that if either 'Greg is white' or 'Mary moved to the garden' but not both then Sandra left the milk. We doubt that if 'Greg is white' or 'John got the milk' or both then Bernhard is a swan.",
        "invalid"
    ],
    [
        0.345787654320399,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '38'}",
        "[{'id': 'unknown_1a', 'response': 'Weet ik niet'}, {'id': 'unknown_1b', 'response': 'Niet omstreden'}, {'id': 'unknown_1d', 'response': 'Omstreden naar huidige maatstaven'}, {'id': 'unknown_1e', 'response': 'Weet ik niet'}, {'id': 'unknown_1f', 'response': 'Niet omstreden'}, {'id': 'unknown_1g', 'response': 'Omstreden naar huidige maatstaven'}]",
        "𝙈𝙖𝙧𝙧𝙤𝙣"
    ],
    [
        0.34578539431095123,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '596'}",
        "It is highly unlikely that Brian is yellow. It is highly unlikely that John went to the office. It is probable that Lily is green. It is unlikely that if either 'Lily is green' or 'John went to the office' but not both then Sandra left the apple. There is almost no chance that if 'John went to the office' or 'Brian is yellow' or both then Mary moved to the garden. It is almost certain that if 'Brian is yellow' or 'John went to the office' or both then Julius is a lion.",
        "invalid"
    ],
    [
        0.3457668572664261,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '32'}",
        "Write an excellent summary of the given text.\n\nTitle: I may never see him ever. I love him to death.\n\nText: I am (F)20 and he is 21. The man I love is leaving back to Arizona. I live in California. He's leaving because he cant stand my family, mainly my older sister constantly nagging him about why he doesn't have a better job. \n\nHe's the kindest, calmest, most lovable man I know. I loved him since I was 16, now 20. I don't know how to handle this. I told him I would go with him but he said he wants me to finish school and become successful. But I can't stand to think about sound all of that without him by my side. \n\nI'm going to miss him. So much. I try not to think about it as much. We only have a couple days left. Our days together are counted. How will I handle this? I may not see him for years, even worse, I may my see him EVER!\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34576060871283215,
        "{'dataset_id': 'allenai/scifact', 'config_id': 'corpus', 'row_id': '457'}",
        "['A system for naming ribosomal proteins is described that the authors intend to use in the future.', 'They urge others to adopt it.', 'The objective is to eliminate the confusion caused by the assignment of identical names to ribosomal proteins from different species that are unrelated in structure and function.', 'In the system proposed here, homologous ribosomal proteins are assigned the same name, regardless of species.', \"It is designed so that new names are similar enough to old names to be easily recognized, but are written in a format that unambiguously identifies them as 'new system' names.\"]",
        "False"
    ],
    [
        0.34574517607688904,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '85'}",
        "Ahold Delhaize says its U.S. subsidiaries will work with suppliers to meet standards higher than what is required by law and collaborate to address causes of contaminants. The company operates Food Lion, Giant Food, Giant/Martin’s, Hannaford, Peapod and Stop & Shop. The “chemicals of concern” outlined in the policy include per- and polyfluoroalkyl substances (PFAS), bisphenol A (BPA) and phthalates. The Portland Press Herald reports these chemicals are still allowed under U.S. Food and Drug Administration rules; environmental health experts say there’s evidence the chemicals can contribute to chronic health issues.",
        "true"
    ],
    [
        0.3457441031932831,
        "{'dataset_id': 'WorkInTheDark/FairytaleQA', 'config_id': 'plain_text', 'row_id': '165'}",
        "wassamo was living with his parents on the shore of a large bay , far out in the north - east . one day , when the season had commenced for fish to be plenty , the mother of wassamo said to him , \" my son , i wish you would go to yonder point and see if you can not procure me some fish ; and ask your cousin to accompany you . \" he did so . they set out , and in the course of the afternoon they arrived at the fishing - ground . the cousin , being the elder , attended to the nets , and they encamped near by , using the bark of the birch for a lodge to shelter them through the night . they lit a fire , and while they sat conversing with each other , the moon arose . not a breath of wind disturbed the smooth surface of the lake . not a cloud was seen . wassamo looked out on the water toward their nets , and he saw that the little black spots , which were no other than the floats , dotting the lake , had disappeared . \" cousin , \" he said , \" let us visit our nets ; perhaps we are fortunate . \"",
        ""
    ],
    [
        0.34574320912361145,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '716'}",
        "It is unlikely that 'Bernhard is gray' or 'Brian is a rhino' or both.",
        "invalid"
    ],
    [
        0.3457385798295339,
        "{'dataset_id': 'factckbr', 'config_id': 'default', 'row_id': '229'}",
        " FALSA a declaração atribuída ao estilista Ricardo Almeida sobre o ex-presidente Luiz Inácio Lula da Silva em uma montagem com uma foto do estilista. De acordo com o conteúdo, o estilista, que já teve o ex-presidente entre seus clientes, teria dito que os ternos do político teriam sido os mais caros que produziu e que seria ele um homem com alma de burguês e que o resto é populismo para enganar os eleitores inocentes. A frase no entanto, nunca foi dita por Almeida, que inclusive já negou a autoria em sua página no Facebook.",
        "falso"
    ],
    [
        0.3457336326440175,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '93'}",
        "langs en wel van niemand minder dan van de groote beroemdheid, den 𝙖𝙛𝙜𝙤𝙙 van alle litterair-sentimenteele dames en heeren....Edmond Fleg.Ne",
        "𝙖𝙛𝙜𝙤𝙙"
    ],
    [
        0.3457302153110504,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '900'}",
        "[Harold] 'son [Robert] could not believe that his father bought him a coffee machine for his birthday. [Michelle] and her sister [Lizzie] went out to eat with [Michelle]'s father, [Robert]. [Antonio], [Lizzie]'s uncle, recently got into fishing.",
        "son"
    ],
    [
        0.34568885465463,
        "{'dataset_id': 'blimp', 'config_id': 'adjunct_island', 'row_id': '527'}",
        "Who did some customers disagree with while questioning Melanie?",
        "False"
    ],
    [
        0.34568025668462116,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '57'}",
        "The post is not accurate. The poster is the one in medical school and is realizing he and his girlfriend are not compatible and do not have the same ambition. He wants to break things off with her until she grows up.",
        "Accuracy"
    ],
    [
        0.3456720958153407,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '126'}",
        "It is probable that either 'Bernhard is a frog' or 'Winona is a wolf' but not both.",
        "invalid"
    ],
    [
        0.3456616699695587,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '897'}",
        "A more accurate description: Two starters bouncing back from testicular cancer. “Both healthy. Both in the big leagues,” the Pirates’ Taillon said. “Life’s good.” The Rockies’ Bettis underwent surgery in November 2016 for testicular cancer and continued cancer treatments through that spring and into last season. So when Taillon had surgery to treat testicular cancer on May 8, 2017, he had an instant line of support. “Baseball is a brotherhood. When something happens to our own, everyone comes together — even more so when there are two people going through the same thing,” the 26-year-old Taillon said. “It made sense to reach out to each other and give our well-wishes and see if there’s anything we could offer up to each other. “I just felt like if I needed anything or had a question, I was very comfortable going to ask him about any part of the process.” Taillon did, too. Simple things: How often did you get your blood levels checked? What was the treatment like? “It was really nothing crazy, but that was comforting,” Taillon said. “He was months ahead of me and what I was going through. It was nice to have somebody I could ask questions.” Taillon’s eyes lit up when he heard that Bettis would come off the disabled list — Bettis has been dealing with a blister — to make the start. Bettis hadn’t been officially named the starter when the clubhouse was open Monday, but he did say how “cool” it would to face Taillon. “It will be really nice for that to happen,” said Bettis, who returned to the Rockies’ starting rotation on Aug. 14, 2017, after his recovery. Bettis hasn’t pitched for the Rockies since July 1 due to a blister on his middle finger. He’s tried every remedy, but it keeps bothering him. So the 29-year-old texted Taillon, who’s been dealing with a cut on his middle finger as well. “He had some good insight,” Bettis said. “There were a couple things he was doing, that I felt we could try and see how it worked out. It was good to get some feedback.” Taillon’s advice? Use a finger sleeve and take days off. He also told Bettis how precisely he was clipping his fingernails. “But you can see I don’t have too much great advice,” Taillon laughed, showing off his cracked finger. “I’m still working through it. I’m still battling my own thing.” It took Taillon about a month to return to the mound last season after testicular cancer surgery. In his first start back on June 12, 2017, he threw five scoreless innings as the Pirates beat the Rockies. Later that season, Taillon got a hit off Chicago Cubs starter Jon Lester, a cancer survivor, and was chatting with first baseman Anthony Rizzo, who was diagnosed with Hodgkin’s lymphoma as a teenager. “Rizzo looked at me and said, ‘Hey, there are three cancer survivors right here — me, you and Lester,’” Taillon recounted. “That moment was cool for me. “Facing off against Chad will be one of those cool moments.” ___ More AP baseball: https://apnews.com/tag/MLBbaseball",
        "true"
    ],
    [
        0.3456607659657796,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '52'}",
        "One unconfirmed, secondhand report says Kennedy smoked marijuana once at the White House. No evidence is available to back the idea that Kennedy regularly used marijuana at the White House because of his physical ailments.",
        "false"
    ],
    [
        0.34562569856643677,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'rcb', 'row_id': '262'}",
        "И, тем самым, их не слышат и не могут, соответственно, быть ими обмануты. Все правильно. – Да уж, – пробормотал Пиар, которому вообще расхотелось говорить, хоть он никого и не собирался обманывать.",
        "Да уж, все правильно."
    ],
    [
        0.3456209848324458,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '919'}",
        "It is probably the case that Julius is green. It is improbable that Mary went to the bedroom. It is impossible that Bernhard is white. There is little chance that if 'Mary went to the bedroom' or 'Bernhard is white' or both then Sandra dropped the apple. It is probably not the case that if 'Julius is green and Bernhard is white' then Jason is tired. It is likely that if either 'Bernhard is white' or 'Julius is green' but not both then Lily is a lion.",
        "invalid"
    ],
    [
        0.34561334053675336,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'ja', 'row_id': '519'}",
        "比較的おとなしく、奇抜な色など入っていないのでフォーマルな場所以外ならどこでも使えるし・ジーンズにも合わない事も無かったので意外に便利な一足になりそうです。",
        "not-counterfactual"
    ],
    [
        0.34561334053675336,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'ja', 'row_id': '519'}",
        "比較的おとなしく、奇抜な色など入っていないのでフォーマルな場所以外ならどこでも使えるし・ジーンズにも合わない事も無かったので意外に便利な一足になりそうです。",
        "not-counterfactual"
    ],
    [
        0.34557657440503436,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '776'}",
        "It is impossible that 'Julius is white' or 'Bernhard is gray' or both.",
        "invalid"
    ],
    [
        0.3455512523651123,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '105'}",
        "میوه خشک مثل پاستیل بود کشمش افتضاح بود مقدار آجیل کم بود نخرید باباااا",
        "طعم"
    ],
    [
        0.34554039935270947,
        "{'dataset_id': 'CLUTRR/v1', 'config_id': 'gen_train234_test2to10', 'row_id': '993'}",
        "[{('Harold', 'son', 'Robert'): [('Harold', 'son', 'Louis'), ('Louis', 'brother', 'Robert')]}, {('Harold', 'son', 'Louis'): [('Harold', 'daughter', 'Marie'), ('Marie', 'brother', 'Louis')]}, {('Marie', 'brother', 'Louis'): [('Marie', 'brother', 'Antonio'), ('Antonio', 'brother', 'Louis')]}]",
        "son"
    ],
    [
        0.34553129971027374,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '403'}",
        "\"There was no estimate of the costs associated with obtaining the amounts of vitamin D mentioned in the story. The story did an adequate job quantifying the benefits found in the meta-analysis:  \"\"Over an average of nearly six years, those who took vitamin D had a 7 percent lower risk of death from all causes than those who did not. Some scientists say more years of study would give better clues as to how large a role vitamin D plays in decreasing mortality. Others point out that while there was a statistically significant 7 percent drop in mortality in Autier’s analysis, because of the size of the study that only accounted for a difference of 117 people who died in the control groups as compared with those who took vitamin D supplements.\"\" The story made it appear as though any form of vitamin D were safe to consume in whatever dosage a reader might envisage and this is misleading. It mentioned \"\"there is little evidence of vitamin D toxicity at levels under 10,000 IU a day\"\", and while rare, there are cases of lethal doses of vitamin D that have been documented. The story could have explained that there are definite harms of excess vitamin D. The story did an adequate job explaining the 18-study meta-analysis. The story did not engage in overt disease mongering. The story included comments from several researchers involved with investigating the benefits of vitamin D who were not connected to the authors of the highlighted study. The story covered the various means for obtaining sufficient levels of vitamin D (food, sunshine, functional foods, and supplements). It could have explained that the application of high SPF value creams and lotions blocks the body’s ability to convert sunlight into circulating vitamin D. The story mentioned that commercially available vitamin D supplements were available, listed some food sources rich in vitamin D, as well as other foods which are fortified with the vitamin. The story was clear that it was reporting on the results of a recently published meta-analysis of previously published data. Does not appear to rely on a press release.\"",
        "true"
    ],
    [
        0.34549092253049213,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '515'}",
        "(1) Опасения Родогуны не напрасны — Клеопатра пышет злобой. (2) Царица не желает отказываться от власти, которая досталась ей слишком дорогой ценой, к тому же ей предстоит увенчать короной ненавистную соперницу, похитившую у неё Деметрия. (3) Она откровенно делится своими замыслами с верной Лаоникой: трон получит тот из сыновей, кто отомстит за мать. (4) Клеопатра рассказывает Антиоху и Селевку о горькой судьбе их отца, погубленного злодейкой Родогуной. (5) Право первородства нужно заслужить — старшего укажет смерть парфянской царевны. (6) Ошеломлённые братья понимают, что мать предлагает им обрести венец ценой преступления. (7) Антиох все же надеется пробудить добрые чувства в Клеопатре, но Селевк в это не верит: мать любит только себя — в её сердце нет места для сыновей. (8) Он предлагает обратиться к Родогуне — пусть царём станет её избранник. (9) Парфянская царевна, предупреждённая Лаоникой, рассказывает близнецам о горькой судьбе их отца, убитого злодейкой Клеопатрой. (10) Любовь необходимо завоевать — мужем её станет тот, кто отомстит за Деметрия. (11) Удручённый Селевк говорит брату, что отказывается от престола и Родогуны — кровожадные женщины отбили у него желание как царствовать, так и любить. (12) Но Антиох по-прежнему убеждён, что мать и возлюбленная не смогут устоять перед слёзными мольбами.",
        "False"
    ],
    [
        0.34548894067605335,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '654'}",
        "It is improbable that Julius is a frog. It is probably the case that Bernhard is a lion. It is almost certain that John discarded the apple.",
        "invalid"
    ],
    [
        0.3454884539047877,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '482'}",
        "There is a better than even chance that Brian is green. We believe that Bernhard is a rhino. There is little chance that Fred dropped the milk. We doubt that if 'Brian is green' or 'Bernhard is a rhino' or both then Sandra left the apple. It is probably not the case that if 'Bernhard is a rhino' or 'Fred dropped the milk' or both then Julius is a swan. It is probable that if either 'Fred dropped the milk' or 'Brian is green' but not both then John went to the hallway.",
        "invalid"
    ],
    [
        0.34547191858291626,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '652'}",
        "Eine sehr schöne Geschichte, wenn doch nur nicht dieser Hugh Grand nicht wäre.",
        "counterfactual"
    ],
    [
        0.34547191858291626,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '652'}",
        "Eine sehr schöne Geschichte, wenn doch nur nicht dieser Hugh Grand nicht wäre.",
        "counterfactual"
    ],
    [
        0.34546366333961487,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '17'}",
        "[{'follow_up_question': 'Is it your Attendance Allowance?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Did you commit benefit fraud?', 'follow_up_answer': 'Yes'}, {'follow_up_question': 'Is it bereavement payment?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.34546366333961487,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '478'}",
        "[{'follow_up_question': 'Is it your Attendance Allowance?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Did you commit benefit fraud?', 'follow_up_answer': 'Yes'}, {'follow_up_question': 'Is it bereavement payment?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.34546366333961487,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '819'}",
        "[{'follow_up_question': 'Is it your Attendance Allowance?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Did you commit benefit fraud?', 'follow_up_answer': 'Yes'}, {'follow_up_question': 'Is it bereavement payment?', 'follow_up_answer': 'No'}]",
        "False"
    ],
    [
        0.34546177585919696,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '397'}",
        "There is a better than even chance that John went to the hallway. It is highly likely that Gertrude is a cat. It is highly unlikely that Mary took the milk. It is probably not the case that if 'Mary took the milk' or 'Gertrude is a cat' or both then Greg is a rhino. It is certain that if either 'John went to the hallway' or 'Mary took the milk' but not both then Daniel dropped the apple. It is certain that if either 'John went to the hallway' or 'Gertrude is a cat' but not both then Lily is a swan.",
        "invalid"
    ],
    [
        0.34544243415196735,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'ja', 'row_id': '215'}",
        "なんというか、クォーツにはないロマンがある気がします（笑）・手巻き機能があれば完璧だったかな。",
        "counterfactual"
    ],
    [
        0.34544243415196735,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'ja', 'row_id': '215'}",
        "なんというか、クォーツにはないロマンがある気がします（笑）・手巻き機能があれば完璧だったかな。",
        "counterfactual"
    ],
    [
        0.3454295297463735,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '983'}",
        "It is improbable that Julius is a swan. There is a better than even chance that Gertrude is a cat. It is unlikely that Bernhard is gray. We doubt that if 'Bernhard is gray' or 'Gertrude is a cat' or both then Greg is yellow. There is little chance that if 'Julius is a swan' or 'Bernhard is gray' or both then Mary went to the office. It is likely that if 'Julius is a swan and Gertrude is a cat' then Winona is a sheep.",
        "invalid"
    ],
    [
        0.34541888535022736,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '449'}",
        "A man does chin-ups at a city park in Kiev, March 19, 2012. REUTERS/Anatolii Stepanov Experts say often a professional tweak can go a long way towards firming up your workout. “People usually injure themselves on basic exercises, like a squat or a bench press,” said New York-based personal trainer Tiffany Boucher. But Boucher, who works for the national chain of fitness centers Equinox, said form is relatively easy to fix. “Something is being overused, usually in tandem with some type of muscle imbalance,” she said. “So it’s often about getting people to put their shoulders in a certain place, find their center of gravity, engage their abdominals, or tilt their pelvis in a certain direction.”   She said even a small adjustment can be transformative. Knees are the most common focus of client complaint, according to Boucher. Once form is corrected, relief often comes within weeks. “People don’t have that continued inflammation,” she said. Dr. Daniel Solomon, a spokesperson for the American Academy of Orthopaedic Surgeons, believes in getting the help of a professional trainer before embarking on a new routine. “Most of what we see are strains and really preventable muscle-type injuries,” said Solomon, a California-based physician specializing in sports medicine. “People just do things their bodies aren’t ready to do or capable of sustaining for long.”   Another big mistake is skipping the warm up. “They jump right in instead of spending 15 minutes to do a good cardio warm up and stretching before grabbing the weight,” he said. He said some workouts just require more expertise than others. “I’m a proponent of using free weights,” he said. “But you’ve got to make sure you have the technique correct.”   Jessica Matthews, an exercise physiologist for the American Council on Exercise, said many highly effective workouts, such as kettle bells, medicine balls, and plyometric (jumping) moves, can be dangerous if done incorrectly. “Some workouts are trickier,” said Matthews, who is based in San Diego, California. “I’ve seen a lot of people use free weights incorrectly. There is a much greater margin of error than with machines, which move on a fixed path.”   Before going all-out on the plyometric training that characterizes so many home DVD workouts, she said it’s important to learn to land safely, which means softly and on the mid-foot. “The body is one big kinetic chain. Dysfunction in one area will create dysfunction in another,” she said. “So suddenly your hip is bothering you because of instability in your ankle.”   Before tackling the latest high-intensity, technique-based workout, Matthews advises strengthening your stability and mobility through back-to-basic exercises such as plank, side plank, lunges and squats. “Build that solid foundation first,” she said. “Then progress to more explosive workouts that take more advanced skills.”   If don’t have your own personal trainer, Boucher said, don’t hesitate to ask a fitness professional at your gym to observe your form for a few seconds. Then be open to the feedback. “Do you hunch your shoulders? Hunch your back? “ she said. “Maybe one side of your body is tighter than the other. Or the left hip is more rotated than the right.”   “Sometimes it’s that little thing that you can’t catch on your own,” she said.",
        "true"
    ],
    [
        0.3453623801469803,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '547'}",
        "داخل بسته،بعضی از آب نباتا بصورت مایع هستن،باعث تاسفه که یه کارخونه همه کار بکنه برا تولید یه محصول،ولی واحد کنترل کیفیت نداشته باشه یا شاید هم داره ولی براشون مهم نیست،در ضمن طعم زنجبیلش زیاد قوی نیست.",
        "کلی"
    ],
    [
        0.34535138805707294,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '365'}",
        "(1)О несправедливости говорят и пишут с древних времён — возможно, с тех пор, как человечество вообще научилось говорить и писать. (2)Что же такое несправедливость — всё ещё не ясно. (3)Очень непросто прийти к согласию в этом вопросе, поскольку в данном случае спор ведётся с достаточной долей заинтересованности. (4)Каждый хочет, чтобы с ним обошлись «справедливо», и жалуется на «несправедливость», однако пытается так истолковать ситуацию, чтобы сразу же стала очевидной несправедливость по отношению к нему. (5)И каждый обладает достаточным самомнением, чтобы судить «справедливо» об отношении к другим людям, и совсем не замечает, что другие возмущаются его мнимой «справедливостью». (6)Так проблема искажается страстями и окутывается предрассудками. (7)Целые поколения застревают в этих предрассудках, и замечаешь порой, как само слово «справедливость» вызывает язвительную улыбку. (8)От предыдущих поколений человечеству досталось по наследству убеждение, будто люди от рождения равны и вследствие этого с ними надо обходиться одинаково. (9)Однако сущность справедливости состоит как раз в неодинаковом обхождении с неодинаковыми людьми. (10)Если бы люди были действительно равны, жизнь была бы предельно простой и справедливость было бы чрезвычайно легко найти. (11)Стоило бы только сказать: одинаковым людям — одинаковую долю или всем всего поровну. (12)Тогда справедливость можно было бы обосновывать арифметически и создавать механически; и все были бы довольны, потому что люди стали бы не чем иным, как одинаковыми атомами, своего рода всюду катящимися механическими шариками, которые были бы похожи внешне и имели бы внутренне одинаковый душевный склад. (13)Как наивно, как просто, как мелко!(14)На самом же деле люди не равны ни телом, ни душою, ни духом. (15)Они родятся существами различного пола, с различным здоровьем и силой, с совершенно различными предрасположенностями, дарами, инстинктами и желаниями, они принадлежат к различному духовному уровню, и с ними (в силу справедливости!)(16)В этом заключается основа и главная трудность справедливости: людей — бесконечное множество; все они различны; как сделать, чтобы каждый получил согласно справедливости?(17)Если люди неодинаковы, значит, и обходиться с ними надо каждый раз согласно их живому своеобразию — иначе возникает несправедливость. (18)Таким образом, справедливость означает именно неравенство: беречь ребёнка, помогать слабому, снисходить к уставшему, ухаживать за больным; проявлять больше строгости к безвольному, больше доверия честному, больше осторожности к болтуну; герою оказывать почести. (19)Справедливость поэтому — искусство неравенства, и она присуща лишь благородным душам. (20) У неё обострённое чувство реальности; проистекающая от доброго сердца и живой наблюдательности, она отвергает механический подход к людям, старается уловить в человеке его сущность и своеобразие и обходиться с ним соответственно этому. (По И. Ильину*)",
        "True"
    ],
    [
        0.3453509161869685,
        "{'dataset_id': 'SetFit/amazon_counterfactual', 'config_id': 'de', 'row_id': '650'}",
        "Das Buch ist derart vage und pauschal geschrieben, dass man es mit Leichtigkeit anzweifeln könnte, dass der Autor überhaupt beim Militär war, wenn er nicht durch öffentliche Auftritte bekannt und damit authentifiziert worden wäre.",
        "counterfactual"
    ],
    [
        0.3453509161869685,
        "{'dataset_id': 'mteb/amazon_counterfactual', 'config_id': 'de', 'row_id': '650'}",
        "Das Buch ist derart vage und pauschal geschrieben, dass man es mit Leichtigkeit anzweifeln könnte, dass der Autor überhaupt beim Militär war, wenn er nicht durch öffentliche Auftritte bekannt und damit authentifiziert worden wäre.",
        "counterfactual"
    ],
    [
        0.3453506926695506,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '10'}",
        "There is a better than even chance that Brian is a frog. Chances are about even that Jeff moved to the garden. There is almost no chance that Sandra took the football. Chances are about even that if 'Sandra took the football and Jeff moved to the garden' then Julius is a swan. It is almost certain that if 'Sandra took the football' or 'Jeff moved to the garden' or both then Greg is a swan. It is likely that if 'Brian is a frog' or 'Jeff moved to the garden' or both then Mary went to the hallway.",
        "invalid"
    ],
    [
        0.34534497559070587,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'danetqa', 'row_id': '425'}",
        "Ме́тод Сокра́та — метод, названный в честь древнегреческого философа Сократа, основывающийся на проведении диалога между двумя индивидуумами, для которых истина и знания не даны в готовом виде, а представляют собой проблему и предполагают поиск. Этот метод часто подразумевает дискуссию, в которой собеседник, отвечая на заданные вопросы, высказывает суждения, обнаруживая свои знания или, напротив, своё неведение. Сократов метод — это метод элиминирования гипотез, где инициатива одной из сторон была направлена в одних случаях на то, чтобы умерить самоуверенность собеседника, мнящего себя знающим, и доказать ему, что он не только ничего не знает, но более того: оставаясь недалёким человеком, не подозревает о своём невежестве; в других случаях оно имело целью ориентировать собеседника на самопознание, а также на обнаружение и уяснение того, что в нём самом до этого оставалось скрытым, неясным и дремлющим. Этому методу Сократ давал название «обличие». Первый случай назывался «ирония».",
        "True"
    ],
    [
        0.34533678491910297,
        "{'dataset_id': 'DFKI-SLT/knowledge_net', 'config_id': 'knet_re', 'row_id': '705'}",
        "Forrest and <his> wife Hazel were among the founders of the Rochester New Hampshire Senior Citizen Forrest Married <Susan Johnstone> on 15 May 1926 and divorced on 7 Apr 1942 No minor children affected by divorce, so no children ???",
        ""
    ],
    [
        0.3452896773815155,
        "{'dataset_id': 'yizhongw/self_instruct', 'config_id': 'super_natural_instructions', 'row_id': '24'}",
        "In this task, you are given a word, followed by two sentences. Your task is to figure out whether both the sentences use the aforementioned word with the same meaning. You should respond with 'True' if the words in both sentences share the same meaning, and 'False' otherwise.\n\nInput: come \n Sentence1: Come into the room. \n Sentence2: He came from France.\n\nOutput:",
        " False."
    ],
    [
        0.3452846109867096,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '497'}",
        "The story outlines how new research about an existing family of consumer blood tests shows accuracy at seven weeks into pregnancy for determining the sex of a fetus. What the story also tells is the complicated weighing of risks and benefits that parents may need to use, since the consumer tests and their laboratories are not regulated by the FDA. We would have liked more information in here about which precise forms of testing among the 57 studies analyzed were most reliable and the quality of the evidence in the Journal of the American Medical Association survey. Earlier sex-determination in pregnancy could lead to parents choosing (or trying to choose) the gender they prefer. Internationally, it is already clear that some parents in China and India are deliberately choosing male babies, and aborting female fetuses. The research reported on, a survey in the Journal of the American Medical Association, does not directly address these larger ethical implications. But the study’s lead author, Diana Bianchi, does stress that she wants to examine “why people are buying these things” and the consequences of consumer access to over-the-counter testing for fetal gender. The New York Times story goes a bit further than the competing Reuters story in exploring how consumers may use the testing.",
        "true"
    ],
    [
        0.3452796886364619,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '162'}",
        "There is almost no chance that Lily is white. It is improbable that John went to the office. It is unlikely that Julius is a swan.",
        "invalid"
    ],
    [
        0.3452186733484268,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '978'}",
        "\"The story does not mention costs, or potential costs of the new drug. At least a general statement could have been made about costs of combination drugs. The story does a good job of presenting the harms of the failed drug in terms of natural frequencies (actual numbers) instead of relative rates. The story mentions the increased risk of death, heart disease and elevated blood pressure with the failed drug. However, in the absence of evidence, the story should not be suggesting that a more \"\"clean\"\" version of the drug would not have such harms. Although the story accurately describes the ILLUMINATE study presented at the meeting, the story repeatedly exaggerates the claims that there is a future for HDL-targeted therapeutics. Starting with the headline and throughout the story, the possibility that other drugs targeting HDL could be viable is consistently overhyped in this story. At this point there is no evidence that targeting HDL will be an effective strategy and hopes that a more \"\"clean\"\" version of the drug will not have the harms of the failed drug is nothing but conjecture. The story does not exaggerate the seriousness or prevalence of heart disease, the target of the new drug. However, the story could have done more to point out that many researchers are now questioning the HDL/heart disease hypothesis. The story does not quote any independent experts or researchers, a major flaw of this story. It’s not clear that anyone was actually interviewed, since only a study and an editorial were cited. Perhaps an independent expert could have put into perspective for the reader the fact that this story focuses on a small, theoretical part of the overall story at the expense of the facts. The story does not mention other, established ways to raise HDL, such as exercise, statins, moderate alcohol consumption, etc., even though these have modest effects on HDL. The story clearly states that the HDL-targeting drugs are still in the early stages of development. The story does not make any claims about when a new drug would be available, however whether it will ever happen is still highly theoretical. However, atorvastatin was studied along with torcetrapib and a note that it is available commercialy and is the largest selling cholesterol lowering drug would have been useful to the readers. The story correctly categorizes the drug as the first of its kind in this class. There is no way to know if the story relied on a press release as the sole source of information.\"",
        " "
    ],
    [
        0.3451768606901169,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '96'}",
        "It is improbable that Brian is yellow. Chances are about even that Bernhard is a swan. It is probable that Yann is hungry. We doubt that if 'Yann is hungry' or 'Brian is yellow' or both then Gertrude is a cat. It is highly likely that if 'Yann is hungry' or 'Brian is yellow' or both then Emily is a wolf. It is probable that if 'Bernhard is a swan' or 'Brian is yellow' or both then Mary moved to the garden.",
        "invalid"
    ],
    [
        0.3451622625192006,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '687'}",
        "سلام به نسبت قیمت برای خرید با تعداد به صرفه است. مخصوصاً برای اونهایی که بچه مدرسه ای دارند. خوبیش به غنی بودنش با ویتامین های مختلفه که برای رشد بچه ها خیلی سفارش میشه",
        "کلی"
    ],
    [
        0.3451482703288396,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '426'}",
        "There is a better than even chance that Lily is a frog. Chances are about even that Daniel dropped the milk. It is highly unlikely that Mary went to the kitchen.",
        "invalid"
    ],
    [
        0.345142995317777,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '129'}",
        "It is impossible that Bernhard is gray. We doubt that Greg is white. It is almost certain that Jeff went to the hallway. We believe that if 'Greg is white' or 'Bernhard is gray' or both then Daniel put down the milk. Chances are slight that if 'Jeff went to the hallway and Greg is white' then John dropped the milk. It is likely that if either 'Bernhard is gray' or 'Jeff went to the hallway' but not both then Lily is green.",
        "invalid"
    ],
    [
        0.3451399902502696,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '224'}",
        "نظر شما در مورد عطر، بو، و طعم این گوشت مرغ چیست؟",
        "طعم"
    ],
    [
        0.3451399902502696,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '280'}",
        "نظر شما در مورد عطر، بو، و طعم این گوشت مرغ چیست؟",
        "طعم"
    ],
    [
        0.3451399902502696,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '448'}",
        "نظر شما در مورد عطر، بو، و طعم این گوشت مرغ چیست؟",
        "طعم"
    ],
    [
        0.3451399902502696,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '812'}",
        "نظر شما در مورد عطر، بو، و طعم این گوشت مرغ چیست؟",
        "طعم"
    ],
    [
        0.3451091746489207,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_1hop', 'row_id': '533'}",
        "There is little chance that Brian is a frog. We believe that Greg is a rhino. Chances are slight that John dropped the apple.",
        "invalid"
    ],
    [
        0.345098078250885,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '430'}",
        "In responses provided to Congress and obtained by The Associated Press, the VA said it never “encouraged or discouraged” its government-run hospitals to use hydroxychloroquine on patients even as President Donald Trump heavily promoted the drug for months without scientific evidence of its effectiveness. Still, it acknowledged that VA Secretary Robert Wilkie had wrongly asserted publicly without evidence that the drug had been shown to benefit younger veterans. The VA, the nation’s largest hospital system, also agreed more study was needed on the drug and suggested its use was now limited to extenuating circumstances, such as last-ditch efforts to save a coronavirus patient’s life. In the first week of May, 17 patients had received the drug for COVID-19, according to VA data obtained by the AP. The department declined to say how many patients had been treated with hydroxychloroquine for the coronavirus since January, but a recent analysis of VA hospital data showed that hundreds of veterans had taken it by early April. “VA has not endorsed nor discouraged the use of hydroxychloroquine in COVID-19 patients and has left those decisions to providers and their patients,” the VA said. “While all drugs have the potential for adverse events and some drugs in particular, like hydroxychloroquine, are known to have specific risks, when they are used carefully and judiciously, they can be managed safely.” As of Friday, 11,883 veterans had been confirmed to be infected with the virus and 985 had died, according to VA statistics. Responding to written questions from Sen. Jon Tester, the top Democrat on the Senate Veterans Affairs Committee, the department admitted it had no studies or evidence to back up Wilkie’s claim that hydroxychloroquine had shown effectiveness in younger veterans in particular. “The use of hydroxychloroquine for COVID has dropped off dramatically,” the VA said. Trump repeatedly has pushed the malaria drug hydroxychloroquine with or without the antibiotic azithromycin, but no large, rigorous studies have found them safe or effective for COVID-19, and they can cause heart rhythm problems and other side effects. The Food and Drug Administration has warned against the drug combination and said hydroxychloroquine should only be used for the coronavirus in formal studies. Two large observational studies, each involving around 1,400 patients in New York, recently found no benefit from hydroxychloroquine. Two new ones published Thursday in the journal BMJ, one by French researchers and the other from China, reached the same conclusion. Tester, who received VA’s responses this week, said he remained concerned about the drug’s safety. “Any drug used to treat patients with COVID-19, especially veterans living with debilitating preexisting conditions, must be proven safe and effective before it’s administered,” he said. “Given recent studies from both VA and other hospitals, hydroxychloroquine seems to fall short of those requirements.” Major veterans organizations and Democrats including Senate Minority Leader Chuck Schumer had called on the VA to explain why it allowed the use of an unproven drug on vets. Last week, a whistleblower complaint by former Health and Human Services official Rick Bright alleged that the Trump administration wanted to “flood” hot spots in New York and New Jersey with the drug. Jeremy Butler, CEO of Iraq and Afghanistan Veterans of America, said Friday that his group was heartened by the VA’s preliminary explanations and called it imperative that it release additional details. “It remains concerning that it took this long to begin to get answers to basic questions,” he said. The analysis of VA hospital data, done by independent researchers at two universities with VA approval, was not a rigorous experiment. Researchers analyzed medical records of 368 older male veterans hospitalized with confirmed coronavirus infection at VA medical centers who died or were discharged by April 11. About 28% of veterans who were given hydroxychloroquine plus usual care died, versus 11% of those getting routine care alone. In its response to Congress, the department provided copies of some of its guidance issued to VA physicians on hydroxychloroquine from March to May. It made clear that hydroxychloroquine should be considered mostly for use in clinical trials or when medically appropriate after a full discussion with the patient about risks. The VA did not explain the circumstances in which veterans in the recent analysis of hospital data were given the drug, only suggesting that “it is possible” they were prescribed as part of last efforts to save a patient’s life. “Based on the principles of patient-centric care, it would be inappropriate to deny patients access to hydroxychloroquine under these dire circumstances,” VA wrote. It said it had followed the approach of the National Institute of Allergy and Infectious Diseases by “summarizing the medical literature regarding unapproved treatments for COVID-19 and making that available to VA clinicians in their shared decision-making with patients.” That guidance now includes preliminary studies on remdesivir, which has been federally approved for emergency use to treat COVID-19. One VA document dated March 25 notes a few “very small cohort studies” showing possible “beneficial effects” but adds “these data have NOT been verified in randomized controlled trials and are extremely preliminary.” The VA acknowledged to Congress that it had placed bulk orders for hydroxychloroquine from Feb. 1 to April 23 for 6.3 million tablets worth $208,000 in anticipation of a possible shortage of the drug, but that most of it was being used for approved uses, such as treating lupus and rheumatoid arthritis. It said it did not have breakdowns. The department also said it planned further studies and clinical trials on hydroxychloroquine, including whether it could help prevent infection in veterans who were potentially exposed to COVID-19. It is in discussions with Novartis to have some VA facilities participate in a national clinical trial that will look at the effectiveness of hydroxychloroquine in combination with azithromycin in patients with moderate and severe disease. ___ AP Chief Medical Writer Marilynn Marchione in Milwaukee contributed to this report.",
        "true"
    ],
    [
        0.34509169061978656,
        "{'dataset_id': 'sileod/probability_words_nli', 'config_id': 'reasoning_2hop', 'row_id': '311'}",
        "Chances are about even that Brian is yellow. There is little chance that Jason is thirsty. There is a very good chance that John picked up the milk. It is improbable that if either 'John picked up the milk' or 'Brian is yellow' but not both then Jessica is a cat. It is probably not the case that if 'Jason is thirsty' or 'Brian is yellow' or both then Jeff moved to the garden. It is highly unlikely that if 'John picked up the milk and Jason is thirsty' then Mary dropped the apple.",
        "invalid"
    ],
    [
        0.345044640203317,
        "{'dataset_id': 'persiannlp/parsinlu_sentiment', 'config_id': 'parsinlu-repo', 'row_id': '830'}",
        "این فیلم رو تو جشنواره دیدم.پیشنهاد میدم ببینید.   فیلمنامه پرکشش نوشته شده بود.سعید آقاخانی واقعا عالی بازی کرد و مهناز افشار به نسبت خودش بهتر از قبل حاضر شده بود.قصه ی قضاوت ما آدمها همیشه در حال تکرار شدنه و یه قسمتهایی از فیلم کاملا همراه میشدیم با بازیگران.موضوعش رو دوست داشتم در کل.",
        " قسم"
    ],
    [
        0.34503928820292157,
        "{'dataset_id': 'biglam/contentious_contexts', 'config_id': 'default', 'row_id': '59'}",
        "[{'id': 'unknown_3a', 'response': 'Illegible OCR'}, {'id': 'unknown_3b', 'response': \"I don't know\"}, {'id': 'unknown_3c', 'response': 'Illegible OCR'}, {'id': 'unknown_3d', 'response': 'Contentious according to current standards'}, {'id': 'unknown_3e', 'response': \"I don't know\"}, {'id': 'unknown_3f', 'response': 'Illegible OCR'}, {'id': 'unknown_3g', 'response': \"I don't know\"}]",
        "𝙢𝙖𝙧𝙧𝙤𝙣"
    ],
    [
        0.34503160913785297,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '659'}",
        "\"During a recent visit to Virginia, U.S. Sen. Rand Paul took exception to claims that budget cuts have hurt the National Institute of Health’s efforts to find a cure for Ebola. The Kentucky Republican was the headliner at an Oct. 15 rally in Ashland for Dave Brat, the GOP nominee for the 7th District congressional seat. Paul, a Tea Party favorite, said NIH has money to waste. \"\"Do you know what the NIH spends money on?\"\" he asked the crowd. Paul listed a series of NIH projects he viewed as profligate. \"\"$2.4 million of the NIH dollars was spent on ‘origami’ condoms,\"\"  he said. \"\"This is a family crowd, so I’m not getting into what that means.\"\" But we will. We wondered if his claim is correct. Origami is the Japanese art of folding paper to form animals, flowers and other designs, according to Webster’s New World College Dictionary. We struggled to imagine how this centuries-old craft might improve the condom. Paul’s office backed the senator’s statement by sending us several articles about NIH’s funding of condom research, the earliest one published by the Washington Free Beacon this March. Turns out, there’s a California company, named ORIGAMI, that’s vowing to reinvent the condom, a contraceptive that many men don’t like. The company believes the popularity of condoms  -- which must be unrolled and are typically made of latex -- would greatly improve if they were more pleasing, less cumbersome and safer to use. ORIGAMI is developing condom with accordion-like pleats. They’re made of silicone and, because they’re loose-fitting and don’t have to be unrolled, can be put on faster than traditional condoms. The company is seeking FDA approval and hopes sell its product next year. A number of global health organizations are encouraging condom research and development, convinced that greater use of devices will lead to fewer unwanted pregnancies and sexually transmitted diseases such as AIDs. Since 2006, NIH has awarded seven grants totaling almost $2.5 million to help develop male and female ORIGAMI condoms. The money was provided to Strata Various, a product design firm headed by Danny Resnic, ORIGAMI’s founder. Resnic is listed on the grant documents as the project leader of the research. ORIGAMI’s work has been praised by the Bill and Melinda Gates Foundation, which last year handed out $1.1 million in grants other entrepreneurs seeking to improve condoms. The Foundation said ORIGAMI \"\"provides an excellent example of a private enterprise focused on new condom design to promote consistent use by emphasizing the sexual experience.\"\" Now, let’s return to Paul’s speech. The senator, in lamenting the use of public funds to develop  \"\"origami’ condoms,\"\" never defined the difference between the folded paper art and the name of a company. We asked Brian Darling, a spokesman for Paul, whether his boss was referring to Origami with a capital \"\"O,\"\" meaning the company, or a small \"\"o,\"\" meaning the art form. \"\"The senator’s words speak for themselves,\"\" Darling replied in an email. \"\"I don’t understand the confusion.\"\" The day before he appeared in Ashland, Paul spelled origami with a small \"\"o\"\" in Facebook post and a tweet assailing NIH’s spending. \"\"NIH blames tightening federal budget for its inability to produce #Ebolavaccine, but somehow found $2.4 million to develop 'origami' condoms designed with Japanese folding paper in mind,\"\" Paul wrote on his Facebook page. He tweeted, \"\"@NIH cant afford #Ebola vaccine bc of 'budget cuts' but can spend $2.4 mill to develop 'origami' condoms #Priorities http://www.dailymail.co.uk/news/article-\"\" So what does the company have to say about all this? Mark Bardwell, an ORIGAMI spokesman, defended the grants, saying they are given out \"\"based on scientific merit.\"\" \"\"Condoms are considered a medical device. As such, it must pass FDA safety testing standards through clinical trials that are very expensive,\"\" Bardwell said. \"\"An innovation condom could take 3-4 years and several million dollars for R&D and human testing.\"\" Our ruling In trying to document waste at NIH, Paul said the health agency spent $2.4 million on \"\"origami\"\" condoms. Paul didn’t provide any more information in his speech, leaving the crowd to wonder whether tax dollars are going to the development of paper condoms folded into fancy shapes. What he didn’t say is that ORIGAMI is the name of a company that has received the NIH grants to develop an improved condom that is made of silicone and has fold-out pleats. NIH has long encouraged  condom use to reduce unwanted pregnancies and sexually transmitted diseases. We don’t find much fault with Paul, however. The company, by its very name, suggests the principles of origami drive its design.\"",
        "true"
    ],
    [
        0.345016082127889,
        "{'dataset_id': 'JeremyAlain/SLF5K', 'config_id': 'SLF5K', 'row_id': '875'}",
        "Write an excellent summary of the given text.\n\nTitle: TIFU by draining my transmission fluid instead of oil\n\nText: This happened earlier this afternoon.  Up until that point I'd had a pretty productive holiday weekend. I had a couple hours to kill before a family get-together so I decided to knock one more thing off my to-do list and change the oil in my 4Runner.  And so I did.  Or so I thought.  I guess I wasn't paying attention to which drain plug I removed because it turns out I drained the transmission fluid and I added 5.5 qts of oil to what turned out to be an already full oil reservoir.  *Then* I drove 3 miles to my parents' house for the shindig.  \n\nThe only good news in all of this was that my drive to my parents' house was via neighborhood streets so speeds never exceeded 35mph.  About halfway home from the get-together my dash lit up like a Christmas tree and that's when I realized I done goofed.\n\nSo I'm wondering how to proceed (clearly I need to drain the oil since it's way overfilled at this point).  Since I actually drove a few miles with in this condition, when I re-fill the transmission, should I change the filter (which involves removing part of the exhaust, removing the pan, replacing the pan gasket, etc) or should I be okay having only driven only 6 miles at 25-35mph?\n\nTL;DR:",
        "Accuracy"
    ],
    [
        0.34501516322294873,
        "{'dataset_id': 'health_fact', 'config_id': 'default', 'row_id': '896'}",
        "\"Not applicable. Costs of blueberries – or of the \"\"daily dietary supplementation of bioactives in freeze-dried whole blueberry powder\"\" – were not given. But we don’t think this is a major issue. No quantification of benefit in the first study described – only that \"\"participants’  insulin sensitivity increased.\"\" How much did it increase? What clinical significance did that or might it have? This is what readers need to know – not just some surrogate marker. Regarding the second study, the story said \"\"researchers saw a seven- to eight-point drop in the systolic blood pressure of patients who had been drinking the blueberry beverage.\"\" Everyone got a 7-8 point drop? Or was this the average decline? And a decline from what starting point? None of this was explained. That’s inadequate. Not applicable. No harms were mentioned, but we’re not sure there were any worth mentioning in these small, short-term studies. But we can’t give a satisfactory score for what wasn’t reported. Inadequate. First, the story never explained that the first study used not blueberries but \"\"daily dietary supplementation of bioactives in freeze-dried whole blueberry power.\"\" More than a matter of semantics, this raises questions about the whole premise of the article about \"\"eating blueberries.\"\" These study subjects did not eat blueberries. That should have been explained. Second, the story never mentioned what the researchers themselves wrote, that this study was not conclusive and that studies of longer duration were needed. Third, the story never explained that the first study involved only 32 people – only 15 whom got the blueberry bioactive concoction. Finally, the story never addressed the inherent limitations in drawing any conclusions from such a small sample. The second study mentioned in the story – the one about blueberries in people with \"\"pre-hypertension\"\" – never mentioned the significant concerns that have been raised in some corners about disease-mongering of \"\"pre-hypertension.\"\" Note, for example, the recent article in the BMJ by journalist Ray Moynihan, \"\"Who benefits from treating prehypertension.\"\" The story could have at least nodded in the direction of controversy about this diagnosis, rather than touting it as one more disease to be prevented by blueberry consumption. No independent sources were quoted – only the lead researchers. In addition, the first study was funded partially by the United States Highbush Blueberry Council, something the story should have explained. There wasn’t even a line about other methods of lowering risk in those at increased risk of developing diabetes or high blood pressure. It wouldn’t have taken but a few words to satisfy this criterion. The story stated the newer study was of \"\"daily consumption of blueberries.\"\" That’s inaccurate and it’s pertinent to this availability criterion. It was a study of \"\"daily dietary supplementation of bioactives in freeze-dried whole blueberry powder.\"\" How available is this stuff outside a research setting? What difference might that make over consumption of blueberries? More than splitting hairs, this is an important clarification, and one this story didn’t provide. The story at least tried to put two newer studies into the context of \"\"the body of research supporting the benefits of eating blueberries.\"\" But we also think this phrase is too simplistic and potentially misleading. Nonethless we’ll give it the benefit of the doubt. Not applicable. We can’t be sure of the extent to which this blog post may have relied on a news release. We know we saw some of the exact same quotes in other places, suggesting they didn’t come from interviewing the sources.\"",
        "false"
    ],
    [
        0.3450108965237935,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '69'}",
        "(1) Вилли в ресторане ждет потенциальных жен, а Марианна приходит на встречу заранее. (2) Молодые люди обращают друг на друга внимание, но не открывают истинных причин, почему пришли сюда. (3) Марианна представляет своего миллионера эксцентричным стариком, и, разумеется, даже не предполагает, что симпатичный мужчина у барной стойки он и есть. (4) Девушка думает, что Вилли - бедный парень, как она сама, поэтому с неохотой отвечает на ухаживания. (5) Все ее мысли сейчас о том, что с помощью вознаграждения от миллионера можно нанять отличного адвоката для отца. (6) Тем не менее, Вилли удается уговорить Марианну встретиться на следующий день. (7) Вилли переполняет восторг. (8) Чтобы завоевать любовь Марианны он готов практически на все. (9) Более того, согласен отказаться от наследства, если понадобится. (10) Сама же Марианна в растерянности. (11) Ей нравится Вилли, но что делать с долгом перед отцом? (12) Если она не поможет ему выйти из тюрьмы, никто не поможет, и, в конце концов, Марианна говорит новому поклоннику, что обручена с другим. (13) А жизнь, между тем, продолжается. (14) Наталия (мачеха Марианны) и Роза додумались шантажировать Валентино, настоящего отца Рикардо.",
        "True"
    ],
    [
        0.3450108965237935,
        "{'dataset_id': 'RussianNLP/russian_super_glue', 'config_id': 'muserc', 'row_id': '71'}",
        "(1) Вилли в ресторане ждет потенциальных жен, а Марианна приходит на встречу заранее. (2) Молодые люди обращают друг на друга внимание, но не открывают истинных причин, почему пришли сюда. (3) Марианна представляет своего миллионера эксцентричным стариком, и, разумеется, даже не предполагает, что симпатичный мужчина у барной стойки он и есть. (4) Девушка думает, что Вилли - бедный парень, как она сама, поэтому с неохотой отвечает на ухаживания. (5) Все ее мысли сейчас о том, что с помощью вознаграждения от миллионера можно нанять отличного адвоката для отца. (6) Тем не менее, Вилли удается уговорить Марианну встретиться на следующий день. (7) Вилли переполняет восторг. (8) Чтобы завоевать любовь Марианны он готов практически на все. (9) Более того, согласен отказаться от наследства, если понадобится. (10) Сама же Марианна в растерянности. (11) Ей нравится Вилли, но что делать с долгом перед отцом? (12) Если она не поможет ему выйти из тюрьмы, никто не поможет, и, в конце концов, Марианна говорит новому поклоннику, что обручена с другим. (13) А жизнь, между тем, продолжается. (14) Наталия (мачеха Марианны) и Роза додумались шантажировать Валентино, настоящего отца Рикардо.",
        "True"
    ],
    [
        0.34499438603719074,
        "{'dataset_id': 'sharc', 'config_id': 'sharc', 'row_id': '177'}",
        "[{'follow_up_question': 'Are you unable to obtain  credit elsewhere at reasonable rates and terms to meet actual needs?', 'follow_up_answer': 'Yes'}, {'follow_up_question': 'DO you possess legal capacity to incur loan obligations?', 'follow_up_answer': 'No'}, {'follow_up_question': 'Are you not delinquent on federal debt?', 'follow_up_answer': 'No'}]",
        "False"
    ]
]